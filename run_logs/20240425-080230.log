/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:4236: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
LR: [0.0004000007974766396]
---- EP [1/5] | BTCH [1/3634] ||| train_loss = 0.00496 ----
LR: [0.000400003189906295]
---- EP [1/5] | BTCH [2/3634] ||| train_loss = 0.01836 ----
LR: [0.0004000071772881711]
---- EP [1/5] | BTCH [3/3634] ||| train_loss = 0.01467 ----
LR: [0.0004000127596209425]
---- EP [1/5] | BTCH [4/3634] ||| train_loss = 0.01600 ----
LR: [0.0004000199369027565]
---- EP [1/5] | BTCH [5/3634] ||| train_loss = 0.01123 ----
LR: [0.0004000287091312244]
---- EP [1/5] | BTCH [6/3634] ||| train_loss = 0.00708 ----
LR: [0.00040003907630343366]
---- EP [1/5] | BTCH [7/3634] ||| train_loss = 0.01585 ----
LR: [0.00040005103841593906]
---- EP [1/5] | BTCH [8/3634] ||| train_loss = 0.01846 ----
LR: [0.0004000645954647646]
---- EP [1/5] | BTCH [9/3634] ||| train_loss = 0.00985 ----
LR: [0.00040007974744540875]
---- EP [1/5] | BTCH [10/3634] ||| train_loss = 0.01248 ----
LR: [0.0004000964943528338]
---- EP [1/5] | BTCH [11/3634] ||| train_loss = 0.00914 ----
LR: [0.0004001148361814765]
---- EP [1/5] | BTCH [12/3634] ||| train_loss = 0.01351 ----
LR: [0.0004001347729252411]
---- EP [1/5] | BTCH [13/3634] ||| train_loss = 0.01175 ----
LR: [0.0004001563045775043]
---- EP [1/5] | BTCH [14/3634] ||| train_loss = 0.01541 ----
LR: [0.0004001794311311105]
---- EP [1/5] | BTCH [15/3634] ||| train_loss = 0.00865 ----
LR: [0.00040020415257837477]
---- EP [1/5] | BTCH [16/3634] ||| train_loss = 0.01015 ----
LR: [0.000400230468911085]
---- EP [1/5] | BTCH [17/3634] ||| train_loss = 0.00897 ----
LR: [0.00040025838012049293]
---- EP [1/5] | BTCH [18/3634] ||| train_loss = 0.00651 ----
LR: [0.0004002878861973265]
---- EP [1/5] | BTCH [19/3634] ||| train_loss = 0.01052 ----
LR: [0.00040031898713178277]
---- EP [1/5] | BTCH [20/3634] ||| train_loss = 0.00703 ----
LR: [0.0004003516829135245]
---- EP [1/5] | BTCH [21/3634] ||| train_loss = 0.01605 ----
LR: [0.0004003859735316889]
---- EP [1/5] | BTCH [22/3634] ||| train_loss = 0.01168 ----
LR: [0.0004004218589748823]
---- EP [1/5] | BTCH [23/3634] ||| train_loss = 0.01212 ----
LR: [0.0004004593392311802]
---- EP [1/5] | BTCH [24/3634] ||| train_loss = 0.01477 ----
LR: [0.00040049841428812724]
---- EP [1/5] | BTCH [25/3634] ||| train_loss = 0.00968 ----
LR: [0.00040053908413274254]
---- EP [1/5] | BTCH [26/3634] ||| train_loss = 0.01171 ----
LR: [0.0004005813487515091]
---- EP [1/5] | BTCH [27/3634] ||| train_loss = 0.00359 ----
LR: [0.00040062520813038613]
---- EP [1/5] | BTCH [28/3634] ||| train_loss = 0.00827 ----
LR: [0.00040067066225479495]
---- EP [1/5] | BTCH [29/3634] ||| train_loss = 0.01437 ----
LR: [0.0004007177111096383]
---- EP [1/5] | BTCH [30/3634] ||| train_loss = 0.01244 ----
LR: [0.0004007663546792793]
---- EP [1/5] | BTCH [31/3634] ||| train_loss = 0.01692 ----
LR: [0.0004008165929475539]
---- EP [1/5] | BTCH [32/3634] ||| train_loss = 0.01049 ----
LR: [0.00040086842589776885]
---- EP [1/5] | BTCH [33/3634] ||| train_loss = 0.01044 ----
LR: [0.0004009218535127052]
---- EP [1/5] | BTCH [34/3634] ||| train_loss = 0.00813 ----
LR: [0.0004009768757746047]
---- EP [1/5] | BTCH [35/3634] ||| train_loss = 0.01204 ----
LR: [0.00040103349266518845]
---- EP [1/5] | BTCH [36/3634] ||| train_loss = 0.00849 ----
LR: [0.00040109170416563825]
---- EP [1/5] | BTCH [37/3634] ||| train_loss = 0.00664 ----
LR: [0.0004011515102566171]
---- EP [1/5] | BTCH [38/3634] ||| train_loss = 0.01415 ----
LR: [0.0004012129109182503]
---- EP [1/5] | BTCH [39/3634] ||| train_loss = 0.00854 ----
LR: [0.00040127590613013575]
---- EP [1/5] | BTCH [40/3634] ||| train_loss = 0.01557 ----
LR: [0.00040134049587134055]
---- EP [1/5] | BTCH [41/3634] ||| train_loss = 0.01452 ----
LR: [0.0004014066801204044]
---- EP [1/5] | BTCH [42/3634] ||| train_loss = 0.00716 ----
LR: [0.0004014744588553328]
---- EP [1/5] | BTCH [43/3634] ||| train_loss = 0.00818 ----
LR: [0.0004015438320536073]
---- EP [1/5] | BTCH [44/3634] ||| train_loss = 0.01215 ----
LR: [0.0004016147996921734]
---- EP [1/5] | BTCH [45/3634] ||| train_loss = 0.01049 ----
LR: [0.00040168736174745097]
---- EP [1/5] | BTCH [46/3634] ||| train_loss = 0.01625 ----
LR: [0.0004017615181953309]
---- EP [1/5] | BTCH [47/3634] ||| train_loss = 0.00902 ----
LR: [0.0004018372690111696]
---- EP [1/5] | BTCH [48/3634] ||| train_loss = 0.01420 ----
LR: [0.00040191461416979636]
---- EP [1/5] | BTCH [49/3634] ||| train_loss = 0.01183 ----
LR: [0.0004019935536455129]
---- EP [1/5] | BTCH [50/3634] ||| train_loss = 0.00842 ----
LR: [0.00040207408741209025]
---- EP [1/5] | BTCH [51/3634] ||| train_loss = 0.01065 ----
LR: [0.0004021562154427633]
---- EP [1/5] | BTCH [52/3634] ||| train_loss = 0.00860 ----
LR: [0.00040223993771024667]
---- EP [1/5] | BTCH [53/3634] ||| train_loss = 0.01011 ----
LR: [0.0004023252541867188]
---- EP [1/5] | BTCH [54/3634] ||| train_loss = 0.01601 ----
LR: [0.0004024121648438326]
---- EP [1/5] | BTCH [55/3634] ||| train_loss = 0.01020 ----
LR: [0.00040250066965270663]
---- EP [1/5] | BTCH [56/3634] ||| train_loss = 0.00984 ----
LR: [0.0004025907685839356]
---- EP [1/5] | BTCH [57/3634] ||| train_loss = 0.00828 ----
LR: [0.00040268246160757824]
---- EP [1/5] | BTCH [58/3634] ||| train_loss = 0.01458 ----
LR: [0.00040277574869316754]
---- EP [1/5] | BTCH [59/3634] ||| train_loss = 0.00924 ----
LR: [0.0004028706298097075]
---- EP [1/5] | BTCH [60/3634] ||| train_loss = 0.01047 ----
LR: [0.0004029671049256677]
---- EP [1/5] | BTCH [61/3634] ||| train_loss = 0.01054 ----
LR: [0.00040306517400899404]
---- EP [1/5] | BTCH [62/3634] ||| train_loss = 0.01468 ----
LR: [0.00040316483702709967]
---- EP [1/5] | BTCH [63/3634] ||| train_loss = 0.00622 ----
LR: [0.000403266093946867]
---- EP [1/5] | BTCH [64/3634] ||| train_loss = 0.01342 ----
LR: [0.00040336894473465106]
---- EP [1/5] | BTCH [65/3634] ||| train_loss = 0.00680 ----
LR: [0.00040347338935627433]
---- EP [1/5] | BTCH [66/3634] ||| train_loss = 0.01394 ----
LR: [0.00040357942777703715]
---- EP [1/5] | BTCH [67/3634] ||| train_loss = 0.01158 ----
LR: [0.0004036870599616986]
---- EP [1/5] | BTCH [68/3634] ||| train_loss = 0.01209 ----
LR: [0.00040379628587449735]
---- EP [1/5] | BTCH [69/3634] ||| train_loss = 0.00778 ----
LR: [0.00040390710547913954]
---- EP [1/5] | BTCH [70/3634] ||| train_loss = 0.00698 ----
LR: [0.00040401951873880043]
---- EP [1/5] | BTCH [71/3634] ||| train_loss = 0.00955 ----
LR: [0.0004041335256161297]
---- EP [1/5] | BTCH [72/3634] ||| train_loss = 0.01410 ----
LR: [0.0004042491260732445]
---- EP [1/5] | BTCH [73/3634] ||| train_loss = 0.01556 ----
LR: [0.000404366320071731]
---- EP [1/5] | BTCH [74/3634] ||| train_loss = 0.01337 ----
LR: [0.00040448510757264827]
---- EP [1/5] | BTCH [75/3634] ||| train_loss = 0.01298 ----
LR: [0.00040460548853652606]
---- EP [1/5] | BTCH [76/3634] ||| train_loss = 0.01943 ----
LR: [0.0004047274629233634]
---- EP [1/5] | BTCH [77/3634] ||| train_loss = 0.00932 ----
LR: [0.00040485103069263194]
---- EP [1/5] | BTCH [78/3634] ||| train_loss = 0.00810 ----
LR: [0.0004049761918032708]
---- EP [1/5] | BTCH [79/3634] ||| train_loss = 0.01320 ----
LR: [0.00040510294621368993]
---- EP [1/5] | BTCH [80/3634] ||| train_loss = 0.00889 ----
LR: [0.00040523129388177377]
---- EP [1/5] | BTCH [81/3634] ||| train_loss = 0.01181 ----
LR: [0.0004053612347648741]
---- EP [1/5] | BTCH [82/3634] ||| train_loss = 0.01282 ----
LR: [0.000405492768819812]
---- EP [1/5] | BTCH [83/3634] ||| train_loss = 0.01993 ----
LR: [0.00040562589600288447]
---- EP [1/5] | BTCH [84/3634] ||| train_loss = 0.01174 ----
LR: [0.00040576061626985266]
---- EP [1/5] | BTCH [85/3634] ||| train_loss = 0.01289 ----
LR: [0.000405896929575952]
---- EP [1/5] | BTCH [86/3634] ||| train_loss = 0.00888 ----
LR: [0.00040603483587589063]
---- EP [1/5] | BTCH [87/3634] ||| train_loss = 0.01034 ----
LR: [0.0004061743351238406]
---- EP [1/5] | BTCH [88/3634] ||| train_loss = 0.01002 ----
LR: [0.00040631542727345357]
---- EP [1/5] | BTCH [89/3634] ||| train_loss = 0.01652 ----
LR: [0.00040645811227784344]
---- EP [1/5] | BTCH [90/3634] ||| train_loss = 0.01067 ----
LR: [0.0004066023900895985]
---- EP [1/5] | BTCH [91/3634] ||| train_loss = 0.00724 ----
LR: [0.0004067482606607796]
---- EP [1/5] | BTCH [92/3634] ||| train_loss = 0.02235 ----
LR: [0.0004068957239429169]
---- EP [1/5] | BTCH [93/3634] ||| train_loss = 0.00986 ----
LR: [0.0004070447798870114]
---- EP [1/5] | BTCH [94/3634] ||| train_loss = 0.01956 ----
LR: [0.0004071954284435315]
---- EP [1/5] | BTCH [95/3634] ||| train_loss = 0.01178 ----
LR: [0.00040734766956242]
---- EP [1/5] | BTCH [96/3634] ||| train_loss = 0.01464 ----
LR: [0.00040750150319309245]
---- EP [1/5] | BTCH [97/3634] ||| train_loss = 0.01596 ----
LR: [0.0004076569292844317]
---- EP [1/5] | BTCH [98/3634] ||| train_loss = 0.00630 ----
LR: [0.00040781394778479155]
---- EP [1/5] | BTCH [99/3634] ||| train_loss = 0.00532 ----
LR: [0.0004079725586420002]
---- EP [1/5] | BTCH [100/3634] ||| train_loss = 0.00911 ----
LR: [0.00040813276180334986]
---- EP [1/5] | BTCH [101/3634] ||| train_loss = 0.01730 ----
LR: [0.0004082945572156122]
---- EP [1/5] | BTCH [102/3634] ||| train_loss = 0.01146 ----
LR: [0.00040845794482502126]
---- EP [1/5] | BTCH [103/3634] ||| train_loss = 0.01274 ----
LR: [0.00040862292457728884]
---- EP [1/5] | BTCH [104/3634] ||| train_loss = 0.01190 ----
LR: [0.00040878949641759595]
---- EP [1/5] | BTCH [105/3634] ||| train_loss = 0.01291 ----
LR: [0.00040895766029059276]
---- EP [1/5] | BTCH [106/3634] ||| train_loss = 0.01320 ----
LR: [0.00040912741614040037]
---- EP [1/5] | BTCH [107/3634] ||| train_loss = 0.01656 ----
LR: [0.00040929876391061423]
---- EP [1/5] | BTCH [108/3634] ||| train_loss = 0.01272 ----
LR: [0.00040947170354429553]
---- EP [1/5] | BTCH [109/3634] ||| train_loss = 0.01150 ----
LR: [0.0004096462349839833]
---- EP [1/5] | BTCH [110/3634] ||| train_loss = 0.01354 ----
LR: [0.0004098223581716805]
---- EP [1/5] | BTCH [111/3634] ||| train_loss = 0.01318 ----
LR: [0.0004100000730488662]
---- EP [1/5] | BTCH [112/3634] ||| train_loss = 0.01137 ----
LR: [0.00041017937955648877]
---- EP [1/5] | BTCH [113/3634] ||| train_loss = 0.01073 ----
LR: [0.00041036027763496907]
---- EP [1/5] | BTCH [114/3634] ||| train_loss = 0.01002 ----
LR: [0.0004105427672241955]
---- EP [1/5] | BTCH [115/3634] ||| train_loss = 0.01029 ----
LR: [0.0004107268482635325]
---- EP [1/5] | BTCH [116/3634] ||| train_loss = 0.01222 ----
LR: [0.00041091252069181024]
---- EP [1/5] | BTCH [117/3634] ||| train_loss = 0.00977 ----
LR: [0.0004110997844473368]
---- EP [1/5] | BTCH [118/3634] ||| train_loss = 0.00827 ----
LR: [0.00041128863946788587]
---- EP [1/5] | BTCH [119/3634] ||| train_loss = 0.00912 ----
LR: [0.0004114790856907021]
---- EP [1/5] | BTCH [120/3634] ||| train_loss = 0.00498 ----
LR: [0.000411671123052508]
---- EP [1/5] | BTCH [121/3634] ||| train_loss = 0.01490 ----
LR: [0.0004118647514894918]
---- EP [1/5] | BTCH [122/3634] ||| train_loss = 0.01368 ----
LR: [0.00041205997093731253]
---- EP [1/5] | BTCH [123/3634] ||| train_loss = 0.01150 ----
LR: [0.0004122567813311037]
---- EP [1/5] | BTCH [124/3634] ||| train_loss = 0.00674 ----
LR: [0.0004124551826054663]
---- EP [1/5] | BTCH [125/3634] ||| train_loss = 0.01089 ----
LR: [0.000412655174694479]
---- EP [1/5] | BTCH [126/3634] ||| train_loss = 0.00838 ----
LR: [0.0004128567575316863]
---- EP [1/5] | BTCH [127/3634] ||| train_loss = 0.00894 ----
LR: [0.00041305993105010715]
---- EP [1/5] | BTCH [128/3634] ||| train_loss = 0.00928 ----
LR: [0.00041326469518222775]
---- EP [1/5] | BTCH [129/3634] ||| train_loss = 0.00974 ----
LR: [0.00041347104986001054]
---- EP [1/5] | BTCH [130/3634] ||| train_loss = 0.00832 ----
LR: [0.0004136789950148871]
---- EP [1/5] | BTCH [131/3634] ||| train_loss = 0.01888 ----
LR: [0.00041388853057775996]
---- EP [1/5] | BTCH [132/3634] ||| train_loss = 0.00797 ----
LR: [0.0004140996564790077]
---- EP [1/5] | BTCH [133/3634] ||| train_loss = 0.00970 ----
LR: [0.00041431237264847286]
---- EP [1/5] | BTCH [134/3634] ||| train_loss = 0.00943 ----
LR: [0.00041452667901547766]
---- EP [1/5] | BTCH [135/3634] ||| train_loss = 0.01106 ----
LR: [0.00041474257550880994]
---- EP [1/5] | BTCH [136/3634] ||| train_loss = 0.00899 ----
LR: [0.0004149600620567285]
---- EP [1/5] | BTCH [137/3634] ||| train_loss = 0.00960 ----
LR: [0.00041517913858697165]
---- EP [1/5] | BTCH [138/3634] ||| train_loss = 0.00826 ----
LR: [0.00041539980502674177]
---- EP [1/5] | BTCH [139/3634] ||| train_loss = 0.00660 ----
LR: [0.0004156220613027138]
---- EP [1/5] | BTCH [140/3634] ||| train_loss = 0.00988 ----
LR: [0.00041584590734103886]
---- EP [1/5] | BTCH [141/3634] ||| train_loss = 0.01071 ----
LR: [0.00041607134306733545]
---- EP [1/5] | BTCH [142/3634] ||| train_loss = 0.01359 ----
LR: [0.00041629836840669475]
---- EP [1/5] | BTCH [143/3634] ||| train_loss = 0.01127 ----
LR: [0.00041652698328368057]
---- EP [1/5] | BTCH [144/3634] ||| train_loss = 0.01305 ----
LR: [0.00041675718762233284]
---- EP [1/5] | BTCH [145/3634] ||| train_loss = 0.01429 ----
LR: [0.00041698898134615026]
---- EP [1/5] | BTCH [146/3634] ||| train_loss = 0.00864 ----
LR: [0.00041722236437811977]
---- EP [1/5] | BTCH [147/3634] ||| train_loss = 0.01312 ----
LR: [0.0004174573366406871]
---- EP [1/5] | BTCH [148/3634] ||| train_loss = 0.01623 ----
LR: [0.0004176938980557793]
---- EP [1/5] | BTCH [149/3634] ||| train_loss = 0.00685 ----
LR: [0.0004179320485447873]
---- EP [1/5] | BTCH [150/3634] ||| train_loss = 0.00763 ----
LR: [0.0004181717880285818]
---- EP [1/5] | BTCH [151/3634] ||| train_loss = 0.01894 ----
LR: [0.000418413116427499]
---- EP [1/5] | BTCH [152/3634] ||| train_loss = 0.01148 ----
LR: [0.0004186560336613514]
---- EP [1/5] | BTCH [153/3634] ||| train_loss = 0.02065 ----
LR: [0.00041890053964941873]
---- EP [1/5] | BTCH [154/3634] ||| train_loss = 0.01554 ----
LR: [0.00041914663431046224]
---- EP [1/5] | BTCH [155/3634] ||| train_loss = 0.01752 ----
LR: [0.0004193943175627036]
---- EP [1/5] | BTCH [156/3634] ||| train_loss = 0.01102 ----
LR: [0.0004196435893238457]
---- EP [1/5] | BTCH [157/3634] ||| train_loss = 0.00935 ----
LR: [0.00041989444951105563]
---- EP [1/5] | BTCH [158/3634] ||| train_loss = 0.02280 ----
LR: [0.00042014689804098157]
---- EP [1/5] | BTCH [159/3634] ||| train_loss = 0.01672 ----
LR: [0.0004204009348297375]
---- EP [1/5] | BTCH [160/3634] ||| train_loss = 0.00698 ----
LR: [0.00042065655979291183]
---- EP [1/5] | BTCH [161/3634] ||| train_loss = 0.01767 ----
LR: [0.0004209137728455655]
---- EP [1/5] | BTCH [162/3634] ||| train_loss = 0.01493 ----
LR: [0.0004211725739022322]
---- EP [1/5] | BTCH [163/3634] ||| train_loss = 0.01304 ----
LR: [0.000421432962876913]
---- EP [1/5] | BTCH [164/3634] ||| train_loss = 0.01650 ----
LR: [0.0004216949396830885]
---- EP [1/5] | BTCH [165/3634] ||| train_loss = 0.01135 ----
LR: [0.00042195850423370866]
---- EP [1/5] | BTCH [166/3634] ||| train_loss = 0.01140 ----
LR: [0.0004222236564411959]
---- EP [1/5] | BTCH [167/3634] ||| train_loss = 0.01264 ----
LR: [0.00042249039621744186]
---- EP [1/5] | BTCH [168/3634] ||| train_loss = 0.02070 ----
LR: [0.0004227587234738178]
---- EP [1/5] | BTCH [169/3634] ||| train_loss = 0.00909 ----
LR: [0.0004230286381211607]
---- EP [1/5] | BTCH [170/3634] ||| train_loss = 0.01068 ----
LR: [0.0004233001400697836]
---- EP [1/5] | BTCH [171/3634] ||| train_loss = 0.01088 ----
LR: [0.0004235732292294705]
---- EP [1/5] | BTCH [172/3634] ||| train_loss = 0.00906 ----
LR: [0.0004238479055094814]
---- EP [1/5] | BTCH [173/3634] ||| train_loss = 0.00918 ----
LR: [0.0004241241688185439]
---- EP [1/5] | BTCH [174/3634] ||| train_loss = 0.01192 ----
LR: [0.0004244020190648616]
---- EP [1/5] | BTCH [175/3634] ||| train_loss = 0.01140 ----
LR: [0.0004246814561561091]
---- EP [1/5] | BTCH [176/3634] ||| train_loss = 0.00983 ----
LR: [0.000424962479999437]
---- EP [1/5] | BTCH [177/3634] ||| train_loss = 0.00622 ----
LR: [0.00042524509050146167]
---- EP [1/5] | BTCH [178/3634] ||| train_loss = 0.01101 ----
LR: [0.00042552928756828083]
---- EP [1/5] | BTCH [179/3634] ||| train_loss = 0.01459 ----
LR: [0.0004258150711054596]
---- EP [1/5] | BTCH [180/3634] ||| train_loss = 0.01125 ----
LR: [0.0004261024410180357]
---- EP [1/5] | BTCH [181/3634] ||| train_loss = 0.01022 ----
LR: [0.0004263913972105231]
---- EP [1/5] | BTCH [182/3634] ||| train_loss = 0.01108 ----
LR: [0.0004266819395869082]
---- EP [1/5] | BTCH [183/3634] ||| train_loss = 0.01928 ----
LR: [0.0004269740680506468]
---- EP [1/5] | BTCH [184/3634] ||| train_loss = 0.01018 ----
LR: [0.00042726778250466897]
---- EP [1/5] | BTCH [185/3634] ||| train_loss = 0.01675 ----
LR: [0.00042756308285138087]
---- EP [1/5] | BTCH [186/3634] ||| train_loss = 0.01379 ----
LR: [0.0004278599689926596]
---- EP [1/5] | BTCH [187/3634] ||| train_loss = 0.01650 ----
LR: [0.0004281584408298532]
---- EP [1/5] | BTCH [188/3634] ||| train_loss = 0.01148 ----
LR: [0.00042845849826378575]
---- EP [1/5] | BTCH [189/3634] ||| train_loss = 0.01127 ----
LR: [0.0004287601411947558]
---- EP [1/5] | BTCH [190/3634] ||| train_loss = 0.01243 ----
LR: [0.000429063369522531]
---- EP [1/5] | BTCH [191/3634] ||| train_loss = 0.01656 ----
LR: [0.00042936818314635167]
---- EP [1/5] | BTCH [192/3634] ||| train_loss = 0.00855 ----
LR: [0.0004296745819649377]
---- EP [1/5] | BTCH [193/3634] ||| train_loss = 0.00938 ----
LR: [0.0004299825658764765]
---- EP [1/5] | BTCH [194/3634] ||| train_loss = 0.01638 ----
LR: [0.0004302921347786315]
---- EP [1/5] | BTCH [195/3634] ||| train_loss = 0.01456 ----
LR: [0.000430603288568537]
---- EP [1/5] | BTCH [196/3634] ||| train_loss = 0.01362 ----
LR: [0.00043091602714280357]
---- EP [1/5] | BTCH [197/3634] ||| train_loss = 0.01437 ----
LR: [0.00043123035039751255]
---- EP [1/5] | BTCH [198/3634] ||| train_loss = 0.00940 ----
LR: [0.00043154625822822146]
---- EP [1/5] | BTCH [199/3634] ||| train_loss = 0.01056 ----
LR: [0.00043186375052996044]
---- EP [1/5] | BTCH [200/3634] ||| train_loss = 0.01735 ----
LR: [0.0004321828271972288]
---- EP [1/5] | BTCH [201/3634] ||| train_loss = 0.00852 ----
LR: [0.00043250348812400724]
---- EP [1/5] | BTCH [202/3634] ||| train_loss = 0.01704 ----
LR: [0.0004328257332037438]
---- EP [1/5] | BTCH [203/3634] ||| train_loss = 0.01527 ----
LR: [0.0004331495623293626]
---- EP [1/5] | BTCH [204/3634] ||| train_loss = 0.01385 ----
LR: [0.0004334749753932606]
---- EP [1/5] | BTCH [205/3634] ||| train_loss = 0.01515 ----
LR: [0.0004338019722873107]
---- EP [1/5] | BTCH [206/3634] ||| train_loss = 0.01503 ----
LR: [0.00043413055290285503]
---- EP [1/5] | BTCH [207/3634] ||| train_loss = 0.01267 ----
LR: [0.0004344607171307153]
---- EP [1/5] | BTCH [208/3634] ||| train_loss = 0.01331 ----
LR: [0.00043479246486118235]
---- EP [1/5] | BTCH [209/3634] ||| train_loss = 0.00970 ----
LR: [0.0004351257959840215]
---- EP [1/5] | BTCH [210/3634] ||| train_loss = 0.00786 ----
LR: [0.0004354607103884741]
---- EP [1/5] | BTCH [211/3634] ||| train_loss = 0.01238 ----
LR: [0.0004357972079632542]
---- EP [1/5] | BTCH [212/3634] ||| train_loss = 0.00993 ----
LR: [0.0004361352885965484]
---- EP [1/5] | BTCH [213/3634] ||| train_loss = 0.01047 ----
LR: [0.00043647495217602125]
---- EP [1/5] | BTCH [214/3634] ||| train_loss = 0.01737 ----
LR: [0.0004368161985888047]
---- EP [1/5] | BTCH [215/3634] ||| train_loss = 0.00803 ----
LR: [0.00043715902772151205]
---- EP [1/5] | BTCH [216/3634] ||| train_loss = 0.00688 ----
LR: [0.0004375034394602257]
---- EP [1/5] | BTCH [217/3634] ||| train_loss = 0.00928 ----
LR: [0.0004378494336905042]
---- EP [1/5] | BTCH [218/3634] ||| train_loss = 0.01323 ----
LR: [0.0004381970102973823]
---- EP [1/5] | BTCH [219/3634] ||| train_loss = 0.00976 ----
LR: [0.00043854616916536374]
---- EP [1/5] | BTCH [220/3634] ||| train_loss = 0.01023 ----
LR: [0.00043889691017842854]
---- EP [1/5] | BTCH [221/3634] ||| train_loss = 0.01083 ----
LR: [0.0004392492332200345]
---- EP [1/5] | BTCH [222/3634] ||| train_loss = 0.00968 ----
LR: [0.0004396031381731103]
---- EP [1/5] | BTCH [223/3634] ||| train_loss = 0.01348 ----
LR: [0.0004399586249200574]
---- EP [1/5] | BTCH [224/3634] ||| train_loss = 0.01593 ----
LR: [0.00044031569334275836]
---- EP [1/5] | BTCH [225/3634] ||| train_loss = 0.01363 ----
LR: [0.0004406743433225616]
---- EP [1/5] | BTCH [226/3634] ||| train_loss = 0.01490 ----
LR: [0.00044103457474029516]
---- EP [1/5] | BTCH [227/3634] ||| train_loss = 0.01340 ----
LR: [0.00044139638747626303]
---- EP [1/5] | BTCH [228/3634] ||| train_loss = 0.01711 ----
LR: [0.0004417597814102385]
---- EP [1/5] | BTCH [229/3634] ||| train_loss = 0.00837 ----
LR: [0.0004421247564214744]
---- EP [1/5] | BTCH [230/3634] ||| train_loss = 0.01212 ----
LR: [0.0004424913123886945]
---- EP [1/5] | BTCH [231/3634] ||| train_loss = 0.01644 ----
LR: [0.00044285944919010035]
---- EP [1/5] | BTCH [232/3634] ||| train_loss = 0.00881 ----
LR: [0.00044322916670336623]
---- EP [1/5] | BTCH [233/3634] ||| train_loss = 0.00948 ----
LR: [0.000443600464805639]
---- EP [1/5] | BTCH [234/3634] ||| train_loss = 0.01173 ----
LR: [0.00044397334337354863]
---- EP [1/5] | BTCH [235/3634] ||| train_loss = 0.01387 ----
LR: [0.0004443478022831907]
---- EP [1/5] | BTCH [236/3634] ||| train_loss = 0.00770 ----
LR: [0.0004447238414101388]
---- EP [1/5] | BTCH [237/3634] ||| train_loss = 0.01508 ----
LR: [0.00044510146062944414]
---- EP [1/5] | BTCH [238/3634] ||| train_loss = 0.00998 ----
LR: [0.0004454806598156273]
---- EP [1/5] | BTCH [239/3634] ||| train_loss = 0.01457 ----
LR: [0.00044586143884269014]
---- EP [1/5] | BTCH [240/3634] ||| train_loss = 0.00830 ----
LR: [0.0004462437975841071]
---- EP [1/5] | BTCH [241/3634] ||| train_loss = 0.01411 ----
LR: [0.00044662773591282526]
---- EP [1/5] | BTCH [242/3634] ||| train_loss = 0.01683 ----
LR: [0.00044701325370126964]
---- EP [1/5] | BTCH [243/3634] ||| train_loss = 0.00816 ----
LR: [0.00044740035082133957]
---- EP [1/5] | BTCH [244/3634] ||| train_loss = 0.00953 ----
LR: [0.00044778902714440877]
---- EP [1/5] | BTCH [245/3634] ||| train_loss = 0.01007 ----
LR: [0.00044817928254133055]
---- EP [1/5] | BTCH [246/3634] ||| train_loss = 0.00821 ----
LR: [0.0004485711168824274]
---- EP [1/5] | BTCH [247/3634] ||| train_loss = 0.01047 ----
LR: [0.0004489645300374979]
---- EP [1/5] | BTCH [248/3634] ||| train_loss = 0.01778 ----
LR: [0.00044935952187582194]
---- EP [1/5] | BTCH [249/3634] ||| train_loss = 0.01217 ----
LR: [0.0004497560922661469]
---- EP [1/5] | BTCH [250/3634] ||| train_loss = 0.01055 ----
LR: [0.0004501542410767032]
---- EP [1/5] | BTCH [251/3634] ||| train_loss = 0.01276 ----
LR: [0.0004505539681751939]
---- EP [1/5] | BTCH [252/3634] ||| train_loss = 0.00590 ----
LR: [0.0004509552734287912]
---- EP [1/5] | BTCH [253/3634] ||| train_loss = 0.00789 ----
LR: [0.0004513581567041538]
---- EP [1/5] | BTCH [254/3634] ||| train_loss = 0.00998 ----
LR: [0.00045176261786740966]
---- EP [1/5] | BTCH [255/3634] ||| train_loss = 0.01317 ----
LR: [0.00045216865678416283]
---- EP [1/5] | BTCH [256/3634] ||| train_loss = 0.01003 ----
LR: [0.0004525762733194952]
---- EP [1/5] | BTCH [257/3634] ||| train_loss = 0.01248 ----
LR: [0.00045298546733796123]
---- EP [1/5] | BTCH [258/3634] ||| train_loss = 0.00842 ----
LR: [0.0004533962387035951]
---- EP [1/5] | BTCH [259/3634] ||| train_loss = 0.01167 ----
LR: [0.0004538085872799035]
---- EP [1/5] | BTCH [260/3634] ||| train_loss = 0.01007 ----
LR: [0.0004542225129298711]
---- EP [1/5] | BTCH [261/3634] ||| train_loss = 0.01432 ----
LR: [0.00045463801551595684]
---- EP [1/5] | BTCH [262/3634] ||| train_loss = 0.01049 ----
LR: [0.0004550550949000993]
---- EP [1/5] | BTCH [263/3634] ||| train_loss = 0.01678 ----
LR: [0.00045547375094370617]
---- EP [1/5] | BTCH [264/3634] ||| train_loss = 0.01808 ----
LR: [0.00045589398350767]
---- EP [1/5] | BTCH [265/3634] ||| train_loss = 0.01402 ----
LR: [0.0004563157924523543]
---- EP [1/5] | BTCH [266/3634] ||| train_loss = 0.01066 ----
LR: [0.00045673917763759675]
---- EP [1/5] | BTCH [267/3634] ||| train_loss = 0.01094 ----
LR: [0.0004571641389227183]
---- EP [1/5] | BTCH [268/3634] ||| train_loss = 0.00757 ----
LR: [0.00045759067616650724]
---- EP [1/5] | BTCH [269/3634] ||| train_loss = 0.00961 ----
LR: [0.00045801878922723666]
---- EP [1/5] | BTCH [270/3634] ||| train_loss = 0.00535 ----
LR: [0.0004584484779626523]
---- EP [1/5] | BTCH [271/3634] ||| train_loss = 0.01199 ----
LR: [0.00045887974222997424]
---- EP [1/5] | BTCH [272/3634] ||| train_loss = 0.01391 ----
LR: [0.0004593125818859022]
---- EP [1/5] | BTCH [273/3634] ||| train_loss = 0.01283 ----
LR: [0.0004597469967866103]
---- EP [1/5] | BTCH [274/3634] ||| train_loss = 0.00706 ----
LR: [0.0004601829867877504]
---- EP [1/5] | BTCH [275/3634] ||| train_loss = 0.01383 ----
LR: [0.00046062055174445407]
---- EP [1/5] | BTCH [276/3634] ||| train_loss = 0.01625 ----
LR: [0.00046105969151132367]
---- EP [1/5] | BTCH [277/3634] ||| train_loss = 0.01070 ----
LR: [0.0004615004059424395]
---- EP [1/5] | BTCH [278/3634] ||| train_loss = 0.01383 ----
LR: [0.00046194269489136484]
---- EP [1/5] | BTCH [279/3634] ||| train_loss = 0.01294 ----
LR: [0.0004623865582111305]
---- EP [1/5] | BTCH [280/3634] ||| train_loss = 0.01667 ----
LR: [0.00046283199575425024]
---- EP [1/5] | BTCH [281/3634] ||| train_loss = 0.01593 ----
LR: [0.000463279007372714]
---- EP [1/5] | BTCH [282/3634] ||| train_loss = 0.01064 ----
LR: [0.00046372759291798786]
---- EP [1/5] | BTCH [283/3634] ||| train_loss = 0.01640 ----
LR: [0.0004641777522410139]
---- EP [1/5] | BTCH [284/3634] ||| train_loss = 0.00986 ----
LR: [0.0004646294851922122]
---- EP [1/5] | BTCH [285/3634] ||| train_loss = 0.01072 ----
LR: [0.00046508279162148225]
---- EP [1/5] | BTCH [286/3634] ||| train_loss = 0.01190 ----
LR: [0.00046553767137819634]
---- EP [1/5] | BTCH [287/3634] ||| train_loss = 0.00934 ----
LR: [0.00046599412431120625]
---- EP [1/5] | BTCH [288/3634] ||| train_loss = 0.00492 ----
LR: [0.00046645215026884165]
---- EP [1/5] | BTCH [289/3634] ||| train_loss = 0.01206 ----
LR: [0.0004669117490989083]
---- EP [1/5] | BTCH [290/3634] ||| train_loss = 0.00882 ----
LR: [0.00046737292064868985]
---- EP [1/5] | BTCH [291/3634] ||| train_loss = 0.01699 ----
LR: [0.00046783566476494773]
---- EP [1/5] | BTCH [292/3634] ||| train_loss = 0.00791 ----
LR: [0.00046829998129392127]
---- EP [1/5] | BTCH [293/3634] ||| train_loss = 0.00914 ----
LR: [0.00046876587008132416]
---- EP [1/5] | BTCH [294/3634] ||| train_loss = 0.02001 ----
LR: [0.0004692333309723514]
---- EP [1/5] | BTCH [295/3634] ||| train_loss = 0.01328 ----
LR: [0.00046970236381167416]
---- EP [1/5] | BTCH [296/3634] ||| train_loss = 0.01228 ----
LR: [0.00047017296844344136]
---- EP [1/5] | BTCH [297/3634] ||| train_loss = 0.01196 ----
LR: [0.00047064514471127986]
---- EP [1/5] | BTCH [298/3634] ||| train_loss = 0.02475 ----
LR: [0.00047111889245829257]
---- EP [1/5] | BTCH [299/3634] ||| train_loss = 0.00905 ----
LR: [0.00047159421152706375]
---- EP [1/5] | BTCH [300/3634] ||| train_loss = 0.00889 ----
LR: [0.00047207110175965204]
---- EP [1/5] | BTCH [301/3634] ||| train_loss = 0.01332 ----
LR: [0.0004725495629975939]
---- EP [1/5] | BTCH [302/3634] ||| train_loss = 0.01159 ----
LR: [0.00047302959508191064]
---- EP [1/5] | BTCH [303/3634] ||| train_loss = 0.01295 ----
LR: [0.0004735111978530909]
---- EP [1/5] | BTCH [304/3634] ||| train_loss = 0.01034 ----
LR: [0.00047399437115110826]
---- EP [1/5] | BTCH [305/3634] ||| train_loss = 0.01008 ----
LR: [0.000474479114815414]
---- EP [1/5] | BTCH [306/3634] ||| train_loss = 0.00912 ----
LR: [0.0004749654286849356]
---- EP [1/5] | BTCH [307/3634] ||| train_loss = 0.00958 ----
LR: [0.0004754533125980818]
---- EP [1/5] | BTCH [308/3634] ||| train_loss = 0.01447 ----
LR: [0.00047594276639273403]
---- EP [1/5] | BTCH [309/3634] ||| train_loss = 0.00832 ----
LR: [0.0004764337899062568]
---- EP [1/5] | BTCH [310/3634] ||| train_loss = 0.01726 ----
LR: [0.0004769263829754941]
---- EP [1/5] | BTCH [311/3634] ||| train_loss = 0.00836 ----
LR: [0.00047742054543676617]
---- EP [1/5] | BTCH [312/3634] ||| train_loss = 0.01866 ----
LR: [0.0004779162771258675]
---- EP [1/5] | BTCH [313/3634] ||| train_loss = 0.01161 ----
LR: [0.00047841357787807917]
---- EP [1/5] | BTCH [314/3634] ||| train_loss = 0.01338 ----
LR: [0.0004789124475281549]
---- EP [1/5] | BTCH [315/3634] ||| train_loss = 0.01030 ----
LR: [0.00047941288591033145]
---- EP [1/5] | BTCH [316/3634] ||| train_loss = 0.00774 ----
LR: [0.0004799148928583217]
---- EP [1/5] | BTCH [317/3634] ||| train_loss = 0.00666 ----
LR: [0.00048041846820531635]
---- EP [1/5] | BTCH [318/3634] ||| train_loss = 0.01201 ----
LR: [0.0004809236117839875]
---- EP [1/5] | BTCH [319/3634] ||| train_loss = 0.01118 ----
LR: [0.00048143032342648495]
---- EP [1/5] | BTCH [320/3634] ||| train_loss = 0.00784 ----
LR: [0.0004819386029644365]
---- EP [1/5] | BTCH [321/3634] ||| train_loss = 0.01140 ----
LR: [0.000482448450228953]
---- EP [1/5] | BTCH [322/3634] ||| train_loss = 0.01244 ----
LR: [0.0004829598650506195]
---- EP [1/5] | BTCH [323/3634] ||| train_loss = 0.01634 ----
LR: [0.0004834728472595008]
---- EP [1/5] | BTCH [324/3634] ||| train_loss = 0.01917 ----
LR: [0.00048398739668514476]
---- EP [1/5] | BTCH [325/3634] ||| train_loss = 0.00846 ----
LR: [0.00048450351315657524]
---- EP [1/5] | BTCH [326/3634] ||| train_loss = 0.01097 ----
LR: [0.0004850211965022923]
---- EP [1/5] | BTCH [327/3634] ||| train_loss = 0.00715 ----
LR: [0.0004855404465502859]
---- EP [1/5] | BTCH [328/3634] ||| train_loss = 0.00959 ----
LR: [0.00048606126312801187]
---- EP [1/5] | BTCH [329/3634] ||| train_loss = 0.01785 ----
LR: [0.0004865836460624176]
---- EP [1/5] | BTCH [330/3634] ||| train_loss = 0.00932 ----
LR: [0.0004871075951799215]
---- EP [1/5] | BTCH [331/3634] ||| train_loss = 0.01148 ----
LR: [0.0004876331103064284]
---- EP [1/5] | BTCH [332/3634] ||| train_loss = 0.01098 ----
LR: [0.0004881601912673124]
---- EP [1/5] | BTCH [333/3634] ||| train_loss = 0.01812 ----
LR: [0.000488688837887441]
---- EP [1/5] | BTCH [334/3634] ||| train_loss = 0.01911 ----
LR: [0.0004892190499911492]
---- EP [1/5] | BTCH [335/3634] ||| train_loss = 0.01149 ----
LR: [0.0004897508274022619]
---- EP [1/5] | BTCH [336/3634] ||| train_loss = 0.02119 ----
LR: [0.000490284169944075]
---- EP [1/5] | BTCH [337/3634] ||| train_loss = 0.01107 ----
LR: [0.0004908190774393709]
---- EP [1/5] | BTCH [338/3634] ||| train_loss = 0.01788 ----
LR: [0.0004913555497104063]
---- EP [1/5] | BTCH [339/3634] ||| train_loss = 0.01402 ----
LR: [0.0004918935865789262]
---- EP [1/5] | BTCH [340/3634] ||| train_loss = 0.01143 ----
LR: [0.0004924331878661484]
---- EP [1/5] | BTCH [341/3634] ||| train_loss = 0.01554 ----
LR: [0.0004929743533927701]
---- EP [1/5] | BTCH [342/3634] ||| train_loss = 0.02083 ----
LR: [0.000493517082978975]
---- EP [1/5] | BTCH [343/3634] ||| train_loss = 0.01912 ----
LR: [0.0004940613764444247]
---- EP [1/5] | BTCH [344/3634] ||| train_loss = 0.01158 ----
LR: [0.0004946072336082588]
---- EP [1/5] | BTCH [345/3634] ||| train_loss = 0.01455 ----
LR: [0.000495154654289098]
---- EP [1/5] | BTCH [346/3634] ||| train_loss = 0.00876 ----
LR: [0.0004957036383050444]
---- EP [1/5] | BTCH [347/3634] ||| train_loss = 0.01137 ----
LR: [0.0004962541854736831]
---- EP [1/5] | BTCH [348/3634] ||| train_loss = 0.00982 ----
LR: [0.0004968062956120754]
---- EP [1/5] | BTCH [349/3634] ||| train_loss = 0.01156 ----
LR: [0.000497359968536764]
---- EP [1/5] | BTCH [350/3634] ||| train_loss = 0.00650 ----
LR: [0.0004979152040637744]
---- EP [1/5] | BTCH [351/3634] ||| train_loss = 0.01067 ----
LR: [0.0004984720020086118]
---- EP [1/5] | BTCH [352/3634] ||| train_loss = 0.00509 ----
LR: [0.0004990303621862629]
---- EP [1/5] | BTCH [353/3634] ||| train_loss = 0.01008 ----
LR: [0.0004995902844111954]
---- EP [1/5] | BTCH [354/3634] ||| train_loss = 0.01250 ----
LR: [0.0005001517684973551]
---- EP [1/5] | BTCH [355/3634] ||| train_loss = 0.01032 ----
LR: [0.0005007148142581724]
---- EP [1/5] | BTCH [356/3634] ||| train_loss = 0.01218 ----
LR: [0.0005012794215065539]
---- EP [1/5] | BTCH [357/3634] ||| train_loss = 0.01120 ----
LR: [0.0005018455900548981]
---- EP [1/5] | BTCH [358/3634] ||| train_loss = 0.01722 ----
LR: [0.0005024133197150723]
---- EP [1/5] | BTCH [359/3634] ||| train_loss = 0.02406 ----
LR: [0.0005029826102984289]
---- EP [1/5] | BTCH [360/3634] ||| train_loss = 0.01126 ----
LR: [0.0005035534616158067]
---- EP [1/5] | BTCH [361/3634] ||| train_loss = 0.00546 ----
LR: [0.0005041258734775206]
---- EP [1/5] | BTCH [362/3634] ||| train_loss = 0.00963 ----
LR: [0.0005046998456933686]
---- EP [1/5] | BTCH [363/3634] ||| train_loss = 0.01095 ----
/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
VAL ||| loss = 0.012943977948795846, psnr = 30.846494674682617, ssim = 0.9098734855651855
LR: [0.00050527537807263]
---- EP [1/5] | BTCH [364/3634] ||| train_loss = 0.00865 ----
LR: [0.0005058524704240654]
---- EP [1/5] | BTCH [365/3634] ||| train_loss = 0.01375 ----
LR: [0.0005064311225559167]
---- EP [1/5] | BTCH [366/3634] ||| train_loss = 0.01963 ----
LR: [0.0005070113342759107]
---- EP [1/5] | BTCH [367/3634] ||| train_loss = 0.00698 ----
LR: [0.0005075931053912519]
---- EP [1/5] | BTCH [368/3634] ||| train_loss = 0.00721 ----
LR: [0.0005081764357086297]
---- EP [1/5] | BTCH [369/3634] ||| train_loss = 0.00637 ----
LR: [0.0005087613250342096]
---- EP [1/5] | BTCH [370/3634] ||| train_loss = 0.01331 ----
LR: [0.0005093477731736486]
---- EP [1/5] | BTCH [371/3634] ||| train_loss = 0.01378 ----
LR: [0.0005099357799320785]
---- EP [1/5] | BTCH [372/3634] ||| train_loss = 0.01104 ----
LR: [0.0005105253451141156]
---- EP [1/5] | BTCH [373/3634] ||| train_loss = 0.01054 ----
LR: [0.0005111164685238593]
---- EP [1/5] | BTCH [374/3634] ||| train_loss = 0.01002 ----
LR: [0.0005117091499648851]
---- EP [1/5] | BTCH [375/3634] ||| train_loss = 0.01192 ----
LR: [0.0005123033892402602]
---- EP [1/5] | BTCH [376/3634] ||| train_loss = 0.01612 ----
LR: [0.0005128991861525298]
---- EP [1/5] | BTCH [377/3634] ||| train_loss = 0.01323 ----
LR: [0.0005134965405037186]
---- EP [1/5] | BTCH [378/3634] ||| train_loss = 0.01093 ----
LR: [0.0005140954520953377]
---- EP [1/5] | BTCH [379/3634] ||| train_loss = 0.01309 ----
LR: [0.0005146959207283815]
---- EP [1/5] | BTCH [380/3634] ||| train_loss = 0.01377 ----
LR: [0.0005152979462033219]
---- EP [1/5] | BTCH [381/3634] ||| train_loss = 0.02071 ----
LR: [0.0005159015283201195]
---- EP [1/5] | BTCH [382/3634] ||| train_loss = 0.01211 ----
LR: [0.000516506666878214]
---- EP [1/5] | BTCH [383/3634] ||| train_loss = 0.02316 ----
LR: [0.0005171133616765269]
---- EP [1/5] | BTCH [384/3634] ||| train_loss = 0.01134 ----
LR: [0.0005177216125134675]
---- EP [1/5] | BTCH [385/3634] ||| train_loss = 0.01408 ----
LR: [0.0005183314191869216]
---- EP [1/5] | BTCH [386/3634] ||| train_loss = 0.01163 ----
LR: [0.0005189427814942648]
---- EP [1/5] | BTCH [387/3634] ||| train_loss = 0.00862 ----
LR: [0.0005195556992323505]
---- EP [1/5] | BTCH [388/3634] ||| train_loss = 0.01447 ----
LR: [0.0005201701721975188]
---- EP [1/5] | BTCH [389/3634] ||| train_loss = 0.00724 ----
LR: [0.0005207862001855891]
---- EP [1/5] | BTCH [390/3634] ||| train_loss = 0.00653 ----
LR: [0.0005214037829918694]
---- EP [1/5] | BTCH [391/3634] ||| train_loss = 0.01740 ----
LR: [0.0005220229204111453]
---- EP [1/5] | BTCH [392/3634] ||| train_loss = 0.01582 ----
LR: [0.0005226436122376908]
---- EP [1/5] | BTCH [393/3634] ||| train_loss = 0.01423 ----
LR: [0.0005232658582652594]
---- EP [1/5] | BTCH [394/3634] ||| train_loss = 0.01308 ----
LR: [0.0005238896582870894]
---- EP [1/5] | BTCH [395/3634] ||| train_loss = 0.01498 ----
LR: [0.0005245150120959073]
---- EP [1/5] | BTCH [396/3634] ||| train_loss = 0.00866 ----
LR: [0.0005251419194839142]
---- EP [1/5] | BTCH [397/3634] ||| train_loss = 0.01627 ----
LR: [0.0005257703802428043]
---- EP [1/5] | BTCH [398/3634] ||| train_loss = 0.01039 ----
LR: [0.00052640039416375]
---- EP [1/5] | BTCH [399/3634] ||| train_loss = 0.01159 ----
LR: [0.0005270319610374066]
---- EP [1/5] | BTCH [400/3634] ||| train_loss = 0.01305 ----
LR: [0.0005276650806539194]
---- EP [1/5] | BTCH [401/3634] ||| train_loss = 0.01390 ----
LR: [0.0005282997528029149]
---- EP [1/5] | BTCH [402/3634] ||| train_loss = 0.00602 ----
LR: [0.0005289359772734977]
---- EP [1/5] | BTCH [403/3634] ||| train_loss = 0.01114 ----
LR: [0.0005295737538542674]
---- EP [1/5] | BTCH [404/3634] ||| train_loss = 0.00860 ----
LR: [0.0005302130823332998]
---- EP [1/5] | BTCH [405/3634] ||| train_loss = 0.00923 ----
LR: [0.0005308539624981554]
---- EP [1/5] | BTCH [406/3634] ||| train_loss = 0.00875 ----
LR: [0.0005314963941358865]
---- EP [1/5] | BTCH [407/3634] ||| train_loss = 0.02128 ----
LR: [0.0005321403770330215]
---- EP [1/5] | BTCH [408/3634] ||| train_loss = 0.00987 ----
LR: [0.0005327859109755771]
---- EP [1/5] | BTCH [409/3634] ||| train_loss = 0.01394 ----
LR: [0.0005334329957490547]
---- EP [1/5] | BTCH [410/3634] ||| train_loss = 0.01918 ----
LR: [0.0005340816311384371]
---- EP [1/5] | BTCH [411/3634] ||| train_loss = 0.01134 ----
LR: [0.0005347318169281971]
---- EP [1/5] | BTCH [412/3634] ||| train_loss = 0.01358 ----
LR: [0.0005353835529022886]
---- EP [1/5] | BTCH [413/3634] ||| train_loss = 0.01342 ----
LR: [0.0005360368388441523]
---- EP [1/5] | BTCH [414/3634] ||| train_loss = 0.00662 ----
LR: [0.0005366916745367135]
---- EP [1/5] | BTCH [415/3634] ||| train_loss = 0.00948 ----
LR: [0.0005373480597623791]
---- EP [1/5] | BTCH [416/3634] ||| train_loss = 0.00668 ----
LR: [0.000538005994303049]
---- EP [1/5] | BTCH [417/3634] ||| train_loss = 0.00965 ----
LR: [0.0005386654779400979]
---- EP [1/5] | BTCH [418/3634] ||| train_loss = 0.01086 ----
LR: [0.0005393265104543972]
---- EP [1/5] | BTCH [419/3634] ||| train_loss = 0.01316 ----
LR: [0.0005399890916262928]
---- EP [1/5] | BTCH [420/3634] ||| train_loss = 0.00944 ----
LR: [0.0005406532212356239]
---- EP [1/5] | BTCH [421/3634] ||| train_loss = 0.00612 ----
LR: [0.0005413188990617095]
---- EP [1/5] | BTCH [422/3634] ||| train_loss = 0.02020 ----
LR: [0.0005419861248833601]
---- EP [1/5] | BTCH [423/3634] ||| train_loss = 0.02023 ----
LR: [0.000542654898478866]
---- EP [1/5] | BTCH [424/3634] ||| train_loss = 0.01110 ----
LR: [0.0005433252196260091]
---- EP [1/5] | BTCH [425/3634] ||| train_loss = 0.01236 ----
LR: [0.0005439970881020492]
---- EP [1/5] | BTCH [426/3634] ||| train_loss = 0.01222 ----
LR: [0.0005446705036837394]
---- EP [1/5] | BTCH [427/3634] ||| train_loss = 0.01544 ----
LR: [0.0005453454661473161]
---- EP [1/5] | BTCH [428/3634] ||| train_loss = 0.01474 ----
LR: [0.0005460219752685003]
---- EP [1/5] | BTCH [429/3634] ||| train_loss = 0.01316 ----
LR: [0.0005467000308224997]
---- EP [1/5] | BTCH [430/3634] ||| train_loss = 0.00950 ----
LR: [0.0005473796325840118]
---- EP [1/5] | BTCH [431/3634] ||| train_loss = 0.01769 ----
LR: [0.0005480607803272138]
---- EP [1/5] | BTCH [432/3634] ||| train_loss = 0.00682 ----
LR: [0.0005487434738257746]
---- EP [1/5] | BTCH [433/3634] ||| train_loss = 0.01221 ----
LR: [0.0005494277128528461]
---- EP [1/5] | BTCH [434/3634] ||| train_loss = 0.01372 ----
LR: [0.0005501134971810685]
---- EP [1/5] | BTCH [435/3634] ||| train_loss = 0.00903 ----
LR: [0.0005508008265825703]
---- EP [1/5] | BTCH [436/3634] ||| train_loss = 0.01926 ----
LR: [0.0005514897008289613]
---- EP [1/5] | BTCH [437/3634] ||| train_loss = 0.01276 ----
LR: [0.0005521801196913412]
---- EP [1/5] | BTCH [438/3634] ||| train_loss = 0.00915 ----
LR: [0.0005528720829402981]
---- EP [1/5] | BTCH [439/3634] ||| train_loss = 0.01037 ----
LR: [0.000553565590345903]
---- EP [1/5] | BTCH [440/3634] ||| train_loss = 0.00731 ----
LR: [0.0005542606416777188]
---- EP [1/5] | BTCH [441/3634] ||| train_loss = 0.01395 ----
LR: [0.0005549572367047895]
---- EP [1/5] | BTCH [442/3634] ||| train_loss = 0.00607 ----
LR: [0.000555655375195651]
---- EP [1/5] | BTCH [443/3634] ||| train_loss = 0.00538 ----
LR: [0.0005563550569183239]
---- EP [1/5] | BTCH [444/3634] ||| train_loss = 0.01459 ----
LR: [0.0005570562816403155]
---- EP [1/5] | BTCH [445/3634] ||| train_loss = 0.01222 ----
LR: [0.0005577590491286245]
---- EP [1/5] | BTCH [446/3634] ||| train_loss = 0.01216 ----
LR: [0.0005584633591497312]
---- EP [1/5] | BTCH [447/3634] ||| train_loss = 0.00735 ----
LR: [0.0005591692114696074]
---- EP [1/5] | BTCH [448/3634] ||| train_loss = 0.01121 ----
LR: [0.0005598766058537118]
---- EP [1/5] | BTCH [449/3634] ||| train_loss = 0.01530 ----
LR: [0.0005605855420669874]
---- EP [1/5] | BTCH [450/3634] ||| train_loss = 0.01563 ----
LR: [0.0005612960198738692]
---- EP [1/5] | BTCH [451/3634] ||| train_loss = 0.01923 ----
LR: [0.0005620080390382788]
---- EP [1/5] | BTCH [452/3634] ||| train_loss = 0.01221 ----
LR: [0.0005627215993236241]
---- EP [1/5] | BTCH [453/3634] ||| train_loss = 0.01109 ----
LR: [0.0005634367004928031]
---- EP [1/5] | BTCH [454/3634] ||| train_loss = 0.00744 ----
LR: [0.0005641533423081969]
---- EP [1/5] | BTCH [455/3634] ||| train_loss = 0.01309 ----
LR: [0.0005648715245316852]
---- EP [1/5] | BTCH [456/3634] ||| train_loss = 0.01636 ----
LR: [0.0005655912469246203]
---- EP [1/5] | BTCH [457/3634] ||| train_loss = 0.01257 ----
LR: [0.0005663125092478603]
---- EP [1/5] | BTCH [458/3634] ||| train_loss = 0.01086 ----
LR: [0.0005670353112617356]
---- EP [1/5] | BTCH [459/3634] ||| train_loss = 0.00976 ----
LR: [0.0005677596527260791]
---- EP [1/5] | BTCH [460/3634] ||| train_loss = 0.00992 ----
LR: [0.0005684855334001995]
---- EP [1/5] | BTCH [461/3634] ||| train_loss = 0.01602 ----
LR: [0.0005692129530428993]
---- EP [1/5] | BTCH [462/3634] ||| train_loss = 0.01205 ----
LR: [0.0005699419114124759]
---- EP [1/5] | BTCH [463/3634] ||| train_loss = 0.01757 ----
LR: [0.0005706724082667029]
---- EP [1/5] | BTCH [464/3634] ||| train_loss = 0.01040 ----
LR: [0.0005714044433628544]
---- EP [1/5] | BTCH [465/3634] ||| train_loss = 0.01928 ----
LR: [0.0005721380164576857]
---- EP [1/5] | BTCH [466/3634] ||| train_loss = 0.01257 ----
LR: [0.0005728731273074456]
---- EP [1/5] | BTCH [467/3634] ||| train_loss = 0.00896 ----
LR: [0.0005736097756678677]
---- EP [1/5] | BTCH [468/3634] ||| train_loss = 0.01491 ----
LR: [0.000574347961294179]
---- EP [1/5] | BTCH [469/3634] ||| train_loss = 0.01751 ----
LR: [0.0005750876839410932]
---- EP [1/5] | BTCH [470/3634] ||| train_loss = 0.01320 ----
LR: [0.0005758289433628154]
---- EP [1/5] | BTCH [471/3634] ||| train_loss = 0.00671 ----
LR: [0.0005765717393130341]
---- EP [1/5] | BTCH [472/3634] ||| train_loss = 0.01147 ----
LR: [0.0005773160715449345]
---- EP [1/5] | BTCH [473/3634] ||| train_loss = 0.01724 ----
LR: [0.0005780619398111902]
---- EP [1/5] | BTCH [474/3634] ||| train_loss = 0.01669 ----
LR: [0.0005788093438639612]
---- EP [1/5] | BTCH [475/3634] ||| train_loss = 0.01456 ----
LR: [0.0005795582834548958]
---- EP [1/5] | BTCH [476/3634] ||| train_loss = 0.00787 ----
LR: [0.0005803087583351376]
---- EP [1/5] | BTCH [477/3634] ||| train_loss = 0.01165 ----
LR: [0.0005810607682553183]
---- EP [1/5] | BTCH [478/3634] ||| train_loss = 0.00459 ----
LR: [0.0005818143129655562]
---- EP [1/5] | BTCH [479/3634] ||| train_loss = 0.01598 ----
LR: [0.000582569392215463]
---- EP [1/5] | BTCH [480/3634] ||| train_loss = 0.00698 ----
LR: [0.0005833260057541423]
---- EP [1/5] | BTCH [481/3634] ||| train_loss = 0.01015 ----
LR: [0.0005840841533301805]
---- EP [1/5] | BTCH [482/3634] ||| train_loss = 0.00647 ----
LR: [0.0005848438346916611]
---- EP [1/5] | BTCH [483/3634] ||| train_loss = 0.01263 ----
LR: [0.0005856050495861524]
---- EP [1/5] | BTCH [484/3634] ||| train_loss = 0.01384 ----
LR: [0.0005863677977607246]
---- EP [1/5] | BTCH [485/3634] ||| train_loss = 0.01245 ----
LR: [0.0005871320789619227]
---- EP [1/5] | BTCH [486/3634] ||| train_loss = 0.01075 ----
LR: [0.0005878978929357917]
---- EP [1/5] | BTCH [487/3634] ||| train_loss = 0.01093 ----
LR: [0.0005886652394278668]
---- EP [1/5] | BTCH [488/3634] ||| train_loss = 0.01106 ----
LR: [0.0005894341181831714]
---- EP [1/5] | BTCH [489/3634] ||| train_loss = 0.01659 ----
LR: [0.0005902045289462206]
---- EP [1/5] | BTCH [490/3634] ||| train_loss = 0.01171 ----
LR: [0.000590976471461023]
---- EP [1/5] | BTCH [491/3634] ||| train_loss = 0.00891 ----
LR: [0.0005917499454710737]
---- EP [1/5] | BTCH [492/3634] ||| train_loss = 0.00754 ----
LR: [0.0005925249507193631]
---- EP [1/5] | BTCH [493/3634] ||| train_loss = 0.01218 ----
LR: [0.0005933014869483697]
---- EP [1/5] | BTCH [494/3634] ||| train_loss = 0.01973 ----
LR: [0.0005940795539000673]
---- EP [1/5] | BTCH [495/3634] ||| train_loss = 0.01012 ----
LR: [0.0005948591513159126]
---- EP [1/5] | BTCH [496/3634] ||| train_loss = 0.01265 ----
LR: [0.0005956402789368646]
---- EP [1/5] | BTCH [497/3634] ||| train_loss = 0.01116 ----
LR: [0.0005964229365033654]
---- EP [1/5] | BTCH [498/3634] ||| train_loss = 0.01102 ----
LR: [0.0005972071237553556]
---- EP [1/5] | BTCH [499/3634] ||| train_loss = 0.01206 ----
LR: [0.0005979928404322606]
---- EP [1/5] | BTCH [500/3634] ||| train_loss = 0.01171 ----
LR: [0.0005987800862730028]
---- EP [1/5] | BTCH [501/3634] ||| train_loss = 0.01233 ----
LR: [0.0005995688610159929]
---- EP [1/5] | BTCH [502/3634] ||| train_loss = 0.01764 ----
LR: [0.0006003591643991384]
---- EP [1/5] | BTCH [503/3634] ||| train_loss = 0.01133 ----
LR: [0.0006011509961598317]
---- EP [1/5] | BTCH [504/3634] ||| train_loss = 0.00989 ----
LR: [0.0006019443560349672]
---- EP [1/5] | BTCH [505/3634] ||| train_loss = 0.00687 ----
LR: [0.0006027392437609174]
---- EP [1/5] | BTCH [506/3634] ||| train_loss = 0.01328 ----
LR: [0.0006035356590735636]
---- EP [1/5] | BTCH [507/3634] ||| train_loss = 0.01340 ----
LR: [0.0006043336017082668]
---- EP [1/5] | BTCH [508/3634] ||| train_loss = 0.01431 ----
LR: [0.000605133071399885]
---- EP [1/5] | BTCH [509/3634] ||| train_loss = 0.00929 ----
LR: [0.000605934067882773]
---- EP [1/5] | BTCH [510/3634] ||| train_loss = 0.01355 ----
LR: [0.0006067365908907687]
---- EP [1/5] | BTCH [511/3634] ||| train_loss = 0.01233 ----
LR: [0.0006075406401572121]
---- EP [1/5] | BTCH [512/3634] ||| train_loss = 0.00839 ----
LR: [0.0006083462154149299]
---- EP [1/5] | BTCH [513/3634] ||| train_loss = 0.01513 ----
LR: [0.0006091533163962454]
---- EP [1/5] | BTCH [514/3634] ||| train_loss = 0.00811 ----
LR: [0.000609961942832974]
---- EP [1/5] | BTCH [515/3634] ||| train_loss = 0.00561 ----
LR: [0.0006107720944564209]
---- EP [1/5] | BTCH [516/3634] ||| train_loss = 0.00656 ----
LR: [0.0006115837709973898]
---- EP [1/5] | BTCH [517/3634] ||| train_loss = 0.00889 ----
LR: [0.0006123969721861747]
---- EP [1/5] | BTCH [518/3634] ||| train_loss = 0.01108 ----
LR: [0.0006132116977525647]
---- EP [1/5] | BTCH [519/3634] ||| train_loss = 0.01007 ----
LR: [0.0006140279474258371]
---- EP [1/5] | BTCH [520/3634] ||| train_loss = 0.01086 ----
LR: [0.000614845720934773]
---- EP [1/5] | BTCH [521/3634] ||| train_loss = 0.01077 ----
LR: [0.0006156650180076367]
---- EP [1/5] | BTCH [522/3634] ||| train_loss = 0.00765 ----
LR: [0.0006164858383721928]
---- EP [1/5] | BTCH [523/3634] ||| train_loss = 0.01672 ----
LR: [0.0006173081817556943]
---- EP [1/5] | BTCH [524/3634] ||| train_loss = 0.00780 ----
LR: [0.0006181320478848944]
---- EP [1/5] | BTCH [525/3634] ||| train_loss = 0.00630 ----
LR: [0.0006189574364860364]
---- EP [1/5] | BTCH [526/3634] ||| train_loss = 0.01094 ----
LR: [0.0006197843472848588]
---- EP [1/5] | BTCH [527/3634] ||| train_loss = 0.01197 ----
LR: [0.0006206127800065936]
---- EP [1/5] | BTCH [528/3634] ||| train_loss = 0.00888 ----
LR: [0.0006214427343759661]
---- EP [1/5] | BTCH [529/3634] ||| train_loss = 0.01224 ----
LR: [0.0006222742101172022]
---- EP [1/5] | BTCH [530/3634] ||| train_loss = 0.00751 ----
LR: [0.0006231072069540124]
---- EP [1/5] | BTCH [531/3634] ||| train_loss = 0.01093 ----
LR: [0.0006239417246096113]
---- EP [1/5] | BTCH [532/3634] ||| train_loss = 0.00725 ----
LR: [0.000624777762806698]
---- EP [1/5] | BTCH [533/3634] ||| train_loss = 0.01165 ----
LR: [0.0006256153212674774]
---- EP [1/5] | BTCH [534/3634] ||| train_loss = 0.01280 ----
LR: [0.0006264543997136444]
---- EP [1/5] | BTCH [535/3634] ||| train_loss = 0.01770 ----
LR: [0.000627294997866382]
---- EP [1/5] | BTCH [536/3634] ||| train_loss = 0.01664 ----
LR: [0.0006281371154463807]
---- EP [1/5] | BTCH [537/3634] ||| train_loss = 0.00704 ----
LR: [0.0006289807521738192]
---- EP [1/5] | BTCH [538/3634] ||| train_loss = 0.00406 ----
LR: [0.0006298259077683697]
---- EP [1/5] | BTCH [539/3634] ||| train_loss = 0.01863 ----
LR: [0.0006306725819492029]
---- EP [1/5] | BTCH [540/3634] ||| train_loss = 0.01271 ----
LR: [0.0006315207744349866]
---- EP [1/5] | BTCH [541/3634] ||| train_loss = 0.01463 ----
LR: [0.0006323704849438786]
---- EP [1/5] | BTCH [542/3634] ||| train_loss = 0.01846 ----
LR: [0.0006332217131935387]
---- EP [1/5] | BTCH [543/3634] ||| train_loss = 0.01226 ----
LR: [0.0006340744589011169]
---- EP [1/5] | BTCH [544/3634] ||| train_loss = 0.01847 ----
LR: [0.0006349287217832615]
---- EP [1/5] | BTCH [545/3634] ||| train_loss = 0.00866 ----
LR: [0.0006357845015561182]
---- EP [1/5] | BTCH [546/3634] ||| train_loss = 0.01111 ----
LR: [0.000636641797935324]
---- EP [1/5] | BTCH [547/3634] ||| train_loss = 0.01305 ----
LR: [0.0006375006106360166]
---- EP [1/5] | BTCH [548/3634] ||| train_loss = 0.00646 ----
LR: [0.0006383609393728271]
---- EP [1/5] | BTCH [549/3634] ||| train_loss = 0.01162 ----
LR: [0.000639222783859885]
---- EP [1/5] | BTCH [550/3634] ||| train_loss = 0.00506 ----
LR: [0.000640086143810812]
---- EP [1/5] | BTCH [551/3634] ||| train_loss = 0.01445 ----
LR: [0.0006409510189387332]
---- EP [1/5] | BTCH [552/3634] ||| train_loss = 0.01802 ----
LR: [0.0006418174089562658]
---- EP [1/5] | BTCH [553/3634] ||| train_loss = 0.01700 ----
LR: [0.0006426853135755202]
---- EP [1/5] | BTCH [554/3634] ||| train_loss = 0.01342 ----
LR: [0.0006435547325081108]
---- EP [1/5] | BTCH [555/3634] ||| train_loss = 0.01066 ----
LR: [0.0006444256654651453]
---- EP [1/5] | BTCH [556/3634] ||| train_loss = 0.00981 ----
LR: [0.0006452981121572252]
---- EP [1/5] | BTCH [557/3634] ||| train_loss = 0.01563 ----
LR: [0.0006461720722944573]
---- EP [1/5] | BTCH [558/3634] ||| train_loss = 0.01125 ----
LR: [0.0006470475455864367]
---- EP [1/5] | BTCH [559/3634] ||| train_loss = 0.00845 ----
LR: [0.0006479245317422607]
---- EP [1/5] | BTCH [560/3634] ||| train_loss = 0.01214 ----
LR: [0.0006488030304705236]
---- EP [1/5] | BTCH [561/3634] ||| train_loss = 0.01281 ----
LR: [0.0006496830414793112]
---- EP [1/5] | BTCH [562/3634] ||| train_loss = 0.00749 ----
LR: [0.0006505645644762185]
---- EP [1/5] | BTCH [563/3634] ||| train_loss = 0.01066 ----
LR: [0.0006514475991683272]
---- EP [1/5] | BTCH [564/3634] ||| train_loss = 0.00900 ----
LR: [0.0006523321452622226]
---- EP [1/5] | BTCH [565/3634] ||| train_loss = 0.00866 ----
LR: [0.0006532182024639854]
---- EP [1/5] | BTCH [566/3634] ||| train_loss = 0.01572 ----
LR: [0.0006541057704791964]
---- EP [1/5] | BTCH [567/3634] ||| train_loss = 0.01448 ----
LR: [0.0006549948490129284]
---- EP [1/5] | BTCH [568/3634] ||| train_loss = 0.01264 ----
LR: [0.0006558854377697598]
---- EP [1/5] | BTCH [569/3634] ||| train_loss = 0.01449 ----
LR: [0.0006567775364537641]
---- EP [1/5] | BTCH [570/3634] ||| train_loss = 0.01019 ----
LR: [0.0006576711447685134]
---- EP [1/5] | BTCH [571/3634] ||| train_loss = 0.01277 ----
LR: [0.000658566262417077]
---- EP [1/5] | BTCH [572/3634] ||| train_loss = 0.00643 ----
LR: [0.0006594628891020225]
---- EP [1/5] | BTCH [573/3634] ||| train_loss = 0.01447 ----
LR: [0.0006603610245254181]
---- EP [1/5] | BTCH [574/3634] ||| train_loss = 0.00528 ----
LR: [0.0006612606683888307]
---- EP [1/5] | BTCH [575/3634] ||| train_loss = 0.00653 ----
LR: [0.0006621618203933224]
---- EP [1/5] | BTCH [576/3634] ||| train_loss = 0.01412 ----
LR: [0.000663064480239459]
---- EP [1/5] | BTCH [577/3634] ||| train_loss = 0.01011 ----
LR: [0.0006639686476273016]
---- EP [1/5] | BTCH [578/3634] ||| train_loss = 0.00846 ----
LR: [0.0006648743222564119]
---- EP [1/5] | BTCH [579/3634] ||| train_loss = 0.00891 ----
LR: [0.0006657815038258498]
---- EP [1/5] | BTCH [580/3634] ||| train_loss = 0.00753 ----
LR: [0.0006666901920341795]
---- EP [1/5] | BTCH [581/3634] ||| train_loss = 0.00704 ----
LR: [0.0006676003865794533]
---- EP [1/5] | BTCH [582/3634] ||| train_loss = 0.01804 ----
LR: [0.000668512087159236]
---- EP [1/5] | BTCH [583/3634] ||| train_loss = 0.01276 ----
LR: [0.0006694252934705842]
---- EP [1/5] | BTCH [584/3634] ||| train_loss = 0.01168 ----
LR: [0.000670340005210053]
---- EP [1/5] | BTCH [585/3634] ||| train_loss = 0.01471 ----
LR: [0.0006712562220737035]
---- EP [1/5] | BTCH [586/3634] ||| train_loss = 0.02054 ----
LR: [0.0006721739437570932]
---- EP [1/5] | BTCH [587/3634] ||| train_loss = 0.01026 ----
LR: [0.0006730931699552804]
---- EP [1/5] | BTCH [588/3634] ||| train_loss = 0.01005 ----
LR: [0.0006740139003628184]
---- EP [1/5] | BTCH [589/3634] ||| train_loss = 0.01077 ----
LR: [0.0006749361346737696]
---- EP [1/5] | BTCH [590/3634] ||| train_loss = 0.01258 ----
LR: [0.0006758598725816918]
---- EP [1/5] | BTCH [591/3634] ||| train_loss = 0.01397 ----
LR: [0.0006767851137796429]
---- EP [1/5] | BTCH [592/3634] ||| train_loss = 0.01167 ----
LR: [0.0006777118579601813]
---- EP [1/5] | BTCH [593/3634] ||| train_loss = 0.00579 ----
LR: [0.0006786401048153659]
---- EP [1/5] | BTCH [594/3634] ||| train_loss = 0.00902 ----
LR: [0.0006795698540367594]
---- EP [1/5] | BTCH [595/3634] ||| train_loss = 0.01401 ----
LR: [0.0006805011053154213]
---- EP [1/5] | BTCH [596/3634] ||| train_loss = 0.01875 ----
LR: [0.0006814338583419136]
---- EP [1/5] | BTCH [597/3634] ||| train_loss = 0.01601 ----
LR: [0.0006823681128063017]
---- EP [1/5] | BTCH [598/3634] ||| train_loss = 0.00938 ----
LR: [0.0006833038683981447]
---- EP [1/5] | BTCH [599/3634] ||| train_loss = 0.01416 ----
LR: [0.0006842411248065144]
---- EP [1/5] | BTCH [600/3634] ||| train_loss = 0.00526 ----
LR: [0.0006851798817199724]
---- EP [1/5] | BTCH [601/3634] ||| train_loss = 0.01433 ----
LR: [0.0006861201388265875]
---- EP [1/5] | BTCH [602/3634] ||| train_loss = 0.01196 ----
LR: [0.0006870618958139309]
---- EP [1/5] | BTCH [603/3634] ||| train_loss = 0.01340 ----
LR: [0.0006880051523690742]
---- EP [1/5] | BTCH [604/3634] ||| train_loss = 0.01141 ----
LR: [0.0006889499081785874]
---- EP [1/5] | BTCH [605/3634] ||| train_loss = 0.01162 ----
LR: [0.000689896162928548]
---- EP [1/5] | BTCH [606/3634] ||| train_loss = 0.00857 ----
LR: [0.0006908439163045305]
---- EP [1/5] | BTCH [607/3634] ||| train_loss = 0.01516 ----
LR: [0.0006917931679916167]
---- EP [1/5] | BTCH [608/3634] ||| train_loss = 0.01128 ----
LR: [0.0006927439176743835]
---- EP [1/5] | BTCH [609/3634] ||| train_loss = 0.00958 ----
LR: [0.000693696165036917]
---- EP [1/5] | BTCH [610/3634] ||| train_loss = 0.01233 ----
LR: [0.0006946499097628001]
---- EP [1/5] | BTCH [611/3634] ||| train_loss = 0.01019 ----
LR: [0.0006956051515351214]
---- EP [1/5] | BTCH [612/3634] ||| train_loss = 0.02101 ----
LR: [0.0006965618900364734]
---- EP [1/5] | BTCH [613/3634] ||| train_loss = 0.01561 ----
LR: [0.0006975201249489488]
---- EP [1/5] | BTCH [614/3634] ||| train_loss = 0.01945 ----
LR: [0.000698479855954141]
---- EP [1/5] | BTCH [615/3634] ||| train_loss = 0.00931 ----
LR: [0.0006994410827331505]
---- EP [1/5] | BTCH [616/3634] ||| train_loss = 0.01598 ----
LR: [0.0007004038049665765]
---- EP [1/5] | BTCH [617/3634] ||| train_loss = 0.00726 ----
LR: [0.0007013680223345274]
---- EP [1/5] | BTCH [618/3634] ||| train_loss = 0.00915 ----
LR: [0.0007023337345166102]
---- EP [1/5] | BTCH [619/3634] ||| train_loss = 0.01649 ----
LR: [0.0007033009411919356]
---- EP [1/5] | BTCH [620/3634] ||| train_loss = 0.00788 ----
LR: [0.0007042696420391185]
---- EP [1/5] | BTCH [621/3634] ||| train_loss = 0.00938 ----
LR: [0.0007052398367362756]
---- EP [1/5] | BTCH [622/3634] ||| train_loss = 0.01697 ----
LR: [0.0007062115249610312]
---- EP [1/5] | BTCH [623/3634] ||| train_loss = 0.01146 ----
LR: [0.0007071847063905082]
---- EP [1/5] | BTCH [624/3634] ||| train_loss = 0.01490 ----
LR: [0.0007081593807013384]
---- EP [1/5] | BTCH [625/3634] ||| train_loss = 0.01695 ----
LR: [0.0007091355475696542]
---- EP [1/5] | BTCH [626/3634] ||| train_loss = 0.01803 ----
LR: [0.0007101132066710935]
---- EP [1/5] | BTCH [627/3634] ||| train_loss = 0.01244 ----
LR: [0.0007110923576807964]
---- EP [1/5] | BTCH [628/3634] ||| train_loss = 0.01490 ----
LR: [0.0007120730002734121]
---- EP [1/5] | BTCH [629/3634] ||| train_loss = 0.01036 ----
LR: [0.0007130551341230865]
---- EP [1/5] | BTCH [630/3634] ||| train_loss = 0.02126 ----
LR: [0.0007140387589034767]
---- EP [1/5] | BTCH [631/3634] ||| train_loss = 0.00884 ----
LR: [0.0007150238742877398]
---- EP [1/5] | BTCH [632/3634] ||| train_loss = 0.00659 ----
LR: [0.000716010479948544]
---- EP [1/5] | BTCH [633/3634] ||| train_loss = 0.00915 ----
LR: [0.0007169985755580525]
---- EP [1/5] | BTCH [634/3634] ||| train_loss = 0.01238 ----
LR: [0.0007179881607879447]
---- EP [1/5] | BTCH [635/3634] ||| train_loss = 0.01908 ----
LR: [0.000718979235309395]
---- EP [1/5] | BTCH [636/3634] ||| train_loss = 0.01684 ----
LR: [0.0007199717987930888]
---- EP [1/5] | BTCH [637/3634] ||| train_loss = 0.00982 ----
LR: [0.0007209658509092151]
---- EP [1/5] | BTCH [638/3634] ||| train_loss = 0.01167 ----
LR: [0.0007219613913274688]
---- EP [1/5] | BTCH [639/3634] ||| train_loss = 0.00494 ----
LR: [0.0007229584197170503]
---- EP [1/5] | BTCH [640/3634] ||| train_loss = 0.01561 ----
LR: [0.000723956935746662]
---- EP [1/5] | BTCH [641/3634] ||| train_loss = 0.01504 ----
LR: [0.000724956939084519]
---- EP [1/5] | BTCH [642/3634] ||| train_loss = 0.00752 ----
LR: [0.0007259584293983351]
---- EP [1/5] | BTCH [643/3634] ||| train_loss = 0.01863 ----
LR: [0.0007269614063553347]
---- EP [1/5] | BTCH [644/3634] ||| train_loss = 0.01361 ----
LR: [0.000727965869622248]
---- EP [1/5] | BTCH [645/3634] ||| train_loss = 0.01102 ----
LR: [0.0007289718188653073]
---- EP [1/5] | BTCH [646/3634] ||| train_loss = 0.00850 ----
LR: [0.0007299792537502538]
---- EP [1/5] | BTCH [647/3634] ||| train_loss = 0.00774 ----
LR: [0.0007309881739423381]
---- EP [1/5] | BTCH [648/3634] ||| train_loss = 0.01680 ----
LR: [0.0007319985791063126]
---- EP [1/5] | BTCH [649/3634] ||| train_loss = 0.01388 ----
LR: [0.0007330104689064372]
---- EP [1/5] | BTCH [650/3634] ||| train_loss = 0.00933 ----
LR: [0.0007340238430064809]
---- EP [1/5] | BTCH [651/3634] ||| train_loss = 0.00781 ----
LR: [0.0007350387010697148]
---- EP [1/5] | BTCH [652/3634] ||| train_loss = 0.00880 ----
LR: [0.0007360550427589225]
---- EP [1/5] | BTCH [653/3634] ||| train_loss = 0.01369 ----
LR: [0.0007370728677363932]
---- EP [1/5] | BTCH [654/3634] ||| train_loss = 0.02441 ----
LR: [0.0007380921756639184]
---- EP [1/5] | BTCH [655/3634] ||| train_loss = 0.01076 ----
LR: [0.0007391129662028036]
---- EP [1/5] | BTCH [656/3634] ||| train_loss = 0.00585 ----
LR: [0.000740135239013855]
---- EP [1/5] | BTCH [657/3634] ||| train_loss = 0.00976 ----
LR: [0.0007411589937573928]
---- EP [1/5] | BTCH [658/3634] ||| train_loss = 0.01816 ----
LR: [0.0007421842300932412]
---- EP [1/5] | BTCH [659/3634] ||| train_loss = 0.00988 ----
LR: [0.0007432109476807336]
---- EP [1/5] | BTCH [660/3634] ||| train_loss = 0.01456 ----
LR: [0.0007442391461787087]
---- EP [1/5] | BTCH [661/3634] ||| train_loss = 0.00965 ----
LR: [0.0007452688252455146]
---- EP [1/5] | BTCH [662/3634] ||| train_loss = 0.00983 ----
LR: [0.0007462999845390082]
---- EP [1/5] | BTCH [663/3634] ||| train_loss = 0.00908 ----
LR: [0.000747332623716554]
---- EP [1/5] | BTCH [664/3634] ||| train_loss = 0.00858 ----
LR: [0.0007483667424350235]
---- EP [1/5] | BTCH [665/3634] ||| train_loss = 0.01185 ----
LR: [0.0007494023403508011]
---- EP [1/5] | BTCH [666/3634] ||| train_loss = 0.01066 ----
LR: [0.0007504394171197731]
---- EP [1/5] | BTCH [667/3634] ||| train_loss = 0.00552 ----
LR: [0.0007514779723973367]
---- EP [1/5] | BTCH [668/3634] ||| train_loss = 0.01100 ----
LR: [0.0007525180058384033]
---- EP [1/5] | BTCH [669/3634] ||| train_loss = 0.00992 ----
LR: [0.0007535595170973831]
---- EP [1/5] | BTCH [670/3634] ||| train_loss = 0.01585 ----
LR: [0.0007546025058282058]
---- EP [1/5] | BTCH [671/3634] ||| train_loss = 0.01678 ----
LR: [0.0007556469716843012]
---- EP [1/5] | BTCH [672/3634] ||| train_loss = 0.00888 ----
LR: [0.0007566929143186154]
---- EP [1/5] | BTCH [673/3634] ||| train_loss = 0.01350 ----
LR: [0.0007577403333835966]
---- EP [1/5] | BTCH [674/3634] ||| train_loss = 0.01542 ----
LR: [0.0007587892285312106]
---- EP [1/5] | BTCH [675/3634] ||| train_loss = 0.00659 ----
LR: [0.0007598395994129255]
---- EP [1/5] | BTCH [676/3634] ||| train_loss = 0.01975 ----
LR: [0.0007608914456797237]
---- EP [1/5] | BTCH [677/3634] ||| train_loss = 0.00663 ----
LR: [0.0007619447669820947]
---- EP [1/5] | BTCH [678/3634] ||| train_loss = 0.01483 ----
LR: [0.000762999562970039]
---- EP [1/5] | BTCH [679/3634] ||| train_loss = 0.01116 ----
LR: [0.0007640558332930678]
---- EP [1/5] | BTCH [680/3634] ||| train_loss = 0.01390 ----
LR: [0.0007651135776001999]
---- EP [1/5] | BTCH [681/3634] ||| train_loss = 0.01036 ----
LR: [0.000766172795539968]
---- EP [1/5] | BTCH [682/3634] ||| train_loss = 0.01383 ----
LR: [0.0007672334867604106]
---- EP [1/5] | BTCH [683/3634] ||| train_loss = 0.01386 ----
LR: [0.0007682956509090823]
---- EP [1/5] | BTCH [684/3634] ||| train_loss = 0.01139 ----
LR: [0.0007693592876330431]
---- EP [1/5] | BTCH [685/3634] ||| train_loss = 0.01244 ----
LR: [0.0007704243965788674]
---- EP [1/5] | BTCH [686/3634] ||| train_loss = 0.01257 ----
LR: [0.0007714909773926353]
---- EP [1/5] | BTCH [687/3634] ||| train_loss = 0.00727 ----
LR: [0.0007725590297199443]
---- EP [1/5] | BTCH [688/3634] ||| train_loss = 0.02108 ----
LR: [0.0007736285532058979]
---- EP [1/5] | BTCH [689/3634] ||| train_loss = 0.01343 ----
LR: [0.0007746995474951172]
---- EP [1/5] | BTCH [690/3634] ||| train_loss = 0.01306 ----
LR: [0.0007757720122317253]
---- EP [1/5] | BTCH [691/3634] ||| train_loss = 0.01488 ----
LR: [0.0007768459470593615]
---- EP [1/5] | BTCH [692/3634] ||| train_loss = 0.01381 ----
LR: [0.0007779213516211792]
---- EP [1/5] | BTCH [693/3634] ||| train_loss = 0.01814 ----
LR: [0.0007789982255598411]
---- EP [1/5] | BTCH [694/3634] ||| train_loss = 0.01202 ----
LR: [0.0007800765685175171]
---- EP [1/5] | BTCH [695/3634] ||| train_loss = 0.00666 ----
LR: [0.0007811563801359]
---- EP [1/5] | BTCH [696/3634] ||| train_loss = 0.01472 ----
LR: [0.0007822376600561832]
---- EP [1/5] | BTCH [697/3634] ||| train_loss = 0.00862 ----
LR: [0.0007833204079190775]
---- EP [1/5] | BTCH [698/3634] ||| train_loss = 0.00972 ----
LR: [0.0007844046233648084]
---- EP [1/5] | BTCH [699/3634] ||| train_loss = 0.01835 ----
LR: [0.0007854903060331066]
---- EP [1/5] | BTCH [700/3634] ||| train_loss = 0.01163 ----
LR: [0.0007865774555632209]
---- EP [1/5] | BTCH [701/3634] ||| train_loss = 0.00806 ----
LR: [0.0007876660715939107]
---- EP [1/5] | BTCH [702/3634] ||| train_loss = 0.01289 ----
LR: [0.0007887561537634497]
---- EP [1/5] | BTCH [703/3634] ||| train_loss = 0.00951 ----
LR: [0.0007898477017096242]
---- EP [1/5] | BTCH [704/3634] ||| train_loss = 0.01581 ----
LR: [0.0007909407150697295]
---- EP [1/5] | BTCH [705/3634] ||| train_loss = 0.00962 ----
LR: [0.0007920351934805787]
---- EP [1/5] | BTCH [706/3634] ||| train_loss = 0.01046 ----
LR: [0.0007931311365784958]
---- EP [1/5] | BTCH [707/3634] ||| train_loss = 0.01068 ----
LR: [0.0007942285439993223]
---- EP [1/5] | BTCH [708/3634] ||| train_loss = 0.01213 ----
LR: [0.0007953274153784037]
---- EP [1/5] | BTCH [709/3634] ||| train_loss = 0.01142 ----
LR: [0.0007964277503506086]
---- EP [1/5] | BTCH [710/3634] ||| train_loss = 0.01319 ----
LR: [0.0007975295485503145]
---- EP [1/5] | BTCH [711/3634] ||| train_loss = 0.01701 ----
LR: [0.0007986328096114131]
---- EP [1/5] | BTCH [712/3634] ||| train_loss = 0.00803 ----
LR: [0.0007997375331673124]
---- EP [1/5] | BTCH [713/3634] ||| train_loss = 0.00745 ----
LR: [0.0008008437188509309]
---- EP [1/5] | BTCH [714/3634] ||| train_loss = 0.01068 ----
LR: [0.000801951366294705]
---- EP [1/5] | BTCH [715/3634] ||| train_loss = 0.01186 ----
LR: [0.000803060475130582]
---- EP [1/5] | BTCH [716/3634] ||| train_loss = 0.01229 ----
LR: [0.000804171044990025]
---- EP [1/5] | BTCH [717/3634] ||| train_loss = 0.01068 ----
LR: [0.0008052830755040132]
---- EP [1/5] | BTCH [718/3634] ||| train_loss = 0.01106 ----
LR: [0.0008063965663030366]
---- EP [1/5] | BTCH [719/3634] ||| train_loss = 0.01375 ----
LR: [0.0008075115170171048]
---- EP [1/5] | BTCH [720/3634] ||| train_loss = 0.01014 ----
LR: [0.0008086279272757381]
---- EP [1/5] | BTCH [721/3634] ||| train_loss = 0.02395 ----
LR: [0.0008097457967079745]
---- EP [1/5] | BTCH [722/3634] ||| train_loss = 0.00898 ----
LR: [0.0008108651249423681]
---- EP [1/5] | BTCH [723/3634] ||| train_loss = 0.01709 ----
LR: [0.0008119859116069803]
---- EP [1/5] | BTCH [724/3634] ||| train_loss = 0.01036 ----
LR: [0.000813108156329399]
---- EP [1/5] | BTCH [725/3634] ||| train_loss = 0.01430 ----
LR: [0.0008142318587367227]
---- EP [1/5] | BTCH [726/3634] ||| train_loss = 0.01086 ----
VAL ||| loss = 0.01302536685602097, psnr = 30.80040740966797, ssim = 0.909324049949646
LR: [0.0008153570184555627]
---- EP [1/5] | BTCH [727/3634] ||| train_loss = 0.01793 ----
LR: [0.0008164836351120495]
---- EP [1/5] | BTCH [728/3634] ||| train_loss = 0.01263 ----
LR: [0.00081761170833183]
---- EP [1/5] | BTCH [729/3634] ||| train_loss = 0.01708 ----
LR: [0.000818741237740065]
---- EP [1/5] | BTCH [730/3634] ||| train_loss = 0.01049 ----
LR: [0.0008198722229614316]
---- EP [1/5] | BTCH [731/3634] ||| train_loss = 0.01297 ----
LR: [0.000821004663620126]
---- EP [1/5] | BTCH [732/3634] ||| train_loss = 0.01346 ----
LR: [0.0008221385593398557]
---- EP [1/5] | BTCH [733/3634] ||| train_loss = 0.00945 ----
LR: [0.0008232739097438508]
---- EP [1/5] | BTCH [734/3634] ||| train_loss = 0.01371 ----
LR: [0.0008244107144548523]
---- EP [1/5] | BTCH [735/3634] ||| train_loss = 0.01227 ----
LR: [0.0008255489730951224]
---- EP [1/5] | BTCH [736/3634] ||| train_loss = 0.01172 ----
LR: [0.000826688685286436]
---- EP [1/5] | BTCH [737/3634] ||| train_loss = 0.00467 ----
LR: [0.0008278298506500907]
---- EP [1/5] | BTCH [738/3634] ||| train_loss = 0.01393 ----
LR: [0.0008289724688068951]
---- EP [1/5] | BTCH [739/3634] ||| train_loss = 0.00886 ----
LR: [0.0008301165393771789]
---- EP [1/5] | BTCH [740/3634] ||| train_loss = 0.01053 ----
LR: [0.0008312620619807878]
---- EP [1/5] | BTCH [741/3634] ||| train_loss = 0.01072 ----
LR: [0.0008324090362370855]
---- EP [1/5] | BTCH [742/3634] ||| train_loss = 0.01207 ----
LR: [0.0008335574617649513]
---- EP [1/5] | BTCH [743/3634] ||| train_loss = 0.01142 ----
LR: [0.0008347073381827878]
---- EP [1/5] | BTCH [744/3634] ||| train_loss = 0.00903 ----
LR: [0.0008358586651085083]
---- EP [1/5] | BTCH [745/3634] ||| train_loss = 0.01904 ----
LR: [0.0008370114421595506]
---- EP [1/5] | BTCH [746/3634] ||| train_loss = 0.01168 ----
LR: [0.0008381656689528654]
---- EP [1/5] | BTCH [747/3634] ||| train_loss = 0.01415 ----
LR: [0.0008393213451049278]
---- EP [1/5] | BTCH [748/3634] ||| train_loss = 0.00989 ----
LR: [0.000840478470231722]
---- EP [1/5] | BTCH [749/3634] ||| train_loss = 0.01247 ----
LR: [0.0008416370439487588]
---- EP [1/5] | BTCH [750/3634] ||| train_loss = 0.00677 ----
LR: [0.0008427970658710683]
---- EP [1/5] | BTCH [751/3634] ||| train_loss = 0.00892 ----
LR: [0.0008439585356131898]
---- EP [1/5] | BTCH [752/3634] ||| train_loss = 0.00753 ----
LR: [0.0008451214527891923]
---- EP [1/5] | BTCH [753/3634] ||| train_loss = 0.01212 ----
LR: [0.0008462858170126594]
---- EP [1/5] | BTCH [754/3634] ||| train_loss = 0.01408 ----
LR: [0.0008474516278966903]
---- EP [1/5] | BTCH [755/3634] ||| train_loss = 0.02466 ----
LR: [0.0008486188850539127]
---- EP [1/5] | BTCH [756/3634] ||| train_loss = 0.00859 ----
LR: [0.000849787588096465]
---- EP [1/5] | BTCH [757/3634] ||| train_loss = 0.01062 ----
LR: [0.0008509577366360068]
---- EP [1/5] | BTCH [758/3634] ||| train_loss = 0.01142 ----
LR: [0.0008521293302837189]
---- EP [1/5] | BTCH [759/3634] ||| train_loss = 0.00706 ----
LR: [0.0008533023686503067]
---- EP [1/5] | BTCH [760/3634] ||| train_loss = 0.01837 ----
LR: [0.0008544768513459849]
---- EP [1/5] | BTCH [761/3634] ||| train_loss = 0.01243 ----
LR: [0.0008556527779804996]
---- EP [1/5] | BTCH [762/3634] ||| train_loss = 0.01281 ----
LR: [0.0008568301481631062]
---- EP [1/5] | BTCH [763/3634] ||| train_loss = 0.01333 ----
LR: [0.0008580089615025897]
---- EP [1/5] | BTCH [764/3634] ||| train_loss = 0.01682 ----
LR: [0.000859189217607248]
---- EP [1/5] | BTCH [765/3634] ||| train_loss = 0.01812 ----
LR: [0.0008603709160849085]
---- EP [1/5] | BTCH [766/3634] ||| train_loss = 0.01240 ----
LR: [0.0008615540565429115]
---- EP [1/5] | BTCH [767/3634] ||| train_loss = 0.00984 ----
LR: [0.0008627386385881182]
---- EP [1/5] | BTCH [768/3634] ||| train_loss = 0.01215 ----
LR: [0.0008639246618269182]
---- EP [1/5] | BTCH [769/3634] ||| train_loss = 0.01690 ----
LR: [0.0008651121258652136]
---- EP [1/5] | BTCH [770/3634] ||| train_loss = 0.01330 ----
LR: [0.0008663010303084345]
---- EP [1/5] | BTCH [771/3634] ||| train_loss = 0.01588 ----
LR: [0.0008674913747615271]
---- EP [1/5] | BTCH [772/3634] ||| train_loss = 0.00969 ----
LR: [0.0008686831588289624]
---- EP [1/5] | BTCH [773/3634] ||| train_loss = 0.00956 ----
LR: [0.0008698763821147308]
---- EP [1/5] | BTCH [774/3634] ||| train_loss = 0.01411 ----
LR: [0.000871071044222349]
---- EP [1/5] | BTCH [775/3634] ||| train_loss = 0.00906 ----
LR: [0.00087226714475485]
---- EP [1/5] | BTCH [776/3634] ||| train_loss = 0.01044 ----
LR: [0.0008734646833147893]
---- EP [1/5] | BTCH [777/3634] ||| train_loss = 0.00526 ----
LR: [0.000874663659504251]
---- EP [1/5] | BTCH [778/3634] ||| train_loss = 0.00769 ----
LR: [0.0008758640729248351]
---- EP [1/5] | BTCH [779/3634] ||| train_loss = 0.01071 ----
LR: [0.0008770659231776643]
---- EP [1/5] | BTCH [780/3634] ||| train_loss = 0.01166 ----
LR: [0.0008782692098633863]
---- EP [1/5] | BTCH [781/3634] ||| train_loss = 0.01343 ----
LR: [0.0008794739325821716]
---- EP [1/5] | BTCH [782/3634] ||| train_loss = 0.01519 ----
LR: [0.000880680090933712]
---- EP [1/5] | BTCH [783/3634] ||| train_loss = 0.00971 ----
LR: [0.000881887684517222]
---- EP [1/5] | BTCH [784/3634] ||| train_loss = 0.00927 ----
LR: [0.0008830967129314429]
---- EP [1/5] | BTCH [785/3634] ||| train_loss = 0.01183 ----
LR: [0.0008843071757746318]
---- EP [1/5] | BTCH [786/3634] ||| train_loss = 0.01122 ----
LR: [0.0008855190726445791]
---- EP [1/5] | BTCH [787/3634] ||| train_loss = 0.00720 ----
LR: [0.0008867324031385897]
---- EP [1/5] | BTCH [788/3634] ||| train_loss = 0.01445 ----
LR: [0.0008879471668534963]
---- EP [1/5] | BTCH [789/3634] ||| train_loss = 0.00867 ----
LR: [0.0008891633633856567]
---- EP [1/5] | BTCH [790/3634] ||| train_loss = 0.00945 ----
LR: [0.000890380992330948]
---- EP [1/5] | BTCH [791/3634] ||| train_loss = 0.00675 ----
LR: [0.000891600053284777]
---- EP [1/5] | BTCH [792/3634] ||| train_loss = 0.02022 ----
LR: [0.0008928205458420685]
---- EP [1/5] | BTCH [793/3634] ||| train_loss = 0.01046 ----
LR: [0.0008940424695972771]
---- EP [1/5] | BTCH [794/3634] ||| train_loss = 0.01024 ----
LR: [0.0008952658241443805]
---- EP [1/5] | BTCH [795/3634] ||| train_loss = 0.00933 ----
LR: [0.0008964906090768773]
---- EP [1/5] | BTCH [796/3634] ||| train_loss = 0.01163 ----
LR: [0.0008977168239877962]
---- EP [1/5] | BTCH [797/3634] ||| train_loss = 0.02830 ----
LR: [0.0008989444684696854]
---- EP [1/5] | BTCH [798/3634] ||| train_loss = 0.01428 ----
LR: [0.0009001735421146229]
---- EP [1/5] | BTCH [799/3634] ||| train_loss = 0.00896 ----
LR: [0.0009014040445142115]
---- EP [1/5] | BTCH [800/3634] ||| train_loss = 0.02408 ----
LR: [0.0009026359752595733]
---- EP [1/5] | BTCH [801/3634] ||| train_loss = 0.00713 ----
LR: [0.0009038693339413623]
---- EP [1/5] | BTCH [802/3634] ||| train_loss = 0.01298 ----
LR: [0.000905104120149755]
---- EP [1/5] | BTCH [803/3634] ||| train_loss = 0.00996 ----
LR: [0.0009063403334744532]
---- EP [1/5] | BTCH [804/3634] ||| train_loss = 0.01527 ----
LR: [0.0009075779735046897]
---- EP [1/5] | BTCH [805/3634] ||| train_loss = 0.01220 ----
LR: [0.0009088170398292138]
---- EP [1/5] | BTCH [806/3634] ||| train_loss = 0.00794 ----
LR: [0.0009100575320363114]
---- EP [1/5] | BTCH [807/3634] ||| train_loss = 0.01421 ----
LR: [0.0009112994497137844]
---- EP [1/5] | BTCH [808/3634] ||| train_loss = 0.00714 ----
LR: [0.0009125427924489681]
---- EP [1/5] | BTCH [809/3634] ||| train_loss = 0.00640 ----
LR: [0.0009137875598287225]
---- EP [1/5] | BTCH [810/3634] ||| train_loss = 0.01382 ----
LR: [0.0009150337514394341]
---- EP [1/5] | BTCH [811/3634] ||| train_loss = 0.00925 ----
LR: [0.0009162813668670156]
---- EP [1/5] | BTCH [812/3634] ||| train_loss = 0.01191 ----
LR: [0.0009175304056969064]
---- EP [1/5] | BTCH [813/3634] ||| train_loss = 0.00809 ----
LR: [0.0009187808675140737]
---- EP [1/5] | BTCH [814/3634] ||| train_loss = 0.00846 ----
LR: [0.0009200327519030133]
---- EP [1/5] | BTCH [815/3634] ||| train_loss = 0.00728 ----
LR: [0.0009212860584477435]
---- EP [1/5] | BTCH [816/3634] ||| train_loss = 0.01486 ----
LR: [0.0009225407867318163]
---- EP [1/5] | BTCH [817/3634] ||| train_loss = 0.00683 ----
LR: [0.0009237969363383048]
---- EP [1/5] | BTCH [818/3634] ||| train_loss = 0.01319 ----
LR: [0.0009250545068498154]
---- EP [1/5] | BTCH [819/3634] ||| train_loss = 0.01319 ----
LR: [0.0009263134978484792]
---- EP [1/5] | BTCH [820/3634] ||| train_loss = 0.01099 ----
LR: [0.0009275739089159591]
---- EP [1/5] | BTCH [821/3634] ||| train_loss = 0.01716 ----
LR: [0.000928835739633439]
---- EP [1/5] | BTCH [822/3634] ||| train_loss = 0.00841 ----
LR: [0.0009300989895816378]
---- EP [1/5] | BTCH [823/3634] ||| train_loss = 0.01818 ----
LR: [0.0009313636583408013]
---- EP [1/5] | BTCH [824/3634] ||| train_loss = 0.01179 ----
LR: [0.0009326297454906995]
---- EP [1/5] | BTCH [825/3634] ||| train_loss = 0.00766 ----
LR: [0.0009338972506106376]
---- EP [1/5] | BTCH [826/3634] ||| train_loss = 0.01047 ----
LR: [0.0009351661732794458]
---- EP [1/5] | BTCH [827/3634] ||| train_loss = 0.01105 ----
LR: [0.0009364365130754837]
---- EP [1/5] | BTCH [828/3634] ||| train_loss = 0.01186 ----
LR: [0.0009377082695766394]
---- EP [1/5] | BTCH [829/3634] ||| train_loss = 0.01838 ----
LR: [0.0009389814423603326]
---- EP [1/5] | BTCH [830/3634] ||| train_loss = 0.00995 ----
LR: [0.000940256031003511]
---- EP [1/5] | BTCH [831/3634] ||| train_loss = 0.01472 ----
LR: [0.0009415320350826505]
---- EP [1/5] | BTCH [832/3634] ||| train_loss = 0.01332 ----
LR: [0.0009428094541737587]
---- EP [1/5] | BTCH [833/3634] ||| train_loss = 0.00830 ----
LR: [0.0009440882878523731]
---- EP [1/5] | BTCH [834/3634] ||| train_loss = 0.01218 ----
LR: [0.0009453685356935609]
---- EP [1/5] | BTCH [835/3634] ||| train_loss = 0.01741 ----
LR: [0.0009466501972719161]
---- EP [1/5] | BTCH [836/3634] ||| train_loss = 0.00929 ----
LR: [0.0009479332721615691]
---- EP [1/5] | BTCH [837/3634] ||| train_loss = 0.01072 ----
LR: [0.0009492177599361717]
---- EP [1/5] | BTCH [838/3634] ||| train_loss = 0.01283 ----
LR: [0.0009505036601689179]
---- EP [1/5] | BTCH [839/3634] ||| train_loss = 0.00780 ----
LR: [0.0009517909724325261]
---- EP [1/5] | BTCH [840/3634] ||| train_loss = 0.01193 ----
LR: [0.0009530796962992413]
---- EP [1/5] | BTCH [841/3634] ||| train_loss = 0.01050 ----
LR: [0.0009543698313408469]
---- EP [1/5] | BTCH [842/3634] ||| train_loss = 0.00988 ----
LR: [0.000955661377128653]
---- EP [1/5] | BTCH [843/3634] ||| train_loss = 0.02044 ----
LR: [0.0009569543332335027]
---- EP [1/5] | BTCH [844/3634] ||| train_loss = 0.01386 ----
LR: [0.0009582486992257711]
---- EP [1/5] | BTCH [845/3634] ||| train_loss = 0.01497 ----
LR: [0.0009595444746753629]
---- EP [1/5] | BTCH [846/3634] ||| train_loss = 0.00839 ----
LR: [0.0009608416591517146]
---- EP [1/5] | BTCH [847/3634] ||| train_loss = 0.01854 ----
LR: [0.0009621402522237959]
---- EP [1/5] | BTCH [848/3634] ||| train_loss = 0.02239 ----
LR: [0.0009634402534601065]
---- EP [1/5] | BTCH [849/3634] ||| train_loss = 0.01949 ----
LR: [0.000964741662428683]
---- EP [1/5] | BTCH [850/3634] ||| train_loss = 0.01422 ----
LR: [0.0009660444786970881]
---- EP [1/5] | BTCH [851/3634] ||| train_loss = 0.00597 ----
LR: [0.0009673487018324201]
---- EP [1/5] | BTCH [852/3634] ||| train_loss = 0.01650 ----
LR: [0.0009686543314013085]
---- EP [1/5] | BTCH [853/3634] ||| train_loss = 0.00962 ----
LR: [0.0009699613669699163]
---- EP [1/5] | BTCH [854/3634] ||| train_loss = 0.00715 ----
LR: [0.0009712698081039382]
---- EP [1/5] | BTCH [855/3634] ||| train_loss = 0.00670 ----
LR: [0.0009725796543686074]
---- EP [1/5] | BTCH [856/3634] ||| train_loss = 0.00892 ----
LR: [0.0009738909053286799]
---- EP [1/5] | BTCH [857/3634] ||| train_loss = 0.01460 ----
LR: [0.000975203560548454]
---- EP [1/5] | BTCH [858/3634] ||| train_loss = 0.01585 ----
LR: [0.0009765176195917578]
---- EP [1/5] | BTCH [859/3634] ||| train_loss = 0.01111 ----
LR: [0.0009778330820219543]
---- EP [1/5] | BTCH [860/3634] ||| train_loss = 0.01684 ----
LR: [0.000979149947401935]
---- EP [1/5] | BTCH [861/3634] ||| train_loss = 0.00908 ----
LR: [0.0009804682152941332]
---- EP [1/5] | BTCH [862/3634] ||| train_loss = 0.00990 ----
LR: [0.0009817878852605103]
---- EP [1/5] | BTCH [863/3634] ||| train_loss = 0.01314 ----
LR: [0.0009831089568625665]
---- EP [1/5] | BTCH [864/3634] ||| train_loss = 0.00919 ----
LR: [0.0009844314296613282]
---- EP [1/5] | BTCH [865/3634] ||| train_loss = 0.01288 ----
LR: [0.0009857553032173675]
---- EP [1/5] | BTCH [866/3634] ||| train_loss = 0.00821 ----
LR: [0.000987080577090781]
---- EP [1/5] | BTCH [867/3634] ||| train_loss = 0.01831 ----
LR: [0.0009884072508412074]
---- EP [1/5] | BTCH [868/3634] ||| train_loss = 0.01423 ----
LR: [0.0009897353240278135]
---- EP [1/5] | BTCH [869/3634] ||| train_loss = 0.01308 ----
LR: [0.0009910647962093084]
---- EP [1/5] | BTCH [870/3634] ||| train_loss = 0.01472 ----
LR: [0.0009923956669439307]
---- EP [1/5] | BTCH [871/3634] ||| train_loss = 0.01164 ----
LR: [0.0009937279357894544]
---- EP [1/5] | BTCH [872/3634] ||| train_loss = 0.00905 ----
LR: [0.000995061602303192]
---- EP [1/5] | BTCH [873/3634] ||| train_loss = 0.00981 ----
LR: [0.0009963966660419907]
---- EP [1/5] | BTCH [874/3634] ||| train_loss = 0.01599 ----
LR: [0.0009977331265622336]
---- EP [1/5] | BTCH [875/3634] ||| train_loss = 0.01166 ----
LR: [0.0009990709834198364]
---- EP [1/5] | BTCH [876/3634] ||| train_loss = 0.01534 ----
LR: [0.0010004102361702554]
---- EP [1/5] | BTCH [877/3634] ||| train_loss = 0.01183 ----
LR: [0.0010017508843684821]
---- EP [1/5] | BTCH [878/3634] ||| train_loss = 0.01173 ----
LR: [0.0010030929275690412]
---- EP [1/5] | BTCH [879/3634] ||| train_loss = 0.01306 ----
LR: [0.001004436365325996]
---- EP [1/5] | BTCH [880/3634] ||| train_loss = 0.01323 ----
LR: [0.0010057811971929485]
---- EP [1/5] | BTCH [881/3634] ||| train_loss = 0.00666 ----
LR: [0.001007127422723032]
---- EP [1/5] | BTCH [882/3634] ||| train_loss = 0.01341 ----
LR: [0.0010084750414689255]
---- EP [1/5] | BTCH [883/3634] ||| train_loss = 0.01360 ----
LR: [0.0010098240529828346]
---- EP [1/5] | BTCH [884/3634] ||| train_loss = 0.02054 ----
LR: [0.0010111744568165066]
---- EP [1/5] | BTCH [885/3634] ||| train_loss = 0.02446 ----
LR: [0.001012526252521231]
---- EP [1/5] | BTCH [886/3634] ||| train_loss = 0.03032 ----
LR: [0.001013879439647829]
---- EP [1/5] | BTCH [887/3634] ||| train_loss = 0.01782 ----
LR: [0.0010152340177466586]
---- EP [1/5] | BTCH [888/3634] ||| train_loss = 0.01579 ----
LR: [0.0010165899863676213]
---- EP [1/5] | BTCH [889/3634] ||| train_loss = 0.01219 ----
LR: [0.0010179473450601505]
---- EP [1/5] | BTCH [890/3634] ||| train_loss = 0.00951 ----
LR: [0.0010193060933732217]
---- EP [1/5] | BTCH [891/3634] ||| train_loss = 0.01380 ----
LR: [0.0010206662308553487]
---- EP [1/5] | BTCH [892/3634] ||| train_loss = 0.01057 ----
LR: [0.0010220277570545805]
---- EP [1/5] | BTCH [893/3634] ||| train_loss = 0.01285 ----
LR: [0.0010233906715185065]
---- EP [1/5] | BTCH [894/3634] ||| train_loss = 0.01620 ----
LR: [0.0010247549737942546]
---- EP [1/5] | BTCH [895/3634] ||| train_loss = 0.01029 ----
LR: [0.0010261206634284946]
---- EP [1/5] | BTCH [896/3634] ||| train_loss = 0.01062 ----
LR: [0.0010274877399674281]
---- EP [1/5] | BTCH [897/3634] ||| train_loss = 0.00767 ----
LR: [0.001028856202956804]
---- EP [1/5] | BTCH [898/3634] ||| train_loss = 0.01813 ----
LR: [0.0010302260519419043]
---- EP [1/5] | BTCH [899/3634] ||| train_loss = 0.01098 ----
LR: [0.001031597286467555]
---- EP [1/5] | BTCH [900/3634] ||| train_loss = 0.00777 ----
LR: [0.0010329699060781187]
---- EP [1/5] | BTCH [901/3634] ||| train_loss = 0.01284 ----
LR: [0.0010343439103174985]
---- EP [1/5] | BTCH [902/3634] ||| train_loss = 0.01368 ----
LR: [0.0010357192987291378]
---- EP [1/5] | BTCH [903/3634] ||| train_loss = 0.01446 ----
LR: [0.0010370960708560202]
---- EP [1/5] | BTCH [904/3634] ||| train_loss = 0.01384 ----
LR: [0.0010384742262406696]
---- EP [1/5] | BTCH [905/3634] ||| train_loss = 0.01944 ----
LR: [0.0010398537644251485]
---- EP [1/5] | BTCH [906/3634] ||| train_loss = 0.01324 ----
LR: [0.0010412346849510597]
---- EP [1/5] | BTCH [907/3634] ||| train_loss = 0.00688 ----
LR: [0.0010426169873595532]
---- EP [1/5] | BTCH [908/3634] ||| train_loss = 0.01173 ----
LR: [0.0010440006711913107]
---- EP [1/5] | BTCH [909/3634] ||| train_loss = 0.00481 ----
LR: [0.001045385735986561]
---- EP [1/5] | BTCH [910/3634] ||| train_loss = 0.00961 ----
LR: [0.0010467721812850734]
---- EP [1/5] | BTCH [911/3634] ||| train_loss = 0.01359 ----
LR: [0.0010481600066261521]
---- EP [1/5] | BTCH [912/3634] ||| train_loss = 0.00882 ----
LR: [0.0010495492115486522]
---- EP [1/5] | BTCH [913/3634] ||| train_loss = 0.01269 ----
LR: [0.001050939795590967]
---- EP [1/5] | BTCH [914/3634] ||| train_loss = 0.00716 ----
LR: [0.0010523317582910273]
---- EP [1/5] | BTCH [915/3634] ||| train_loss = 0.01338 ----
LR: [0.0010537250991863086]
---- EP [1/5] | BTCH [916/3634] ||| train_loss = 0.01344 ----
LR: [0.0010551198178138325]
---- EP [1/5] | BTCH [917/3634] ||| train_loss = 0.01407 ----
LR: [0.0010565159137101553]
---- EP [1/5] | BTCH [918/3634] ||| train_loss = 0.01556 ----
LR: [0.0010579133864113827]
---- EP [1/5] | BTCH [919/3634] ||| train_loss = 0.00974 ----
LR: [0.0010593122354531585]
---- EP [1/5] | BTCH [920/3634] ||| train_loss = 0.01361 ----
LR: [0.0010607124603706705]
---- EP [1/5] | BTCH [921/3634] ||| train_loss = 0.00970 ----
LR: [0.0010621140606986487]
---- EP [1/5] | BTCH [922/3634] ||| train_loss = 0.00703 ----
LR: [0.0010635170359713682]
---- EP [1/5] | BTCH [923/3634] ||| train_loss = 0.01070 ----
LR: [0.001064921385722643]
---- EP [1/5] | BTCH [924/3634] ||| train_loss = 0.00970 ----
LR: [0.001066327109485836]
---- EP [1/5] | BTCH [925/3634] ||| train_loss = 0.00856 ----
LR: [0.0010677342067938484]
---- EP [1/5] | BTCH [926/3634] ||| train_loss = 0.01755 ----
LR: [0.0010691426771791274]
---- EP [1/5] | BTCH [927/3634] ||| train_loss = 0.01682 ----
LR: [0.001070552520173667]
---- EP [1/5] | BTCH [928/3634] ||| train_loss = 0.01209 ----
LR: [0.0010719637353089981]
---- EP [1/5] | BTCH [929/3634] ||| train_loss = 0.00730 ----
LR: [0.0010733763221161992]
---- EP [1/5] | BTCH [930/3634] ||| train_loss = 0.01146 ----
LR: [0.0010747902801258938]
---- EP [1/5] | BTCH [931/3634] ||| train_loss = 0.00842 ----
LR: [0.001076205608868253]
---- EP [1/5] | BTCH [932/3634] ||| train_loss = 0.01484 ----
LR: [0.0010776223078729826]
---- EP [1/5] | BTCH [933/3634] ||| train_loss = 0.00941 ----
LR: [0.0010790403766693449]
---- EP [1/5] | BTCH [934/3634] ||| train_loss = 0.00958 ----
LR: [0.0010804598147861368]
---- EP [1/5] | BTCH [935/3634] ||| train_loss = 0.01367 ----
LR: [0.001081880621751706]
---- EP [1/5] | BTCH [936/3634] ||| train_loss = 0.01099 ----
LR: [0.0010833027970939442]
---- EP [1/5] | BTCH [937/3634] ||| train_loss = 0.01126 ----
LR: [0.00108472634034029]
---- EP [1/5] | BTCH [938/3634] ||| train_loss = 0.00970 ----
LR: [0.0010861512510177227]
---- EP [1/5] | BTCH [939/3634] ||| train_loss = 0.00904 ----
LR: [0.001087577528652772]
---- EP [1/5] | BTCH [940/3634] ||| train_loss = 0.00915 ----
LR: [0.0010890051727715094]
---- EP [1/5] | BTCH [941/3634] ||| train_loss = 0.00808 ----
LR: [0.0010904341828995578]
---- EP [1/5] | BTCH [942/3634] ||| train_loss = 0.00763 ----
LR: [0.0010918645585620834]
---- EP [1/5] | BTCH [943/3634] ||| train_loss = 0.01119 ----
LR: [0.0010932962992837945]
---- EP [1/5] | BTCH [944/3634] ||| train_loss = 0.01107 ----
LR: [0.00109472940458895]
---- EP [1/5] | BTCH [945/3634] ||| train_loss = 0.01323 ----
LR: [0.001096163874001358]
---- EP [1/5] | BTCH [946/3634] ||| train_loss = 0.01426 ----
LR: [0.0010975997070443687]
---- EP [1/5] | BTCH [947/3634] ||| train_loss = 0.00611 ----
LR: [0.001099036903240879]
---- EP [1/5] | BTCH [948/3634] ||| train_loss = 0.01309 ----
LR: [0.0011004754621133372]
---- EP [1/5] | BTCH [949/3634] ||| train_loss = 0.01244 ----
LR: [0.0011019153831837332]
---- EP [1/5] | BTCH [950/3634] ||| train_loss = 0.01650 ----
LR: [0.0011033566659736111]
---- EP [1/5] | BTCH [951/3634] ||| train_loss = 0.01098 ----
LR: [0.0011047993100040572]
---- EP [1/5] | BTCH [952/3634] ||| train_loss = 0.01821 ----
LR: [0.001106243314795705]
---- EP [1/5] | BTCH [953/3634] ||| train_loss = 0.00748 ----
LR: [0.0011076886798687385]
---- EP [1/5] | BTCH [954/3634] ||| train_loss = 0.01510 ----
LR: [0.0011091354047428892]
---- EP [1/5] | BTCH [955/3634] ||| train_loss = 0.01324 ----
LR: [0.0011105834889374392]
---- EP [1/5] | BTCH [956/3634] ||| train_loss = 0.01378 ----
LR: [0.0011120329319712127]
---- EP [1/5] | BTCH [957/3634] ||| train_loss = 0.02085 ----
LR: [0.0011134837333625879]
---- EP [1/5] | BTCH [958/3634] ||| train_loss = 0.01339 ----
LR: [0.0011149358926294903]
---- EP [1/5] | BTCH [959/3634] ||| train_loss = 0.01416 ----
LR: [0.0011163894092893912]
---- EP [1/5] | BTCH [960/3634] ||| train_loss = 0.01703 ----
LR: [0.0011178442828593139]
---- EP [1/5] | BTCH [961/3634] ||| train_loss = 0.01459 ----
LR: [0.0011193005128558309]
---- EP [1/5] | BTCH [962/3634] ||| train_loss = 0.01561 ----
LR: [0.0011207580987950636]
---- EP [1/5] | BTCH [963/3634] ||| train_loss = 0.01691 ----
LR: [0.0011222170401926843]
---- EP [1/5] | BTCH [964/3634] ||| train_loss = 0.00967 ----
LR: [0.0011236773365639087]
---- EP [1/5] | BTCH [965/3634] ||| train_loss = 0.01171 ----
LR: [0.0011251389874235105]
---- EP [1/5] | BTCH [966/3634] ||| train_loss = 0.00940 ----
LR: [0.0011266019922858053]
---- EP [1/5] | BTCH [967/3634] ||| train_loss = 0.01223 ----
LR: [0.001128066350664668]
---- EP [1/5] | BTCH [968/3634] ||| train_loss = 0.01132 ----
LR: [0.0011295320620735155]
---- EP [1/5] | BTCH [969/3634] ||| train_loss = 0.01365 ----
LR: [0.001130999126025321]
---- EP [1/5] | BTCH [970/3634] ||| train_loss = 0.01242 ----
LR: [0.0011324675420326027]
---- EP [1/5] | BTCH [971/3634] ||| train_loss = 0.01443 ----
LR: [0.001133937309607435]
---- EP [1/5] | BTCH [972/3634] ||| train_loss = 0.00919 ----
LR: [0.0011354084282614377]
---- EP [1/5] | BTCH [973/3634] ||| train_loss = 0.01148 ----
LR: [0.0011368808975057865]
---- EP [1/5] | BTCH [974/3634] ||| train_loss = 0.00732 ----
LR: [0.0011383547168512097]
---- EP [1/5] | BTCH [975/3634] ||| train_loss = 0.00858 ----
LR: [0.0011398298858079758]
---- EP [1/5] | BTCH [976/3634] ||| train_loss = 0.01344 ----
LR: [0.0011413064038859212]
---- EP [1/5] | BTCH [977/3634] ||| train_loss = 0.01240 ----
LR: [0.001142784270594421]
---- EP [1/5] | BTCH [978/3634] ||| train_loss = 0.01413 ----
LR: [0.0011442634854424063]
---- EP [1/5] | BTCH [979/3634] ||| train_loss = 0.01345 ----
LR: [0.001145744047938364]
---- EP [1/5] | BTCH [980/3634] ||| train_loss = 0.01354 ----
LR: [0.0011472259575903265]
---- EP [1/5] | BTCH [981/3634] ||| train_loss = 0.01126 ----
LR: [0.0011487092139058838]
---- EP [1/5] | BTCH [982/3634] ||| train_loss = 0.00919 ----
LR: [0.0011501938163921786]
---- EP [1/5] | BTCH [983/3634] ||| train_loss = 0.01401 ----
LR: [0.0011516797645559004]
---- EP [1/5] | BTCH [984/3634] ||| train_loss = 0.01427 ----
LR: [0.0011531670579032968]
---- EP [1/5] | BTCH [985/3634] ||| train_loss = 0.01415 ----
LR: [0.0011546556959401676]
---- EP [1/5] | BTCH [986/3634] ||| train_loss = 0.00973 ----
LR: [0.0011561456781718667]
---- EP [1/5] | BTCH [987/3634] ||| train_loss = 0.01173 ----
LR: [0.0011576370041032971]
---- EP [1/5] | BTCH [988/3634] ||| train_loss = 0.01375 ----
LR: [0.0011591296732389178]
---- EP [1/5] | BTCH [989/3634] ||| train_loss = 0.01209 ----
LR: [0.0011606236850827453]
---- EP [1/5] | BTCH [990/3634] ||| train_loss = 0.00632 ----
LR: [0.001162119039138345]
---- EP [1/5] | BTCH [991/3634] ||| train_loss = 0.00988 ----
LR: [0.0011636157349088367]
---- EP [1/5] | BTCH [992/3634] ||| train_loss = 0.00791 ----
LR: [0.001165113771896896]
---- EP [1/5] | BTCH [993/3634] ||| train_loss = 0.01365 ----
LR: [0.0011666131496047526]
---- EP [1/5] | BTCH [994/3634] ||| train_loss = 0.01553 ----
LR: [0.0011681138675341905]
---- EP [1/5] | BTCH [995/3634] ||| train_loss = 0.01841 ----
LR: [0.0011696159251865478]
---- EP [1/5] | BTCH [996/3634] ||| train_loss = 0.00657 ----
LR: [0.0011711193220627168]
---- EP [1/5] | BTCH [997/3634] ||| train_loss = 0.01208 ----
LR: [0.0011726240576631491]
---- EP [1/5] | BTCH [998/3634] ||| train_loss = 0.00948 ----
LR: [0.0011741301314878438]
---- EP [1/5] | BTCH [999/3634] ||| train_loss = 0.01110 ----
LR: [0.0011756375430363626]
---- EP [1/5] | BTCH [1000/3634] ||| train_loss = 0.01741 ----
LR: [0.0011771462918078197]
---- EP [1/5] | BTCH [1001/3634] ||| train_loss = 0.02034 ----
LR: [0.0011786563773008869]
---- EP [1/5] | BTCH [1002/3634] ||| train_loss = 0.01110 ----
LR: [0.001180167799013785]
---- EP [1/5] | BTCH [1003/3634] ||| train_loss = 0.01206 ----
LR: [0.0011816805564443013]
---- EP [1/5] | BTCH [1004/3634] ||| train_loss = 0.01413 ----
LR: [0.00118319464908977]
---- EP [1/5] | BTCH [1005/3634] ||| train_loss = 0.00958 ----
LR: [0.0011847100764470885]
---- EP [1/5] | BTCH [1006/3634] ||| train_loss = 0.00905 ----
LR: [0.0011862268380127047]
---- EP [1/5] | BTCH [1007/3634] ||| train_loss = 0.01262 ----
LR: [0.0011877449332826275]
---- EP [1/5] | BTCH [1008/3634] ||| train_loss = 0.01353 ----
LR: [0.0011892643617524203]
---- EP [1/5] | BTCH [1009/3634] ||| train_loss = 0.01103 ----
LR: [0.0011907851229172074]
---- EP [1/5] | BTCH [1010/3634] ||| train_loss = 0.01324 ----
LR: [0.0011923072162716639]
---- EP [1/5] | BTCH [1011/3634] ||| train_loss = 0.01147 ----
LR: [0.0011938306413100293]
---- EP [1/5] | BTCH [1012/3634] ||| train_loss = 0.00972 ----
LR: [0.001195355397526094]
---- EP [1/5] | BTCH [1013/3634] ||| train_loss = 0.01533 ----
LR: [0.0011968814844132095]
---- EP [1/5] | BTCH [1014/3634] ||| train_loss = 0.00851 ----
LR: [0.001198408901464285]
---- EP [1/5] | BTCH [1015/3634] ||| train_loss = 0.00822 ----
LR: [0.0011999376481717887]
---- EP [1/5] | BTCH [1016/3634] ||| train_loss = 0.01779 ----
LR: [0.0012014677240277435]
---- EP [1/5] | BTCH [1017/3634] ||| train_loss = 0.00926 ----
LR: [0.001202999128523733]
---- EP [1/5] | BTCH [1018/3634] ||| train_loss = 0.01213 ----
LR: [0.0012045318611509006]
---- EP [1/5] | BTCH [1019/3634] ||| train_loss = 0.01726 ----
LR: [0.0012060659213999469]
---- EP [1/5] | BTCH [1020/3634] ||| train_loss = 0.00868 ----
LR: [0.0012076013087611304]
---- EP [1/5] | BTCH [1021/3634] ||| train_loss = 0.01683 ----
LR: [0.0012091380227242706]
---- EP [1/5] | BTCH [1022/3634] ||| train_loss = 0.01074 ----
LR: [0.0012106760627787448]
---- EP [1/5] | BTCH [1023/3634] ||| train_loss = 0.00696 ----
LR: [0.0012122154284134896]
---- EP [1/5] | BTCH [1024/3634] ||| train_loss = 0.02121 ----
LR: [0.0012137561191170008]
---- EP [1/5] | BTCH [1025/3634] ||| train_loss = 0.00876 ----
LR: [0.0012152981343773375]
---- EP [1/5] | BTCH [1026/3634] ||| train_loss = 0.01256 ----
LR: [0.0012168414736821141]
---- EP [1/5] | BTCH [1027/3634] ||| train_loss = 0.01653 ----
LR: [0.001218386136518505]
---- EP [1/5] | BTCH [1028/3634] ||| train_loss = 0.01229 ----
LR: [0.0012199321223732504]
---- EP [1/5] | BTCH [1029/3634] ||| train_loss = 0.01169 ----
LR: [0.0012214794307326467]
---- EP [1/5] | BTCH [1030/3634] ||| train_loss = 0.01395 ----
LR: [0.0012230280610825463]
---- EP [1/5] | BTCH [1031/3634] ||| train_loss = 0.01219 ----
LR: [0.0012245780129083745]
---- EP [1/5] | BTCH [1032/3634] ||| train_loss = 0.01221 ----
LR: [0.0012261292856951059]
---- EP [1/5] | BTCH [1033/3634] ||| train_loss = 0.01502 ----
LR: [0.0012276818789272795]
---- EP [1/5] | BTCH [1034/3634] ||| train_loss = 0.00966 ----
LR: [0.0012292357920890007]
---- EP [1/5] | BTCH [1035/3634] ||| train_loss = 0.00996 ----
LR: [0.001230791024663929]
---- EP [1/5] | BTCH [1036/3634] ||| train_loss = 0.00760 ----
LR: [0.0012323475761352905]
---- EP [1/5] | BTCH [1037/3634] ||| train_loss = 0.01123 ----
LR: [0.0012339054459858702]
---- EP [1/5] | BTCH [1038/3634] ||| train_loss = 0.00947 ----
LR: [0.001235464633698018]
---- EP [1/5] | BTCH [1039/3634] ||| train_loss = 0.01333 ----
LR: [0.0012370251387536398]
---- EP [1/5] | BTCH [1040/3634] ||| train_loss = 0.02055 ----
LR: [0.0012385869606342127]
---- EP [1/5] | BTCH [1041/3634] ||| train_loss = 0.01384 ----
LR: [0.00124015009882077]
---- EP [1/5] | BTCH [1042/3634] ||| train_loss = 0.01140 ----
LR: [0.0012417145527939058]
---- EP [1/5] | BTCH [1043/3634] ||| train_loss = 0.01739 ----
LR: [0.0012432803220337844]
---- EP [1/5] | BTCH [1044/3634] ||| train_loss = 0.00672 ----
LR: [0.0012448474060201293]
---- EP [1/5] | BTCH [1045/3634] ||| train_loss = 0.01037 ----
LR: [0.0012464158042322232]
---- EP [1/5] | BTCH [1046/3634] ||| train_loss = 0.00761 ----
LR: [0.001247985516148917]
---- EP [1/5] | BTCH [1047/3634] ||| train_loss = 0.00794 ----
LR: [0.0012495565412486264]
---- EP [1/5] | BTCH [1048/3634] ||| train_loss = 0.01263 ----
LR: [0.0012511288790093243]
---- EP [1/5] | BTCH [1049/3634] ||| train_loss = 0.00914 ----
LR: [0.0012527025289085555]
---- EP [1/5] | BTCH [1050/3634] ||| train_loss = 0.01387 ----
LR: [0.0012542774904234204]
---- EP [1/5] | BTCH [1051/3634] ||| train_loss = 0.00670 ----
LR: [0.0012558537630305896]
---- EP [1/5] | BTCH [1052/3634] ||| train_loss = 0.00778 ----
LR: [0.001257431346206296]
---- EP [1/5] | BTCH [1053/3634] ||| train_loss = 0.02237 ----
LR: [0.0012590102394263395]
---- EP [1/5] | BTCH [1054/3634] ||| train_loss = 0.01615 ----
LR: [0.0012605904421660787]
---- EP [1/5] | BTCH [1055/3634] ||| train_loss = 0.01302 ----
LR: [0.0012621719539004424]
---- EP [1/5] | BTCH [1056/3634] ||| train_loss = 0.01382 ----
LR: [0.001263754774103924]
---- EP [1/5] | BTCH [1057/3634] ||| train_loss = 0.01275 ----
LR: [0.0012653389022505776]
---- EP [1/5] | BTCH [1058/3634] ||| train_loss = 0.01901 ----
LR: [0.0012669243378140294]
---- EP [1/5] | BTCH [1059/3634] ||| train_loss = 0.01036 ----
LR: [0.0012685110802674662]
---- EP [1/5] | BTCH [1060/3634] ||| train_loss = 0.00948 ----
LR: [0.0012700991290836433]
---- EP [1/5] | BTCH [1061/3634] ||| train_loss = 0.00893 ----
LR: [0.0012716884837348785]
---- EP [1/5] | BTCH [1062/3634] ||| train_loss = 0.00786 ----
LR: [0.0012732791436930613]
---- EP [1/5] | BTCH [1063/3634] ||| train_loss = 0.01020 ----
LR: [0.0012748711084296406]
---- EP [1/5] | BTCH [1064/3634] ||| train_loss = 0.01628 ----
LR: [0.0012764643774156384]
---- EP [1/5] | BTCH [1065/3634] ||| train_loss = 0.01318 ----
LR: [0.001278058950121638]
---- EP [1/5] | BTCH [1066/3634] ||| train_loss = 0.01124 ----
LR: [0.0012796548260177922]
---- EP [1/5] | BTCH [1067/3634] ||| train_loss = 0.01155 ----
LR: [0.0012812520045738206]
---- EP [1/5] | BTCH [1068/3634] ||| train_loss = 0.00884 ----
LR: [0.0012828504852590104]
---- EP [1/5] | BTCH [1069/3634] ||| train_loss = 0.01733 ----
LR: [0.0012844502675422136]
---- EP [1/5] | BTCH [1070/3634] ||| train_loss = 0.01364 ----
LR: [0.001286051350891852]
---- EP [1/5] | BTCH [1071/3634] ||| train_loss = 0.01355 ----
LR: [0.001287653734775917]
---- EP [1/5] | BTCH [1072/3634] ||| train_loss = 0.01219 ----
LR: [0.0012892574186619613]
---- EP [1/5] | BTCH [1073/3634] ||| train_loss = 0.00508 ----
LR: [0.0012908624020171126]
---- EP [1/5] | BTCH [1074/3634] ||| train_loss = 0.01630 ----
LR: [0.0012924686843080613]
---- EP [1/5] | BTCH [1075/3634] ||| train_loss = 0.00679 ----
LR: [0.001294076265001073]
---- EP [1/5] | BTCH [1076/3634] ||| train_loss = 0.01195 ----
LR: [0.0012956851435619744]
---- EP [1/5] | BTCH [1077/3634] ||| train_loss = 0.01307 ----
LR: [0.0012972953194561633]
---- EP [1/5] | BTCH [1078/3634] ||| train_loss = 0.01062 ----
LR: [0.0012989067921486113]
---- EP [1/5] | BTCH [1079/3634] ||| train_loss = 0.01087 ----
LR: [0.0013005195611038526]
---- EP [1/5] | BTCH [1080/3634] ||| train_loss = 0.01136 ----
LR: [0.001302133625785993]
---- EP [1/5] | BTCH [1081/3634] ||| train_loss = 0.01329 ----
LR: [0.0013037489856587096]
---- EP [1/5] | BTCH [1082/3634] ||| train_loss = 0.01120 ----
LR: [0.0013053656401852427]
---- EP [1/5] | BTCH [1083/3634] ||| train_loss = 0.01463 ----
LR: [0.0013069835888284143]
---- EP [1/5] | BTCH [1084/3634] ||| train_loss = 0.02050 ----
LR: [0.0013086028310506058]
---- EP [1/5] | BTCH [1085/3634] ||| train_loss = 0.00765 ----
LR: [0.0013102233663137702]
---- EP [1/5] | BTCH [1086/3634] ||| train_loss = 0.01072 ----
LR: [0.0013118451940794373]
---- EP [1/5] | BTCH [1087/3634] ||| train_loss = 0.01556 ----
LR: [0.0013134683138086994]
---- EP [1/5] | BTCH [1088/3634] ||| train_loss = 0.01228 ----
LR: [0.001315092724962226]
---- EP [1/5] | BTCH [1089/3634] ||| train_loss = 0.01340 ----
VAL ||| loss = 0.013337532062980141, psnr = 30.653779983520508, ssim = 0.9076311588287354
LR: [0.0013167184270002508]
---- EP [1/5] | BTCH [1090/3634] ||| train_loss = 0.01175 ----
LR: [0.001318345419382588]
---- EP [1/5] | BTCH [1091/3634] ||| train_loss = 0.01213 ----
LR: [0.0013199737015686108]
---- EP [1/5] | BTCH [1092/3634] ||| train_loss = 0.01479 ----
LR: [0.0013216032730172765]
---- EP [1/5] | BTCH [1093/3634] ||| train_loss = 0.01000 ----
LR: [0.0013232341331871032]
---- EP [1/5] | BTCH [1094/3634] ||| train_loss = 0.01268 ----
LR: [0.0013248662815361894]
---- EP [1/5] | BTCH [1095/3634] ||| train_loss = 0.01402 ----
LR: [0.001326499717522198]
---- EP [1/5] | BTCH [1096/3634] ||| train_loss = 0.00686 ----
LR: [0.0013281344406023722]
---- EP [1/5] | BTCH [1097/3634] ||| train_loss = 0.00804 ----
LR: [0.001329770450233518]
---- EP [1/5] | BTCH [1098/3634] ||| train_loss = 0.01323 ----
LR: [0.0013314077458720219]
---- EP [1/5] | BTCH [1099/3634] ||| train_loss = 0.01497 ----
LR: [0.0013330463269738396]
---- EP [1/5] | BTCH [1100/3634] ||| train_loss = 0.01284 ----
LR: [0.0013346861929945022]
---- EP [1/5] | BTCH [1101/3634] ||| train_loss = 0.00918 ----
LR: [0.0013363273433891088]
---- EP [1/5] | BTCH [1102/3634] ||| train_loss = 0.01088 ----
LR: [0.0013379697776123353]
---- EP [1/5] | BTCH [1103/3634] ||| train_loss = 0.01082 ----
LR: [0.0013396134951184323]
---- EP [1/5] | BTCH [1104/3634] ||| train_loss = 0.01302 ----
LR: [0.0013412584953612187]
---- EP [1/5] | BTCH [1105/3634] ||| train_loss = 0.01228 ----
LR: [0.0013429047777940937]
---- EP [1/5] | BTCH [1106/3634] ||| train_loss = 0.01046 ----
LR: [0.0013445523418700277]
---- EP [1/5] | BTCH [1107/3634] ||| train_loss = 0.01549 ----
LR: [0.0013462011870415628]
---- EP [1/5] | BTCH [1108/3634] ||| train_loss = 0.01323 ----
LR: [0.0013478513127608178]
---- EP [1/5] | BTCH [1109/3634] ||| train_loss = 0.01266 ----
LR: [0.0013495027184794884]
---- EP [1/5] | BTCH [1110/3634] ||| train_loss = 0.01698 ----
LR: [0.0013511554036488398]
---- EP [1/5] | BTCH [1111/3634] ||| train_loss = 0.01303 ----
LR: [0.001352809367719714]
---- EP [1/5] | BTCH [1112/3634] ||| train_loss = 0.01180 ----
LR: [0.0013544646101425317]
---- EP [1/5] | BTCH [1113/3634] ||| train_loss = 0.01685 ----
LR: [0.001356121130367283]
---- EP [1/5] | BTCH [1114/3634] ||| train_loss = 0.01242 ----
LR: [0.0013577789278435368]
---- EP [1/5] | BTCH [1115/3634] ||| train_loss = 0.01398 ----
LR: [0.001359438002020437]
---- EP [1/5] | BTCH [1116/3634] ||| train_loss = 0.01669 ----
LR: [0.0013610983523467037]
---- EP [1/5] | BTCH [1117/3634] ||| train_loss = 0.01382 ----
LR: [0.0013627599782706327]
---- EP [1/5] | BTCH [1118/3634] ||| train_loss = 0.01033 ----
LR: [0.0013644228792400927]
---- EP [1/5] | BTCH [1119/3634] ||| train_loss = 0.01774 ----
LR: [0.001366087054702536]
---- EP [1/5] | BTCH [1120/3634] ||| train_loss = 0.01620 ----
LR: [0.001367752504104985]
---- EP [1/5] | BTCH [1121/3634] ||| train_loss = 0.01617 ----
LR: [0.001369419226894042]
---- EP [1/5] | BTCH [1122/3634] ||| train_loss = 0.00820 ----
LR: [0.0013710872225158842]
---- EP [1/5] | BTCH [1123/3634] ||| train_loss = 0.00997 ----
LR: [0.0013727564904162676]
---- EP [1/5] | BTCH [1124/3634] ||| train_loss = 0.01268 ----
LR: [0.0013744270300405231]
---- EP [1/5] | BTCH [1125/3634] ||| train_loss = 0.01081 ----
LR: [0.0013760988408335617]
---- EP [1/5] | BTCH [1126/3634] ||| train_loss = 0.01794 ----
LR: [0.0013777719222398711]
---- EP [1/5] | BTCH [1127/3634] ||| train_loss = 0.00754 ----
LR: [0.0013794462737035142]
---- EP [1/5] | BTCH [1128/3634] ||| train_loss = 0.00846 ----
LR: [0.001381121894668139]
---- EP [1/5] | BTCH [1129/3634] ||| train_loss = 0.00929 ----
LR: [0.0013827987845769635]
---- EP [1/5] | BTCH [1130/3634] ||| train_loss = 0.01338 ----
LR: [0.0013844769428727876]
---- EP [1/5] | BTCH [1131/3634] ||| train_loss = 0.00959 ----
LR: [0.0013861563689979914]
---- EP [1/5] | BTCH [1132/3634] ||| train_loss = 0.00715 ----
LR: [0.00138783706239453]
---- EP [1/5] | BTCH [1133/3634] ||| train_loss = 0.00934 ----
LR: [0.0013895190225039385]
---- EP [1/5] | BTCH [1134/3634] ||| train_loss = 0.01077 ----
LR: [0.001391202248767336]
---- EP [1/5] | BTCH [1135/3634] ||| train_loss = 0.01295 ----
LR: [0.0013928867406254129]
---- EP [1/5] | BTCH [1136/3634] ||| train_loss = 0.01625 ----
LR: [0.001394572497518445]
---- EP [1/5] | BTCH [1137/3634] ||| train_loss = 0.01148 ----
LR: [0.001396259518886285]
---- EP [1/5] | BTCH [1138/3634] ||| train_loss = 0.00664 ----
LR: [0.0013979478041683657]
---- EP [1/5] | BTCH [1139/3634] ||| train_loss = 0.00937 ----
LR: [0.0013996373528037016]
---- EP [1/5] | BTCH [1140/3634] ||| train_loss = 0.00709 ----
LR: [0.0014013281642308861]
---- EP [1/5] | BTCH [1141/3634] ||| train_loss = 0.01648 ----
LR: [0.0014030202378880908]
---- EP [1/5] | BTCH [1142/3634] ||| train_loss = 0.00975 ----
LR: [0.0014047135732130726]
---- EP [1/5] | BTCH [1143/3634] ||| train_loss = 0.01111 ----
LR: [0.001406408169643169]
---- EP [1/5] | BTCH [1144/3634] ||| train_loss = 0.00787 ----
LR: [0.0014081040266152919]
---- EP [1/5] | BTCH [1145/3634] ||| train_loss = 0.01343 ----
LR: [0.001409801143565939]
---- EP [1/5] | BTCH [1146/3634] ||| train_loss = 0.01047 ----
LR: [0.001411499519931192]
---- EP [1/5] | BTCH [1147/3634] ||| train_loss = 0.01651 ----
LR: [0.0014131991551467066]
---- EP [1/5] | BTCH [1148/3634] ||| train_loss = 0.01393 ----
LR: [0.0014149000486477301]
---- EP [1/5] | BTCH [1149/3634] ||| train_loss = 0.01485 ----
LR: [0.0014166021998690843]
---- EP [1/5] | BTCH [1150/3634] ||| train_loss = 0.01651 ----
LR: [0.0014183056082451712]
---- EP [1/5] | BTCH [1151/3634] ||| train_loss = 0.01557 ----
LR: [0.0014200102732099852]
---- EP [1/5] | BTCH [1152/3634] ||| train_loss = 0.01299 ----
LR: [0.0014217161941970924]
---- EP [1/5] | BTCH [1153/3634] ||| train_loss = 0.00812 ----
LR: [0.0014234233706396475]
---- EP [1/5] | BTCH [1154/3634] ||| train_loss = 0.00775 ----
LR: [0.001425131801970389]
---- EP [1/5] | BTCH [1155/3634] ||| train_loss = 0.01779 ----
LR: [0.0014268414876216304]
---- EP [1/5] | BTCH [1156/3634] ||| train_loss = 0.01371 ----
LR: [0.0014285524270252793]
---- EP [1/5] | BTCH [1157/3634] ||| train_loss = 0.01393 ----
LR: [0.00143026461961282]
---- EP [1/5] | BTCH [1158/3634] ||| train_loss = 0.01448 ----
LR: [0.0014319780648153202]
---- EP [1/5] | BTCH [1159/3634] ||| train_loss = 0.00759 ----
LR: [0.0014336927620634352]
---- EP [1/5] | BTCH [1160/3634] ||| train_loss = 0.01131 ----
LR: [0.0014354087107874003]
---- EP [1/5] | BTCH [1161/3634] ||| train_loss = 0.01568 ----
LR: [0.0014371259104170395]
---- EP [1/5] | BTCH [1162/3634] ||| train_loss = 0.01260 ----
LR: [0.0014388443603817538]
---- EP [1/5] | BTCH [1163/3634] ||| train_loss = 0.01002 ----
LR: [0.0014405640601105382]
---- EP [1/5] | BTCH [1164/3634] ||| train_loss = 0.00985 ----
LR: [0.0014422850090319642]
---- EP [1/5] | BTCH [1165/3634] ||| train_loss = 0.00894 ----
LR: [0.0014440072065741924]
---- EP [1/5] | BTCH [1166/3634] ||| train_loss = 0.01236 ----
LR: [0.001445730652164967]
---- EP [1/5] | BTCH [1167/3634] ||| train_loss = 0.00765 ----
LR: [0.0014474553452316213]
---- EP [1/5] | BTCH [1168/3634] ||| train_loss = 0.01628 ----
LR: [0.0014491812852010684]
---- EP [1/5] | BTCH [1169/3634] ||| train_loss = 0.02221 ----
LR: [0.0014509084714998104]
---- EP [1/5] | BTCH [1170/3634] ||| train_loss = 0.01440 ----
LR: [0.0014526369035539333]
---- EP [1/5] | BTCH [1171/3634] ||| train_loss = 0.01953 ----
LR: [0.0014543665807891099]
---- EP [1/5] | BTCH [1172/3634] ||| train_loss = 0.01843 ----
LR: [0.0014560975026306038]
---- EP [1/5] | BTCH [1173/3634] ||| train_loss = 0.01087 ----
LR: [0.0014578296685032553]
---- EP [1/5] | BTCH [1174/3634] ||| train_loss = 0.01238 ----
LR: [0.0014595630778315022]
---- EP [1/5] | BTCH [1175/3634] ||| train_loss = 0.01933 ----
LR: [0.0014612977300393591]
---- EP [1/5] | BTCH [1176/3634] ||| train_loss = 0.00726 ----
LR: [0.0014630336245504364]
---- EP [1/5] | BTCH [1177/3634] ||| train_loss = 0.01033 ----
