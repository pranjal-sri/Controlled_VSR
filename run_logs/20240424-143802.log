/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn("None of the inputs have requires_grad=True. Gradients will be None")
LR: [0.0004000007974766396]
---- EP [1/5] | BTCH [1/3634] ||| train_loss = 0.02208 ----
LR: [0.000400003189906295]
---- EP [1/5] | BTCH [2/3634] ||| train_loss = 0.01547 ----
LR: [0.0004000071772881711]
---- EP [1/5] | BTCH [3/3634] ||| train_loss = 0.01128 ----
LR: [0.0004000127596209425]
---- EP [1/5] | BTCH [4/3634] ||| train_loss = 0.01741 ----
LR: [0.0004000199369027565]
---- EP [1/5] | BTCH [5/3634] ||| train_loss = 0.01835 ----
LR: [0.0004000287091312244]
---- EP [1/5] | BTCH [6/3634] ||| train_loss = 0.00673 ----
LR: [0.00040003907630343366]
---- EP [1/5] | BTCH [7/3634] ||| train_loss = 0.02308 ----
LR: [0.00040005103841593906]
---- EP [1/5] | BTCH [8/3634] ||| train_loss = 0.01333 ----
LR: [0.0004000645954647646]
---- EP [1/5] | BTCH [9/3634] ||| train_loss = 0.01081 ----
LR: [0.00040007974744540875]
---- EP [1/5] | BTCH [10/3634] ||| train_loss = 0.01643 ----
LR: [0.0004000964943528338]
---- EP [1/5] | BTCH [11/3634] ||| train_loss = 0.01977 ----
LR: [0.0004001148361814765]
---- EP [1/5] | BTCH [12/3634] ||| train_loss = 0.01370 ----
LR: [0.0004001347729252411]
---- EP [1/5] | BTCH [13/3634] ||| train_loss = 0.01395 ----
LR: [0.0004001563045775043]
---- EP [1/5] | BTCH [14/3634] ||| train_loss = 0.01277 ----
LR: [0.0004001794311311105]
---- EP [1/5] | BTCH [15/3634] ||| train_loss = 0.02123 ----
LR: [0.00040020415257837477]
---- EP [1/5] | BTCH [16/3634] ||| train_loss = 0.02738 ----
LR: [0.000400230468911085]
---- EP [1/5] | BTCH [17/3634] ||| train_loss = 0.01410 ----
LR: [0.00040025838012049293]
---- EP [1/5] | BTCH [18/3634] ||| train_loss = 0.01279 ----
LR: [0.0004002878861973265]
---- EP [1/5] | BTCH [19/3634] ||| train_loss = 0.01024 ----
LR: [0.00040031898713178277]
---- EP [1/5] | BTCH [20/3634] ||| train_loss = 0.02050 ----
LR: [0.0004003516829135245]
---- EP [1/5] | BTCH [21/3634] ||| train_loss = 0.01141 ----
LR: [0.0004003859735316889]
---- EP [1/5] | BTCH [22/3634] ||| train_loss = 0.01055 ----
LR: [0.0004004218589748823]
---- EP [1/5] | BTCH [23/3634] ||| train_loss = 0.01649 ----
LR: [0.0004004593392311802]
---- EP [1/5] | BTCH [24/3634] ||| train_loss = 0.01333 ----
LR: [0.00040049841428812724]
---- EP [1/5] | BTCH [25/3634] ||| train_loss = 0.01807 ----
LR: [0.00040053908413274254]
---- EP [1/5] | BTCH [26/3634] ||| train_loss = 0.01048 ----
LR: [0.0004005813487515091]
---- EP [1/5] | BTCH [27/3634] ||| train_loss = 0.01335 ----
LR: [0.00040062520813038613]
---- EP [1/5] | BTCH [28/3634] ||| train_loss = 0.01388 ----
LR: [0.00040067066225479495]
---- EP [1/5] | BTCH [29/3634] ||| train_loss = 0.01061 ----
LR: [0.0004007177111096383]
---- EP [1/5] | BTCH [30/3634] ||| train_loss = 0.01732 ----
LR: [0.0004007663546792793]
---- EP [1/5] | BTCH [31/3634] ||| train_loss = 0.01402 ----
LR: [0.0004008165929475539]
---- EP [1/5] | BTCH [32/3634] ||| train_loss = 0.01620 ----
LR: [0.00040086842589776885]
---- EP [1/5] | BTCH [33/3634] ||| train_loss = 0.02143 ----
LR: [0.0004009218535127052]
---- EP [1/5] | BTCH [34/3634] ||| train_loss = 0.01970 ----
LR: [0.0004009768757746047]
---- EP [1/5] | BTCH [35/3634] ||| train_loss = 0.01007 ----
LR: [0.00040103349266518845]
---- EP [1/5] | BTCH [36/3634] ||| train_loss = 0.02214 ----
LR: [0.00040109170416563825]
---- EP [1/5] | BTCH [37/3634] ||| train_loss = 0.01520 ----
LR: [0.0004011515102566171]
---- EP [1/5] | BTCH [38/3634] ||| train_loss = 0.00729 ----
LR: [0.0004012129109182503]
---- EP [1/5] | BTCH [39/3634] ||| train_loss = 0.02055 ----
LR: [0.00040127590613013575]
---- EP [1/5] | BTCH [40/3634] ||| train_loss = 0.01738 ----
LR: [0.00040134049587134055]
---- EP [1/5] | BTCH [41/3634] ||| train_loss = 0.01250 ----
LR: [0.0004014066801204044]
---- EP [1/5] | BTCH [42/3634] ||| train_loss = 0.01100 ----
LR: [0.0004014744588553328]
---- EP [1/5] | BTCH [43/3634] ||| train_loss = 0.01782 ----
LR: [0.0004015438320536073]
---- EP [1/5] | BTCH [44/3634] ||| train_loss = 0.01009 ----
LR: [0.0004016147996921734]
---- EP [1/5] | BTCH [45/3634] ||| train_loss = 0.00838 ----
LR: [0.00040168736174745097]
---- EP [1/5] | BTCH [46/3634] ||| train_loss = 0.00983 ----
LR: [0.0004017615181953309]
---- EP [1/5] | BTCH [47/3634] ||| train_loss = 0.01263 ----
LR: [0.0004018372690111696]
---- EP [1/5] | BTCH [48/3634] ||| train_loss = 0.01497 ----
LR: [0.00040191461416979636]
---- EP [1/5] | BTCH [49/3634] ||| train_loss = 0.01771 ----
LR: [0.0004019935536455129]
---- EP [1/5] | BTCH [50/3634] ||| train_loss = 0.01110 ----
LR: [0.00040207408741209025]
---- EP [1/5] | BTCH [51/3634] ||| train_loss = 0.00861 ----
LR: [0.0004021562154427633]
---- EP [1/5] | BTCH [52/3634] ||| train_loss = 0.01586 ----
LR: [0.00040223993771024667]
---- EP [1/5] | BTCH [53/3634] ||| train_loss = 0.01400 ----
LR: [0.0004023252541867188]
---- EP [1/5] | BTCH [54/3634] ||| train_loss = 0.01815 ----
LR: [0.0004024121648438326]
---- EP [1/5] | BTCH [55/3634] ||| train_loss = 0.01391 ----
LR: [0.00040250066965270663]
---- EP [1/5] | BTCH [56/3634] ||| train_loss = 0.01058 ----
LR: [0.0004025907685839356]
---- EP [1/5] | BTCH [57/3634] ||| train_loss = 0.01275 ----
LR: [0.00040268246160757824]
---- EP [1/5] | BTCH [58/3634] ||| train_loss = 0.00985 ----
LR: [0.00040277574869316754]
---- EP [1/5] | BTCH [59/3634] ||| train_loss = 0.00892 ----
LR: [0.0004028706298097075]
---- EP [1/5] | BTCH [60/3634] ||| train_loss = 0.01349 ----
LR: [0.0004029671049256677]
---- EP [1/5] | BTCH [61/3634] ||| train_loss = 0.01028 ----
LR: [0.00040306517400899404]
---- EP [1/5] | BTCH [62/3634] ||| train_loss = 0.01643 ----
LR: [0.00040316483702709967]
---- EP [1/5] | BTCH [63/3634] ||| train_loss = 0.01245 ----
LR: [0.000403266093946867]
---- EP [1/5] | BTCH [64/3634] ||| train_loss = 0.01349 ----
LR: [0.00040336894473465106]
---- EP [1/5] | BTCH [65/3634] ||| train_loss = 0.00827 ----
LR: [0.00040347338935627433]
---- EP [1/5] | BTCH [66/3634] ||| train_loss = 0.00658 ----
LR: [0.00040357942777703715]
---- EP [1/5] | BTCH [67/3634] ||| train_loss = 0.01277 ----
LR: [0.0004036870599616986]
---- EP [1/5] | BTCH [68/3634] ||| train_loss = 0.01690 ----
LR: [0.00040379628587449735]
---- EP [1/5] | BTCH [69/3634] ||| train_loss = 0.00915 ----
LR: [0.00040390710547913954]
---- EP [1/5] | BTCH [70/3634] ||| train_loss = 0.01387 ----
LR: [0.00040401951873880043]
---- EP [1/5] | BTCH [71/3634] ||| train_loss = 0.01344 ----
LR: [0.0004041335256161297]
---- EP [1/5] | BTCH [72/3634] ||| train_loss = 0.01051 ----
LR: [0.0004042491260732445]
---- EP [1/5] | BTCH [73/3634] ||| train_loss = 0.00987 ----
LR: [0.000404366320071731]
---- EP [1/5] | BTCH [74/3634] ||| train_loss = 0.01163 ----
LR: [0.00040448510757264827]
---- EP [1/5] | BTCH [75/3634] ||| train_loss = 0.01196 ----
LR: [0.00040460548853652606]
---- EP [1/5] | BTCH [76/3634] ||| train_loss = 0.00839 ----
LR: [0.0004047274629233634]
---- EP [1/5] | BTCH [77/3634] ||| train_loss = 0.01046 ----
LR: [0.00040485103069263194]
---- EP [1/5] | BTCH [78/3634] ||| train_loss = 0.02465 ----
LR: [0.0004049761918032708]
---- EP [1/5] | BTCH [79/3634] ||| train_loss = 0.01043 ----
LR: [0.00040510294621368993]
---- EP [1/5] | BTCH [80/3634] ||| train_loss = 0.01325 ----
LR: [0.00040523129388177377]
---- EP [1/5] | BTCH [81/3634] ||| train_loss = 0.01685 ----
LR: [0.0004053612347648741]
---- EP [1/5] | BTCH [82/3634] ||| train_loss = 0.01941 ----
LR: [0.000405492768819812]
---- EP [1/5] | BTCH [83/3634] ||| train_loss = 0.00710 ----
LR: [0.00040562589600288447]
---- EP [1/5] | BTCH [84/3634] ||| train_loss = 0.01492 ----
LR: [0.00040576061626985266]
---- EP [1/5] | BTCH [85/3634] ||| train_loss = 0.02240 ----
LR: [0.000405896929575952]
---- EP [1/5] | BTCH [86/3634] ||| train_loss = 0.01196 ----
LR: [0.00040603483587589063]
---- EP [1/5] | BTCH [87/3634] ||| train_loss = 0.01763 ----
LR: [0.0004061743351238406]
---- EP [1/5] | BTCH [88/3634] ||| train_loss = 0.02130 ----
LR: [0.00040631542727345357]
---- EP [1/5] | BTCH [89/3634] ||| train_loss = 0.00904 ----
LR: [0.00040645811227784344]
---- EP [1/5] | BTCH [90/3634] ||| train_loss = 0.00840 ----
LR: [0.0004066023900895985]
---- EP [1/5] | BTCH [91/3634] ||| train_loss = 0.01527 ----
LR: [0.0004067482606607796]
---- EP [1/5] | BTCH [92/3634] ||| train_loss = 0.02030 ----
LR: [0.0004068957239429169]
---- EP [1/5] | BTCH [93/3634] ||| train_loss = 0.00907 ----
LR: [0.0004070447798870114]
---- EP [1/5] | BTCH [94/3634] ||| train_loss = 0.01542 ----
LR: [0.0004071954284435315]
---- EP [1/5] | BTCH [95/3634] ||| train_loss = 0.01680 ----
LR: [0.00040734766956242]
---- EP [1/5] | BTCH [96/3634] ||| train_loss = 0.01218 ----
LR: [0.00040750150319309245]
---- EP [1/5] | BTCH [97/3634] ||| train_loss = 0.01289 ----
LR: [0.0004076569292844317]
---- EP [1/5] | BTCH [98/3634] ||| train_loss = 0.01521 ----
LR: [0.00040781394778479155]
---- EP [1/5] | BTCH [99/3634] ||| train_loss = 0.01600 ----
LR: [0.0004079725586420002]
---- EP [1/5] | BTCH [100/3634] ||| train_loss = 0.00986 ----
LR: [0.00040813276180334986]
---- EP [1/5] | BTCH [101/3634] ||| train_loss = 0.01254 ----
LR: [0.0004082945572156122]
---- EP [1/5] | BTCH [102/3634] ||| train_loss = 0.00822 ----
LR: [0.00040845794482502126]
---- EP [1/5] | BTCH [103/3634] ||| train_loss = 0.00908 ----
LR: [0.00040862292457728884]
---- EP [1/5] | BTCH [104/3634] ||| train_loss = 0.00877 ----
LR: [0.00040878949641759595]
---- EP [1/5] | BTCH [105/3634] ||| train_loss = 0.01295 ----
LR: [0.00040895766029059276]
---- EP [1/5] | BTCH [106/3634] ||| train_loss = 0.01383 ----
LR: [0.00040912741614040037]
---- EP [1/5] | BTCH [107/3634] ||| train_loss = 0.01894 ----
LR: [0.00040929876391061423]
---- EP [1/5] | BTCH [108/3634] ||| train_loss = 0.00974 ----
LR: [0.00040947170354429553]
---- EP [1/5] | BTCH [109/3634] ||| train_loss = 0.01032 ----
LR: [0.0004096462349839833]
---- EP [1/5] | BTCH [110/3634] ||| train_loss = 0.01131 ----
LR: [0.0004098223581716805]
---- EP [1/5] | BTCH [111/3634] ||| train_loss = 0.01798 ----
LR: [0.0004100000730488662]
---- EP [1/5] | BTCH [112/3634] ||| train_loss = 0.01043 ----
LR: [0.00041017937955648877]
---- EP [1/5] | BTCH [113/3634] ||| train_loss = 0.00815 ----
LR: [0.00041036027763496907]
---- EP [1/5] | BTCH [114/3634] ||| train_loss = 0.01000 ----
LR: [0.0004105427672241955]
---- EP [1/5] | BTCH [115/3634] ||| train_loss = 0.01559 ----
LR: [0.0004107268482635325]
---- EP [1/5] | BTCH [116/3634] ||| train_loss = 0.01957 ----
LR: [0.00041091252069181024]
---- EP [1/5] | BTCH [117/3634] ||| train_loss = 0.00951 ----
LR: [0.0004110997844473368]
---- EP [1/5] | BTCH [118/3634] ||| train_loss = 0.01424 ----
LR: [0.00041128863946788587]
---- EP [1/5] | BTCH [119/3634] ||| train_loss = 0.00907 ----
LR: [0.0004114790856907021]
---- EP [1/5] | BTCH [120/3634] ||| train_loss = 0.01313 ----
LR: [0.000411671123052508]
---- EP [1/5] | BTCH [121/3634] ||| train_loss = 0.01661 ----
LR: [0.0004118647514894918]
---- EP [1/5] | BTCH [122/3634] ||| train_loss = 0.01084 ----
LR: [0.00041205997093731253]
---- EP [1/5] | BTCH [123/3634] ||| train_loss = 0.01109 ----
LR: [0.0004122567813311037]
---- EP [1/5] | BTCH [124/3634] ||| train_loss = 0.01091 ----
LR: [0.0004124551826054663]
---- EP [1/5] | BTCH [125/3634] ||| train_loss = 0.01060 ----
LR: [0.000412655174694479]
---- EP [1/5] | BTCH [126/3634] ||| train_loss = 0.01692 ----
LR: [0.0004128567575316863]
---- EP [1/5] | BTCH [127/3634] ||| train_loss = 0.01401 ----
LR: [0.00041305993105010715]
---- EP [1/5] | BTCH [128/3634] ||| train_loss = 0.01193 ----
LR: [0.00041326469518222775]
---- EP [1/5] | BTCH [129/3634] ||| train_loss = 0.01330 ----
LR: [0.00041347104986001054]
---- EP [1/5] | BTCH [130/3634] ||| train_loss = 0.01044 ----
LR: [0.0004136789950148871]
---- EP [1/5] | BTCH [131/3634] ||| train_loss = 0.02214 ----
LR: [0.00041388853057775996]
---- EP [1/5] | BTCH [132/3634] ||| train_loss = 0.00922 ----
LR: [0.0004140996564790077]
---- EP [1/5] | BTCH [133/3634] ||| train_loss = 0.01063 ----
LR: [0.00041431237264847286]
---- EP [1/5] | BTCH [134/3634] ||| train_loss = 0.01396 ----
LR: [0.00041452667901547766]
---- EP [1/5] | BTCH [135/3634] ||| train_loss = 0.00629 ----
LR: [0.00041474257550880994]
---- EP [1/5] | BTCH [136/3634] ||| train_loss = 0.00886 ----
LR: [0.0004149600620567285]
---- EP [1/5] | BTCH [137/3634] ||| train_loss = 0.00657 ----
LR: [0.00041517913858697165]
---- EP [1/5] | BTCH [138/3634] ||| train_loss = 0.01083 ----
LR: [0.00041539980502674177]
---- EP [1/5] | BTCH [139/3634] ||| train_loss = 0.01113 ----
LR: [0.0004156220613027138]
---- EP [1/5] | BTCH [140/3634] ||| train_loss = 0.01426 ----
LR: [0.00041584590734103886]
---- EP [1/5] | BTCH [141/3634] ||| train_loss = 0.00916 ----
LR: [0.00041607134306733545]
---- EP [1/5] | BTCH [142/3634] ||| train_loss = 0.00909 ----
LR: [0.00041629836840669475]
---- EP [1/5] | BTCH [143/3634] ||| train_loss = 0.01299 ----
LR: [0.00041652698328368057]
---- EP [1/5] | BTCH [144/3634] ||| train_loss = 0.01685 ----
LR: [0.00041675718762233284]
---- EP [1/5] | BTCH [145/3634] ||| train_loss = 0.02254 ----
LR: [0.00041698898134615026]
---- EP [1/5] | BTCH [146/3634] ||| train_loss = 0.01046 ----
LR: [0.00041722236437811977]
---- EP [1/5] | BTCH [147/3634] ||| train_loss = 0.00851 ----
LR: [0.0004174573366406871]
---- EP [1/5] | BTCH [148/3634] ||| train_loss = 0.02001 ----
LR: [0.0004176938980557793]
---- EP [1/5] | BTCH [149/3634] ||| train_loss = 0.01477 ----
LR: [0.0004179320485447873]
---- EP [1/5] | BTCH [150/3634] ||| train_loss = 0.01158 ----
LR: [0.0004181717880285818]
---- EP [1/5] | BTCH [151/3634] ||| train_loss = 0.00985 ----
LR: [0.000418413116427499]
---- EP [1/5] | BTCH [152/3634] ||| train_loss = 0.01400 ----
LR: [0.0004186560336613514]
---- EP [1/5] | BTCH [153/3634] ||| train_loss = 0.01759 ----
LR: [0.00041890053964941873]
---- EP [1/5] | BTCH [154/3634] ||| train_loss = 0.01084 ----
LR: [0.00041914663431046224]
---- EP [1/5] | BTCH [155/3634] ||| train_loss = 0.00746 ----
LR: [0.0004193943175627036]
---- EP [1/5] | BTCH [156/3634] ||| train_loss = 0.01471 ----
LR: [0.0004196435893238457]
---- EP [1/5] | BTCH [157/3634] ||| train_loss = 0.01376 ----
LR: [0.00041989444951105563]
---- EP [1/5] | BTCH [158/3634] ||| train_loss = 0.01426 ----
LR: [0.00042014689804098157]
---- EP [1/5] | BTCH [159/3634] ||| train_loss = 0.01153 ----
LR: [0.0004204009348297375]
---- EP [1/5] | BTCH [160/3634] ||| train_loss = 0.01421 ----
LR: [0.00042065655979291183]
---- EP [1/5] | BTCH [161/3634] ||| train_loss = 0.02313 ----
LR: [0.0004209137728455655]
---- EP [1/5] | BTCH [162/3634] ||| train_loss = 0.00699 ----
LR: [0.0004211725739022322]
---- EP [1/5] | BTCH [163/3634] ||| train_loss = 0.01250 ----
LR: [0.000421432962876913]
---- EP [1/5] | BTCH [164/3634] ||| train_loss = 0.01061 ----
LR: [0.0004216949396830885]
---- EP [1/5] | BTCH [165/3634] ||| train_loss = 0.00650 ----
LR: [0.00042195850423370866]
---- EP [1/5] | BTCH [166/3634] ||| train_loss = 0.01482 ----
LR: [0.0004222236564411959]
---- EP [1/5] | BTCH [167/3634] ||| train_loss = 0.01332 ----
LR: [0.00042249039621744186]
---- EP [1/5] | BTCH [168/3634] ||| train_loss = 0.01603 ----
LR: [0.0004227587234738178]
---- EP [1/5] | BTCH [169/3634] ||| train_loss = 0.00591 ----
LR: [0.0004230286381211607]
---- EP [1/5] | BTCH [170/3634] ||| train_loss = 0.01307 ----
LR: [0.0004233001400697836]
---- EP [1/5] | BTCH [171/3634] ||| train_loss = 0.00667 ----
LR: [0.0004235732292294705]
---- EP [1/5] | BTCH [172/3634] ||| train_loss = 0.00703 ----
LR: [0.0004238479055094814]
---- EP [1/5] | BTCH [173/3634] ||| train_loss = 0.01381 ----
LR: [0.0004241241688185439]
---- EP [1/5] | BTCH [174/3634] ||| train_loss = 0.01172 ----
LR: [0.0004244020190648616]
---- EP [1/5] | BTCH [175/3634] ||| train_loss = 0.00805 ----
LR: [0.0004246814561561091]
---- EP [1/5] | BTCH [176/3634] ||| train_loss = 0.01658 ----
LR: [0.000424962479999437]
---- EP [1/5] | BTCH [177/3634] ||| train_loss = 0.01324 ----
LR: [0.00042524509050146167]
---- EP [1/5] | BTCH [178/3634] ||| train_loss = 0.01580 ----
LR: [0.00042552928756828083]
---- EP [1/5] | BTCH [179/3634] ||| train_loss = 0.00962 ----
LR: [0.0004258150711054596]
---- EP [1/5] | BTCH [180/3634] ||| train_loss = 0.01693 ----
LR: [0.0004261024410180357]
---- EP [1/5] | BTCH [181/3634] ||| train_loss = 0.01233 ----
VAL ||| loss = 0.013839589627159218, psnr = 30.5132999420166, ssim = 0.9031299352645874
LR: [0.0004263913972105231]
---- EP [1/5] | BTCH [182/3634] ||| train_loss = 0.01133 ----
LR: [0.0004266819395869082]
---- EP [1/5] | BTCH [183/3634] ||| train_loss = 0.01941 ----
LR: [0.0004269740680506468]
---- EP [1/5] | BTCH [184/3634] ||| train_loss = 0.01460 ----
LR: [0.00042726778250466897]
---- EP [1/5] | BTCH [185/3634] ||| train_loss = 0.00943 ----
LR: [0.00042756308285138087]
---- EP [1/5] | BTCH [186/3634] ||| train_loss = 0.00775 ----
LR: [0.0004278599689926596]
---- EP [1/5] | BTCH [187/3634] ||| train_loss = 0.01415 ----
LR: [0.0004281584408298532]
---- EP [1/5] | BTCH [188/3634] ||| train_loss = 0.02868 ----
LR: [0.00042845849826378575]
---- EP [1/5] | BTCH [189/3634] ||| train_loss = 0.00981 ----
LR: [0.0004287601411947558]
---- EP [1/5] | BTCH [190/3634] ||| train_loss = 0.01039 ----
LR: [0.000429063369522531]
---- EP [1/5] | BTCH [191/3634] ||| train_loss = 0.01886 ----
LR: [0.00042936818314635167]
---- EP [1/5] | BTCH [192/3634] ||| train_loss = 0.01592 ----
LR: [0.0004296745819649377]
---- EP [1/5] | BTCH [193/3634] ||| train_loss = 0.00994 ----
LR: [0.0004299825658764765]
---- EP [1/5] | BTCH [194/3634] ||| train_loss = 0.01281 ----
LR: [0.0004302921347786315]
---- EP [1/5] | BTCH [195/3634] ||| train_loss = 0.00560 ----
LR: [0.000430603288568537]
---- EP [1/5] | BTCH [196/3634] ||| train_loss = 0.00846 ----
LR: [0.00043091602714280357]
---- EP [1/5] | BTCH [197/3634] ||| train_loss = 0.00896 ----
LR: [0.00043123035039751255]
---- EP [1/5] | BTCH [198/3634] ||| train_loss = 0.00800 ----
LR: [0.00043154625822822146]
---- EP [1/5] | BTCH [199/3634] ||| train_loss = 0.01636 ----
LR: [0.00043186375052996044]
---- EP [1/5] | BTCH [200/3634] ||| train_loss = 0.01715 ----
LR: [0.0004321828271972288]
---- EP [1/5] | BTCH [201/3634] ||| train_loss = 0.01184 ----
LR: [0.00043250348812400724]
---- EP [1/5] | BTCH [202/3634] ||| train_loss = 0.00849 ----
LR: [0.0004328257332037438]
---- EP [1/5] | BTCH [203/3634] ||| train_loss = 0.01589 ----
LR: [0.0004331495623293626]
---- EP [1/5] | BTCH [204/3634] ||| train_loss = 0.01477 ----
LR: [0.0004334749753932606]
---- EP [1/5] | BTCH [205/3634] ||| train_loss = 0.00782 ----
LR: [0.0004338019722873107]
---- EP [1/5] | BTCH [206/3634] ||| train_loss = 0.00857 ----
LR: [0.00043413055290285503]
---- EP [1/5] | BTCH [207/3634] ||| train_loss = 0.01600 ----
LR: [0.0004344607171307153]
---- EP [1/5] | BTCH [208/3634] ||| train_loss = 0.01356 ----
LR: [0.00043479246486118235]
---- EP [1/5] | BTCH [209/3634] ||| train_loss = 0.01034 ----
LR: [0.0004351257959840215]
---- EP [1/5] | BTCH [210/3634] ||| train_loss = 0.01040 ----
LR: [0.0004354607103884741]
---- EP [1/5] | BTCH [211/3634] ||| train_loss = 0.00923 ----
LR: [0.0004357972079632542]
---- EP [1/5] | BTCH [212/3634] ||| train_loss = 0.01120 ----
LR: [0.0004361352885965484]
---- EP [1/5] | BTCH [213/3634] ||| train_loss = 0.00902 ----
LR: [0.00043647495217602125]
---- EP [1/5] | BTCH [214/3634] ||| train_loss = 0.01833 ----
LR: [0.0004368161985888047]
---- EP [1/5] | BTCH [215/3634] ||| train_loss = 0.00680 ----
LR: [0.00043715902772151205]
---- EP [1/5] | BTCH [216/3634] ||| train_loss = 0.01085 ----
LR: [0.0004375034394602257]
---- EP [1/5] | BTCH [217/3634] ||| train_loss = 0.01101 ----
LR: [0.0004378494336905042]
---- EP [1/5] | BTCH [218/3634] ||| train_loss = 0.01316 ----
LR: [0.0004381970102973823]
---- EP [1/5] | BTCH [219/3634] ||| train_loss = 0.01629 ----
LR: [0.00043854616916536374]
---- EP [1/5] | BTCH [220/3634] ||| train_loss = 0.01129 ----
LR: [0.00043889691017842854]
---- EP [1/5] | BTCH [221/3634] ||| train_loss = 0.01120 ----
LR: [0.0004392492332200345]
---- EP [1/5] | BTCH [222/3634] ||| train_loss = 0.01957 ----
LR: [0.0004396031381731103]
---- EP [1/5] | BTCH [223/3634] ||| train_loss = 0.01585 ----
LR: [0.0004399586249200574]
---- EP [1/5] | BTCH [224/3634] ||| train_loss = 0.01167 ----
LR: [0.00044031569334275836]
---- EP [1/5] | BTCH [225/3634] ||| train_loss = 0.01327 ----
LR: [0.0004406743433225616]
---- EP [1/5] | BTCH [226/3634] ||| train_loss = 0.01541 ----
LR: [0.00044103457474029516]
---- EP [1/5] | BTCH [227/3634] ||| train_loss = 0.01054 ----
LR: [0.00044139638747626303]
---- EP [1/5] | BTCH [228/3634] ||| train_loss = 0.01601 ----
LR: [0.0004417597814102385]
---- EP [1/5] | BTCH [229/3634] ||| train_loss = 0.00993 ----
LR: [0.0004421247564214744]
---- EP [1/5] | BTCH [230/3634] ||| train_loss = 0.01168 ----
LR: [0.0004424913123886945]
---- EP [1/5] | BTCH [231/3634] ||| train_loss = 0.01256 ----
LR: [0.00044285944919010035]
---- EP [1/5] | BTCH [232/3634] ||| train_loss = 0.01640 ----
LR: [0.00044322916670336623]
---- EP [1/5] | BTCH [233/3634] ||| train_loss = 0.00998 ----
LR: [0.000443600464805639]
---- EP [1/5] | BTCH [234/3634] ||| train_loss = 0.01629 ----
LR: [0.00044397334337354863]
---- EP [1/5] | BTCH [235/3634] ||| train_loss = 0.00577 ----
LR: [0.0004443478022831907]
---- EP [1/5] | BTCH [236/3634] ||| train_loss = 0.01551 ----
LR: [0.0004447238414101388]
---- EP [1/5] | BTCH [237/3634] ||| train_loss = 0.00933 ----
LR: [0.00044510146062944414]
---- EP [1/5] | BTCH [238/3634] ||| train_loss = 0.00865 ----
LR: [0.0004454806598156273]
---- EP [1/5] | BTCH [239/3634] ||| train_loss = 0.01225 ----
LR: [0.00044586143884269014]
---- EP [1/5] | BTCH [240/3634] ||| train_loss = 0.01221 ----
LR: [0.0004462437975841071]
---- EP [1/5] | BTCH [241/3634] ||| train_loss = 0.01643 ----
LR: [0.00044662773591282526]
---- EP [1/5] | BTCH [242/3634] ||| train_loss = 0.01733 ----
LR: [0.00044701325370126964]
---- EP [1/5] | BTCH [243/3634] ||| train_loss = 0.01431 ----
LR: [0.00044740035082133957]
---- EP [1/5] | BTCH [244/3634] ||| train_loss = 0.01946 ----
LR: [0.00044778902714440877]
---- EP [1/5] | BTCH [245/3634] ||| train_loss = 0.00909 ----
LR: [0.00044817928254133055]
---- EP [1/5] | BTCH [246/3634] ||| train_loss = 0.01149 ----
LR: [0.0004485711168824274]
---- EP [1/5] | BTCH [247/3634] ||| train_loss = 0.01235 ----
LR: [0.0004489645300374979]
---- EP [1/5] | BTCH [248/3634] ||| train_loss = 0.01252 ----
LR: [0.00044935952187582194]
---- EP [1/5] | BTCH [249/3634] ||| train_loss = 0.01842 ----
LR: [0.0004497560922661469]
---- EP [1/5] | BTCH [250/3634] ||| train_loss = 0.00584 ----
LR: [0.0004501542410767032]
---- EP [1/5] | BTCH [251/3634] ||| train_loss = 0.01768 ----
LR: [0.0004505539681751939]
---- EP [1/5] | BTCH [252/3634] ||| train_loss = 0.01454 ----
LR: [0.0004509552734287912]
---- EP [1/5] | BTCH [253/3634] ||| train_loss = 0.01356 ----
LR: [0.0004513581567041538]
---- EP [1/5] | BTCH [254/3634] ||| train_loss = 0.00913 ----
LR: [0.00045176261786740966]
---- EP [1/5] | BTCH [255/3634] ||| train_loss = 0.00844 ----
LR: [0.00045216865678416283]
---- EP [1/5] | BTCH [256/3634] ||| train_loss = 0.01214 ----
LR: [0.0004525762733194952]
---- EP [1/5] | BTCH [257/3634] ||| train_loss = 0.01419 ----
LR: [0.00045298546733796123]
---- EP [1/5] | BTCH [258/3634] ||| train_loss = 0.01037 ----
LR: [0.0004533962387035951]
---- EP [1/5] | BTCH [259/3634] ||| train_loss = 0.00944 ----
LR: [0.0004538085872799035]
---- EP [1/5] | BTCH [260/3634] ||| train_loss = 0.01931 ----
LR: [0.0004542225129298711]
---- EP [1/5] | BTCH [261/3634] ||| train_loss = 0.01404 ----
LR: [0.00045463801551595684]
---- EP [1/5] | BTCH [262/3634] ||| train_loss = 0.01079 ----
LR: [0.0004550550949000993]
---- EP [1/5] | BTCH [263/3634] ||| train_loss = 0.00633 ----
LR: [0.00045547375094370617]
---- EP [1/5] | BTCH [264/3634] ||| train_loss = 0.00626 ----
LR: [0.00045589398350767]
---- EP [1/5] | BTCH [265/3634] ||| train_loss = 0.00756 ----
LR: [0.0004563157924523543]
---- EP [1/5] | BTCH [266/3634] ||| train_loss = 0.01315 ----
LR: [0.00045673917763759675]
---- EP [1/5] | BTCH [267/3634] ||| train_loss = 0.01047 ----
LR: [0.0004571641389227183]
---- EP [1/5] | BTCH [268/3634] ||| train_loss = 0.01133 ----
LR: [0.00045759067616650724]
---- EP [1/5] | BTCH [269/3634] ||| train_loss = 0.01048 ----
LR: [0.00045801878922723666]
---- EP [1/5] | BTCH [270/3634] ||| train_loss = 0.01136 ----
LR: [0.0004584484779626523]
---- EP [1/5] | BTCH [271/3634] ||| train_loss = 0.01666 ----
LR: [0.00045887974222997424]
---- EP [1/5] | BTCH [272/3634] ||| train_loss = 0.01404 ----
LR: [0.0004593125818859022]
---- EP [1/5] | BTCH [273/3634] ||| train_loss = 0.01004 ----
LR: [0.0004597469967866103]
---- EP [1/5] | BTCH [274/3634] ||| train_loss = 0.00841 ----
LR: [0.0004601829867877504]
---- EP [1/5] | BTCH [275/3634] ||| train_loss = 0.01213 ----
LR: [0.00046062055174445407]
---- EP [1/5] | BTCH [276/3634] ||| train_loss = 0.01144 ----
LR: [0.00046105969151132367]
---- EP [1/5] | BTCH [277/3634] ||| train_loss = 0.01380 ----
LR: [0.0004615004059424395]
---- EP [1/5] | BTCH [278/3634] ||| train_loss = 0.00973 ----
LR: [0.00046194269489136484]
---- EP [1/5] | BTCH [279/3634] ||| train_loss = 0.00833 ----
LR: [0.0004623865582111305]
---- EP [1/5] | BTCH [280/3634] ||| train_loss = 0.01049 ----
LR: [0.00046283199575425024]
---- EP [1/5] | BTCH [281/3634] ||| train_loss = 0.00917 ----
LR: [0.000463279007372714]
---- EP [1/5] | BTCH [282/3634] ||| train_loss = 0.01070 ----
LR: [0.00046372759291798786]
---- EP [1/5] | BTCH [283/3634] ||| train_loss = 0.00923 ----
LR: [0.0004641777522410139]
---- EP [1/5] | BTCH [284/3634] ||| train_loss = 0.01247 ----
LR: [0.0004646294851922122]
---- EP [1/5] | BTCH [285/3634] ||| train_loss = 0.02836 ----
LR: [0.00046508279162148225]
---- EP [1/5] | BTCH [286/3634] ||| train_loss = 0.01323 ----
LR: [0.00046553767137819634]
---- EP [1/5] | BTCH [287/3634] ||| train_loss = 0.00997 ----
LR: [0.00046599412431120625]
---- EP [1/5] | BTCH [288/3634] ||| train_loss = 0.00664 ----
LR: [0.00046645215026884165]
---- EP [1/5] | BTCH [289/3634] ||| train_loss = 0.01026 ----
LR: [0.0004669117490989083]
---- EP [1/5] | BTCH [290/3634] ||| train_loss = 0.01486 ----
LR: [0.00046737292064868985]
---- EP [1/5] | BTCH [291/3634] ||| train_loss = 0.00879 ----
LR: [0.00046783566476494773]
---- EP [1/5] | BTCH [292/3634] ||| train_loss = 0.01170 ----
LR: [0.00046829998129392127]
---- EP [1/5] | BTCH [293/3634] ||| train_loss = 0.01062 ----
LR: [0.00046876587008132416]
---- EP [1/5] | BTCH [294/3634] ||| train_loss = 0.01275 ----
LR: [0.0004692333309723514]
---- EP [1/5] | BTCH [295/3634] ||| train_loss = 0.01634 ----
LR: [0.00046970236381167416]
---- EP [1/5] | BTCH [296/3634] ||| train_loss = 0.01076 ----
LR: [0.00047017296844344136]
---- EP [1/5] | BTCH [297/3634] ||| train_loss = 0.01256 ----
LR: [0.00047064514471127986]
---- EP [1/5] | BTCH [298/3634] ||| train_loss = 0.01474 ----
LR: [0.00047111889245829257]
---- EP [1/5] | BTCH [299/3634] ||| train_loss = 0.01890 ----
LR: [0.00047159421152706375]
---- EP [1/5] | BTCH [300/3634] ||| train_loss = 0.00819 ----
LR: [0.00047207110175965204]
---- EP [1/5] | BTCH [301/3634] ||| train_loss = 0.01846 ----
LR: [0.0004725495629975939]
---- EP [1/5] | BTCH [302/3634] ||| train_loss = 0.01282 ----
LR: [0.00047302959508191064]
---- EP [1/5] | BTCH [303/3634] ||| train_loss = 0.01657 ----
LR: [0.0004735111978530909]
---- EP [1/5] | BTCH [304/3634] ||| train_loss = 0.01127 ----
LR: [0.00047399437115110826]
---- EP [1/5] | BTCH [305/3634] ||| train_loss = 0.01383 ----
LR: [0.000474479114815414]
---- EP [1/5] | BTCH [306/3634] ||| train_loss = 0.01673 ----
LR: [0.0004749654286849356]
---- EP [1/5] | BTCH [307/3634] ||| train_loss = 0.01624 ----
LR: [0.0004754533125980818]
---- EP [1/5] | BTCH [308/3634] ||| train_loss = 0.01395 ----
LR: [0.00047594276639273403]
---- EP [1/5] | BTCH [309/3634] ||| train_loss = 0.00910 ----
LR: [0.0004764337899062568]
---- EP [1/5] | BTCH [310/3634] ||| train_loss = 0.01784 ----
LR: [0.0004769263829754941]
---- EP [1/5] | BTCH [311/3634] ||| train_loss = 0.01918 ----
LR: [0.00047742054543676617]
---- EP [1/5] | BTCH [312/3634] ||| train_loss = 0.01065 ----
LR: [0.0004779162771258675]
---- EP [1/5] | BTCH [313/3634] ||| train_loss = 0.01387 ----
LR: [0.00047841357787807917]
---- EP [1/5] | BTCH [314/3634] ||| train_loss = 0.00655 ----
LR: [0.0004789124475281549]
---- EP [1/5] | BTCH [315/3634] ||| train_loss = 0.01665 ----
LR: [0.00047941288591033145]
---- EP [1/5] | BTCH [316/3634] ||| train_loss = 0.01524 ----
LR: [0.0004799148928583217]
---- EP [1/5] | BTCH [317/3634] ||| train_loss = 0.02028 ----
LR: [0.00048041846820531635]
---- EP [1/5] | BTCH [318/3634] ||| train_loss = 0.00932 ----
LR: [0.0004809236117839875]
---- EP [1/5] | BTCH [319/3634] ||| train_loss = 0.01041 ----
LR: [0.00048143032342648495]
---- EP [1/5] | BTCH [320/3634] ||| train_loss = 0.01612 ----
LR: [0.0004819386029644365]
---- EP [1/5] | BTCH [321/3634] ||| train_loss = 0.01091 ----
LR: [0.000482448450228953]
---- EP [1/5] | BTCH [322/3634] ||| train_loss = 0.01232 ----
LR: [0.0004829598650506195]
---- EP [1/5] | BTCH [323/3634] ||| train_loss = 0.00915 ----
LR: [0.0004834728472595008]
---- EP [1/5] | BTCH [324/3634] ||| train_loss = 0.00774 ----
LR: [0.00048398739668514476]
---- EP [1/5] | BTCH [325/3634] ||| train_loss = 0.01306 ----
LR: [0.00048450351315657524]
---- EP [1/5] | BTCH [326/3634] ||| train_loss = 0.00618 ----
LR: [0.0004850211965022923]
---- EP [1/5] | BTCH [327/3634] ||| train_loss = 0.01387 ----
LR: [0.0004855404465502859]
---- EP [1/5] | BTCH [328/3634] ||| train_loss = 0.01374 ----
LR: [0.00048606126312801187]
---- EP [1/5] | BTCH [329/3634] ||| train_loss = 0.00830 ----
LR: [0.0004865836460624176]
---- EP [1/5] | BTCH [330/3634] ||| train_loss = 0.01141 ----
LR: [0.0004871075951799215]
---- EP [1/5] | BTCH [331/3634] ||| train_loss = 0.00860 ----
LR: [0.0004876331103064284]
---- EP [1/5] | BTCH [332/3634] ||| train_loss = 0.00786 ----
LR: [0.0004881601912673124]
---- EP [1/5] | BTCH [333/3634] ||| train_loss = 0.01423 ----
LR: [0.000488688837887441]
---- EP [1/5] | BTCH [334/3634] ||| train_loss = 0.01279 ----
LR: [0.0004892190499911492]
---- EP [1/5] | BTCH [335/3634] ||| train_loss = 0.00830 ----
LR: [0.0004897508274022619]
---- EP [1/5] | BTCH [336/3634] ||| train_loss = 0.01094 ----
LR: [0.000490284169944075]
---- EP [1/5] | BTCH [337/3634] ||| train_loss = 0.01020 ----
LR: [0.0004908190774393709]
---- EP [1/5] | BTCH [338/3634] ||| train_loss = 0.01012 ----
LR: [0.0004913555497104063]
---- EP [1/5] | BTCH [339/3634] ||| train_loss = 0.01293 ----
LR: [0.0004918935865789262]
---- EP [1/5] | BTCH [340/3634] ||| train_loss = 0.01621 ----
LR: [0.0004924331878661484]
---- EP [1/5] | BTCH [341/3634] ||| train_loss = 0.00744 ----
LR: [0.0004929743533927701]
---- EP [1/5] | BTCH [342/3634] ||| train_loss = 0.01994 ----
LR: [0.000493517082978975]
---- EP [1/5] | BTCH [343/3634] ||| train_loss = 0.01420 ----
LR: [0.0004940613764444247]
---- EP [1/5] | BTCH [344/3634] ||| train_loss = 0.01241 ----
LR: [0.0004946072336082588]
---- EP [1/5] | BTCH [345/3634] ||| train_loss = 0.01152 ----
LR: [0.000495154654289098]
---- EP [1/5] | BTCH [346/3634] ||| train_loss = 0.00998 ----
LR: [0.0004957036383050444]
---- EP [1/5] | BTCH [347/3634] ||| train_loss = 0.01257 ----
LR: [0.0004962541854736831]
---- EP [1/5] | BTCH [348/3634] ||| train_loss = 0.01411 ----
LR: [0.0004968062956120754]
---- EP [1/5] | BTCH [349/3634] ||| train_loss = 0.01027 ----
LR: [0.000497359968536764]
---- EP [1/5] | BTCH [350/3634] ||| train_loss = 0.01890 ----
LR: [0.0004979152040637744]
---- EP [1/5] | BTCH [351/3634] ||| train_loss = 0.01098 ----
LR: [0.0004984720020086118]
---- EP [1/5] | BTCH [352/3634] ||| train_loss = 0.01252 ----
LR: [0.0004990303621862629]
---- EP [1/5] | BTCH [353/3634] ||| train_loss = 0.01065 ----
LR: [0.0004995902844111954]
---- EP [1/5] | BTCH [354/3634] ||| train_loss = 0.01356 ----
LR: [0.0005001517684973551]
---- EP [1/5] | BTCH [355/3634] ||| train_loss = 0.01241 ----
LR: [0.0005007148142581724]
---- EP [1/5] | BTCH [356/3634] ||| train_loss = 0.01536 ----
LR: [0.0005012794215065539]
---- EP [1/5] | BTCH [357/3634] ||| train_loss = 0.00605 ----
LR: [0.0005018455900548981]
---- EP [1/5] | BTCH [358/3634] ||| train_loss = 0.01116 ----
LR: [0.0005024133197150723]
---- EP [1/5] | BTCH [359/3634] ||| train_loss = 0.00818 ----
LR: [0.0005029826102984289]
---- EP [1/5] | BTCH [360/3634] ||| train_loss = 0.01774 ----
LR: [0.0005035534616158067]
---- EP [1/5] | BTCH [361/3634] ||| train_loss = 0.01544 ----
LR: [0.0005041258734775206]
---- EP [1/5] | BTCH [362/3634] ||| train_loss = 0.00786 ----
VAL ||| loss = 0.013677962806085055, psnr = 30.585824966430664, ssim = 0.9047825336456299
LR: [0.0005046998456933686]
---- EP [1/5] | BTCH [363/3634] ||| train_loss = 0.00890 ----
LR: [0.00050527537807263]
---- EP [1/5] | BTCH [364/3634] ||| train_loss = 0.02057 ----
LR: [0.0005058524704240654]
---- EP [1/5] | BTCH [365/3634] ||| train_loss = 0.00802 ----
LR: [0.0005064311225559167]
---- EP [1/5] | BTCH [366/3634] ||| train_loss = 0.01382 ----
LR: [0.0005070113342759107]
---- EP [1/5] | BTCH [367/3634] ||| train_loss = 0.01100 ----
LR: [0.0005075931053912519]
---- EP [1/5] | BTCH [368/3634] ||| train_loss = 0.00850 ----
LR: [0.0005081764357086297]
---- EP [1/5] | BTCH [369/3634] ||| train_loss = 0.01647 ----
LR: [0.0005087613250342096]
---- EP [1/5] | BTCH [370/3634] ||| train_loss = 0.01607 ----
LR: [0.0005093477731736486]
---- EP [1/5] | BTCH [371/3634] ||| train_loss = 0.01229 ----
LR: [0.0005099357799320785]
---- EP [1/5] | BTCH [372/3634] ||| train_loss = 0.00912 ----
LR: [0.0005105253451141156]
---- EP [1/5] | BTCH [373/3634] ||| train_loss = 0.00749 ----
LR: [0.0005111164685238593]
---- EP [1/5] | BTCH [374/3634] ||| train_loss = 0.01573 ----
LR: [0.0005117091499648851]
---- EP [1/5] | BTCH [375/3634] ||| train_loss = 0.00932 ----
LR: [0.0005123033892402602]
---- EP [1/5] | BTCH [376/3634] ||| train_loss = 0.01377 ----
LR: [0.0005128991861525298]
---- EP [1/5] | BTCH [377/3634] ||| train_loss = 0.01659 ----
LR: [0.0005134965405037186]
---- EP [1/5] | BTCH [378/3634] ||| train_loss = 0.01167 ----
LR: [0.0005140954520953377]
---- EP [1/5] | BTCH [379/3634] ||| train_loss = 0.00824 ----
LR: [0.0005146959207283815]
---- EP [1/5] | BTCH [380/3634] ||| train_loss = 0.00967 ----
LR: [0.0005152979462033219]
---- EP [1/5] | BTCH [381/3634] ||| train_loss = 0.01582 ----
LR: [0.0005159015283201195]
---- EP [1/5] | BTCH [382/3634] ||| train_loss = 0.01757 ----
LR: [0.000516506666878214]
---- EP [1/5] | BTCH [383/3634] ||| train_loss = 0.01589 ----
LR: [0.0005171133616765269]
---- EP [1/5] | BTCH [384/3634] ||| train_loss = 0.00981 ----
LR: [0.0005177216125134675]
---- EP [1/5] | BTCH [385/3634] ||| train_loss = 0.01074 ----
LR: [0.0005183314191869216]
---- EP [1/5] | BTCH [386/3634] ||| train_loss = 0.01585 ----
LR: [0.0005189427814942648]
---- EP [1/5] | BTCH [387/3634] ||| train_loss = 0.00737 ----
LR: [0.0005195556992323505]
---- EP [1/5] | BTCH [388/3634] ||| train_loss = 0.02106 ----
LR: [0.0005201701721975188]
---- EP [1/5] | BTCH [389/3634] ||| train_loss = 0.01102 ----
LR: [0.0005207862001855891]
---- EP [1/5] | BTCH [390/3634] ||| train_loss = 0.01467 ----
LR: [0.0005214037829918694]
---- EP [1/5] | BTCH [391/3634] ||| train_loss = 0.01896 ----
LR: [0.0005220229204111453]
---- EP [1/5] | BTCH [392/3634] ||| train_loss = 0.01097 ----
LR: [0.0005226436122376908]
---- EP [1/5] | BTCH [393/3634] ||| train_loss = 0.01167 ----
LR: [0.0005232658582652594]
---- EP [1/5] | BTCH [394/3634] ||| train_loss = 0.01364 ----
LR: [0.0005238896582870894]
---- EP [1/5] | BTCH [395/3634] ||| train_loss = 0.02010 ----
LR: [0.0005245150120959073]
---- EP [1/5] | BTCH [396/3634] ||| train_loss = 0.01532 ----
LR: [0.0005251419194839142]
---- EP [1/5] | BTCH [397/3634] ||| train_loss = 0.01548 ----
LR: [0.0005257703802428043]
---- EP [1/5] | BTCH [398/3634] ||| train_loss = 0.01479 ----
LR: [0.00052640039416375]
---- EP [1/5] | BTCH [399/3634] ||| train_loss = 0.01267 ----
LR: [0.0005270319610374066]
---- EP [1/5] | BTCH [400/3634] ||| train_loss = 0.00767 ----
LR: [0.0005276650806539194]
---- EP [1/5] | BTCH [401/3634] ||| train_loss = 0.02017 ----
LR: [0.0005282997528029149]
---- EP [1/5] | BTCH [402/3634] ||| train_loss = 0.01374 ----
LR: [0.0005289359772734977]
---- EP [1/5] | BTCH [403/3634] ||| train_loss = 0.01628 ----
LR: [0.0005295737538542674]
---- EP [1/5] | BTCH [404/3634] ||| train_loss = 0.00691 ----
LR: [0.0005302130823332998]
---- EP [1/5] | BTCH [405/3634] ||| train_loss = 0.00941 ----
LR: [0.0005308539624981554]
---- EP [1/5] | BTCH [406/3634] ||| train_loss = 0.00965 ----
LR: [0.0005314963941358865]
---- EP [1/5] | BTCH [407/3634] ||| train_loss = 0.00937 ----
LR: [0.0005321403770330215]
---- EP [1/5] | BTCH [408/3634] ||| train_loss = 0.01840 ----
LR: [0.0005327859109755771]
---- EP [1/5] | BTCH [409/3634] ||| train_loss = 0.00738 ----
LR: [0.0005334329957490547]
---- EP [1/5] | BTCH [410/3634] ||| train_loss = 0.01296 ----
LR: [0.0005340816311384371]
---- EP [1/5] | BTCH [411/3634] ||| train_loss = 0.00611 ----
LR: [0.0005347318169281971]
---- EP [1/5] | BTCH [412/3634] ||| train_loss = 0.00629 ----
LR: [0.0005353835529022886]
---- EP [1/5] | BTCH [413/3634] ||| train_loss = 0.01149 ----
LR: [0.0005360368388441523]
---- EP [1/5] | BTCH [414/3634] ||| train_loss = 0.01941 ----
LR: [0.0005366916745367135]
---- EP [1/5] | BTCH [415/3634] ||| train_loss = 0.01167 ----
LR: [0.0005373480597623791]
---- EP [1/5] | BTCH [416/3634] ||| train_loss = 0.00971 ----
LR: [0.000538005994303049]
---- EP [1/5] | BTCH [417/3634] ||| train_loss = 0.01250 ----
LR: [0.0005386654779400979]
---- EP [1/5] | BTCH [418/3634] ||| train_loss = 0.01250 ----
LR: [0.0005393265104543972]
---- EP [1/5] | BTCH [419/3634] ||| train_loss = 0.01129 ----
LR: [0.0005399890916262928]
---- EP [1/5] | BTCH [420/3634] ||| train_loss = 0.01544 ----
LR: [0.0005406532212356239]
---- EP [1/5] | BTCH [421/3634] ||| train_loss = 0.01199 ----
LR: [0.0005413188990617095]
---- EP [1/5] | BTCH [422/3634] ||| train_loss = 0.00730 ----
LR: [0.0005419861248833601]
---- EP [1/5] | BTCH [423/3634] ||| train_loss = 0.01253 ----
LR: [0.000542654898478866]
---- EP [1/5] | BTCH [424/3634] ||| train_loss = 0.01176 ----
LR: [0.0005433252196260091]
---- EP [1/5] | BTCH [425/3634] ||| train_loss = 0.00828 ----
LR: [0.0005439970881020492]
---- EP [1/5] | BTCH [426/3634] ||| train_loss = 0.01320 ----
LR: [0.0005446705036837394]
---- EP [1/5] | BTCH [427/3634] ||| train_loss = 0.01126 ----
LR: [0.0005453454661473161]
---- EP [1/5] | BTCH [428/3634] ||| train_loss = 0.01272 ----
LR: [0.0005460219752685003]
---- EP [1/5] | BTCH [429/3634] ||| train_loss = 0.01412 ----
LR: [0.0005467000308224997]
---- EP [1/5] | BTCH [430/3634] ||| train_loss = 0.01566 ----
LR: [0.0005473796325840118]
---- EP [1/5] | BTCH [431/3634] ||| train_loss = 0.01572 ----
LR: [0.0005480607803272138]
---- EP [1/5] | BTCH [432/3634] ||| train_loss = 0.00916 ----
LR: [0.0005487434738257746]
---- EP [1/5] | BTCH [433/3634] ||| train_loss = 0.01643 ----
LR: [0.0005494277128528461]
---- EP [1/5] | BTCH [434/3634] ||| train_loss = 0.00978 ----
LR: [0.0005501134971810685]
---- EP [1/5] | BTCH [435/3634] ||| train_loss = 0.01243 ----
LR: [0.0005508008265825703]
---- EP [1/5] | BTCH [436/3634] ||| train_loss = 0.01570 ----
LR: [0.0005514897008289613]
---- EP [1/5] | BTCH [437/3634] ||| train_loss = 0.01453 ----
LR: [0.0005521801196913412]
---- EP [1/5] | BTCH [438/3634] ||| train_loss = 0.01688 ----
LR: [0.0005528720829402981]
---- EP [1/5] | BTCH [439/3634] ||| train_loss = 0.01331 ----
LR: [0.000553565590345903]
---- EP [1/5] | BTCH [440/3634] ||| train_loss = 0.00970 ----
LR: [0.0005542606416777188]
---- EP [1/5] | BTCH [441/3634] ||| train_loss = 0.00923 ----
LR: [0.0005549572367047895]
---- EP [1/5] | BTCH [442/3634] ||| train_loss = 0.00795 ----
LR: [0.000555655375195651]
---- EP [1/5] | BTCH [443/3634] ||| train_loss = 0.01309 ----
LR: [0.0005563550569183239]
---- EP [1/5] | BTCH [444/3634] ||| train_loss = 0.01472 ----
LR: [0.0005570562816403155]
---- EP [1/5] | BTCH [445/3634] ||| train_loss = 0.00992 ----
LR: [0.0005577590491286245]
---- EP [1/5] | BTCH [446/3634] ||| train_loss = 0.00967 ----
LR: [0.0005584633591497312]
---- EP [1/5] | BTCH [447/3634] ||| train_loss = 0.01687 ----
LR: [0.0005591692114696074]
---- EP [1/5] | BTCH [448/3634] ||| train_loss = 0.01543 ----
LR: [0.0005598766058537118]
---- EP [1/5] | BTCH [449/3634] ||| train_loss = 0.01214 ----
LR: [0.0005605855420669874]
---- EP [1/5] | BTCH [450/3634] ||| train_loss = 0.01403 ----
LR: [0.0005612960198738692]
---- EP [1/5] | BTCH [451/3634] ||| train_loss = 0.01087 ----
LR: [0.0005620080390382788]
---- EP [1/5] | BTCH [452/3634] ||| train_loss = 0.00958 ----
LR: [0.0005627215993236241]
---- EP [1/5] | BTCH [453/3634] ||| train_loss = 0.01096 ----
LR: [0.0005634367004928031]
---- EP [1/5] | BTCH [454/3634] ||| train_loss = 0.01441 ----
LR: [0.0005641533423081969]
---- EP [1/5] | BTCH [455/3634] ||| train_loss = 0.00850 ----
LR: [0.0005648715245316852]
---- EP [1/5] | BTCH [456/3634] ||| train_loss = 0.01205 ----
LR: [0.0005655912469246203]
---- EP [1/5] | BTCH [457/3634] ||| train_loss = 0.00674 ----
LR: [0.0005663125092478603]
---- EP [1/5] | BTCH [458/3634] ||| train_loss = 0.01875 ----
LR: [0.0005670353112617356]
---- EP [1/5] | BTCH [459/3634] ||| train_loss = 0.01818 ----
LR: [0.0005677596527260791]
---- EP [1/5] | BTCH [460/3634] ||| train_loss = 0.01713 ----
LR: [0.0005684855334001995]
---- EP [1/5] | BTCH [461/3634] ||| train_loss = 0.01690 ----
LR: [0.0005692129530428993]
---- EP [1/5] | BTCH [462/3634] ||| train_loss = 0.00585 ----
LR: [0.0005699419114124759]
---- EP [1/5] | BTCH [463/3634] ||| train_loss = 0.00918 ----
LR: [0.0005706724082667029]
---- EP [1/5] | BTCH [464/3634] ||| train_loss = 0.00993 ----
LR: [0.0005714044433628544]
---- EP [1/5] | BTCH [465/3634] ||| train_loss = 0.00987 ----
LR: [0.0005721380164576857]
---- EP [1/5] | BTCH [466/3634] ||| train_loss = 0.00973 ----
LR: [0.0005728731273074456]
---- EP [1/5] | BTCH [467/3634] ||| train_loss = 0.01150 ----
LR: [0.0005736097756678677]
---- EP [1/5] | BTCH [468/3634] ||| train_loss = 0.01114 ----
LR: [0.000574347961294179]
---- EP [1/5] | BTCH [469/3634] ||| train_loss = 0.00820 ----
LR: [0.0005750876839410932]
---- EP [1/5] | BTCH [470/3634] ||| train_loss = 0.01634 ----
LR: [0.0005758289433628154]
---- EP [1/5] | BTCH [471/3634] ||| train_loss = 0.01077 ----
LR: [0.0005765717393130341]
---- EP [1/5] | BTCH [472/3634] ||| train_loss = 0.01621 ----
LR: [0.0005773160715449345]
---- EP [1/5] | BTCH [473/3634] ||| train_loss = 0.01674 ----
LR: [0.0005780619398111902]
---- EP [1/5] | BTCH [474/3634] ||| train_loss = 0.01976 ----
LR: [0.0005788093438639612]
---- EP [1/5] | BTCH [475/3634] ||| train_loss = 0.01293 ----
LR: [0.0005795582834548958]
---- EP [1/5] | BTCH [476/3634] ||| train_loss = 0.02583 ----
LR: [0.0005803087583351376]
---- EP [1/5] | BTCH [477/3634] ||| train_loss = 0.00839 ----
LR: [0.0005810607682553183]
---- EP [1/5] | BTCH [478/3634] ||| train_loss = 0.01351 ----
LR: [0.0005818143129655562]
---- EP [1/5] | BTCH [479/3634] ||| train_loss = 0.02111 ----
LR: [0.000582569392215463]
---- EP [1/5] | BTCH [480/3634] ||| train_loss = 0.01115 ----
LR: [0.0005833260057541423]
---- EP [1/5] | BTCH [481/3634] ||| train_loss = 0.01780 ----
LR: [0.0005840841533301805]
---- EP [1/5] | BTCH [482/3634] ||| train_loss = 0.01060 ----
LR: [0.0005848438346916611]
---- EP [1/5] | BTCH [483/3634] ||| train_loss = 0.00594 ----
LR: [0.0005856050495861524]
---- EP [1/5] | BTCH [484/3634] ||| train_loss = 0.01128 ----
LR: [0.0005863677977607246]
---- EP [1/5] | BTCH [485/3634] ||| train_loss = 0.00987 ----
LR: [0.0005871320789619227]
---- EP [1/5] | BTCH [486/3634] ||| train_loss = 0.00644 ----
LR: [0.0005878978929357917]
---- EP [1/5] | BTCH [487/3634] ||| train_loss = 0.01246 ----
LR: [0.0005886652394278668]
---- EP [1/5] | BTCH [488/3634] ||| train_loss = 0.01402 ----
LR: [0.0005894341181831714]
---- EP [1/5] | BTCH [489/3634] ||| train_loss = 0.00745 ----
LR: [0.0005902045289462206]
---- EP [1/5] | BTCH [490/3634] ||| train_loss = 0.01301 ----
LR: [0.000590976471461023]
---- EP [1/5] | BTCH [491/3634] ||| train_loss = 0.01164 ----
LR: [0.0005917499454710737]
---- EP [1/5] | BTCH [492/3634] ||| train_loss = 0.01426 ----
LR: [0.0005925249507193631]
---- EP [1/5] | BTCH [493/3634] ||| train_loss = 0.00954 ----
LR: [0.0005933014869483697]
---- EP [1/5] | BTCH [494/3634] ||| train_loss = 0.01092 ----
LR: [0.0005940795539000673]
---- EP [1/5] | BTCH [495/3634] ||| train_loss = 0.01605 ----
LR: [0.0005948591513159126]
---- EP [1/5] | BTCH [496/3634] ||| train_loss = 0.01010 ----
LR: [0.0005956402789368646]
---- EP [1/5] | BTCH [497/3634] ||| train_loss = 0.01724 ----
LR: [0.0005964229365033654]
---- EP [1/5] | BTCH [498/3634] ||| train_loss = 0.00840 ----
LR: [0.0005972071237553556]
---- EP [1/5] | BTCH [499/3634] ||| train_loss = 0.01336 ----
LR: [0.0005979928404322606]
---- EP [1/5] | BTCH [500/3634] ||| train_loss = 0.01970 ----
LR: [0.0005987800862730028]
---- EP [1/5] | BTCH [501/3634] ||| train_loss = 0.01095 ----
LR: [0.0005995688610159929]
---- EP [1/5] | BTCH [502/3634] ||| train_loss = 0.01157 ----
LR: [0.0006003591643991384]
---- EP [1/5] | BTCH [503/3634] ||| train_loss = 0.01314 ----
LR: [0.0006011509961598317]
---- EP [1/5] | BTCH [504/3634] ||| train_loss = 0.00884 ----
LR: [0.0006019443560349672]
---- EP [1/5] | BTCH [505/3634] ||| train_loss = 0.01359 ----
LR: [0.0006027392437609174]
---- EP [1/5] | BTCH [506/3634] ||| train_loss = 0.00793 ----
LR: [0.0006035356590735636]
---- EP [1/5] | BTCH [507/3634] ||| train_loss = 0.01530 ----
LR: [0.0006043336017082668]
---- EP [1/5] | BTCH [508/3634] ||| train_loss = 0.01673 ----
LR: [0.000605133071399885]
---- EP [1/5] | BTCH [509/3634] ||| train_loss = 0.00975 ----
LR: [0.000605934067882773]
---- EP [1/5] | BTCH [510/3634] ||| train_loss = 0.01192 ----
LR: [0.0006067365908907687]
---- EP [1/5] | BTCH [511/3634] ||| train_loss = 0.00857 ----
LR: [0.0006075406401572121]
---- EP [1/5] | BTCH [512/3634] ||| train_loss = 0.01232 ----
LR: [0.0006083462154149299]
---- EP [1/5] | BTCH [513/3634] ||| train_loss = 0.01263 ----
LR: [0.0006091533163962454]
---- EP [1/5] | BTCH [514/3634] ||| train_loss = 0.01271 ----
LR: [0.000609961942832974]
---- EP [1/5] | BTCH [515/3634] ||| train_loss = 0.01720 ----
LR: [0.0006107720944564209]
---- EP [1/5] | BTCH [516/3634] ||| train_loss = 0.01357 ----
LR: [0.0006115837709973898]
---- EP [1/5] | BTCH [517/3634] ||| train_loss = 0.00924 ----
LR: [0.0006123969721861747]
---- EP [1/5] | BTCH [518/3634] ||| train_loss = 0.02030 ----
LR: [0.0006132116977525647]
---- EP [1/5] | BTCH [519/3634] ||| train_loss = 0.00851 ----
LR: [0.0006140279474258371]
---- EP [1/5] | BTCH [520/3634] ||| train_loss = 0.01368 ----
LR: [0.000614845720934773]
---- EP [1/5] | BTCH [521/3634] ||| train_loss = 0.01222 ----
LR: [0.0006156650180076367]
---- EP [1/5] | BTCH [522/3634] ||| train_loss = 0.00737 ----
LR: [0.0006164858383721928]
---- EP [1/5] | BTCH [523/3634] ||| train_loss = 0.01615 ----
LR: [0.0006173081817556943]
---- EP [1/5] | BTCH [524/3634] ||| train_loss = 0.01961 ----
LR: [0.0006181320478848944]
---- EP [1/5] | BTCH [525/3634] ||| train_loss = 0.00982 ----
LR: [0.0006189574364860364]
---- EP [1/5] | BTCH [526/3634] ||| train_loss = 0.00754 ----
LR: [0.0006197843472848588]
---- EP [1/5] | BTCH [527/3634] ||| train_loss = 0.01295 ----
LR: [0.0006206127800065936]
---- EP [1/5] | BTCH [528/3634] ||| train_loss = 0.01117 ----
LR: [0.0006214427343759661]
---- EP [1/5] | BTCH [529/3634] ||| train_loss = 0.01578 ----
LR: [0.0006222742101172022]
---- EP [1/5] | BTCH [530/3634] ||| train_loss = 0.00936 ----
LR: [0.0006231072069540124]
---- EP [1/5] | BTCH [531/3634] ||| train_loss = 0.01544 ----
LR: [0.0006239417246096113]
---- EP [1/5] | BTCH [532/3634] ||| train_loss = 0.00789 ----
LR: [0.000624777762806698]
---- EP [1/5] | BTCH [533/3634] ||| train_loss = 0.01253 ----
LR: [0.0006256153212674774]
---- EP [1/5] | BTCH [534/3634] ||| train_loss = 0.00802 ----
LR: [0.0006264543997136444]
---- EP [1/5] | BTCH [535/3634] ||| train_loss = 0.01011 ----
LR: [0.000627294997866382]
---- EP [1/5] | BTCH [536/3634] ||| train_loss = 0.01428 ----
LR: [0.0006281371154463807]
---- EP [1/5] | BTCH [537/3634] ||| train_loss = 0.01765 ----
LR: [0.0006289807521738192]
---- EP [1/5] | BTCH [538/3634] ||| train_loss = 0.01030 ----
LR: [0.0006298259077683697]
---- EP [1/5] | BTCH [539/3634] ||| train_loss = 0.01286 ----
LR: [0.0006306725819492029]
---- EP [1/5] | BTCH [540/3634] ||| train_loss = 0.01526 ----
LR: [0.0006315207744349866]
---- EP [1/5] | BTCH [541/3634] ||| train_loss = 0.01214 ----
LR: [0.0006323704849438786]
---- EP [1/5] | BTCH [542/3634] ||| train_loss = 0.00739 ----
LR: [0.0006332217131935387]
---- EP [1/5] | BTCH [543/3634] ||| train_loss = 0.00829 ----
VAL ||| loss = 0.01351092521577297, psnr = 30.651832580566406, ssim = 0.9061436653137207
LR: [0.0006340744589011169]
---- EP [1/5] | BTCH [544/3634] ||| train_loss = 0.01844 ----
LR: [0.0006349287217832615]
---- EP [1/5] | BTCH [545/3634] ||| train_loss = 0.00963 ----
LR: [0.0006357845015561182]
---- EP [1/5] | BTCH [546/3634] ||| train_loss = 0.01573 ----
LR: [0.000636641797935324]
---- EP [1/5] | BTCH [547/3634] ||| train_loss = 0.01682 ----
LR: [0.0006375006106360166]
---- EP [1/5] | BTCH [548/3634] ||| train_loss = 0.01628 ----
LR: [0.0006383609393728271]
---- EP [1/5] | BTCH [549/3634] ||| train_loss = 0.00857 ----
LR: [0.000639222783859885]
---- EP [1/5] | BTCH [550/3634] ||| train_loss = 0.01463 ----
LR: [0.000640086143810812]
---- EP [1/5] | BTCH [551/3634] ||| train_loss = 0.02200 ----
LR: [0.0006409510189387332]
---- EP [1/5] | BTCH [552/3634] ||| train_loss = 0.01586 ----
LR: [0.0006418174089562658]
---- EP [1/5] | BTCH [553/3634] ||| train_loss = 0.01595 ----
LR: [0.0006426853135755202]
---- EP [1/5] | BTCH [554/3634] ||| train_loss = 0.01351 ----
LR: [0.0006435547325081108]
---- EP [1/5] | BTCH [555/3634] ||| train_loss = 0.00928 ----
LR: [0.0006444256654651453]
---- EP [1/5] | BTCH [556/3634] ||| train_loss = 0.01599 ----
LR: [0.0006452981121572252]
---- EP [1/5] | BTCH [557/3634] ||| train_loss = 0.01076 ----
LR: [0.0006461720722944573]
---- EP [1/5] | BTCH [558/3634] ||| train_loss = 0.02087 ----
LR: [0.0006470475455864367]
---- EP [1/5] | BTCH [559/3634] ||| train_loss = 0.00851 ----
LR: [0.0006479245317422607]
---- EP [1/5] | BTCH [560/3634] ||| train_loss = 0.00578 ----
LR: [0.0006488030304705236]
---- EP [1/5] | BTCH [561/3634] ||| train_loss = 0.00914 ----
LR: [0.0006496830414793112]
---- EP [1/5] | BTCH [562/3634] ||| train_loss = 0.01262 ----
LR: [0.0006505645644762185]
---- EP [1/5] | BTCH [563/3634] ||| train_loss = 0.01695 ----
LR: [0.0006514475991683272]
---- EP [1/5] | BTCH [564/3634] ||| train_loss = 0.01295 ----
LR: [0.0006523321452622226]
---- EP [1/5] | BTCH [565/3634] ||| train_loss = 0.01040 ----
LR: [0.0006532182024639854]
---- EP [1/5] | BTCH [566/3634] ||| train_loss = 0.01481 ----
LR: [0.0006541057704791964]
---- EP [1/5] | BTCH [567/3634] ||| train_loss = 0.00787 ----
LR: [0.0006549948490129284]
---- EP [1/5] | BTCH [568/3634] ||| train_loss = 0.01634 ----
LR: [0.0006558854377697598]
---- EP [1/5] | BTCH [569/3634] ||| train_loss = 0.00643 ----
LR: [0.0006567775364537641]
---- EP [1/5] | BTCH [570/3634] ||| train_loss = 0.00945 ----
LR: [0.0006576711447685134]
---- EP [1/5] | BTCH [571/3634] ||| train_loss = 0.01826 ----
LR: [0.000658566262417077]
---- EP [1/5] | BTCH [572/3634] ||| train_loss = 0.01129 ----
LR: [0.0006594628891020225]
---- EP [1/5] | BTCH [573/3634] ||| train_loss = 0.01699 ----
LR: [0.0006603610245254181]
---- EP [1/5] | BTCH [574/3634] ||| train_loss = 0.00727 ----
LR: [0.0006612606683888307]
---- EP [1/5] | BTCH [575/3634] ||| train_loss = 0.01325 ----
LR: [0.0006621618203933224]
---- EP [1/5] | BTCH [576/3634] ||| train_loss = 0.01722 ----
LR: [0.000663064480239459]
---- EP [1/5] | BTCH [577/3634] ||| train_loss = 0.00656 ----
LR: [0.0006639686476273016]
---- EP [1/5] | BTCH [578/3634] ||| train_loss = 0.00918 ----
LR: [0.0006648743222564119]
---- EP [1/5] | BTCH [579/3634] ||| train_loss = 0.01205 ----
LR: [0.0006657815038258498]
---- EP [1/5] | BTCH [580/3634] ||| train_loss = 0.01308 ----
LR: [0.0006666901920341795]
---- EP [1/5] | BTCH [581/3634] ||| train_loss = 0.01765 ----
LR: [0.0006676003865794533]
---- EP [1/5] | BTCH [582/3634] ||| train_loss = 0.01073 ----
LR: [0.000668512087159236]
---- EP [1/5] | BTCH [583/3634] ||| train_loss = 0.01322 ----
LR: [0.0006694252934705842]
---- EP [1/5] | BTCH [584/3634] ||| train_loss = 0.01327 ----
LR: [0.000670340005210053]
---- EP [1/5] | BTCH [585/3634] ||| train_loss = 0.01173 ----
LR: [0.0006712562220737035]
---- EP [1/5] | BTCH [586/3634] ||| train_loss = 0.00899 ----
LR: [0.0006721739437570932]
---- EP [1/5] | BTCH [587/3634] ||| train_loss = 0.01415 ----
LR: [0.0006730931699552804]
---- EP [1/5] | BTCH [588/3634] ||| train_loss = 0.01359 ----
LR: [0.0006740139003628184]
---- EP [1/5] | BTCH [589/3634] ||| train_loss = 0.01589 ----
LR: [0.0006749361346737696]
---- EP [1/5] | BTCH [590/3634] ||| train_loss = 0.02014 ----
LR: [0.0006758598725816918]
---- EP [1/5] | BTCH [591/3634] ||| train_loss = 0.01987 ----
LR: [0.0006767851137796429]
---- EP [1/5] | BTCH [592/3634] ||| train_loss = 0.01220 ----
LR: [0.0006777118579601813]
---- EP [1/5] | BTCH [593/3634] ||| train_loss = 0.01416 ----
LR: [0.0006786401048153659]
---- EP [1/5] | BTCH [594/3634] ||| train_loss = 0.00797 ----
LR: [0.0006795698540367594]
---- EP [1/5] | BTCH [595/3634] ||| train_loss = 0.00835 ----
LR: [0.0006805011053154213]
---- EP [1/5] | BTCH [596/3634] ||| train_loss = 0.00688 ----
LR: [0.0006814338583419136]
---- EP [1/5] | BTCH [597/3634] ||| train_loss = 0.01255 ----
LR: [0.0006823681128063017]
---- EP [1/5] | BTCH [598/3634] ||| train_loss = 0.00920 ----
LR: [0.0006833038683981447]
---- EP [1/5] | BTCH [599/3634] ||| train_loss = 0.01411 ----
LR: [0.0006842411248065144]
---- EP [1/5] | BTCH [600/3634] ||| train_loss = 0.01651 ----
LR: [0.0006851798817199724]
---- EP [1/5] | BTCH [601/3634] ||| train_loss = 0.01049 ----
LR: [0.0006861201388265875]
---- EP [1/5] | BTCH [602/3634] ||| train_loss = 0.00950 ----
LR: [0.0006870618958139309]
---- EP [1/5] | BTCH [603/3634] ||| train_loss = 0.01729 ----
LR: [0.0006880051523690742]
---- EP [1/5] | BTCH [604/3634] ||| train_loss = 0.00908 ----
LR: [0.0006889499081785874]
---- EP [1/5] | BTCH [605/3634] ||| train_loss = 0.00891 ----
LR: [0.000689896162928548]
---- EP [1/5] | BTCH [606/3634] ||| train_loss = 0.01282 ----
LR: [0.0006908439163045305]
---- EP [1/5] | BTCH [607/3634] ||| train_loss = 0.00877 ----
LR: [0.0006917931679916167]
---- EP [1/5] | BTCH [608/3634] ||| train_loss = 0.01050 ----
LR: [0.0006927439176743835]
---- EP [1/5] | BTCH [609/3634] ||| train_loss = 0.01605 ----
LR: [0.000693696165036917]
---- EP [1/5] | BTCH [610/3634] ||| train_loss = 0.01120 ----
LR: [0.0006946499097628001]
---- EP [1/5] | BTCH [611/3634] ||| train_loss = 0.01331 ----
LR: [0.0006956051515351214]
---- EP [1/5] | BTCH [612/3634] ||| train_loss = 0.00872 ----
LR: [0.0006965618900364734]
---- EP [1/5] | BTCH [613/3634] ||| train_loss = 0.00733 ----
LR: [0.0006975201249489488]
---- EP [1/5] | BTCH [614/3634] ||| train_loss = 0.01201 ----
LR: [0.000698479855954141]
---- EP [1/5] | BTCH [615/3634] ||| train_loss = 0.01104 ----
LR: [0.0006994410827331505]
---- EP [1/5] | BTCH [616/3634] ||| train_loss = 0.00834 ----
LR: [0.0007004038049665765]
---- EP [1/5] | BTCH [617/3634] ||| train_loss = 0.00917 ----
LR: [0.0007013680223345274]
---- EP [1/5] | BTCH [618/3634] ||| train_loss = 0.01074 ----
LR: [0.0007023337345166102]
---- EP [1/5] | BTCH [619/3634] ||| train_loss = 0.00882 ----
LR: [0.0007033009411919356]
---- EP [1/5] | BTCH [620/3634] ||| train_loss = 0.01044 ----
LR: [0.0007042696420391185]
---- EP [1/5] | BTCH [621/3634] ||| train_loss = 0.01334 ----
LR: [0.0007052398367362756]
---- EP [1/5] | BTCH [622/3634] ||| train_loss = 0.00686 ----
LR: [0.0007062115249610312]
---- EP [1/5] | BTCH [623/3634] ||| train_loss = 0.01432 ----
LR: [0.0007071847063905082]
---- EP [1/5] | BTCH [624/3634] ||| train_loss = 0.01173 ----
LR: [0.0007081593807013384]
---- EP [1/5] | BTCH [625/3634] ||| train_loss = 0.01184 ----
LR: [0.0007091355475696542]
---- EP [1/5] | BTCH [626/3634] ||| train_loss = 0.01502 ----
LR: [0.0007101132066710935]
---- EP [1/5] | BTCH [627/3634] ||| train_loss = 0.01251 ----
LR: [0.0007110923576807964]
---- EP [1/5] | BTCH [628/3634] ||| train_loss = 0.02167 ----
LR: [0.0007120730002734121]
---- EP [1/5] | BTCH [629/3634] ||| train_loss = 0.01278 ----
LR: [0.0007130551341230865]
---- EP [1/5] | BTCH [630/3634] ||| train_loss = 0.00757 ----
LR: [0.0007140387589034767]
---- EP [1/5] | BTCH [631/3634] ||| train_loss = 0.01010 ----
LR: [0.0007150238742877398]
---- EP [1/5] | BTCH [632/3634] ||| train_loss = 0.00693 ----
LR: [0.000716010479948544]
---- EP [1/5] | BTCH [633/3634] ||| train_loss = 0.01151 ----
LR: [0.0007169985755580525]
---- EP [1/5] | BTCH [634/3634] ||| train_loss = 0.01541 ----
LR: [0.0007179881607879447]
---- EP [1/5] | BTCH [635/3634] ||| train_loss = 0.01527 ----
LR: [0.000718979235309395]
---- EP [1/5] | BTCH [636/3634] ||| train_loss = 0.01671 ----
LR: [0.0007199717987930888]
---- EP [1/5] | BTCH [637/3634] ||| train_loss = 0.01667 ----
LR: [0.0007209658509092151]
---- EP [1/5] | BTCH [638/3634] ||| train_loss = 0.01682 ----
LR: [0.0007219613913274688]
---- EP [1/5] | BTCH [639/3634] ||| train_loss = 0.01053 ----
LR: [0.0007229584197170503]
---- EP [1/5] | BTCH [640/3634] ||| train_loss = 0.01505 ----
LR: [0.000723956935746662]
---- EP [1/5] | BTCH [641/3634] ||| train_loss = 0.00965 ----
LR: [0.000724956939084519]
---- EP [1/5] | BTCH [642/3634] ||| train_loss = 0.01074 ----
LR: [0.0007259584293983351]
---- EP [1/5] | BTCH [643/3634] ||| train_loss = 0.00611 ----
LR: [0.0007269614063553347]
---- EP [1/5] | BTCH [644/3634] ||| train_loss = 0.01002 ----
LR: [0.000727965869622248]
---- EP [1/5] | BTCH [645/3634] ||| train_loss = 0.01807 ----
LR: [0.0007289718188653073]
---- EP [1/5] | BTCH [646/3634] ||| train_loss = 0.01557 ----
LR: [0.0007299792537502538]
---- EP [1/5] | BTCH [647/3634] ||| train_loss = 0.01397 ----
LR: [0.0007309881739423381]
---- EP [1/5] | BTCH [648/3634] ||| train_loss = 0.01292 ----
LR: [0.0007319985791063126]
---- EP [1/5] | BTCH [649/3634] ||| train_loss = 0.02269 ----
LR: [0.0007330104689064372]
---- EP [1/5] | BTCH [650/3634] ||| train_loss = 0.01191 ----
LR: [0.0007340238430064809]
---- EP [1/5] | BTCH [651/3634] ||| train_loss = 0.00818 ----
LR: [0.0007350387010697148]
---- EP [1/5] | BTCH [652/3634] ||| train_loss = 0.00699 ----
LR: [0.0007360550427589225]
---- EP [1/5] | BTCH [653/3634] ||| train_loss = 0.01594 ----
LR: [0.0007370728677363932]
---- EP [1/5] | BTCH [654/3634] ||| train_loss = 0.01436 ----
LR: [0.0007380921756639184]
---- EP [1/5] | BTCH [655/3634] ||| train_loss = 0.00894 ----
LR: [0.0007391129662028036]
---- EP [1/5] | BTCH [656/3634] ||| train_loss = 0.01042 ----
LR: [0.000740135239013855]
---- EP [1/5] | BTCH [657/3634] ||| train_loss = 0.01577 ----
LR: [0.0007411589937573928]
---- EP [1/5] | BTCH [658/3634] ||| train_loss = 0.01275 ----
LR: [0.0007421842300932412]
---- EP [1/5] | BTCH [659/3634] ||| train_loss = 0.01434 ----
LR: [0.0007432109476807336]
---- EP [1/5] | BTCH [660/3634] ||| train_loss = 0.00936 ----
LR: [0.0007442391461787087]
---- EP [1/5] | BTCH [661/3634] ||| train_loss = 0.01688 ----
LR: [0.0007452688252455146]
---- EP [1/5] | BTCH [662/3634] ||| train_loss = 0.01179 ----
LR: [0.0007462999845390082]
---- EP [1/5] | BTCH [663/3634] ||| train_loss = 0.01158 ----
LR: [0.000747332623716554]
---- EP [1/5] | BTCH [664/3634] ||| train_loss = 0.01796 ----
LR: [0.0007483667424350235]
---- EP [1/5] | BTCH [665/3634] ||| train_loss = 0.01432 ----
LR: [0.0007494023403508011]
---- EP [1/5] | BTCH [666/3634] ||| train_loss = 0.01201 ----
LR: [0.0007504394171197731]
---- EP [1/5] | BTCH [667/3634] ||| train_loss = 0.00950 ----
LR: [0.0007514779723973367]
---- EP [1/5] | BTCH [668/3634] ||| train_loss = 0.00905 ----
LR: [0.0007525180058384033]
---- EP [1/5] | BTCH [669/3634] ||| train_loss = 0.01123 ----
LR: [0.0007535595170973831]
---- EP [1/5] | BTCH [670/3634] ||| train_loss = 0.01384 ----
LR: [0.0007546025058282058]
---- EP [1/5] | BTCH [671/3634] ||| train_loss = 0.01140 ----
LR: [0.0007556469716843012]
---- EP [1/5] | BTCH [672/3634] ||| train_loss = 0.00898 ----
LR: [0.0007566929143186154]
---- EP [1/5] | BTCH [673/3634] ||| train_loss = 0.00705 ----
LR: [0.0007577403333835966]
---- EP [1/5] | BTCH [674/3634] ||| train_loss = 0.01141 ----
LR: [0.0007587892285312106]
---- EP [1/5] | BTCH [675/3634] ||| train_loss = 0.01402 ----
LR: [0.0007598395994129255]
---- EP [1/5] | BTCH [676/3634] ||| train_loss = 0.02622 ----
LR: [0.0007608914456797237]
---- EP [1/5] | BTCH [677/3634] ||| train_loss = 0.01565 ----
LR: [0.0007619447669820947]
---- EP [1/5] | BTCH [678/3634] ||| train_loss = 0.01014 ----
LR: [0.000762999562970039]
---- EP [1/5] | BTCH [679/3634] ||| train_loss = 0.00903 ----
LR: [0.0007640558332930678]
---- EP [1/5] | BTCH [680/3634] ||| train_loss = 0.01269 ----
LR: [0.0007651135776001999]
---- EP [1/5] | BTCH [681/3634] ||| train_loss = 0.00901 ----
LR: [0.000766172795539968]
---- EP [1/5] | BTCH [682/3634] ||| train_loss = 0.01325 ----
LR: [0.0007672334867604106]
---- EP [1/5] | BTCH [683/3634] ||| train_loss = 0.01158 ----
LR: [0.0007682956509090823]
---- EP [1/5] | BTCH [684/3634] ||| train_loss = 0.01110 ----
LR: [0.0007693592876330431]
---- EP [1/5] | BTCH [685/3634] ||| train_loss = 0.01179 ----
LR: [0.0007704243965788674]
---- EP [1/5] | BTCH [686/3634] ||| train_loss = 0.01392 ----
LR: [0.0007714909773926353]
---- EP [1/5] | BTCH [687/3634] ||| train_loss = 0.00704 ----
LR: [0.0007725590297199443]
---- EP [1/5] | BTCH [688/3634] ||| train_loss = 0.01582 ----
LR: [0.0007736285532058979]
---- EP [1/5] | BTCH [689/3634] ||| train_loss = 0.01453 ----
LR: [0.0007746995474951172]
---- EP [1/5] | BTCH [690/3634] ||| train_loss = 0.01228 ----
LR: [0.0007757720122317253]
---- EP [1/5] | BTCH [691/3634] ||| train_loss = 0.00832 ----
LR: [0.0007768459470593615]
---- EP [1/5] | BTCH [692/3634] ||| train_loss = 0.01164 ----
LR: [0.0007779213516211792]
---- EP [1/5] | BTCH [693/3634] ||| train_loss = 0.00993 ----
LR: [0.0007789982255598411]
---- EP [1/5] | BTCH [694/3634] ||| train_loss = 0.01391 ----
LR: [0.0007800765685175171]
---- EP [1/5] | BTCH [695/3634] ||| train_loss = 0.00705 ----
LR: [0.0007811563801359]
---- EP [1/5] | BTCH [696/3634] ||| train_loss = 0.01103 ----
LR: [0.0007822376600561832]
---- EP [1/5] | BTCH [697/3634] ||| train_loss = 0.01234 ----
LR: [0.0007833204079190775]
---- EP [1/5] | BTCH [698/3634] ||| train_loss = 0.00997 ----
LR: [0.0007844046233648084]
---- EP [1/5] | BTCH [699/3634] ||| train_loss = 0.00896 ----
LR: [0.0007854903060331066]
---- EP [1/5] | BTCH [700/3634] ||| train_loss = 0.00921 ----
LR: [0.0007865774555632209]
---- EP [1/5] | BTCH [701/3634] ||| train_loss = 0.00919 ----
LR: [0.0007876660715939107]
---- EP [1/5] | BTCH [702/3634] ||| train_loss = 0.01390 ----
LR: [0.0007887561537634497]
---- EP [1/5] | BTCH [703/3634] ||| train_loss = 0.01855 ----
LR: [0.0007898477017096242]
---- EP [1/5] | BTCH [704/3634] ||| train_loss = 0.01345 ----
LR: [0.0007909407150697295]
---- EP [1/5] | BTCH [705/3634] ||| train_loss = 0.01338 ----
LR: [0.0007920351934805787]
---- EP [1/5] | BTCH [706/3634] ||| train_loss = 0.02255 ----
LR: [0.0007931311365784958]
---- EP [1/5] | BTCH [707/3634] ||| train_loss = 0.00919 ----
LR: [0.0007942285439993223]
---- EP [1/5] | BTCH [708/3634] ||| train_loss = 0.01315 ----
LR: [0.0007953274153784037]
---- EP [1/5] | BTCH [709/3634] ||| train_loss = 0.02459 ----
LR: [0.0007964277503506086]
---- EP [1/5] | BTCH [710/3634] ||| train_loss = 0.01337 ----
LR: [0.0007975295485503145]
---- EP [1/5] | BTCH [711/3634] ||| train_loss = 0.01706 ----
LR: [0.0007986328096114131]
---- EP [1/5] | BTCH [712/3634] ||| train_loss = 0.00715 ----
LR: [0.0007997375331673124]
---- EP [1/5] | BTCH [713/3634] ||| train_loss = 0.01137 ----
LR: [0.0008008437188509309]
---- EP [1/5] | BTCH [714/3634] ||| train_loss = 0.00930 ----
LR: [0.000801951366294705]
---- EP [1/5] | BTCH [715/3634] ||| train_loss = 0.01478 ----
LR: [0.000803060475130582]
---- EP [1/5] | BTCH [716/3634] ||| train_loss = 0.01342 ----
LR: [0.000804171044990025]
---- EP [1/5] | BTCH [717/3634] ||| train_loss = 0.01532 ----
LR: [0.0008052830755040132]
---- EP [1/5] | BTCH [718/3634] ||| train_loss = 0.01192 ----
LR: [0.0008063965663030366]
---- EP [1/5] | BTCH [719/3634] ||| train_loss = 0.01151 ----
LR: [0.0008075115170171048]
---- EP [1/5] | BTCH [720/3634] ||| train_loss = 0.00787 ----
LR: [0.0008086279272757381]
---- EP [1/5] | BTCH [721/3634] ||| train_loss = 0.01272 ----
LR: [0.0008097457967079745]
---- EP [1/5] | BTCH [722/3634] ||| train_loss = 0.01889 ----
LR: [0.0008108651249423681]
---- EP [1/5] | BTCH [723/3634] ||| train_loss = 0.01846 ----
LR: [0.0008119859116069803]
---- EP [1/5] | BTCH [724/3634] ||| train_loss = 0.00983 ----
VAL ||| loss = 0.013477523194131424, psnr = 30.654878616333008, ssim = 0.9060855507850647
LR: [0.000813108156329399]
---- EP [1/5] | BTCH [725/3634] ||| train_loss = 0.02045 ----
LR: [0.0008142318587367227]
---- EP [1/5] | BTCH [726/3634] ||| train_loss = 0.01720 ----
LR: [0.0008153570184555627]
---- EP [1/5] | BTCH [727/3634] ||| train_loss = 0.01810 ----
LR: [0.0008164836351120495]
---- EP [1/5] | BTCH [728/3634] ||| train_loss = 0.01286 ----
LR: [0.00081761170833183]
---- EP [1/5] | BTCH [729/3634] ||| train_loss = 0.00744 ----
LR: [0.000818741237740065]
---- EP [1/5] | BTCH [730/3634] ||| train_loss = 0.00738 ----
LR: [0.0008198722229614316]
---- EP [1/5] | BTCH [731/3634] ||| train_loss = 0.01128 ----
LR: [0.000821004663620126]
---- EP [1/5] | BTCH [732/3634] ||| train_loss = 0.01685 ----
LR: [0.0008221385593398557]
---- EP [1/5] | BTCH [733/3634] ||| train_loss = 0.01867 ----
LR: [0.0008232739097438508]
---- EP [1/5] | BTCH [734/3634] ||| train_loss = 0.01127 ----
LR: [0.0008244107144548523]
---- EP [1/5] | BTCH [735/3634] ||| train_loss = 0.00929 ----
LR: [0.0008255489730951224]
---- EP [1/5] | BTCH [736/3634] ||| train_loss = 0.00881 ----
LR: [0.000826688685286436]
---- EP [1/5] | BTCH [737/3634] ||| train_loss = 0.00859 ----
LR: [0.0008278298506500907]
---- EP [1/5] | BTCH [738/3634] ||| train_loss = 0.00974 ----
LR: [0.0008289724688068951]
---- EP [1/5] | BTCH [739/3634] ||| train_loss = 0.00446 ----
LR: [0.0008301165393771789]
---- EP [1/5] | BTCH [740/3634] ||| train_loss = 0.01357 ----
LR: [0.0008312620619807878]
---- EP [1/5] | BTCH [741/3634] ||| train_loss = 0.01167 ----
LR: [0.0008324090362370855]
---- EP [1/5] | BTCH [742/3634] ||| train_loss = 0.01168 ----
LR: [0.0008335574617649513]
---- EP [1/5] | BTCH [743/3634] ||| train_loss = 0.00865 ----
LR: [0.0008347073381827878]
---- EP [1/5] | BTCH [744/3634] ||| train_loss = 0.00989 ----
LR: [0.0008358586651085083]
---- EP [1/5] | BTCH [745/3634] ||| train_loss = 0.01115 ----
LR: [0.0008370114421595506]
---- EP [1/5] | BTCH [746/3634] ||| train_loss = 0.00979 ----
LR: [0.0008381656689528654]
---- EP [1/5] | BTCH [747/3634] ||| train_loss = 0.00956 ----
LR: [0.0008393213451049278]
---- EP [1/5] | BTCH [748/3634] ||| train_loss = 0.02468 ----
LR: [0.000840478470231722]
---- EP [1/5] | BTCH [749/3634] ||| train_loss = 0.00923 ----
LR: [0.0008416370439487588]
---- EP [1/5] | BTCH [750/3634] ||| train_loss = 0.01138 ----
LR: [0.0008427970658710683]
---- EP [1/5] | BTCH [751/3634] ||| train_loss = 0.01040 ----
LR: [0.0008439585356131898]
---- EP [1/5] | BTCH [752/3634] ||| train_loss = 0.01145 ----
LR: [0.0008451214527891923]
---- EP [1/5] | BTCH [753/3634] ||| train_loss = 0.01192 ----
LR: [0.0008462858170126594]
---- EP [1/5] | BTCH [754/3634] ||| train_loss = 0.00993 ----
LR: [0.0008474516278966903]
---- EP [1/5] | BTCH [755/3634] ||| train_loss = 0.00709 ----
LR: [0.0008486188850539127]
---- EP [1/5] | BTCH [756/3634] ||| train_loss = 0.01347 ----
LR: [0.000849787588096465]
---- EP [1/5] | BTCH [757/3634] ||| train_loss = 0.00722 ----
LR: [0.0008509577366360068]
---- EP [1/5] | BTCH [758/3634] ||| train_loss = 0.00815 ----
LR: [0.0008521293302837189]
---- EP [1/5] | BTCH [759/3634] ||| train_loss = 0.01261 ----
LR: [0.0008533023686503067]
---- EP [1/5] | BTCH [760/3634] ||| train_loss = 0.00706 ----
LR: [0.0008544768513459849]
---- EP [1/5] | BTCH [761/3634] ||| train_loss = 0.01697 ----
LR: [0.0008556527779804996]
---- EP [1/5] | BTCH [762/3634] ||| train_loss = 0.01259 ----
LR: [0.0008568301481631062]
---- EP [1/5] | BTCH [763/3634] ||| train_loss = 0.00823 ----
LR: [0.0008580089615025897]
---- EP [1/5] | BTCH [764/3634] ||| train_loss = 0.01553 ----
LR: [0.000859189217607248]
---- EP [1/5] | BTCH [765/3634] ||| train_loss = 0.01085 ----
LR: [0.0008603709160849085]
---- EP [1/5] | BTCH [766/3634] ||| train_loss = 0.00986 ----
LR: [0.0008615540565429115]
---- EP [1/5] | BTCH [767/3634] ||| train_loss = 0.01126 ----
LR: [0.0008627386385881182]
---- EP [1/5] | BTCH [768/3634] ||| train_loss = 0.01029 ----
LR: [0.0008639246618269182]
---- EP [1/5] | BTCH [769/3634] ||| train_loss = 0.01289 ----
LR: [0.0008651121258652136]
---- EP [1/5] | BTCH [770/3634] ||| train_loss = 0.01473 ----
LR: [0.0008663010303084345]
---- EP [1/5] | BTCH [771/3634] ||| train_loss = 0.01399 ----
LR: [0.0008674913747615271]
---- EP [1/5] | BTCH [772/3634] ||| train_loss = 0.02000 ----
LR: [0.0008686831588289624]
---- EP [1/5] | BTCH [773/3634] ||| train_loss = 0.01081 ----
LR: [0.0008698763821147308]
---- EP [1/5] | BTCH [774/3634] ||| train_loss = 0.01122 ----
LR: [0.000871071044222349]
---- EP [1/5] | BTCH [775/3634] ||| train_loss = 0.00756 ----
LR: [0.00087226714475485]
---- EP [1/5] | BTCH [776/3634] ||| train_loss = 0.01146 ----
LR: [0.0008734646833147893]
---- EP [1/5] | BTCH [777/3634] ||| train_loss = 0.00734 ----
LR: [0.000874663659504251]
---- EP [1/5] | BTCH [778/3634] ||| train_loss = 0.01709 ----
LR: [0.0008758640729248351]
---- EP [1/5] | BTCH [779/3634] ||| train_loss = 0.01494 ----
LR: [0.0008770659231776643]
---- EP [1/5] | BTCH [780/3634] ||| train_loss = 0.02019 ----
LR: [0.0008782692098633863]
---- EP [1/5] | BTCH [781/3634] ||| train_loss = 0.01461 ----
LR: [0.0008794739325821716]
---- EP [1/5] | BTCH [782/3634] ||| train_loss = 0.01814 ----
LR: [0.000880680090933712]
---- EP [1/5] | BTCH [783/3634] ||| train_loss = 0.01035 ----
LR: [0.000881887684517222]
---- EP [1/5] | BTCH [784/3634] ||| train_loss = 0.01730 ----
LR: [0.0008830967129314429]
---- EP [1/5] | BTCH [785/3634] ||| train_loss = 0.01439 ----
LR: [0.0008843071757746318]
---- EP [1/5] | BTCH [786/3634] ||| train_loss = 0.01687 ----
LR: [0.0008855190726445791]
---- EP [1/5] | BTCH [787/3634] ||| train_loss = 0.01388 ----
LR: [0.0008867324031385897]
---- EP [1/5] | BTCH [788/3634] ||| train_loss = 0.01479 ----
LR: [0.0008879471668534963]
---- EP [1/5] | BTCH [789/3634] ||| train_loss = 0.01026 ----
LR: [0.0008891633633856567]
---- EP [1/5] | BTCH [790/3634] ||| train_loss = 0.01123 ----
LR: [0.000890380992330948]
---- EP [1/5] | BTCH [791/3634] ||| train_loss = 0.01240 ----
LR: [0.000891600053284777]
---- EP [1/5] | BTCH [792/3634] ||| train_loss = 0.01758 ----
LR: [0.0008928205458420685]
---- EP [1/5] | BTCH [793/3634] ||| train_loss = 0.00944 ----
LR: [0.0008940424695972771]
---- EP [1/5] | BTCH [794/3634] ||| train_loss = 0.01554 ----
LR: [0.0008952658241443805]
---- EP [1/5] | BTCH [795/3634] ||| train_loss = 0.01178 ----
LR: [0.0008964906090768773]
---- EP [1/5] | BTCH [796/3634] ||| train_loss = 0.02055 ----
LR: [0.0008977168239877962]
---- EP [1/5] | BTCH [797/3634] ||| train_loss = 0.00658 ----
LR: [0.0008989444684696854]
---- EP [1/5] | BTCH [798/3634] ||| train_loss = 0.00836 ----
LR: [0.0009001735421146229]
---- EP [1/5] | BTCH [799/3634] ||| train_loss = 0.00857 ----
LR: [0.0009014040445142115]
---- EP [1/5] | BTCH [800/3634] ||| train_loss = 0.00804 ----
LR: [0.0009026359752595733]
---- EP [1/5] | BTCH [801/3634] ||| train_loss = 0.01010 ----
LR: [0.0009038693339413623]
---- EP [1/5] | BTCH [802/3634] ||| train_loss = 0.01584 ----
LR: [0.000905104120149755]
---- EP [1/5] | BTCH [803/3634] ||| train_loss = 0.00819 ----
LR: [0.0009063403334744532]
---- EP [1/5] | BTCH [804/3634] ||| train_loss = 0.00731 ----
LR: [0.0009075779735046897]
---- EP [1/5] | BTCH [805/3634] ||| train_loss = 0.01285 ----
LR: [0.0009088170398292138]
---- EP [1/5] | BTCH [806/3634] ||| train_loss = 0.00876 ----
LR: [0.0009100575320363114]
---- EP [1/5] | BTCH [807/3634] ||| train_loss = 0.00919 ----
LR: [0.0009112994497137844]
---- EP [1/5] | BTCH [808/3634] ||| train_loss = 0.01180 ----
LR: [0.0009125427924489681]
---- EP [1/5] | BTCH [809/3634] ||| train_loss = 0.01697 ----
LR: [0.0009137875598287225]
---- EP [1/5] | BTCH [810/3634] ||| train_loss = 0.01323 ----
LR: [0.0009150337514394341]
---- EP [1/5] | BTCH [811/3634] ||| train_loss = 0.00626 ----
LR: [0.0009162813668670156]
---- EP [1/5] | BTCH [812/3634] ||| train_loss = 0.01288 ----
LR: [0.0009175304056969064]
---- EP [1/5] | BTCH [813/3634] ||| train_loss = 0.00809 ----
LR: [0.0009187808675140737]
---- EP [1/5] | BTCH [814/3634] ||| train_loss = 0.01328 ----
LR: [0.0009200327519030133]
---- EP [1/5] | BTCH [815/3634] ||| train_loss = 0.01557 ----
LR: [0.0009212860584477435]
---- EP [1/5] | BTCH [816/3634] ||| train_loss = 0.00844 ----
LR: [0.0009225407867318163]
---- EP [1/5] | BTCH [817/3634] ||| train_loss = 0.01807 ----
LR: [0.0009237969363383048]
---- EP [1/5] | BTCH [818/3634] ||| train_loss = 0.01000 ----
LR: [0.0009250545068498154]
---- EP [1/5] | BTCH [819/3634] ||| train_loss = 0.00917 ----
LR: [0.0009263134978484792]
---- EP [1/5] | BTCH [820/3634] ||| train_loss = 0.01268 ----
LR: [0.0009275739089159591]
---- EP [1/5] | BTCH [821/3634] ||| train_loss = 0.01124 ----
LR: [0.000928835739633439]
---- EP [1/5] | BTCH [822/3634] ||| train_loss = 0.01385 ----
LR: [0.0009300989895816378]
---- EP [1/5] | BTCH [823/3634] ||| train_loss = 0.01102 ----
LR: [0.0009313636583408013]
---- EP [1/5] | BTCH [824/3634] ||| train_loss = 0.00738 ----
LR: [0.0009326297454906995]
---- EP [1/5] | BTCH [825/3634] ||| train_loss = 0.01239 ----
LR: [0.0009338972506106376]
---- EP [1/5] | BTCH [826/3634] ||| train_loss = 0.01003 ----
LR: [0.0009351661732794458]
---- EP [1/5] | BTCH [827/3634] ||| train_loss = 0.01599 ----
LR: [0.0009364365130754837]
---- EP [1/5] | BTCH [828/3634] ||| train_loss = 0.00891 ----
LR: [0.0009377082695766394]
---- EP [1/5] | BTCH [829/3634] ||| train_loss = 0.00813 ----
LR: [0.0009389814423603326]
---- EP [1/5] | BTCH [830/3634] ||| train_loss = 0.01132 ----
LR: [0.000940256031003511]
---- EP [1/5] | BTCH [831/3634] ||| train_loss = 0.01718 ----
LR: [0.0009415320350826505]
---- EP [1/5] | BTCH [832/3634] ||| train_loss = 0.01022 ----
LR: [0.0009428094541737587]
---- EP [1/5] | BTCH [833/3634] ||| train_loss = 0.00737 ----
LR: [0.0009440882878523731]
---- EP [1/5] | BTCH [834/3634] ||| train_loss = 0.01408 ----
LR: [0.0009453685356935609]
---- EP [1/5] | BTCH [835/3634] ||| train_loss = 0.01265 ----
LR: [0.0009466501972719161]
---- EP [1/5] | BTCH [836/3634] ||| train_loss = 0.00851 ----
LR: [0.0009479332721615691]
---- EP [1/5] | BTCH [837/3634] ||| train_loss = 0.02251 ----
LR: [0.0009492177599361717]
---- EP [1/5] | BTCH [838/3634] ||| train_loss = 0.01017 ----
LR: [0.0009505036601689179]
---- EP [1/5] | BTCH [839/3634] ||| train_loss = 0.00975 ----
LR: [0.0009517909724325261]
---- EP [1/5] | BTCH [840/3634] ||| train_loss = 0.01125 ----
LR: [0.0009530796962992413]
---- EP [1/5] | BTCH [841/3634] ||| train_loss = 0.00912 ----
LR: [0.0009543698313408469]
---- EP [1/5] | BTCH [842/3634] ||| train_loss = 0.01614 ----
LR: [0.000955661377128653]
---- EP [1/5] | BTCH [843/3634] ||| train_loss = 0.01047 ----
LR: [0.0009569543332335027]
---- EP [1/5] | BTCH [844/3634] ||| train_loss = 0.00567 ----
LR: [0.0009582486992257711]
---- EP [1/5] | BTCH [845/3634] ||| train_loss = 0.01796 ----
LR: [0.0009595444746753629]
---- EP [1/5] | BTCH [846/3634] ||| train_loss = 0.01583 ----
LR: [0.0009608416591517146]
---- EP [1/5] | BTCH [847/3634] ||| train_loss = 0.00913 ----
LR: [0.0009621402522237959]
---- EP [1/5] | BTCH [848/3634] ||| train_loss = 0.02347 ----
LR: [0.0009634402534601065]
---- EP [1/5] | BTCH [849/3634] ||| train_loss = 0.00832 ----
LR: [0.000964741662428683]
---- EP [1/5] | BTCH [850/3634] ||| train_loss = 0.01082 ----
LR: [0.0009660444786970881]
---- EP [1/5] | BTCH [851/3634] ||| train_loss = 0.02099 ----
LR: [0.0009673487018324201]
---- EP [1/5] | BTCH [852/3634] ||| train_loss = 0.01326 ----
LR: [0.0009686543314013085]
---- EP [1/5] | BTCH [853/3634] ||| train_loss = 0.01567 ----
LR: [0.0009699613669699163]
---- EP [1/5] | BTCH [854/3634] ||| train_loss = 0.01511 ----
LR: [0.0009712698081039382]
---- EP [1/5] | BTCH [855/3634] ||| train_loss = 0.00758 ----
LR: [0.0009725796543686074]
---- EP [1/5] | BTCH [856/3634] ||| train_loss = 0.00735 ----
LR: [0.0009738909053286799]
---- EP [1/5] | BTCH [857/3634] ||| train_loss = 0.00955 ----
LR: [0.000975203560548454]
---- EP [1/5] | BTCH [858/3634] ||| train_loss = 0.00635 ----
LR: [0.0009765176195917578]
---- EP [1/5] | BTCH [859/3634] ||| train_loss = 0.00864 ----
LR: [0.0009778330820219543]
---- EP [1/5] | BTCH [860/3634] ||| train_loss = 0.00758 ----
LR: [0.000979149947401935]
---- EP [1/5] | BTCH [861/3634] ||| train_loss = 0.01346 ----
LR: [0.0009804682152941332]
---- EP [1/5] | BTCH [862/3634] ||| train_loss = 0.02145 ----
LR: [0.0009817878852605103]
---- EP [1/5] | BTCH [863/3634] ||| train_loss = 0.00734 ----
LR: [0.0009831089568625665]
---- EP [1/5] | BTCH [864/3634] ||| train_loss = 0.01044 ----
LR: [0.0009844314296613282]
---- EP [1/5] | BTCH [865/3634] ||| train_loss = 0.01364 ----
LR: [0.0009857553032173675]
---- EP [1/5] | BTCH [866/3634] ||| train_loss = 0.01980 ----
LR: [0.000987080577090781]
---- EP [1/5] | BTCH [867/3634] ||| train_loss = 0.01132 ----
LR: [0.0009884072508412074]
---- EP [1/5] | BTCH [868/3634] ||| train_loss = 0.01563 ----
LR: [0.0009897353240278135]
---- EP [1/5] | BTCH [869/3634] ||| train_loss = 0.01222 ----
LR: [0.0009910647962093084]
---- EP [1/5] | BTCH [870/3634] ||| train_loss = 0.00675 ----
LR: [0.0009923956669439307]
---- EP [1/5] | BTCH [871/3634] ||| train_loss = 0.00906 ----
LR: [0.0009937279357894544]
---- EP [1/5] | BTCH [872/3634] ||| train_loss = 0.01444 ----
LR: [0.000995061602303192]
---- EP [1/5] | BTCH [873/3634] ||| train_loss = 0.01345 ----
LR: [0.0009963966660419907]
---- EP [1/5] | BTCH [874/3634] ||| train_loss = 0.00855 ----
LR: [0.0009977331265622336]
---- EP [1/5] | BTCH [875/3634] ||| train_loss = 0.01330 ----
LR: [0.0009990709834198364]
---- EP [1/5] | BTCH [876/3634] ||| train_loss = 0.01310 ----
LR: [0.0010004102361702554]
---- EP [1/5] | BTCH [877/3634] ||| train_loss = 0.01309 ----
LR: [0.0010017508843684821]
---- EP [1/5] | BTCH [878/3634] ||| train_loss = 0.01317 ----
LR: [0.0010030929275690412]
---- EP [1/5] | BTCH [879/3634] ||| train_loss = 0.00778 ----
LR: [0.001004436365325996]
---- EP [1/5] | BTCH [880/3634] ||| train_loss = 0.00492 ----
LR: [0.0010057811971929485]
---- EP [1/5] | BTCH [881/3634] ||| train_loss = 0.01870 ----
LR: [0.001007127422723032]
---- EP [1/5] | BTCH [882/3634] ||| train_loss = 0.00984 ----
LR: [0.0010084750414689255]
---- EP [1/5] | BTCH [883/3634] ||| train_loss = 0.01128 ----
LR: [0.0010098240529828346]
---- EP [1/5] | BTCH [884/3634] ||| train_loss = 0.01110 ----
LR: [0.0010111744568165066]
---- EP [1/5] | BTCH [885/3634] ||| train_loss = 0.01467 ----
LR: [0.001012526252521231]
---- EP [1/5] | BTCH [886/3634] ||| train_loss = 0.00774 ----
LR: [0.001013879439647829]
---- EP [1/5] | BTCH [887/3634] ||| train_loss = 0.00962 ----
LR: [0.0010152340177466586]
---- EP [1/5] | BTCH [888/3634] ||| train_loss = 0.01861 ----
LR: [0.0010165899863676213]
---- EP [1/5] | BTCH [889/3634] ||| train_loss = 0.01090 ----
LR: [0.0010179473450601505]
---- EP [1/5] | BTCH [890/3634] ||| train_loss = 0.01725 ----
LR: [0.0010193060933732217]
---- EP [1/5] | BTCH [891/3634] ||| train_loss = 0.01285 ----
LR: [0.0010206662308553487]
---- EP [1/5] | BTCH [892/3634] ||| train_loss = 0.01130 ----
LR: [0.0010220277570545805]
---- EP [1/5] | BTCH [893/3634] ||| train_loss = 0.01008 ----
LR: [0.0010233906715185065]
---- EP [1/5] | BTCH [894/3634] ||| train_loss = 0.01269 ----
LR: [0.0010247549737942546]
---- EP [1/5] | BTCH [895/3634] ||| train_loss = 0.01186 ----
LR: [0.0010261206634284946]
---- EP [1/5] | BTCH [896/3634] ||| train_loss = 0.01355 ----
LR: [0.0010274877399674281]
---- EP [1/5] | BTCH [897/3634] ||| train_loss = 0.02509 ----
LR: [0.001028856202956804]
---- EP [1/5] | BTCH [898/3634] ||| train_loss = 0.01033 ----
LR: [0.0010302260519419043]
---- EP [1/5] | BTCH [899/3634] ||| train_loss = 0.01417 ----
LR: [0.001031597286467555]
---- EP [1/5] | BTCH [900/3634] ||| train_loss = 0.01087 ----
LR: [0.0010329699060781187]
---- EP [1/5] | BTCH [901/3634] ||| train_loss = 0.01345 ----
LR: [0.0010343439103174985]
---- EP [1/5] | BTCH [902/3634] ||| train_loss = 0.01582 ----
LR: [0.0010357192987291378]
---- EP [1/5] | BTCH [903/3634] ||| train_loss = 0.01053 ----
LR: [0.0010370960708560202]
---- EP [1/5] | BTCH [904/3634] ||| train_loss = 0.00786 ----
LR: [0.0010384742262406696]
---- EP [1/5] | BTCH [905/3634] ||| train_loss = 0.00949 ----
VAL ||| loss = 0.013416619014651248, psnr = 30.689035415649414, ssim = 0.9067491888999939
LR: [0.0010398537644251485]
---- EP [1/5] | BTCH [906/3634] ||| train_loss = 0.00730 ----
LR: [0.0010412346849510597]
---- EP [1/5] | BTCH [907/3634] ||| train_loss = 0.02017 ----
LR: [0.0010426169873595532]
---- EP [1/5] | BTCH [908/3634] ||| train_loss = 0.01330 ----
LR: [0.0010440006711913107]
---- EP [1/5] | BTCH [909/3634] ||| train_loss = 0.01121 ----
LR: [0.001045385735986561]
---- EP [1/5] | BTCH [910/3634] ||| train_loss = 0.01709 ----
LR: [0.0010467721812850734]
---- EP [1/5] | BTCH [911/3634] ||| train_loss = 0.01064 ----
LR: [0.0010481600066261521]
---- EP [1/5] | BTCH [912/3634] ||| train_loss = 0.01282 ----
LR: [0.0010495492115486522]
---- EP [1/5] | BTCH [913/3634] ||| train_loss = 0.01246 ----
LR: [0.001050939795590967]
---- EP [1/5] | BTCH [914/3634] ||| train_loss = 0.01365 ----
LR: [0.0010523317582910273]
---- EP [1/5] | BTCH [915/3634] ||| train_loss = 0.02023 ----
LR: [0.0010537250991863086]
---- EP [1/5] | BTCH [916/3634] ||| train_loss = 0.02338 ----
LR: [0.0010551198178138325]
---- EP [1/5] | BTCH [917/3634] ||| train_loss = 0.01163 ----
LR: [0.0010565159137101553]
---- EP [1/5] | BTCH [918/3634] ||| train_loss = 0.01226 ----
LR: [0.0010579133864113827]
---- EP [1/5] | BTCH [919/3634] ||| train_loss = 0.01533 ----
LR: [0.0010593122354531585]
---- EP [1/5] | BTCH [920/3634] ||| train_loss = 0.01300 ----
LR: [0.0010607124603706705]
---- EP [1/5] | BTCH [921/3634] ||| train_loss = 0.01118 ----
LR: [0.0010621140606986487]
---- EP [1/5] | BTCH [922/3634] ||| train_loss = 0.01130 ----
LR: [0.0010635170359713682]
---- EP [1/5] | BTCH [923/3634] ||| train_loss = 0.01041 ----
LR: [0.001064921385722643]
---- EP [1/5] | BTCH [924/3634] ||| train_loss = 0.01264 ----
LR: [0.001066327109485836]
---- EP [1/5] | BTCH [925/3634] ||| train_loss = 0.00893 ----
LR: [0.0010677342067938484]
---- EP [1/5] | BTCH [926/3634] ||| train_loss = 0.01047 ----
LR: [0.0010691426771791274]
---- EP [1/5] | BTCH [927/3634] ||| train_loss = 0.01211 ----
LR: [0.001070552520173667]
---- EP [1/5] | BTCH [928/3634] ||| train_loss = 0.01337 ----
LR: [0.0010719637353089981]
---- EP [1/5] | BTCH [929/3634] ||| train_loss = 0.01238 ----
LR: [0.0010733763221161992]
---- EP [1/5] | BTCH [930/3634] ||| train_loss = 0.00976 ----
LR: [0.0010747902801258938]
---- EP [1/5] | BTCH [931/3634] ||| train_loss = 0.01674 ----
LR: [0.001076205608868253]
---- EP [1/5] | BTCH [932/3634] ||| train_loss = 0.01356 ----
LR: [0.0010776223078729826]
---- EP [1/5] | BTCH [933/3634] ||| train_loss = 0.01042 ----
LR: [0.0010790403766693449]
---- EP [1/5] | BTCH [934/3634] ||| train_loss = 0.01228 ----
LR: [0.0010804598147861368]
---- EP [1/5] | BTCH [935/3634] ||| train_loss = 0.01033 ----
LR: [0.001081880621751706]
---- EP [1/5] | BTCH [936/3634] ||| train_loss = 0.00857 ----
LR: [0.0010833027970939442]
---- EP [1/5] | BTCH [937/3634] ||| train_loss = 0.01477 ----
LR: [0.00108472634034029]
---- EP [1/5] | BTCH [938/3634] ||| train_loss = 0.00996 ----
LR: [0.0010861512510177227]
---- EP [1/5] | BTCH [939/3634] ||| train_loss = 0.00904 ----
LR: [0.001087577528652772]
---- EP [1/5] | BTCH [940/3634] ||| train_loss = 0.01390 ----
LR: [0.0010890051727715094]
---- EP [1/5] | BTCH [941/3634] ||| train_loss = 0.00554 ----
LR: [0.0010904341828995578]
---- EP [1/5] | BTCH [942/3634] ||| train_loss = 0.00881 ----
LR: [0.0010918645585620834]
---- EP [1/5] | BTCH [943/3634] ||| train_loss = 0.01571 ----
LR: [0.0010932962992837945]
---- EP [1/5] | BTCH [944/3634] ||| train_loss = 0.00849 ----
LR: [0.00109472940458895]
---- EP [1/5] | BTCH [945/3634] ||| train_loss = 0.01274 ----
LR: [0.001096163874001358]
---- EP [1/5] | BTCH [946/3634] ||| train_loss = 0.00869 ----
LR: [0.0010975997070443687]
---- EP [1/5] | BTCH [947/3634] ||| train_loss = 0.01079 ----
LR: [0.001099036903240879]
---- EP [1/5] | BTCH [948/3634] ||| train_loss = 0.01014 ----
LR: [0.0011004754621133372]
---- EP [1/5] | BTCH [949/3634] ||| train_loss = 0.01654 ----
LR: [0.0011019153831837332]
---- EP [1/5] | BTCH [950/3634] ||| train_loss = 0.00742 ----
LR: [0.0011033566659736111]
---- EP [1/5] | BTCH [951/3634] ||| train_loss = 0.00833 ----
LR: [0.0011047993100040572]
---- EP [1/5] | BTCH [952/3634] ||| train_loss = 0.00772 ----
LR: [0.001106243314795705]
---- EP [1/5] | BTCH [953/3634] ||| train_loss = 0.01931 ----
LR: [0.0011076886798687385]
---- EP [1/5] | BTCH [954/3634] ||| train_loss = 0.00850 ----
LR: [0.0011091354047428892]
---- EP [1/5] | BTCH [955/3634] ||| train_loss = 0.00824 ----
LR: [0.0011105834889374392]
---- EP [1/5] | BTCH [956/3634] ||| train_loss = 0.00733 ----
LR: [0.0011120329319712127]
---- EP [1/5] | BTCH [957/3634] ||| train_loss = 0.01073 ----
LR: [0.0011134837333625879]
---- EP [1/5] | BTCH [958/3634] ||| train_loss = 0.01471 ----
LR: [0.0011149358926294903]
---- EP [1/5] | BTCH [959/3634] ||| train_loss = 0.01142 ----
LR: [0.0011163894092893912]
---- EP [1/5] | BTCH [960/3634] ||| train_loss = 0.00884 ----
LR: [0.0011178442828593139]
---- EP [1/5] | BTCH [961/3634] ||| train_loss = 0.01255 ----
LR: [0.0011193005128558309]
---- EP [1/5] | BTCH [962/3634] ||| train_loss = 0.01246 ----
LR: [0.0011207580987950636]
---- EP [1/5] | BTCH [963/3634] ||| train_loss = 0.01372 ----
LR: [0.0011222170401926843]
---- EP [1/5] | BTCH [964/3634] ||| train_loss = 0.01646 ----
LR: [0.0011236773365639087]
---- EP [1/5] | BTCH [965/3634] ||| train_loss = 0.01602 ----
LR: [0.0011251389874235105]
---- EP [1/5] | BTCH [966/3634] ||| train_loss = 0.01130 ----
LR: [0.0011266019922858053]
---- EP [1/5] | BTCH [967/3634] ||| train_loss = 0.01138 ----
LR: [0.001128066350664668]
---- EP [1/5] | BTCH [968/3634] ||| train_loss = 0.01320 ----
LR: [0.0011295320620735155]
---- EP [1/5] | BTCH [969/3634] ||| train_loss = 0.00840 ----
LR: [0.001130999126025321]
---- EP [1/5] | BTCH [970/3634] ||| train_loss = 0.01036 ----
LR: [0.0011324675420326027]
---- EP [1/5] | BTCH [971/3634] ||| train_loss = 0.01085 ----
LR: [0.001133937309607435]
---- EP [1/5] | BTCH [972/3634] ||| train_loss = 0.01042 ----
LR: [0.0011354084282614377]
---- EP [1/5] | BTCH [973/3634] ||| train_loss = 0.01626 ----
LR: [0.0011368808975057865]
---- EP [1/5] | BTCH [974/3634] ||| train_loss = 0.02092 ----
LR: [0.0011383547168512097]
---- EP [1/5] | BTCH [975/3634] ||| train_loss = 0.02035 ----
LR: [0.0011398298858079758]
---- EP [1/5] | BTCH [976/3634] ||| train_loss = 0.00788 ----
LR: [0.0011413064038859212]
---- EP [1/5] | BTCH [977/3634] ||| train_loss = 0.01710 ----
LR: [0.001142784270594421]
---- EP [1/5] | BTCH [978/3634] ||| train_loss = 0.01492 ----
LR: [0.0011442634854424063]
---- EP [1/5] | BTCH [979/3634] ||| train_loss = 0.02125 ----
LR: [0.001145744047938364]
---- EP [1/5] | BTCH [980/3634] ||| train_loss = 0.01311 ----
LR: [0.0011472259575903265]
---- EP [1/5] | BTCH [981/3634] ||| train_loss = 0.00917 ----
LR: [0.0011487092139058838]
---- EP [1/5] | BTCH [982/3634] ||| train_loss = 0.01364 ----
LR: [0.0011501938163921786]
---- EP [1/5] | BTCH [983/3634] ||| train_loss = 0.01828 ----
LR: [0.0011516797645559004]
---- EP [1/5] | BTCH [984/3634] ||| train_loss = 0.00959 ----
LR: [0.0011531670579032968]
---- EP [1/5] | BTCH [985/3634] ||| train_loss = 0.00925 ----
LR: [0.0011546556959401676]
---- EP [1/5] | BTCH [986/3634] ||| train_loss = 0.02411 ----
LR: [0.0011561456781718667]
---- EP [1/5] | BTCH [987/3634] ||| train_loss = 0.01473 ----
LR: [0.0011576370041032971]
---- EP [1/5] | BTCH [988/3634] ||| train_loss = 0.00799 ----
LR: [0.0011591296732389178]
---- EP [1/5] | BTCH [989/3634] ||| train_loss = 0.01517 ----
LR: [0.0011606236850827453]
---- EP [1/5] | BTCH [990/3634] ||| train_loss = 0.01811 ----
LR: [0.001162119039138345]
---- EP [1/5] | BTCH [991/3634] ||| train_loss = 0.00740 ----
LR: [0.0011636157349088367]
---- EP [1/5] | BTCH [992/3634] ||| train_loss = 0.01276 ----
LR: [0.001165113771896896]
---- EP [1/5] | BTCH [993/3634] ||| train_loss = 0.01089 ----
LR: [0.0011666131496047526]
---- EP [1/5] | BTCH [994/3634] ||| train_loss = 0.00811 ----
LR: [0.0011681138675341905]
---- EP [1/5] | BTCH [995/3634] ||| train_loss = 0.01589 ----
LR: [0.0011696159251865478]
---- EP [1/5] | BTCH [996/3634] ||| train_loss = 0.01136 ----
LR: [0.0011711193220627168]
---- EP [1/5] | BTCH [997/3634] ||| train_loss = 0.01088 ----
LR: [0.0011726240576631491]
---- EP [1/5] | BTCH [998/3634] ||| train_loss = 0.01678 ----
LR: [0.0011741301314878438]
---- EP [1/5] | BTCH [999/3634] ||| train_loss = 0.01084 ----
LR: [0.0011756375430363626]
---- EP [1/5] | BTCH [1000/3634] ||| train_loss = 0.01386 ----
LR: [0.0011771462918078197]
---- EP [1/5] | BTCH [1001/3634] ||| train_loss = 0.01352 ----
LR: [0.0011786563773008869]
---- EP [1/5] | BTCH [1002/3634] ||| train_loss = 0.01187 ----
LR: [0.001180167799013785]
---- EP [1/5] | BTCH [1003/3634] ||| train_loss = 0.00786 ----
LR: [0.0011816805564443013]
---- EP [1/5] | BTCH [1004/3634] ||| train_loss = 0.00897 ----
LR: [0.00118319464908977]
---- EP [1/5] | BTCH [1005/3634] ||| train_loss = 0.01309 ----
LR: [0.0011847100764470885]
---- EP [1/5] | BTCH [1006/3634] ||| train_loss = 0.01089 ----
LR: [0.0011862268380127047]
---- EP [1/5] | BTCH [1007/3634] ||| train_loss = 0.00855 ----
LR: [0.0011877449332826275]
---- EP [1/5] | BTCH [1008/3634] ||| train_loss = 0.01657 ----
LR: [0.0011892643617524203]
---- EP [1/5] | BTCH [1009/3634] ||| train_loss = 0.01228 ----
LR: [0.0011907851229172074]
---- EP [1/5] | BTCH [1010/3634] ||| train_loss = 0.00702 ----
LR: [0.0011923072162716639]
---- EP [1/5] | BTCH [1011/3634] ||| train_loss = 0.01160 ----
LR: [0.0011938306413100293]
---- EP [1/5] | BTCH [1012/3634] ||| train_loss = 0.01007 ----
LR: [0.001195355397526094]
---- EP [1/5] | BTCH [1013/3634] ||| train_loss = 0.01116 ----
LR: [0.0011968814844132095]
---- EP [1/5] | BTCH [1014/3634] ||| train_loss = 0.01267 ----
LR: [0.001198408901464285]
---- EP [1/5] | BTCH [1015/3634] ||| train_loss = 0.00989 ----
LR: [0.0011999376481717887]
---- EP [1/5] | BTCH [1016/3634] ||| train_loss = 0.00956 ----
LR: [0.0012014677240277435]
---- EP [1/5] | BTCH [1017/3634] ||| train_loss = 0.01273 ----
LR: [0.001202999128523733]
---- EP [1/5] | BTCH [1018/3634] ||| train_loss = 0.00602 ----
LR: [0.0012045318611509006]
---- EP [1/5] | BTCH [1019/3634] ||| train_loss = 0.00970 ----
LR: [0.0012060659213999469]
---- EP [1/5] | BTCH [1020/3634] ||| train_loss = 0.01234 ----
LR: [0.0012076013087611304]
---- EP [1/5] | BTCH [1021/3634] ||| train_loss = 0.01460 ----
LR: [0.0012091380227242706]
---- EP [1/5] | BTCH [1022/3634] ||| train_loss = 0.01476 ----
LR: [0.0012106760627787448]
---- EP [1/5] | BTCH [1023/3634] ||| train_loss = 0.01027 ----
LR: [0.0012122154284134896]
---- EP [1/5] | BTCH [1024/3634] ||| train_loss = 0.01093 ----
LR: [0.0012137561191170008]
---- EP [1/5] | BTCH [1025/3634] ||| train_loss = 0.01088 ----
LR: [0.0012152981343773375]
---- EP [1/5] | BTCH [1026/3634] ||| train_loss = 0.01134 ----
LR: [0.0012168414736821141]
---- EP [1/5] | BTCH [1027/3634] ||| train_loss = 0.00772 ----
LR: [0.001218386136518505]
---- EP [1/5] | BTCH [1028/3634] ||| train_loss = 0.01284 ----
LR: [0.0012199321223732504]
---- EP [1/5] | BTCH [1029/3634] ||| train_loss = 0.01489 ----
LR: [0.0012214794307326467]
---- EP [1/5] | BTCH [1030/3634] ||| train_loss = 0.01028 ----
LR: [0.0012230280610825463]
---- EP [1/5] | BTCH [1031/3634] ||| train_loss = 0.01095 ----
LR: [0.0012245780129083745]
---- EP [1/5] | BTCH [1032/3634] ||| train_loss = 0.01078 ----
LR: [0.0012261292856951059]
---- EP [1/5] | BTCH [1033/3634] ||| train_loss = 0.01129 ----
LR: [0.0012276818789272795]
---- EP [1/5] | BTCH [1034/3634] ||| train_loss = 0.00640 ----
LR: [0.0012292357920890007]
---- EP [1/5] | BTCH [1035/3634] ||| train_loss = 0.01309 ----
LR: [0.001230791024663929]
---- EP [1/5] | BTCH [1036/3634] ||| train_loss = 0.01282 ----
LR: [0.0012323475761352905]
---- EP [1/5] | BTCH [1037/3634] ||| train_loss = 0.01131 ----
LR: [0.0012339054459858702]
---- EP [1/5] | BTCH [1038/3634] ||| train_loss = 0.00988 ----
LR: [0.001235464633698018]
---- EP [1/5] | BTCH [1039/3634] ||| train_loss = 0.01135 ----
LR: [0.0012370251387536398]
---- EP [1/5] | BTCH [1040/3634] ||| train_loss = 0.01731 ----
LR: [0.0012385869606342127]
---- EP [1/5] | BTCH [1041/3634] ||| train_loss = 0.01302 ----
LR: [0.00124015009882077]
---- EP [1/5] | BTCH [1042/3634] ||| train_loss = 0.01140 ----
LR: [0.0012417145527939058]
---- EP [1/5] | BTCH [1043/3634] ||| train_loss = 0.01166 ----
LR: [0.0012432803220337844]
---- EP [1/5] | BTCH [1044/3634] ||| train_loss = 0.01237 ----
LR: [0.0012448474060201293]
---- EP [1/5] | BTCH [1045/3634] ||| train_loss = 0.01602 ----
LR: [0.0012464158042322232]
---- EP [1/5] | BTCH [1046/3634] ||| train_loss = 0.01160 ----
LR: [0.001247985516148917]
---- EP [1/5] | BTCH [1047/3634] ||| train_loss = 0.00969 ----
LR: [0.0012495565412486264]
---- EP [1/5] | BTCH [1048/3634] ||| train_loss = 0.02240 ----
LR: [0.0012511288790093243]
---- EP [1/5] | BTCH [1049/3634] ||| train_loss = 0.01293 ----
LR: [0.0012527025289085555]
---- EP [1/5] | BTCH [1050/3634] ||| train_loss = 0.00618 ----
LR: [0.0012542774904234204]
---- EP [1/5] | BTCH [1051/3634] ||| train_loss = 0.00874 ----
LR: [0.0012558537630305896]
---- EP [1/5] | BTCH [1052/3634] ||| train_loss = 0.00937 ----
LR: [0.001257431346206296]
---- EP [1/5] | BTCH [1053/3634] ||| train_loss = 0.00990 ----
LR: [0.0012590102394263395]
---- EP [1/5] | BTCH [1054/3634] ||| train_loss = 0.01098 ----
LR: [0.0012605904421660787]
---- EP [1/5] | BTCH [1055/3634] ||| train_loss = 0.01818 ----
LR: [0.0012621719539004424]
---- EP [1/5] | BTCH [1056/3634] ||| train_loss = 0.01771 ----
LR: [0.001263754774103924]
---- EP [1/5] | BTCH [1057/3634] ||| train_loss = 0.01401 ----
LR: [0.0012653389022505776]
---- EP [1/5] | BTCH [1058/3634] ||| train_loss = 0.00860 ----
LR: [0.0012669243378140294]
---- EP [1/5] | BTCH [1059/3634] ||| train_loss = 0.00842 ----
LR: [0.0012685110802674662]
---- EP [1/5] | BTCH [1060/3634] ||| train_loss = 0.01253 ----
LR: [0.0012700991290836433]
---- EP [1/5] | BTCH [1061/3634] ||| train_loss = 0.01914 ----
LR: [0.0012716884837348785]
---- EP [1/5] | BTCH [1062/3634] ||| train_loss = 0.01375 ----
LR: [0.0012732791436930613]
---- EP [1/5] | BTCH [1063/3634] ||| train_loss = 0.01111 ----
LR: [0.0012748711084296406]
---- EP [1/5] | BTCH [1064/3634] ||| train_loss = 0.01032 ----
LR: [0.0012764643774156384]
---- EP [1/5] | BTCH [1065/3634] ||| train_loss = 0.01863 ----
LR: [0.001278058950121638]
---- EP [1/5] | BTCH [1066/3634] ||| train_loss = 0.01903 ----
LR: [0.0012796548260177922]
---- EP [1/5] | BTCH [1067/3634] ||| train_loss = 0.01103 ----
LR: [0.0012812520045738206]
---- EP [1/5] | BTCH [1068/3634] ||| train_loss = 0.01499 ----
LR: [0.0012828504852590104]
---- EP [1/5] | BTCH [1069/3634] ||| train_loss = 0.01172 ----
LR: [0.0012844502675422136]
---- EP [1/5] | BTCH [1070/3634] ||| train_loss = 0.01282 ----
LR: [0.001286051350891852]
---- EP [1/5] | BTCH [1071/3634] ||| train_loss = 0.01151 ----
LR: [0.001287653734775917]
---- EP [1/5] | BTCH [1072/3634] ||| train_loss = 0.01321 ----
LR: [0.0012892574186619613]
---- EP [1/5] | BTCH [1073/3634] ||| train_loss = 0.01770 ----
LR: [0.0012908624020171126]
---- EP [1/5] | BTCH [1074/3634] ||| train_loss = 0.01120 ----
LR: [0.0012924686843080613]
---- EP [1/5] | BTCH [1075/3634] ||| train_loss = 0.01581 ----
LR: [0.001294076265001073]
---- EP [1/5] | BTCH [1076/3634] ||| train_loss = 0.01593 ----
LR: [0.0012956851435619744]
---- EP [1/5] | BTCH [1077/3634] ||| train_loss = 0.00813 ----
LR: [0.0012972953194561633]
---- EP [1/5] | BTCH [1078/3634] ||| train_loss = 0.01543 ----
LR: [0.0012989067921486113]
---- EP [1/5] | BTCH [1079/3634] ||| train_loss = 0.01218 ----
LR: [0.0013005195611038526]
---- EP [1/5] | BTCH [1080/3634] ||| train_loss = 0.01071 ----
LR: [0.001302133625785993]
---- EP [1/5] | BTCH [1081/3634] ||| train_loss = 0.01537 ----
LR: [0.0013037489856587096]
---- EP [1/5] | BTCH [1082/3634] ||| train_loss = 0.01353 ----
LR: [0.0013053656401852427]
---- EP [1/5] | BTCH [1083/3634] ||| train_loss = 0.01246 ----
LR: [0.0013069835888284143]
---- EP [1/5] | BTCH [1084/3634] ||| train_loss = 0.00725 ----
LR: [0.0013086028310506058]
---- EP [1/5] | BTCH [1085/3634] ||| train_loss = 0.00757 ----
LR: [0.0013102233663137702]
---- EP [1/5] | BTCH [1086/3634] ||| train_loss = 0.01331 ----
VAL ||| loss = 0.01368338505970892, psnr = 30.63458251953125, ssim = 0.9059269428253174
LR: [0.0013118451940794373]
---- EP [1/5] | BTCH [1087/3634] ||| train_loss = 0.00807 ----
LR: [0.0013134683138086994]
---- EP [1/5] | BTCH [1088/3634] ||| train_loss = 0.00724 ----
LR: [0.001315092724962226]
---- EP [1/5] | BTCH [1089/3634] ||| train_loss = 0.00631 ----
LR: [0.0013167184270002508]
---- EP [1/5] | BTCH [1090/3634] ||| train_loss = 0.00767 ----
LR: [0.001318345419382588]
---- EP [1/5] | BTCH [1091/3634] ||| train_loss = 0.00985 ----
LR: [0.0013199737015686108]
---- EP [1/5] | BTCH [1092/3634] ||| train_loss = 0.00782 ----
LR: [0.0013216032730172765]
---- EP [1/5] | BTCH [1093/3634] ||| train_loss = 0.01428 ----
LR: [0.0013232341331871032]
---- EP [1/5] | BTCH [1094/3634] ||| train_loss = 0.02071 ----
LR: [0.0013248662815361894]
---- EP [1/5] | BTCH [1095/3634] ||| train_loss = 0.02147 ----
LR: [0.001326499717522198]
---- EP [1/5] | BTCH [1096/3634] ||| train_loss = 0.02744 ----
LR: [0.0013281344406023722]
---- EP [1/5] | BTCH [1097/3634] ||| train_loss = 0.01398 ----
LR: [0.001329770450233518]
---- EP [1/5] | BTCH [1098/3634] ||| train_loss = 0.01013 ----
LR: [0.0013314077458720219]
---- EP [1/5] | BTCH [1099/3634] ||| train_loss = 0.01300 ----
LR: [0.0013330463269738396]
---- EP [1/5] | BTCH [1100/3634] ||| train_loss = 0.01115 ----
LR: [0.0013346861929945022]
---- EP [1/5] | BTCH [1101/3634] ||| train_loss = 0.00777 ----
LR: [0.0013363273433891088]
---- EP [1/5] | BTCH [1102/3634] ||| train_loss = 0.00832 ----
LR: [0.0013379697776123353]
---- EP [1/5] | BTCH [1103/3634] ||| train_loss = 0.01828 ----
LR: [0.0013396134951184323]
---- EP [1/5] | BTCH [1104/3634] ||| train_loss = 0.01356 ----
LR: [0.0013412584953612187]
---- EP [1/5] | BTCH [1105/3634] ||| train_loss = 0.01607 ----
LR: [0.0013429047777940937]
---- EP [1/5] | BTCH [1106/3634] ||| train_loss = 0.00920 ----
LR: [0.0013445523418700277]
---- EP [1/5] | BTCH [1107/3634] ||| train_loss = 0.02083 ----
LR: [0.0013462011870415628]
---- EP [1/5] | BTCH [1108/3634] ||| train_loss = 0.01104 ----
LR: [0.0013478513127608178]
---- EP [1/5] | BTCH [1109/3634] ||| train_loss = 0.01316 ----
LR: [0.0013495027184794884]
---- EP [1/5] | BTCH [1110/3634] ||| train_loss = 0.01776 ----
LR: [0.0013511554036488398]
---- EP [1/5] | BTCH [1111/3634] ||| train_loss = 0.01584 ----
LR: [0.001352809367719714]
---- EP [1/5] | BTCH [1112/3634] ||| train_loss = 0.01255 ----
LR: [0.0013544646101425317]
---- EP [1/5] | BTCH [1113/3634] ||| train_loss = 0.01628 ----
LR: [0.001356121130367283]
---- EP [1/5] | BTCH [1114/3634] ||| train_loss = 0.01032 ----
LR: [0.0013577789278435368]
---- EP [1/5] | BTCH [1115/3634] ||| train_loss = 0.01055 ----
LR: [0.001359438002020437]
---- EP [1/5] | BTCH [1116/3634] ||| train_loss = 0.01037 ----
LR: [0.0013610983523467037]
---- EP [1/5] | BTCH [1117/3634] ||| train_loss = 0.00886 ----
LR: [0.0013627599782706327]
---- EP [1/5] | BTCH [1118/3634] ||| train_loss = 0.00999 ----
LR: [0.0013644228792400927]
---- EP [1/5] | BTCH [1119/3634] ||| train_loss = 0.00982 ----
LR: [0.001366087054702536]
---- EP [1/5] | BTCH [1120/3634] ||| train_loss = 0.01351 ----
LR: [0.001367752504104985]
---- EP [1/5] | BTCH [1121/3634] ||| train_loss = 0.00810 ----
LR: [0.001369419226894042]
---- EP [1/5] | BTCH [1122/3634] ||| train_loss = 0.01292 ----
LR: [0.0013710872225158842]
---- EP [1/5] | BTCH [1123/3634] ||| train_loss = 0.01066 ----
LR: [0.0013727564904162676]
---- EP [1/5] | BTCH [1124/3634] ||| train_loss = 0.01823 ----
LR: [0.0013744270300405231]
---- EP [1/5] | BTCH [1125/3634] ||| train_loss = 0.01182 ----
LR: [0.0013760988408335617]
---- EP [1/5] | BTCH [1126/3634] ||| train_loss = 0.01227 ----
LR: [0.0013777719222398711]
---- EP [1/5] | BTCH [1127/3634] ||| train_loss = 0.01292 ----
LR: [0.0013794462737035142]
---- EP [1/5] | BTCH [1128/3634] ||| train_loss = 0.01060 ----
LR: [0.001381121894668139]
---- EP [1/5] | BTCH [1129/3634] ||| train_loss = 0.00826 ----
LR: [0.0013827987845769635]
---- EP [1/5] | BTCH [1130/3634] ||| train_loss = 0.01874 ----
LR: [0.0013844769428727876]
---- EP [1/5] | BTCH [1131/3634] ||| train_loss = 0.00858 ----
LR: [0.0013861563689979914]
---- EP [1/5] | BTCH [1132/3634] ||| train_loss = 0.01258 ----
LR: [0.00138783706239453]
---- EP [1/5] | BTCH [1133/3634] ||| train_loss = 0.00960 ----
LR: [0.0013895190225039385]
---- EP [1/5] | BTCH [1134/3634] ||| train_loss = 0.00830 ----
LR: [0.001391202248767336]
---- EP [1/5] | BTCH [1135/3634] ||| train_loss = 0.00925 ----
LR: [0.0013928867406254129]
---- EP [1/5] | BTCH [1136/3634] ||| train_loss = 0.00903 ----
LR: [0.001394572497518445]
---- EP [1/5] | BTCH [1137/3634] ||| train_loss = 0.01732 ----
LR: [0.001396259518886285]
---- EP [1/5] | BTCH [1138/3634] ||| train_loss = 0.01353 ----
LR: [0.0013979478041683657]
---- EP [1/5] | BTCH [1139/3634] ||| train_loss = 0.01329 ----
LR: [0.0013996373528037016]
---- EP [1/5] | BTCH [1140/3634] ||| train_loss = 0.00870 ----
LR: [0.0014013281642308861]
---- EP [1/5] | BTCH [1141/3634] ||| train_loss = 0.01492 ----
LR: [0.0014030202378880908]
---- EP [1/5] | BTCH [1142/3634] ||| train_loss = 0.01291 ----
LR: [0.0014047135732130726]
---- EP [1/5] | BTCH [1143/3634] ||| train_loss = 0.01453 ----
LR: [0.001406408169643169]
---- EP [1/5] | BTCH [1144/3634] ||| train_loss = 0.01622 ----
LR: [0.0014081040266152919]
---- EP [1/5] | BTCH [1145/3634] ||| train_loss = 0.01039 ----
LR: [0.001409801143565939]
---- EP [1/5] | BTCH [1146/3634] ||| train_loss = 0.01839 ----
LR: [0.001411499519931192]
---- EP [1/5] | BTCH [1147/3634] ||| train_loss = 0.01093 ----
LR: [0.0014131991551467066]
---- EP [1/5] | BTCH [1148/3634] ||| train_loss = 0.00789 ----
LR: [0.0014149000486477301]
---- EP [1/5] | BTCH [1149/3634] ||| train_loss = 0.00943 ----
LR: [0.0014166021998690843]
---- EP [1/5] | BTCH [1150/3634] ||| train_loss = 0.01114 ----
LR: [0.0014183056082451712]
---- EP [1/5] | BTCH [1151/3634] ||| train_loss = 0.01112 ----
LR: [0.0014200102732099852]
---- EP [1/5] | BTCH [1152/3634] ||| train_loss = 0.01162 ----
LR: [0.0014217161941970924]
---- EP [1/5] | BTCH [1153/3634] ||| train_loss = 0.00549 ----
LR: [0.0014234233706396475]
---- EP [1/5] | BTCH [1154/3634] ||| train_loss = 0.00936 ----
LR: [0.001425131801970389]
---- EP [1/5] | BTCH [1155/3634] ||| train_loss = 0.01353 ----
LR: [0.0014268414876216304]
---- EP [1/5] | BTCH [1156/3634] ||| train_loss = 0.02260 ----
LR: [0.0014285524270252793]
---- EP [1/5] | BTCH [1157/3634] ||| train_loss = 0.01138 ----
LR: [0.00143026461961282]
---- EP [1/5] | BTCH [1158/3634] ||| train_loss = 0.01442 ----
LR: [0.0014319780648153202]
---- EP [1/5] | BTCH [1159/3634] ||| train_loss = 0.00742 ----
LR: [0.0014336927620634352]
---- EP [1/5] | BTCH [1160/3634] ||| train_loss = 0.00996 ----
LR: [0.0014354087107874003]
---- EP [1/5] | BTCH [1161/3634] ||| train_loss = 0.01187 ----
LR: [0.0014371259104170395]
---- EP [1/5] | BTCH [1162/3634] ||| train_loss = 0.01139 ----
LR: [0.0014388443603817538]
---- EP [1/5] | BTCH [1163/3634] ||| train_loss = 0.01263 ----
LR: [0.0014405640601105382]
---- EP [1/5] | BTCH [1164/3634] ||| train_loss = 0.01105 ----
LR: [0.0014422850090319642]
---- EP [1/5] | BTCH [1165/3634] ||| train_loss = 0.00694 ----
LR: [0.0014440072065741924]
---- EP [1/5] | BTCH [1166/3634] ||| train_loss = 0.01635 ----
LR: [0.001445730652164967]
---- EP [1/5] | BTCH [1167/3634] ||| train_loss = 0.01099 ----
LR: [0.0014474553452316213]
---- EP [1/5] | BTCH [1168/3634] ||| train_loss = 0.00834 ----
LR: [0.0014491812852010684]
---- EP [1/5] | BTCH [1169/3634] ||| train_loss = 0.01568 ----
LR: [0.0014509084714998104]
---- EP [1/5] | BTCH [1170/3634] ||| train_loss = 0.01598 ----
LR: [0.0014526369035539333]
---- EP [1/5] | BTCH [1171/3634] ||| train_loss = 0.00835 ----
LR: [0.0014543665807891099]
---- EP [1/5] | BTCH [1172/3634] ||| train_loss = 0.01151 ----
LR: [0.0014560975026306038]
---- EP [1/5] | BTCH [1173/3634] ||| train_loss = 0.00743 ----
LR: [0.0014578296685032553]
---- EP [1/5] | BTCH [1174/3634] ||| train_loss = 0.00769 ----
LR: [0.0014595630778315022]
---- EP [1/5] | BTCH [1175/3634] ||| train_loss = 0.00957 ----
LR: [0.0014612977300393591]
---- EP [1/5] | BTCH [1176/3634] ||| train_loss = 0.01001 ----
LR: [0.0014630336245504364]
---- EP [1/5] | BTCH [1177/3634] ||| train_loss = 0.01098 ----
LR: [0.0014647707607879264]
---- EP [1/5] | BTCH [1178/3634] ||| train_loss = 0.01278 ----
LR: [0.0014665091381746084]
---- EP [1/5] | BTCH [1179/3634] ||| train_loss = 0.01305 ----
LR: [0.0014682487561328544]
---- EP [1/5] | BTCH [1180/3634] ||| train_loss = 0.01065 ----
LR: [0.001469989614084618]
---- EP [1/5] | BTCH [1181/3634] ||| train_loss = 0.01429 ----
LR: [0.0014717317114514433]
---- EP [1/5] | BTCH [1182/3634] ||| train_loss = 0.00980 ----
LR: [0.0014734750476544638]
---- EP [1/5] | BTCH [1183/3634] ||| train_loss = 0.01060 ----
LR: [0.0014752196221144015]
---- EP [1/5] | BTCH [1184/3634] ||| train_loss = 0.01414 ----
LR: [0.0014769654342515655]
---- EP [1/5] | BTCH [1185/3634] ||| train_loss = 0.00634 ----
LR: [0.0014787124834858521]
---- EP [1/5] | BTCH [1186/3634] ||| train_loss = 0.00832 ----
LR: [0.0014804607692367484]
---- EP [1/5] | BTCH [1187/3634] ||| train_loss = 0.01466 ----
LR: [0.0014822102909233335]
---- EP [1/5] | BTCH [1188/3634] ||| train_loss = 0.01051 ----
LR: [0.0014839610479642704]
---- EP [1/5] | BTCH [1189/3634] ||| train_loss = 0.00840 ----
LR: [0.001485713039777816]
---- EP [1/5] | BTCH [1190/3634] ||| train_loss = 0.01029 ----
LR: [0.001487466265781813]
---- EP [1/5] | BTCH [1191/3634] ||| train_loss = 0.00892 ----
LR: [0.0014892207253936977]
---- EP [1/5] | BTCH [1192/3634] ||| train_loss = 0.02649 ----
LR: [0.0014909764180304954]
---- EP [1/5] | BTCH [1193/3634] ||| train_loss = 0.00472 ----
LR: [0.001492733343108817]
---- EP [1/5] | BTCH [1194/3634] ||| train_loss = 0.02431 ----
LR: [0.0014944915000448741]
---- EP [1/5] | BTCH [1195/3634] ||| train_loss = 0.00744 ----
LR: [0.0014962508882544572]
---- EP [1/5] | BTCH [1196/3634] ||| train_loss = 0.01368 ----
LR: [0.001498011507152959]
---- EP [1/5] | BTCH [1197/3634] ||| train_loss = 0.00985 ----
LR: [0.0014997733561553529]
---- EP [1/5] | BTCH [1198/3634] ||| train_loss = 0.00581 ----
LR: [0.0015015364346762112]
---- EP [1/5] | BTCH [1199/3634] ||| train_loss = 0.01161 ----
LR: [0.0015033007421296936]
---- EP [1/5] | BTCH [1200/3634] ||| train_loss = 0.01488 ----
LR: [0.001505066277929552]
---- EP [1/5] | BTCH [1201/3634] ||| train_loss = 0.00824 ----
LR: [0.0015068330414891307]
---- EP [1/5] | BTCH [1202/3634] ||| train_loss = 0.01403 ----
LR: [0.001508601032221368]
---- EP [1/5] | BTCH [1203/3634] ||| train_loss = 0.01685 ----
LR: [0.0015103702495387911]
---- EP [1/5] | BTCH [1204/3634] ||| train_loss = 0.01039 ----
LR: [0.0015121406928535232]
---- EP [1/5] | BTCH [1205/3634] ||| train_loss = 0.01024 ----
LR: [0.0015139123615772743]
---- EP [1/5] | BTCH [1206/3634] ||| train_loss = 0.01005 ----
LR: [0.0015156852551213521]
---- EP [1/5] | BTCH [1207/3634] ||| train_loss = 0.01572 ----
LR: [0.0015174593728966585]
---- EP [1/5] | BTCH [1208/3634] ||| train_loss = 0.00884 ----
LR: [0.0015192347143136824]
---- EP [1/5] | BTCH [1209/3634] ||| train_loss = 0.01138 ----
LR: [0.0015210112787825136]
---- EP [1/5] | BTCH [1210/3634] ||| train_loss = 0.01720 ----
LR: [0.0015227890657128294]
---- EP [1/5] | BTCH [1211/3634] ||| train_loss = 0.00905 ----
LR: [0.0015245680745139042]
---- EP [1/5] | BTCH [1212/3634] ||| train_loss = 0.01984 ----
LR: [0.001526348304594605]
---- EP [1/5] | BTCH [1213/3634] ||| train_loss = 0.01605 ----
LR: [0.0015281297553633947]
---- EP [1/5] | BTCH [1214/3634] ||| train_loss = 0.00911 ----
LR: [0.0015299124262283283]
---- EP [1/5] | BTCH [1215/3634] ||| train_loss = 0.01088 ----
LR: [0.0015316963165970567]
---- EP [1/5] | BTCH [1216/3634] ||| train_loss = 0.01416 ----
LR: [0.0015334814258768266]
---- EP [1/5] | BTCH [1217/3634] ||| train_loss = 0.01429 ----
LR: [0.0015352677534744754]
---- EP [1/5] | BTCH [1218/3634] ||| train_loss = 0.00694 ----
LR: [0.0015370552987964397]
---- EP [1/5] | BTCH [1219/3634] ||| train_loss = 0.01743 ----
LR: [0.0015388440612487536]
---- EP [1/5] | BTCH [1220/3634] ||| train_loss = 0.01374 ----
LR: [0.001540634040237042]
---- EP [1/5] | BTCH [1221/3634] ||| train_loss = 0.01388 ----
LR: [0.0015424252351665252]
---- EP [1/5] | BTCH [1222/3634] ||| train_loss = 0.01736 ----
LR: [0.0015442176454420215]
---- EP [1/5] | BTCH [1223/3634] ||| train_loss = 0.01850 ----
LR: [0.00154601127046795]
---- EP [1/5] | BTCH [1224/3634] ||| train_loss = 0.01130 ----
LR: [0.001547806109648317]
---- EP [1/5] | BTCH [1225/3634] ||| train_loss = 0.01446 ----
LR: [0.0015496021623867297]
---- EP [1/5] | BTCH [1226/3634] ||| train_loss = 0.00638 ----
LR: [0.0015513994280863964]
---- EP [1/5] | BTCH [1227/3634] ||| train_loss = 0.01048 ----
LR: [0.0015531979061501142]
---- EP [1/5] | BTCH [1228/3634] ||| train_loss = 0.01683 ----
LR: [0.0015549975959802814]
---- EP [1/5] | BTCH [1229/3634] ||| train_loss = 0.01315 ----
LR: [0.0015567984969788954]
---- EP [1/5] | BTCH [1230/3634] ||| train_loss = 0.01596 ----
LR: [0.0015586006085475494]
---- EP [1/5] | BTCH [1231/3634] ||| train_loss = 0.01144 ----
LR: [0.0015604039300874343]
---- EP [1/5] | BTCH [1232/3634] ||| train_loss = 0.00888 ----
LR: [0.0015622084609993366]
---- EP [1/5] | BTCH [1233/3634] ||| train_loss = 0.01773 ----
LR: [0.0015640142006836458]
---- EP [1/5] | BTCH [1234/3634] ||| train_loss = 0.01540 ----
LR: [0.001565821148540347]
---- EP [1/5] | BTCH [1235/3634] ||| train_loss = 0.01054 ----
LR: [0.001567629303969021]
---- EP [1/5] | BTCH [1236/3634] ||| train_loss = 0.01690 ----
LR: [0.0015694386663688553]
---- EP [1/5] | BTCH [1237/3634] ||| train_loss = 0.00924 ----
LR: [0.0015712492351386276]
---- EP [1/5] | BTCH [1238/3634] ||| train_loss = 0.00673 ----
LR: [0.00157306100967672]
---- EP [1/5] | BTCH [1239/3634] ||| train_loss = 0.01691 ----
LR: [0.0015748739893811127]
---- EP [1/5] | BTCH [1240/3634] ||| train_loss = 0.01621 ----
LR: [0.0015766881736493845]
---- EP [1/5] | BTCH [1241/3634] ||| train_loss = 0.01419 ----
LR: [0.0015785035618787174]
---- EP [1/5] | BTCH [1242/3634] ||| train_loss = 0.01231 ----
LR: [0.0015803201534658872]
---- EP [1/5] | BTCH [1243/3634] ||| train_loss = 0.01223 ----
LR: [0.0015821379478072745]
---- EP [1/5] | BTCH [1244/3634] ||| train_loss = 0.01309 ----
LR: [0.0015839569442988605]
---- EP [1/5] | BTCH [1245/3634] ||| train_loss = 0.00904 ----
LR: [0.0015857771423362227]
---- EP [1/5] | BTCH [1246/3634] ||| train_loss = 0.01396 ----
LR: [0.001587598541314546]
---- EP [1/5] | BTCH [1247/3634] ||| train_loss = 0.00710 ----
LR: [0.0015894211406286083]
---- EP [1/5] | BTCH [1248/3634] ||| train_loss = 0.01512 ----
LR: [0.0015912449396727965]
---- EP [1/5] | BTCH [1249/3634] ||| train_loss = 0.01084 ----
LR: [0.0015930699378410938]
---- EP [1/5] | BTCH [1250/3634] ||| train_loss = 0.00787 ----
LR: [0.0015948961345270858]
---- EP [1/5] | BTCH [1251/3634] ||| train_loss = 0.00732 ----
LR: [0.0015967235291239595]
---- EP [1/5] | BTCH [1252/3634] ||| train_loss = 0.01098 ----
LR: [0.001598552121024506]
---- EP [1/5] | BTCH [1253/3634] ||| train_loss = 0.02379 ----
LR: [0.001600381909621116]
---- EP [1/5] | BTCH [1254/3634] ||| train_loss = 0.00714 ----
LR: [0.0016022128943057844]
---- EP [1/5] | BTCH [1255/3634] ||| train_loss = 0.01189 ----
LR: [0.0016040450744701108]
---- EP [1/5] | BTCH [1256/3634] ||| train_loss = 0.00829 ----
LR: [0.0016058784495052904]
---- EP [1/5] | BTCH [1257/3634] ||| train_loss = 0.02353 ----
LR: [0.0016077130188021267]
---- EP [1/5] | BTCH [1258/3634] ||| train_loss = 0.01615 ----
LR: [0.0016095487817510308]
---- EP [1/5] | BTCH [1259/3634] ||| train_loss = 0.01400 ----
LR: [0.0016113857377420045]
---- EP [1/5] | BTCH [1260/3634] ||| train_loss = 0.01195 ----
LR: [0.001613223886164663]
---- EP [1/5] | BTCH [1261/3634] ||| train_loss = 0.01473 ----
LR: [0.0016150632264082254]
---- EP [1/5] | BTCH [1262/3634] ||| train_loss = 0.00869 ----
LR: [0.001616903757861509]
---- EP [1/5] | BTCH [1263/3634] ||| train_loss = 0.00936 ----
LR: [0.0016187454799129388]
---- EP [1/5] | BTCH [1264/3634] ||| train_loss = 0.01350 ----
LR: [0.0016205883919505459]
---- EP [1/5] | BTCH [1265/3634] ||| train_loss = 0.01189 ----
LR: [0.0016224324933619624]
---- EP [1/5] | BTCH [1266/3634] ||| train_loss = 0.00978 ----
LR: [0.0016242777835344287]
---- EP [1/5] | BTCH [1267/3634] ||| train_loss = 0.00754 ----
VAL ||| loss = 0.013457680486775841, psnr = 30.673391342163086, ssim = 0.9068437814712524
LR: [0.001626124261854784]
---- EP [1/5] | BTCH [1268/3634] ||| train_loss = 0.00982 ----
LR: [0.001627971927709481]
---- EP [1/5] | BTCH [1269/3634] ||| train_loss = 0.01090 ----
LR: [0.0016298207804845716]
---- EP [1/5] | BTCH [1270/3634] ||| train_loss = 0.00898 ----
LR: [0.001631670819565714]
---- EP [1/5] | BTCH [1271/3634] ||| train_loss = 0.01634 ----
LR: [0.001633522044338179]
---- EP [1/5] | BTCH [1272/3634] ||| train_loss = 0.01152 ----
LR: [0.0016353744541868324]
---- EP [1/5] | BTCH [1273/3634] ||| train_loss = 0.00740 ----
LR: [0.001637228048496156]
---- EP [1/5] | BTCH [1274/3634] ||| train_loss = 0.01333 ----
LR: [0.0016390828266502292]
---- EP [1/5] | BTCH [1275/3634] ||| train_loss = 0.01073 ----
LR: [0.0016409387880327482]
---- EP [1/5] | BTCH [1276/3634] ||| train_loss = 0.00925 ----
LR: [0.0016427959320270066]
---- EP [1/5] | BTCH [1277/3634] ||| train_loss = 0.00741 ----
LR: [0.0016446542580159096]
---- EP [1/5] | BTCH [1278/3634] ||| train_loss = 0.01211 ----
LR: [0.0016465137653819718]
---- EP [1/5] | BTCH [1279/3634] ||| train_loss = 0.01254 ----
LR: [0.0016483744535073109]
---- EP [1/5] | BTCH [1280/3634] ||| train_loss = 0.00871 ----
LR: [0.0016502363217736505]
---- EP [1/5] | BTCH [1281/3634] ||| train_loss = 0.01270 ----
LR: [0.001652099369562331]
---- EP [1/5] | BTCH [1282/3634] ||| train_loss = 0.00883 ----
LR: [0.0016539635962542903]
---- EP [1/5] | BTCH [1283/3634] ||| train_loss = 0.01339 ----
LR: [0.001655829001230083]
---- EP [1/5] | BTCH [1284/3634] ||| train_loss = 0.01536 ----
LR: [0.001657695583869868]
---- EP [1/5] | BTCH [1285/3634] ||| train_loss = 0.01160 ----
LR: [0.0016595633435534125]
---- EP [1/5] | BTCH [1286/3634] ||| train_loss = 0.01552 ----
LR: [0.0016614322796600946]
---- EP [1/5] | BTCH [1287/3634] ||| train_loss = 0.00848 ----
LR: [0.0016633023915689008]
---- EP [1/5] | BTCH [1288/3634] ||| train_loss = 0.01409 ----
LR: [0.0016651736786584253]
---- EP [1/5] | BTCH [1289/3634] ||| train_loss = 0.01474 ----
LR: [0.0016670461403068756]
---- EP [1/5] | BTCH [1290/3634] ||| train_loss = 0.00746 ----
LR: [0.0016689197758920638]
---- EP [1/5] | BTCH [1291/3634] ||| train_loss = 0.01047 ----
LR: [0.0016707945847914164]
---- EP [1/5] | BTCH [1292/3634] ||| train_loss = 0.01162 ----
LR: [0.0016726705663819685]
---- EP [1/5] | BTCH [1293/3634] ||| train_loss = 0.02369 ----
LR: [0.0016745477200403643]
---- EP [1/5] | BTCH [1294/3634] ||| train_loss = 0.01306 ----
LR: [0.00167642604514286]
---- EP [1/5] | BTCH [1295/3634] ||| train_loss = 0.00783 ----
LR: [0.0016783055410653225]
---- EP [1/5] | BTCH [1296/3634] ||| train_loss = 0.00941 ----
LR: [0.0016801862071832274]
---- EP [1/5] | BTCH [1297/3634] ||| train_loss = 0.01664 ----
LR: [0.0016820680428716647]
---- EP [1/5] | BTCH [1298/3634] ||| train_loss = 0.00849 ----
LR: [0.001683951047505336]
---- EP [1/5] | BTCH [1299/3634] ||| train_loss = 0.01208 ----
LR: [0.001685835220458549]
---- EP [1/5] | BTCH [1300/3634] ||| train_loss = 0.01109 ----
LR: [0.001687720561105232]
---- EP [1/5] | BTCH [1301/3634] ||| train_loss = 0.01324 ----
LR: [0.0016896070688189168]
---- EP [1/5] | BTCH [1302/3634] ||| train_loss = 0.00869 ----
LR: [0.001691494742972751]
---- EP [1/5] | BTCH [1303/3634] ||| train_loss = 0.01029 ----
LR: [0.0016933835829394967]
---- EP [1/5] | BTCH [1304/3634] ||| train_loss = 0.01702 ----
LR: [0.0016952735880915223]
---- EP [1/5] | BTCH [1305/3634] ||| train_loss = 0.01834 ----
LR: [0.0016971647578008196]
---- EP [1/5] | BTCH [1306/3634] ||| train_loss = 0.00737 ----
LR: [0.0016990570914389817]
---- EP [1/5] | BTCH [1307/3634] ||| train_loss = 0.01617 ----
LR: [0.0017009505883772234]
---- EP [1/5] | BTCH [1308/3634] ||| train_loss = 0.01736 ----
LR: [0.001702845247986369]
---- EP [1/5] | BTCH [1309/3634] ||| train_loss = 0.01444 ----
LR: [0.0017047410696368562]
---- EP [1/5] | BTCH [1310/3634] ||| train_loss = 0.01030 ----
LR: [0.0017066380526987394]
---- EP [1/5] | BTCH [1311/3634] ||| train_loss = 0.01905 ----
LR: [0.001708536196541684]
---- EP [1/5] | BTCH [1312/3634] ||| train_loss = 0.01278 ----
LR: [0.0017104355005349726]
---- EP [1/5] | BTCH [1313/3634] ||| train_loss = 0.01007 ----
LR: [0.0017123359640474987]
---- EP [1/5] | BTCH [1314/3634] ||| train_loss = 0.00753 ----
LR: [0.0017142375864477744]
---- EP [1/5] | BTCH [1315/3634] ||| train_loss = 0.00737 ----
LR: [0.001716140367103925]
---- EP [1/5] | BTCH [1316/3634] ||| train_loss = 0.00927 ----
LR: [0.001718044305383689]
---- EP [1/5] | BTCH [1317/3634] ||| train_loss = 0.01197 ----
LR: [0.0017199494006544247]
---- EP [1/5] | BTCH [1318/3634] ||| train_loss = 0.01213 ----
LR: [0.0017218556522831004]
---- EP [1/5] | BTCH [1319/3634] ||| train_loss = 0.01330 ----
LR: [0.001723763059636306]
---- EP [1/5] | BTCH [1320/3634] ||| train_loss = 0.01420 ----
LR: [0.001725671622080243]
---- EP [1/5] | BTCH [1321/3634] ||| train_loss = 0.00696 ----
LR: [0.0017275813389807312]
---- EP [1/5] | BTCH [1322/3634] ||| train_loss = 0.01049 ----
LR: [0.0017294922097032053]
---- EP [1/5] | BTCH [1323/3634] ||| train_loss = 0.01856 ----
LR: [0.0017314042336127183]
---- EP [1/5] | BTCH [1324/3634] ||| train_loss = 0.01138 ----
LR: [0.0017333174100739382]
---- EP [1/5] | BTCH [1325/3634] ||| train_loss = 0.00595 ----
LR: [0.0017352317384511512]
---- EP [1/5] | BTCH [1326/3634] ||| train_loss = 0.01823 ----
LR: [0.001737147218108262]
---- EP [1/5] | BTCH [1327/3634] ||| train_loss = 0.00960 ----
LR: [0.0017390638484087902]
---- EP [1/5] | BTCH [1328/3634] ||| train_loss = 0.01566 ----
LR: [0.0017409816287158736]
---- EP [1/5] | BTCH [1329/3634] ||| train_loss = 0.01648 ----
LR: [0.0017429005583922703]
---- EP [1/5] | BTCH [1330/3634] ||| train_loss = 0.00951 ----
LR: [0.0017448206368003531]
---- EP [1/5] | BTCH [1331/3634] ||| train_loss = 0.01622 ----
LR: [0.0017467418633021134]
---- EP [1/5] | BTCH [1332/3634] ||| train_loss = 0.01033 ----
LR: [0.001748664237259166]
---- EP [1/5] | BTCH [1333/3634] ||| train_loss = 0.00927 ----
LR: [0.0017505877580327386]
---- EP [1/5] | BTCH [1334/3634] ||| train_loss = 0.00919 ----
LR: [0.0017525124249836797]
---- EP [1/5] | BTCH [1335/3634] ||| train_loss = 0.01297 ----
LR: [0.0017544382374724589]
---- EP [1/5] | BTCH [1336/3634] ||| train_loss = 0.01072 ----
LR: [0.001756365194859161]
---- EP [1/5] | BTCH [1337/3634] ||| train_loss = 0.01037 ----
LR: [0.0017582932965034947]
---- EP [1/5] | BTCH [1338/3634] ||| train_loss = 0.00571 ----
LR: [0.0017602225417647863]
---- EP [1/5] | BTCH [1339/3634] ||| train_loss = 0.01220 ----
LR: [0.0017621529300019811]
---- EP [1/5] | BTCH [1340/3634] ||| train_loss = 0.02137 ----
LR: [0.0017640844605736495]
---- EP [1/5] | BTCH [1341/3634] ||| train_loss = 0.02437 ----
LR: [0.001766017132837975]
---- EP [1/5] | BTCH [1342/3634] ||| train_loss = 0.00856 ----
LR: [0.0017679509461527663]
---- EP [1/5] | BTCH [1343/3634] ||| train_loss = 0.01087 ----
LR: [0.0017698858998754542]
---- EP [1/5] | BTCH [1344/3634] ||| train_loss = 0.02274 ----
LR: [0.001771821993363086]
---- EP [1/5] | BTCH [1345/3634] ||| train_loss = 0.01122 ----
LR: [0.0017737592259723343]
---- EP [1/5] | BTCH [1346/3634] ||| train_loss = 0.00542 ----
LR: [0.0017756975970594918]
---- EP [1/5] | BTCH [1347/3634] ||| train_loss = 0.00875 ----
LR: [0.0017776371059804712]
---- EP [1/5] | BTCH [1348/3634] ||| train_loss = 0.01649 ----
LR: [0.0017795777520908124]
---- EP [1/5] | BTCH [1349/3634] ||| train_loss = 0.01680 ----
LR: [0.0017815195347456701]
---- EP [1/5] | BTCH [1350/3634] ||| train_loss = 0.01509 ----
LR: [0.001783462453299826]
---- EP [1/5] | BTCH [1351/3634] ||| train_loss = 0.01345 ----
LR: [0.001785406507107682]
---- EP [1/5] | BTCH [1352/3634] ||| train_loss = 0.01325 ----
LR: [0.0017873516955232687]
---- EP [1/5] | BTCH [1353/3634] ||| train_loss = 0.01899 ----
LR: [0.0017892980179002316]
---- EP [1/5] | BTCH [1354/3634] ||| train_loss = 0.00807 ----
LR: [0.0017912454735918414]
---- EP [1/5] | BTCH [1355/3634] ||| train_loss = 0.00789 ----
LR: [0.0017931940619509978]
---- EP [1/5] | BTCH [1356/3634] ||| train_loss = 0.01305 ----
LR: [0.0017951437823302153]
---- EP [1/5] | BTCH [1357/3634] ||| train_loss = 0.01205 ----
LR: [0.001797094634081644]
---- EP [1/5] | BTCH [1358/3634] ||| train_loss = 0.01479 ----
LR: [0.0017990466165570436]
---- EP [1/5] | BTCH [1359/3634] ||| train_loss = 0.00876 ----
LR: [0.00180099972910781]
---- EP [1/5] | BTCH [1360/3634] ||| train_loss = 0.01358 ----
LR: [0.0018029539710849585]
---- EP [1/5] | BTCH [1361/3634] ||| train_loss = 0.00788 ----
LR: [0.0018049093418391303]
---- EP [1/5] | BTCH [1362/3634] ||| train_loss = 0.01044 ----
LR: [0.0018068658407205881]
---- EP [1/5] | BTCH [1363/3634] ||| train_loss = 0.01217 ----
LR: [0.001808823467079227]
---- EP [1/5] | BTCH [1364/3634] ||| train_loss = 0.00468 ----
LR: [0.0018107822202645587]
---- EP [1/5] | BTCH [1365/3634] ||| train_loss = 0.01061 ----
LR: [0.0018127420996257287]
---- EP [1/5] | BTCH [1366/3634] ||| train_loss = 0.01212 ----
LR: [0.0018147031045115027]
---- EP [1/5] | BTCH [1367/3634] ||| train_loss = 0.01410 ----
LR: [0.0018166652342702736]
---- EP [1/5] | BTCH [1368/3634] ||| train_loss = 0.01123 ----
LR: [0.0018186284882500629]
---- EP [1/5] | BTCH [1369/3634] ||| train_loss = 0.01822 ----
LR: [0.0018205928657985156]
---- EP [1/5] | BTCH [1370/3634] ||| train_loss = 0.01256 ----
LR: [0.0018225583662629021]
---- EP [1/5] | BTCH [1371/3634] ||| train_loss = 0.01070 ----
LR: [0.0018245249889901269]
---- EP [1/5] | BTCH [1372/3634] ||| train_loss = 0.01389 ----
LR: [0.001826492733326716]
---- EP [1/5] | BTCH [1373/3634] ||| train_loss = 0.01111 ----
LR: [0.0018284615986188194]
---- EP [1/5] | BTCH [1374/3634] ||| train_loss = 0.01481 ----
LR: [0.0018304315842122242]
---- EP [1/5] | BTCH [1375/3634] ||| train_loss = 0.01349 ----
LR: [0.001832402689452334]
---- EP [1/5] | BTCH [1376/3634] ||| train_loss = 0.01757 ----
LR: [0.0018343749136841923]
---- EP [1/5] | BTCH [1377/3634] ||| train_loss = 0.01061 ----
LR: [0.0018363482562524583]
---- EP [1/5] | BTCH [1378/3634] ||| train_loss = 0.00820 ----
LR: [0.001838322716501431]
---- EP [1/5] | BTCH [1379/3634] ||| train_loss = 0.01428 ----
LR: [0.001840298293775031]
---- EP [1/5] | BTCH [1380/3634] ||| train_loss = 0.01414 ----
LR: [0.0018422749874168112]
---- EP [1/5] | BTCH [1381/3634] ||| train_loss = 0.01023 ----
LR: [0.001844252796769948]
---- EP [1/5] | BTCH [1382/3634] ||| train_loss = 0.01303 ----
LR: [0.0018462317211772553]
---- EP [1/5] | BTCH [1383/3634] ||| train_loss = 0.01793 ----
LR: [0.001848211759981169]
---- EP [1/5] | BTCH [1384/3634] ||| train_loss = 0.00858 ----
LR: [0.0018501929125237602]
---- EP [1/5] | BTCH [1385/3634] ||| train_loss = 0.01372 ----
LR: [0.0018521751781467276]
---- EP [1/5] | BTCH [1386/3634] ||| train_loss = 0.01015 ----
LR: [0.0018541585561913983]
---- EP [1/5] | BTCH [1387/3634] ||| train_loss = 0.00651 ----
LR: [0.0018561430459987337]
---- EP [1/5] | BTCH [1388/3634] ||| train_loss = 0.01211 ----
LR: [0.0018581286469093235]
---- EP [1/5] | BTCH [1389/3634] ||| train_loss = 0.01241 ----
LR: [0.0018601153582633867]
---- EP [1/5] | BTCH [1390/3634] ||| train_loss = 0.01182 ----
LR: [0.0018621031794007759]
---- EP [1/5] | BTCH [1391/3634] ||| train_loss = 0.00932 ----
LR: [0.001864092109660976]
---- EP [1/5] | BTCH [1392/3634] ||| train_loss = 0.01404 ----
LR: [0.0018660821483830973]
---- EP [1/5] | BTCH [1393/3634] ||| train_loss = 0.01122 ----
LR: [0.001868073294905891]
---- EP [1/5] | BTCH [1394/3634] ||| train_loss = 0.02392 ----
LR: [0.0018700655485677318]
---- EP [1/5] | BTCH [1395/3634] ||| train_loss = 0.01152 ----
LR: [0.0018720589087066284]
---- EP [1/5] | BTCH [1396/3634] ||| train_loss = 0.01037 ----
LR: [0.001874053374660227]
---- EP [1/5] | BTCH [1397/3634] ||| train_loss = 0.00769 ----
LR: [0.001876048945765799]
---- EP [1/5] | BTCH [1398/3634] ||| train_loss = 0.00689 ----
LR: [0.0018780456213602532]
---- EP [1/5] | BTCH [1399/3634] ||| train_loss = 0.01413 ----
LR: [0.0018800434007801344]
---- EP [1/5] | BTCH [1400/3634] ||| train_loss = 0.01237 ----
LR: [0.0018820422833616107]
---- EP [1/5] | BTCH [1401/3634] ||| train_loss = 0.01218 ----
LR: [0.0018840422684404945]
---- EP [1/5] | BTCH [1402/3634] ||| train_loss = 0.00967 ----
LR: [0.0018860433553522238]
---- EP [1/5] | BTCH [1403/3634] ||| train_loss = 0.01143 ----
LR: [0.001888045543431872]
---- EP [1/5] | BTCH [1404/3634] ||| train_loss = 0.01092 ----
LR: [0.001890048832014152]
---- EP [1/5] | BTCH [1405/3634] ||| train_loss = 0.01209 ----
LR: [0.001892053220433407]
---- EP [1/5] | BTCH [1406/3634] ||| train_loss = 0.01040 ----
LR: [0.0018940587080236125]
---- EP [1/5] | BTCH [1407/3634] ||| train_loss = 0.01455 ----
LR: [0.0018960652941183813]
---- EP [1/5] | BTCH [1408/3634] ||| train_loss = 0.00850 ----
LR: [0.0018980729780509638]
---- EP [1/5] | BTCH [1409/3634] ||| train_loss = 0.01605 ----
LR: [0.0019000817591542409]
---- EP [1/5] | BTCH [1410/3634] ||| train_loss = 0.01127 ----
LR: [0.001902091636760729]
---- EP [1/5] | BTCH [1411/3634] ||| train_loss = 0.00620 ----
LR: [0.001904102610202586]
---- EP [1/5] | BTCH [1412/3634] ||| train_loss = 0.01746 ----
LR: [0.001906114678811601]
---- EP [1/5] | BTCH [1413/3634] ||| train_loss = 0.01335 ----
LR: [0.0019081278419191983]
---- EP [1/5] | BTCH [1414/3634] ||| train_loss = 0.01230 ----
LR: [0.0019101420988564405]
---- EP [1/5] | BTCH [1415/3634] ||| train_loss = 0.00817 ----
LR: [0.0019121574489540279]
---- EP [1/5] | BTCH [1416/3634] ||| train_loss = 0.01398 ----
LR: [0.001914173891542293]
---- EP [1/5] | BTCH [1417/3634] ||| train_loss = 0.01688 ----
LR: [0.0019161914259512112]
---- EP [1/5] | BTCH [1418/3634] ||| train_loss = 0.01101 ----
LR: [0.0019182100515103932]
---- EP [1/5] | BTCH [1419/3634] ||| train_loss = 0.00529 ----
LR: [0.001920229767549084]
---- EP [1/5] | BTCH [1420/3634] ||| train_loss = 0.01442 ----
LR: [0.001922250573396166]
---- EP [1/5] | BTCH [1421/3634] ||| train_loss = 0.00809 ----
LR: [0.0019242724683801657]
---- EP [1/5] | BTCH [1422/3634] ||| train_loss = 0.01425 ----
LR: [0.0019262954518292456]
---- EP [1/5] | BTCH [1423/3634] ||| train_loss = 0.01026 ----
LR: [0.0019283195230712005]
---- EP [1/5] | BTCH [1424/3634] ||| train_loss = 0.01573 ----
LR: [0.0019303446814334692]
---- EP [1/5] | BTCH [1425/3634] ||| train_loss = 0.01858 ----
LR: [0.0019323709262431318]
---- EP [1/5] | BTCH [1426/3634] ||| train_loss = 0.01417 ----
LR: [0.001934398256826897]
---- EP [1/5] | BTCH [1427/3634] ||| train_loss = 0.01150 ----
LR: [0.001936426672511123]
---- EP [1/5] | BTCH [1428/3634] ||| train_loss = 0.01450 ----
LR: [0.0019384561726218073]
---- EP [1/5] | BTCH [1429/3634] ||| train_loss = 0.00826 ----
LR: [0.0019404867564845798]
---- EP [1/5] | BTCH [1430/3634] ||| train_loss = 0.01387 ----
LR: [0.0019425184234247127]
---- EP [1/5] | BTCH [1431/3634] ||| train_loss = 0.01108 ----
LR: [0.0019445511727671245]
---- EP [1/5] | BTCH [1432/3634] ||| train_loss = 0.01143 ----
LR: [0.001946585003836366]
---- EP [1/5] | BTCH [1433/3634] ||| train_loss = 0.01115 ----
LR: [0.0019486199159566321]
---- EP [1/5] | BTCH [1434/3634] ||| train_loss = 0.00907 ----
LR: [0.0019506559084517608]
---- EP [1/5] | BTCH [1435/3634] ||| train_loss = 0.01775 ----
LR: [0.0019526929806452254]
---- EP [1/5] | BTCH [1436/3634] ||| train_loss = 0.01407 ----
LR: [0.001954731131860142]
---- EP [1/5] | BTCH [1437/3634] ||| train_loss = 0.01007 ----
LR: [0.0019567703614192765]
---- EP [1/5] | BTCH [1438/3634] ||| train_loss = 0.01488 ----
LR: [0.001958810668645023]
---- EP [1/5] | BTCH [1439/3634] ||| train_loss = 0.00997 ----
LR: [0.0019608520528594294]
---- EP [1/5] | BTCH [1440/3634] ||| train_loss = 0.00885 ----
LR: [0.001962894513384177]
---- EP [1/5] | BTCH [1441/3634] ||| train_loss = 0.01421 ----
LR: [0.0019649380495405967]
---- EP [1/5] | BTCH [1442/3634] ||| train_loss = 0.00945 ----
LR: [0.001966982660649654]
---- EP [1/5] | BTCH [1443/3634] ||| train_loss = 0.01173 ----
LR: [0.0019690283460319646]
---- EP [1/5] | BTCH [1444/3634] ||| train_loss = 0.00849 ----
LR: [0.001971075105007781]
---- EP [1/5] | BTCH [1445/3634] ||| train_loss = 0.01175 ----
LR: [0.001973122936897007]
---- EP [1/5] | BTCH [1446/3634] ||| train_loss = 0.01378 ----
LR: [0.0019751718410191826]
---- EP [1/5] | BTCH [1447/3634] ||| train_loss = 0.01074 ----
LR: [0.001977221816693492]
---- EP [1/5] | BTCH [1448/3634] ||| train_loss = 0.00697 ----
VAL ||| loss = 0.013483615557457466, psnr = 30.660295486450195, ssim = 0.9066900610923767
LR: [0.0019792728632387676]
---- EP [1/5] | BTCH [1449/3634] ||| train_loss = 0.01028 ----
LR: [0.001981324979973484]
---- EP [1/5] | BTCH [1450/3634] ||| train_loss = 0.01544 ----
LR: [0.001983378166215759]
---- EP [1/5] | BTCH [1451/3634] ||| train_loss = 0.01081 ----
LR: [0.001985432421283356]
---- EP [1/5] | BTCH [1452/3634] ||| train_loss = 0.01042 ----
LR: [0.0019874877444936833]
---- EP [1/5] | BTCH [1453/3634] ||| train_loss = 0.00746 ----
LR: [0.0019895441351637944]
---- EP [1/5] | BTCH [1454/3634] ||| train_loss = 0.00790 ----
LR: [0.001991601592610385]
---- EP [1/5] | BTCH [1455/3634] ||| train_loss = 0.00856 ----
LR: [0.0019936601161498046]
---- EP [1/5] | BTCH [1456/3634] ||| train_loss = 0.01312 ----
LR: [0.0019957197050980407]
---- EP [1/5] | BTCH [1457/3634] ||| train_loss = 0.01294 ----
LR: [0.0019977803587707243]
---- EP [1/5] | BTCH [1458/3634] ||| train_loss = 0.00898 ----
LR: [0.0019998420764831444]
---- EP [1/5] | BTCH [1459/3634] ||| train_loss = 0.01013 ----
LR: [0.0020019048575502275]
---- EP [1/5] | BTCH [1460/3634] ||| train_loss = 0.01116 ----
LR: [0.0020039687012865445]
---- EP [1/5] | BTCH [1461/3634] ||| train_loss = 0.01206 ----
LR: [0.0020060336070063245]
---- EP [1/5] | BTCH [1462/3634] ||| train_loss = 0.01222 ----
LR: [0.0020080995740234305]
---- EP [1/5] | BTCH [1463/3634] ||| train_loss = 0.01200 ----
LR: [0.0020101666016513822]
---- EP [1/5] | BTCH [1464/3634] ||| train_loss = 0.00825 ----
LR: [0.0020122346892033436]
---- EP [1/5] | BTCH [1465/3634] ||| train_loss = 0.01264 ----
LR: [0.0020143038359921248]
---- EP [1/5] | BTCH [1466/3634] ||| train_loss = 0.01066 ----
LR: [0.002016374041330187]
---- EP [1/5] | BTCH [1467/3634] ||| train_loss = 0.01082 ----
LR: [0.0020184453045296383]
---- EP [1/5] | BTCH [1468/3634] ||| train_loss = 0.01187 ----
LR: [0.0020205176249022336]
---- EP [1/5] | BTCH [1469/3634] ||| train_loss = 0.02105 ----
LR: [0.0020225910017593815]
---- EP [1/5] | BTCH [1470/3634] ||| train_loss = 0.00865 ----
LR: [0.002024665434412133]
---- EP [1/5] | BTCH [1471/3634] ||| train_loss = 0.01234 ----
LR: [0.0020267409221711944]
---- EP [1/5] | BTCH [1472/3634] ||| train_loss = 0.00928 ----
LR: [0.002028817464346919]
---- EP [1/5] | BTCH [1473/3634] ||| train_loss = 0.00628 ----
LR: [0.002030895060249305]
---- EP [1/5] | BTCH [1474/3634] ||| train_loss = 0.00988 ----
LR: [0.002032973709188009]
---- EP [1/5] | BTCH [1475/3634] ||| train_loss = 0.02386 ----
LR: [0.0020350534104723317]
---- EP [1/5] | BTCH [1476/3634] ||| train_loss = 0.01440 ----
LR: [0.0020371341634112267]
---- EP [1/5] | BTCH [1477/3634] ||| train_loss = 0.01135 ----
LR: [0.002039215967313296]
---- EP [1/5] | BTCH [1478/3634] ||| train_loss = 0.01673 ----
LR: [0.0020412988214867974]
---- EP [1/5] | BTCH [1479/3634] ||| train_loss = 0.00884 ----
LR: [0.002043382725239632]
---- EP [1/5] | BTCH [1480/3634] ||| train_loss = 0.02093 ----
LR: [0.0020454676778793573]
---- EP [1/5] | BTCH [1481/3634] ||| train_loss = 0.01248 ----
LR: [0.0020475536787131817]
---- EP [1/5] | BTCH [1482/3634] ||| train_loss = 0.01994 ----
LR: [0.002049640727047967]
---- EP [1/5] | BTCH [1483/3634] ||| train_loss = 0.01462 ----
LR: [0.0020517288221902196]
---- EP [1/5] | BTCH [1484/3634] ||| train_loss = 0.01365 ----
LR: [0.002053817963446107]
---- EP [1/5] | BTCH [1485/3634] ||| train_loss = 0.01191 ----
LR: [0.002055908150121445]
---- EP [1/5] | BTCH [1486/3634] ||| train_loss = 0.00978 ----
LR: [0.002057999381521701]
---- EP [1/5] | BTCH [1487/3634] ||| train_loss = 0.01565 ----
LR: [0.002060091656951998]
---- EP [1/5] | BTCH [1488/3634] ||| train_loss = 0.02126 ----
LR: [0.002062184975717111]
---- EP [1/5] | BTCH [1489/3634] ||| train_loss = 0.00943 ----
LR: [0.002064279337121465]
---- EP [1/5] | BTCH [1490/3634] ||| train_loss = 0.00707 ----
LR: [0.0020663747404691454]
---- EP [1/5] | BTCH [1491/3634] ||| train_loss = 0.01010 ----
LR: [0.002068471185063883]
---- EP [1/5] | BTCH [1492/3634] ||| train_loss = 0.00951 ----
LR: [0.002070568670209074]
---- EP [1/5] | BTCH [1493/3634] ||| train_loss = 0.00915 ----
LR: [0.0020726671952077547]
---- EP [1/5] | BTCH [1494/3634] ||| train_loss = 0.00821 ----
LR: [0.002074766759362627]
---- EP [1/5] | BTCH [1495/3634] ||| train_loss = 0.00906 ----
LR: [0.0020768673619760425]
---- EP [1/5] | BTCH [1496/3634] ||| train_loss = 0.01858 ----
LR: [0.002078969002350009]
---- EP [1/5] | BTCH [1497/3634] ||| train_loss = 0.00961 ----
LR: [0.002081071679786191]
---- EP [1/5] | BTCH [1498/3634] ||| train_loss = 0.01125 ----
LR: [0.002083175393585905]
---- EP [1/5] | BTCH [1499/3634] ||| train_loss = 0.01852 ----
LR: [0.0020852801430501257]
---- EP [1/5] | BTCH [1500/3634] ||| train_loss = 0.01624 ----
LR: [0.0020873859274794827]
---- EP [1/5] | BTCH [1501/3634] ||| train_loss = 0.01218 ----
LR: [0.0020894927461742614]
---- EP [1/5] | BTCH [1502/3634] ||| train_loss = 0.01410 ----
LR: [0.0020916005984344035]
---- EP [1/5] | BTCH [1503/3634] ||| train_loss = 0.01435 ----
LR: [0.0020937094835595093]
---- EP [1/5] | BTCH [1504/3634] ||| train_loss = 0.01545 ----
LR: [0.002095819400848834]
---- EP [1/5] | BTCH [1505/3634] ||| train_loss = 0.00931 ----
LR: [0.00209793034960129]
---- EP [1/5] | BTCH [1506/3634] ||| train_loss = 0.00904 ----
LR: [0.002100042329115445]
---- EP [1/5] | BTCH [1507/3634] ||| train_loss = 0.00654 ----
LR: [0.002102155338689531]
---- EP [1/5] | BTCH [1508/3634] ||| train_loss = 0.00907 ----
LR: [0.0021042693776214295]
---- EP [1/5] | BTCH [1509/3634] ||| train_loss = 0.01246 ----
LR: [0.0021063844452086852]
---- EP [1/5] | BTCH [1510/3634] ||| train_loss = 0.01224 ----
LR: [0.002108500540748499]
---- EP [1/5] | BTCH [1511/3634] ||| train_loss = 0.01409 ----
LR: [0.0021106176635377286]
---- EP [1/5] | BTCH [1512/3634] ||| train_loss = 0.00858 ----
LR: [0.0021127358128728967]
---- EP [1/5] | BTCH [1513/3634] ||| train_loss = 0.00711 ----
LR: [0.0021148549880501757]
---- EP [1/5] | BTCH [1514/3634] ||| train_loss = 0.02017 ----
LR: [0.0021169751883654032]
---- EP [1/5] | BTCH [1515/3634] ||| train_loss = 0.01262 ----
LR: [0.0021190964131140803]
---- EP [1/5] | BTCH [1516/3634] ||| train_loss = 0.01263 ----
LR: [0.002121218661591354]
---- EP [1/5] | BTCH [1517/3634] ||| train_loss = 0.01068 ----
LR: [0.0021233419330920454]
---- EP [1/5] | BTCH [1518/3634] ||| train_loss = 0.01239 ----
LR: [0.002125466226910627]
---- EP [1/5] | BTCH [1519/3634] ||| train_loss = 0.01330 ----
LR: [0.002127591542341236]
---- EP [1/5] | BTCH [1520/3634] ||| train_loss = 0.00969 ----
LR: [0.002129717878677665]
---- EP [1/5] | BTCH [1521/3634] ||| train_loss = 0.01503 ----
LR: [0.002131845235213375]
---- EP [1/5] | BTCH [1522/3634] ||| train_loss = 0.01120 ----
LR: [0.0021339736112414836]
---- EP [1/5] | BTCH [1523/3634] ||| train_loss = 0.01087 ----
LR: [0.002136103006054768]
---- EP [1/5] | BTCH [1524/3634] ||| train_loss = 0.00983 ----
LR: [0.002138233418945668]
---- EP [1/5] | BTCH [1525/3634] ||| train_loss = 0.01747 ----
LR: [0.002140364849206289]
---- EP [1/5] | BTCH [1526/3634] ||| train_loss = 0.01078 ----
LR: [0.002142497296128393]
---- EP [1/5] | BTCH [1527/3634] ||| train_loss = 0.01566 ----
LR: [0.002144630759003407]
---- EP [1/5] | BTCH [1528/3634] ||| train_loss = 0.01316 ----
LR: [0.002146765237122419]
---- EP [1/5] | BTCH [1529/3634] ||| train_loss = 0.00720 ----
LR: [0.0021489007297761827]
---- EP [1/5] | BTCH [1530/3634] ||| train_loss = 0.01393 ----
LR: [0.002151037236255109]
---- EP [1/5] | BTCH [1531/3634] ||| train_loss = 0.01167 ----
LR: [0.0021531747558492763]
---- EP [1/5] | BTCH [1532/3634] ||| train_loss = 0.01737 ----
LR: [0.0021553132878484316]
---- EP [1/5] | BTCH [1533/3634] ||| train_loss = 0.01055 ----
LR: [0.0021574528315419714]
---- EP [1/5] | BTCH [1534/3634] ||| train_loss = 0.01075 ----
LR: [0.0021595933862189644]
---- EP [1/5] | BTCH [1535/3634] ||| train_loss = 0.00848 ----
LR: [0.0021617349511681497]
---- EP [1/5] | BTCH [1536/3634] ||| train_loss = 0.01726 ----
LR: [0.0021638775256779177]
---- EP [1/5] | BTCH [1537/3634] ||| train_loss = 0.01048 ----
LR: [0.002166021109036331]
---- EP [1/5] | BTCH [1538/3634] ||| train_loss = 0.01125 ----
LR: [0.002168165700531117]
---- EP [1/5] | BTCH [1539/3634] ||| train_loss = 0.01514 ----
LR: [0.002170311299449666]
---- EP [1/5] | BTCH [1540/3634] ||| train_loss = 0.00959 ----
LR: [0.002172457905079035]
---- EP [1/5] | BTCH [1541/3634] ||| train_loss = 0.00948 ----
LR: [0.0021746055167059433]
---- EP [1/5] | BTCH [1542/3634] ||| train_loss = 0.00588 ----
LR: [0.0021767541336167803]
---- EP [1/5] | BTCH [1543/3634] ||| train_loss = 0.01750 ----
LR: [0.0021789037550976]
---- EP [1/5] | BTCH [1544/3634] ||| train_loss = 0.00797 ----
LR: [0.00218105438043412]
---- EP [1/5] | BTCH [1545/3634] ||| train_loss = 0.00671 ----
LR: [0.0021832060089117273]
---- EP [1/5] | BTCH [1546/3634] ||| train_loss = 0.01746 ----
LR: [0.002185358639815475]
---- EP [1/5] | BTCH [1547/3634] ||| train_loss = 0.01121 ----
LR: [0.002187512272430083]
---- EP [1/5] | BTCH [1548/3634] ||| train_loss = 0.01078 ----
LR: [0.0021896669060399365]
---- EP [1/5] | BTCH [1549/3634] ||| train_loss = 0.01254 ----
LR: [0.0021918225399290914]
---- EP [1/5] | BTCH [1550/3634] ||| train_loss = 0.00544 ----
LR: [0.002193979173381269]
---- EP [1/5] | BTCH [1551/3634] ||| train_loss = 0.01273 ----
LR: [0.0021961368056798583]
---- EP [1/5] | BTCH [1552/3634] ||| train_loss = 0.01438 ----
LR: [0.0021982954361079183]
---- EP [1/5] | BTCH [1553/3634] ||| train_loss = 0.00962 ----
LR: [0.0022004550639481745]
---- EP [1/5] | BTCH [1554/3634] ||| train_loss = 0.01708 ----
LR: [0.0022026156884830195]
---- EP [1/5] | BTCH [1555/3634] ||| train_loss = 0.01529 ----
LR: [0.0022047773089945216]
---- EP [1/5] | BTCH [1556/3634] ||| train_loss = 0.02230 ----
LR: [0.002206939924764408]
---- EP [1/5] | BTCH [1557/3634] ||| train_loss = 0.00718 ----
LR: [0.0022091035350740845]
---- EP [1/5] | BTCH [1558/3634] ||| train_loss = 0.01104 ----
LR: [0.0022112681392046215]
---- EP [1/5] | BTCH [1559/3634] ||| train_loss = 0.01946 ----
LR: [0.0022134337364367587]
---- EP [1/5] | BTCH [1560/3634] ||| train_loss = 0.01501 ----
LR: [0.0022156003260509084]
---- EP [1/5] | BTCH [1561/3634] ||| train_loss = 0.01650 ----
LR: [0.0022177679073271525]
---- EP [1/5] | BTCH [1562/3634] ||| train_loss = 0.00870 ----
LR: [0.0022199364795452417]
---- EP [1/5] | BTCH [1563/3634] ||| train_loss = 0.00867 ----
LR: [0.0022221060419845987]
---- EP [1/5] | BTCH [1564/3634] ||| train_loss = 0.01351 ----
LR: [0.0022242765939243176]
---- EP [1/5] | BTCH [1565/3634] ||| train_loss = 0.00896 ----
LR: [0.002226448134643166]
---- EP [1/5] | BTCH [1566/3634] ||| train_loss = 0.01197 ----
LR: [0.002228620663419575]
---- EP [1/5] | BTCH [1567/3634] ||| train_loss = 0.01421 ----
LR: [0.0022307941795316547]
---- EP [1/5] | BTCH [1568/3634] ||| train_loss = 0.01646 ----
LR: [0.0022329686822571857]
---- EP [1/5] | BTCH [1569/3634] ||| train_loss = 0.01785 ----
LR: [0.0022351441708736196]
---- EP [1/5] | BTCH [1570/3634] ||| train_loss = 0.01042 ----
LR: [0.0022373206446580805]
---- EP [1/5] | BTCH [1571/3634] ||| train_loss = 0.01419 ----
LR: [0.0022394981028873657]
---- EP [1/5] | BTCH [1572/3634] ||| train_loss = 0.01124 ----
LR: [0.002241676544837947]
---- EP [1/5] | BTCH [1573/3634] ||| train_loss = 0.01662 ----
LR: [0.002243855969785963]
---- EP [1/5] | BTCH [1574/3634] ||| train_loss = 0.01115 ----
LR: [0.0022460363770072343]
---- EP [1/5] | BTCH [1575/3634] ||| train_loss = 0.00732 ----
LR: [0.002248217765777249]
---- EP [1/5] | BTCH [1576/3634] ||| train_loss = 0.01675 ----
LR: [0.0022504001353711714]
---- EP [1/5] | BTCH [1577/3634] ||| train_loss = 0.01061 ----
LR: [0.0022525834850638414]
---- EP [1/5] | BTCH [1578/3634] ||| train_loss = 0.01177 ----
LR: [0.0022547678141297666]
---- EP [1/5] | BTCH [1579/3634] ||| train_loss = 0.01033 ----
LR: [0.0022569531218431397]
---- EP [1/5] | BTCH [1580/3634] ||| train_loss = 0.02045 ----
LR: [0.002259139407477819]
---- EP [1/5] | BTCH [1581/3634] ||| train_loss = 0.01647 ----
LR: [0.002261326670307342]
---- EP [1/5] | BTCH [1582/3634] ||| train_loss = 0.00859 ----
LR: [0.0022635149096049195]
---- EP [1/5] | BTCH [1583/3634] ||| train_loss = 0.01338 ----
LR: [0.002265704124643441]
---- EP [1/5] | BTCH [1584/3634] ||| train_loss = 0.01077 ----
LR: [0.0022678943146954697]
---- EP [1/5] | BTCH [1585/3634] ||| train_loss = 0.01134 ----
LR: [0.0022700854790332443]
---- EP [1/5] | BTCH [1586/3634] ||| train_loss = 0.01233 ----
LR: [0.0022722776169286796]
---- EP [1/5] | BTCH [1587/3634] ||| train_loss = 0.01007 ----
LR: [0.0022744707276533714]
---- EP [1/5] | BTCH [1588/3634] ||| train_loss = 0.01230 ----
LR: [0.002276664810478583]
---- EP [1/5] | BTCH [1589/3634] ||| train_loss = 0.00886 ----
LR: [0.0022788598646752657]
---- EP [1/5] | BTCH [1590/3634] ||| train_loss = 0.00515 ----
LR: [0.0022810558895140394]
---- EP [1/5] | BTCH [1591/3634] ||| train_loss = 0.00973 ----
LR: [0.0022832528842652066]
---- EP [1/5] | BTCH [1592/3634] ||| train_loss = 0.01419 ----
LR: [0.0022854508481987444]
---- EP [1/5] | BTCH [1593/3634] ||| train_loss = 0.01016 ----
LR: [0.00228764978058431]
---- EP [1/5] | BTCH [1594/3634] ||| train_loss = 0.00977 ----
LR: [0.002289849680691235]
---- EP [1/5] | BTCH [1595/3634] ||| train_loss = 0.02323 ----
LR: [0.002292050547788537]
---- EP [1/5] | BTCH [1596/3634] ||| train_loss = 0.01389 ----
LR: [0.002294252381144905]
---- EP [1/5] | BTCH [1597/3634] ||| train_loss = 0.00964 ----
LR: [0.0022964551800287083]
---- EP [1/5] | BTCH [1598/3634] ||| train_loss = 0.02090 ----
LR: [0.002298658943707999]
---- EP [1/5] | BTCH [1599/3634] ||| train_loss = 0.01512 ----
LR: [0.0023008636714505065]
---- EP [1/5] | BTCH [1600/3634] ||| train_loss = 0.00805 ----
LR: [0.002303069362523639]
---- EP [1/5] | BTCH [1601/3634] ||| train_loss = 0.00737 ----
LR: [0.0023052760161944826]
---- EP [1/5] | BTCH [1602/3634] ||| train_loss = 0.00831 ----
LR: [0.00230748363172981]
---- EP [1/5] | BTCH [1603/3634] ||| train_loss = 0.01597 ----
LR: [0.0023096922083960672]
---- EP [1/5] | BTCH [1604/3634] ||| train_loss = 0.01820 ----
LR: [0.0023119017454593877]
---- EP [1/5] | BTCH [1605/3634] ||| train_loss = 0.01492 ----
LR: [0.002314112242185578]
---- EP [1/5] | BTCH [1606/3634] ||| train_loss = 0.01078 ----
LR: [0.002316323697840134]
---- EP [1/5] | BTCH [1607/3634] ||| train_loss = 0.01222 ----
LR: [0.002318536111688226]
---- EP [1/5] | BTCH [1608/3634] ||| train_loss = 0.01909 ----
LR: [0.002320749482994709]
---- EP [1/5] | BTCH [1609/3634] ||| train_loss = 0.01739 ----
LR: [0.002322963811024123]
---- EP [1/5] | BTCH [1610/3634] ||| train_loss = 0.00931 ----
LR: [0.002325179095040682]
---- EP [1/5] | BTCH [1611/3634] ||| train_loss = 0.00785 ----
LR: [0.0023273953343082906]
---- EP [1/5] | BTCH [1612/3634] ||| train_loss = 0.01118 ----
LR: [0.0023296125280905314]
---- EP [1/5] | BTCH [1613/3634] ||| train_loss = 0.01427 ----
LR: [0.002331830675650671]
---- EP [1/5] | BTCH [1614/3634] ||| train_loss = 0.01643 ----
LR: [0.0023340497762516597]
---- EP [1/5] | BTCH [1615/3634] ||| train_loss = 0.01467 ----
LR: [0.0023362698291561294]
---- EP [1/5] | BTCH [1616/3634] ||| train_loss = 0.01004 ----
LR: [0.0023384908336263974]
---- EP [1/5] | BTCH [1617/3634] ||| train_loss = 0.00692 ----
LR: [0.002340712788924464]
---- EP [1/5] | BTCH [1618/3634] ||| train_loss = 0.01775 ----
LR: [0.0023429356943120124]
---- EP [1/5] | BTCH [1619/3634] ||| train_loss = 0.01848 ----
LR: [0.002345159549050413]
---- EP [1/5] | BTCH [1620/3634] ||| train_loss = 0.01324 ----
LR: [0.002347384352400718]
---- EP [1/5] | BTCH [1621/3634] ||| train_loss = 0.01726 ----
LR: [0.0023496101036236646]
---- EP [1/5] | BTCH [1622/3634] ||| train_loss = 0.00729 ----
LR: [0.00235183680197968]
---- EP [1/5] | BTCH [1623/3634] ||| train_loss = 0.01568 ----
LR: [0.002354064446728867]
---- EP [1/5] | BTCH [1624/3634] ||| train_loss = 0.01011 ----
LR: [0.002356293037131022]
---- EP [1/5] | BTCH [1625/3634] ||| train_loss = 0.01378 ----
LR: [0.0023585225724456257]
---- EP [1/5] | BTCH [1626/3634] ||| train_loss = 0.01299 ----
LR: [0.0023607530519318427]
---- EP [1/5] | BTCH [1627/3634] ||| train_loss = 0.01689 ----
LR: [0.0023629844748485253]
---- EP [1/5] | BTCH [1628/3634] ||| train_loss = 0.00970 ----
LR: [0.002365216840454212]
---- EP [1/5] | BTCH [1629/3634] ||| train_loss = 0.01277 ----
VAL ||| loss = 0.013522017258392744, psnr = 30.680768966674805, ssim = 0.9068557024002075
LR: [0.0023674501480071266]
---- EP [1/5] | BTCH [1630/3634] ||| train_loss = 0.01339 ----
LR: [0.0023696843967651836]
---- EP [1/5] | BTCH [1631/3634] ||| train_loss = 0.00968 ----
LR: [0.0023719195859859803]
---- EP [1/5] | BTCH [1632/3634] ||| train_loss = 0.01051 ----
LR: [0.002374155714926808]
---- EP [1/5] | BTCH [1633/3634] ||| train_loss = 0.01709 ----
LR: [0.0023763927828446343]
---- EP [1/5] | BTCH [1634/3634] ||| train_loss = 0.01795 ----
LR: [0.0023786307889961285]
---- EP [1/5] | BTCH [1635/3634] ||| train_loss = 0.00939 ----
LR: [0.002380869732637637]
---- EP [1/5] | BTCH [1636/3634] ||| train_loss = 0.01153 ----
LR: [0.002383109613025204]
---- EP [1/5] | BTCH [1637/3634] ||| train_loss = 0.01231 ----
LR: [0.002385350429414552]
---- EP [1/5] | BTCH [1638/3634] ||| train_loss = 0.00973 ----
LR: [0.0023875921810611045]
---- EP [1/5] | BTCH [1639/3634] ||| train_loss = 0.01506 ----
LR: [0.002389834867219963]
---- EP [1/5] | BTCH [1640/3634] ||| train_loss = 0.00964 ----
LR: [0.0023920784871459258]
---- EP [1/5] | BTCH [1641/3634] ||| train_loss = 0.01473 ----
LR: [0.0023943230400934757]
---- EP [1/5] | BTCH [1642/3634] ||| train_loss = 0.00881 ----
LR: [0.0023965685253167935]
---- EP [1/5] | BTCH [1643/3634] ||| train_loss = 0.01117 ----
LR: [0.00239881494206974]
---- EP [1/5] | BTCH [1644/3634] ||| train_loss = 0.01815 ----
LR: [0.0024010622896058747]
---- EP [1/5] | BTCH [1645/3634] ||| train_loss = 0.01619 ----
LR: [0.002403310567178441]
---- EP [1/5] | BTCH [1646/3634] ||| train_loss = 0.01279 ----
LR: [0.002405559774040382]
---- EP [1/5] | BTCH [1647/3634] ||| train_loss = 0.01028 ----
LR: [0.0024078099094443223]
---- EP [1/5] | BTCH [1648/3634] ||| train_loss = 0.01818 ----
LR: [0.0024100609726425857]
---- EP [1/5] | BTCH [1649/3634] ||| train_loss = 0.01307 ----
LR: [0.002412312962887182]
---- EP [1/5] | BTCH [1650/3634] ||| train_loss = 0.01519 ----
LR: [0.0024145658794298176]
---- EP [1/5] | BTCH [1651/3634] ||| train_loss = 0.00830 ----
LR: [0.002416819721521888]
---- EP [1/5] | BTCH [1652/3634] ||| train_loss = 0.01339 ----
LR: [0.0024190744884144827]
---- EP [1/5] | BTCH [1653/3634] ||| train_loss = 0.01286 ----
LR: [0.0024213301793583834]
---- EP [1/5] | BTCH [1654/3634] ||| train_loss = 0.01510 ----
LR: [0.0024235867936040637]
---- EP [1/5] | BTCH [1655/3634] ||| train_loss = 0.00978 ----
LR: [0.002425844330401692]
---- EP [1/5] | BTCH [1656/3634] ||| train_loss = 0.01274 ----
LR: [0.0024281027890011306]
---- EP [1/5] | BTCH [1657/3634] ||| train_loss = 0.01108 ----
LR: [0.0024303621686519337]
---- EP [1/5] | BTCH [1658/3634] ||| train_loss = 0.02046 ----
LR: [0.0024326224686033494]
---- EP [1/5] | BTCH [1659/3634] ||| train_loss = 0.01362 ----
LR: [0.002434883688104323]
---- EP [1/5] | BTCH [1660/3634] ||| train_loss = 0.01057 ----
LR: [0.00243714582640349]
---- EP [1/5] | BTCH [1661/3634] ||| train_loss = 0.01649 ----
LR: [0.0024394088827491833]
---- EP [1/5] | BTCH [1662/3634] ||| train_loss = 0.01005 ----
LR: [0.0024416728563894322]
---- EP [1/5] | BTCH [1663/3634] ||| train_loss = 0.01428 ----
LR: [0.0024439377465719572]
---- EP [1/5] | BTCH [1664/3634] ||| train_loss = 0.01468 ----
LR: [0.0024462035525441746]
---- EP [1/5] | BTCH [1665/3634] ||| train_loss = 0.01001 ----
LR: [0.0024484702735531995]
---- EP [1/5] | BTCH [1666/3634] ||| train_loss = 0.01419 ----
LR: [0.0024507379088458438]
---- EP [1/5] | BTCH [1667/3634] ||| train_loss = 0.01028 ----
LR: [0.0024530064576686102]
---- EP [1/5] | BTCH [1668/3634] ||| train_loss = 0.01151 ----
LR: [0.0024552759192677026]
---- EP [1/5] | BTCH [1669/3634] ||| train_loss = 0.01914 ----
LR: [0.002457546292889019]
---- EP [1/5] | BTCH [1670/3634] ||| train_loss = 0.01117 ----
LR: [0.0024598175777781565]
---- EP [1/5] | BTCH [1671/3634] ||| train_loss = 0.01701 ----
LR: [0.002462089773180405]
---- EP [1/5] | BTCH [1672/3634] ||| train_loss = 0.01332 ----
LR: [0.00246436287834076]
---- EP [1/5] | BTCH [1673/3634] ||| train_loss = 0.00741 ----
LR: [0.0024666368925039053]
---- EP [1/5] | BTCH [1674/3634] ||| train_loss = 0.01235 ----
LR: [0.002468911814914228]
---- EP [1/5] | BTCH [1675/3634] ||| train_loss = 0.00826 ----
LR: [0.002471187644815814]
---- EP [1/5] | BTCH [1676/3634] ||| train_loss = 0.00802 ----
LR: [0.002473464381452446]
---- EP [1/5] | BTCH [1677/3634] ||| train_loss = 0.00918 ----
LR: [0.002475742024067604]
---- EP [1/5] | BTCH [1678/3634] ||| train_loss = 0.01524 ----
LR: [0.00247802057190447]
---- EP [1/5] | BTCH [1679/3634] ||| train_loss = 0.01118 ----
LR: [0.0024803000242059232]
---- EP [1/5] | BTCH [1680/3634] ||| train_loss = 0.01287 ----
LR: [0.002482580380214543]
---- EP [1/5] | BTCH [1681/3634] ||| train_loss = 0.01758 ----
LR: [0.0024848616391726077]
---- EP [1/5] | BTCH [1682/3634] ||| train_loss = 0.01249 ----
LR: [0.0024871438003220957]
---- EP [1/5] | BTCH [1683/3634] ||| train_loss = 0.01746 ----
LR: [0.0024894268629046873]
---- EP [1/5] | BTCH [1684/3634] ||| train_loss = 0.02090 ----
LR: [0.002491710826161761]
---- EP [1/5] | BTCH [1685/3634] ||| train_loss = 0.01669 ----
LR: [0.002493995689334399]
---- EP [1/5] | BTCH [1686/3634] ||| train_loss = 0.00871 ----
LR: [0.00249628145166338]
---- EP [1/5] | BTCH [1687/3634] ||| train_loss = 0.00889 ----
LR: [0.0024985681123891887]
---- EP [1/5] | BTCH [1688/3634] ||| train_loss = 0.01346 ----
LR: [0.0025008556707520075]
---- EP [1/5] | BTCH [1689/3634] ||| train_loss = 0.01148 ----
LR: [0.0025031441259917237]
---- EP [1/5] | BTCH [1690/3634] ||| train_loss = 0.01116 ----
LR: [0.002505433477347923]
---- EP [1/5] | BTCH [1691/3634] ||| train_loss = 0.00771 ----
LR: [0.0025077237240598953]
---- EP [1/5] | BTCH [1692/3634] ||| train_loss = 0.01582 ----
LR: [0.0025100148653666356]
---- EP [1/5] | BTCH [1693/3634] ||| train_loss = 0.01185 ----
LR: [0.0025123069005068364]
---- EP [1/5] | BTCH [1694/3634] ||| train_loss = 0.01009 ----
LR: [0.0025145998287188966]
---- EP [1/5] | BTCH [1695/3634] ||| train_loss = 0.01187 ----
LR: [0.002516893649240917]
---- EP [1/5] | BTCH [1696/3634] ||| train_loss = 0.00958 ----
LR: [0.0025191883613107065]
---- EP [1/5] | BTCH [1697/3634] ||| train_loss = 0.01229 ----
LR: [0.0025214839641657678]
---- EP [1/5] | BTCH [1698/3634] ||| train_loss = 0.01798 ----
LR: [0.002523780457043316]
---- EP [1/5] | BTCH [1699/3634] ||| train_loss = 0.01544 ----
LR: [0.0025260778391802694]
---- EP [1/5] | BTCH [1700/3634] ||| train_loss = 0.00864 ----
LR: [0.0025283761098132476]
---- EP [1/5] | BTCH [1701/3634] ||| train_loss = 0.01606 ----
LR: [0.002530675268178578]
---- EP [1/5] | BTCH [1702/3634] ||| train_loss = 0.01003 ----
LR: [0.0025329753135122906]
---- EP [1/5] | BTCH [1703/3634] ||| train_loss = 0.00856 ----
LR: [0.002535276245050124]
---- EP [1/5] | BTCH [1704/3634] ||| train_loss = 0.01240 ----
LR: [0.0025375780620275163]
---- EP [1/5] | BTCH [1705/3634] ||| train_loss = 0.01744 ----
LR: [0.002539880763679619]
---- EP [1/5] | BTCH [1706/3634] ||| train_loss = 0.00855 ----
LR: [0.0025421843492412855]
---- EP [1/5] | BTCH [1707/3634] ||| train_loss = 0.01186 ----
LR: [0.002544488817947073]
---- EP [1/5] | BTCH [1708/3634] ||| train_loss = 0.01881 ----
LR: [0.0025467941690312523]
---- EP [1/5] | BTCH [1709/3634] ||| train_loss = 0.01089 ----
LR: [0.0025491004017277955]
---- EP [1/5] | BTCH [1710/3634] ||| train_loss = 0.00667 ----
LR: [0.0025514075152703805]
---- EP [1/5] | BTCH [1711/3634] ||| train_loss = 0.01127 ----
LR: [0.0025537155088923976]
---- EP [1/5] | BTCH [1712/3634] ||| train_loss = 0.01118 ----
LR: [0.002556024381826943]
---- EP [1/5] | BTCH [1713/3634] ||| train_loss = 0.01487 ----
LR: [0.0025583341333068185]
---- EP [1/5] | BTCH [1714/3634] ||| train_loss = 0.00691 ----
LR: [0.002560644762564534]
---- EP [1/5] | BTCH [1715/3634] ||| train_loss = 0.00883 ----
LR: [0.0025629562688323122]
---- EP [1/5] | BTCH [1716/3634] ||| train_loss = 0.01748 ----
LR: [0.0025652686513420817]
---- EP [1/5] | BTCH [1717/3634] ||| train_loss = 0.01130 ----
LR: [0.0025675819093254745]
---- EP [1/5] | BTCH [1718/3634] ||| train_loss = 0.01674 ----
LR: [0.0025698960420138424]
---- EP [1/5] | BTCH [1719/3634] ||| train_loss = 0.00513 ----
LR: [0.002572211048638237]
---- EP [1/5] | BTCH [1720/3634] ||| train_loss = 0.01170 ----
LR: [0.002574526928429425]
---- EP [1/5] | BTCH [1721/3634] ||| train_loss = 0.01028 ----
LR: [0.002576843680617883]
---- EP [1/5] | BTCH [1722/3634] ||| train_loss = 0.01037 ----
LR: [0.0025791613044337932]
---- EP [1/5] | BTCH [1723/3634] ||| train_loss = 0.01169 ----
LR: [0.0025814797991070525]
---- EP [1/5] | BTCH [1724/3634] ||| train_loss = 0.01202 ----
LR: [0.0025837991638672673]
---- EP [1/5] | BTCH [1725/3634] ||| train_loss = 0.00731 ----
LR: [0.002586119397943754]
---- EP [1/5] | BTCH [1726/3634] ||| train_loss = 0.01162 ----
LR: [0.0025884405005655413]
---- EP [1/5] | BTCH [1727/3634] ||| train_loss = 0.01329 ----
LR: [0.002590762470961368]
---- EP [1/5] | BTCH [1728/3634] ||| train_loss = 0.01229 ----
LR: [0.002593085308359685]
---- EP [1/5] | BTCH [1729/3634] ||| train_loss = 0.01114 ----
LR: [0.0025954090119886574]
---- EP [1/5] | BTCH [1730/3634] ||| train_loss = 0.00956 ----
LR: [0.002597733581076158]
---- EP [1/5] | BTCH [1731/3634] ||| train_loss = 0.01819 ----
LR: [0.002600059014849775]
---- EP [1/5] | BTCH [1732/3634] ||| train_loss = 0.00765 ----
LR: [0.002602385312536812]
---- EP [1/5] | BTCH [1733/3634] ||| train_loss = 0.00555 ----
LR: [0.002604712473364277]
---- EP [1/5] | BTCH [1734/3634] ||| train_loss = 0.01006 ----
LR: [0.0026070404965589005]
---- EP [1/5] | BTCH [1735/3634] ||| train_loss = 0.01064 ----
LR: [0.002609369381347121]
---- EP [1/5] | BTCH [1736/3634] ||| train_loss = 0.00707 ----
LR: [0.0026116991269550917]
---- EP [1/5] | BTCH [1737/3634] ||| train_loss = 0.01159 ----
LR: [0.0026140297326086807]
---- EP [1/5] | BTCH [1738/3634] ||| train_loss = 0.01949 ----
LR: [0.0026163611975334707]
---- EP [1/5] | BTCH [1739/3634] ||| train_loss = 0.01291 ----
LR: [0.002618693520954757]
---- EP [1/5] | BTCH [1740/3634] ||| train_loss = 0.01378 ----
LR: [0.0026210267020975514]
---- EP [1/5] | BTCH [1741/3634] ||| train_loss = 0.01266 ----
LR: [0.0026233607401865786]
---- EP [1/5] | BTCH [1742/3634] ||| train_loss = 0.02134 ----
LR: [0.002625695634446282]
---- EP [1/5] | BTCH [1743/3634] ||| train_loss = 0.00808 ----
LR: [0.0026280313841008157]
---- EP [1/5] | BTCH [1744/3634] ||| train_loss = 0.01490 ----
LR: [0.002630367988374055]
---- EP [1/5] | BTCH [1745/3634] ||| train_loss = 0.00965 ----
LR: [0.0026327054464895857]
---- EP [1/5] | BTCH [1746/3634] ||| train_loss = 0.01073 ----
LR: [0.002635043757670716]
---- EP [1/5] | BTCH [1747/3634] ||| train_loss = 0.00858 ----
LR: [0.002637382921140465]
---- EP [1/5] | BTCH [1748/3634] ||| train_loss = 0.01440 ----
LR: [0.0026397229361215723]
---- EP [1/5] | BTCH [1749/3634] ||| train_loss = 0.01278 ----
LR: [0.0026420638018364914]
---- EP [1/5] | BTCH [1750/3634] ||| train_loss = 0.00799 ----
LR: [0.002644405517507397]
---- EP [1/5] | BTCH [1751/3634] ||| train_loss = 0.01665 ----
LR: [0.0026467480823561774]
---- EP [1/5] | BTCH [1752/3634] ||| train_loss = 0.00678 ----
LR: [0.002649091495604444]
---- EP [1/5] | BTCH [1753/3634] ||| train_loss = 0.01753 ----
LR: [0.002651435756473518]
---- EP [1/5] | BTCH [1754/3634] ||| train_loss = 0.00852 ----
LR: [0.002653780864184446]
---- EP [1/5] | BTCH [1755/3634] ||| train_loss = 0.01150 ----
LR: [0.0026561268179579912]
---- EP [1/5] | BTCH [1756/3634] ||| train_loss = 0.01760 ----
LR: [0.002658473617014638]
---- EP [1/5] | BTCH [1757/3634] ||| train_loss = 0.00759 ----
LR: [0.0026608212605745843]
---- EP [1/5] | BTCH [1758/3634] ||| train_loss = 0.00510 ----
LR: [0.0026631697478577505]
---- EP [1/5] | BTCH [1759/3634] ||| train_loss = 0.01117 ----
LR: [0.002665519078083779]
---- EP [1/5] | BTCH [1760/3634] ||| train_loss = 0.00844 ----
LR: [0.0026678692504720275]
---- EP [1/5] | BTCH [1761/3634] ||| train_loss = 0.01683 ----
LR: [0.0026702202642415775]
---- EP [1/5] | BTCH [1762/3634] ||| train_loss = 0.00743 ----
LR: [0.002672572118611231]
---- EP [1/5] | BTCH [1763/3634] ||| train_loss = 0.01512 ----
LR: [0.002674924812799505]
---- EP [1/5] | BTCH [1764/3634] ||| train_loss = 0.00848 ----
LR: [0.0026772783460246447]
---- EP [1/5] | BTCH [1765/3634] ||| train_loss = 0.01405 ----
LR: [0.0026796327175046125]
---- EP [1/5] | BTCH [1766/3634] ||| train_loss = 0.01703 ----
LR: [0.0026819879264570953]
---- EP [1/5] | BTCH [1767/3634] ||| train_loss = 0.01265 ----
LR: [0.0026843439720994977]
---- EP [1/5] | BTCH [1768/3634] ||| train_loss = 0.01903 ----
LR: [0.0026867008536489495]
---- EP [1/5] | BTCH [1769/3634] ||| train_loss = 0.01866 ----
LR: [0.0026890585703223]
---- EP [1/5] | BTCH [1770/3634] ||| train_loss = 0.02060 ----
LR: [0.002691417121336124]
---- EP [1/5] | BTCH [1771/3634] ||| train_loss = 0.01338 ----
LR: [0.002693776505906717]
---- EP [1/5] | BTCH [1772/3634] ||| train_loss = 0.01203 ----
LR: [0.0026961367232500987]
---- EP [1/5] | BTCH [1773/3634] ||| train_loss = 0.02499 ----
LR: [0.0026984977725820107]
---- EP [1/5] | BTCH [1774/3634] ||| train_loss = 0.01606 ----
LR: [0.002700859653117918]
---- EP [1/5] | BTCH [1775/3634] ||| train_loss = 0.01890 ----
LR: [0.002703222364073013]
---- EP [1/5] | BTCH [1776/3634] ||| train_loss = 0.00789 ----
LR: [0.0027055859046622097]
---- EP [1/5] | BTCH [1777/3634] ||| train_loss = 0.01150 ----
LR: [0.0027079502741001434]
---- EP [1/5] | BTCH [1778/3634] ||| train_loss = 0.01063 ----
LR: [0.002710315471601178]
---- EP [1/5] | BTCH [1779/3634] ||| train_loss = 0.01249 ----
LR: [0.002712681496379401]
---- EP [1/5] | BTCH [1780/3634] ||| train_loss = 0.00968 ----
LR: [0.0027150483476486263]
---- EP [1/5] | BTCH [1781/3634] ||| train_loss = 0.01932 ----
LR: [0.0027174160246223895]
---- EP [1/5] | BTCH [1782/3634] ||| train_loss = 0.00868 ----
LR: [0.0027197845265139586]
---- EP [1/5] | BTCH [1783/3634] ||| train_loss = 0.01624 ----
LR: [0.00272215385253632]
---- EP [1/5] | BTCH [1784/3634] ||| train_loss = 0.01160 ----
LR: [0.0027245240019021875]
---- EP [1/5] | BTCH [1785/3634] ||| train_loss = 0.01095 ----
LR: [0.002726894973824007]
---- EP [1/5] | BTCH [1786/3634] ||| train_loss = 0.01291 ----
LR: [0.0027292667675139475]
---- EP [1/5] | BTCH [1787/3634] ||| train_loss = 0.01257 ----
LR: [0.0027316393821839027]
---- EP [1/5] | BTCH [1788/3634] ||| train_loss = 0.01208 ----
LR: [0.0027340128170454964]
---- EP [1/5] | BTCH [1789/3634] ||| train_loss = 0.01841 ----
LR: [0.0027363870713100783]
---- EP [1/5] | BTCH [1790/3634] ||| train_loss = 0.01189 ----
LR: [0.0027387621441887283]
---- EP [1/5] | BTCH [1791/3634] ||| train_loss = 0.01562 ----
LR: [0.002741138034892251]
---- EP [1/5] | BTCH [1792/3634] ||| train_loss = 0.00914 ----
LR: [0.002743514742631183]
---- EP [1/5] | BTCH [1793/3634] ||| train_loss = 0.02218 ----
LR: [0.0027458922666157848]
---- EP [1/5] | BTCH [1794/3634] ||| train_loss = 0.01557 ----
LR: [0.002748270606056049]
---- EP [1/5] | BTCH [1795/3634] ||| train_loss = 0.01473 ----
LR: [0.002750649760161695]
---- EP [1/5] | BTCH [1796/3634] ||| train_loss = 0.00657 ----
LR: [0.0027530297281421773]
---- EP [1/5] | BTCH [1797/3634] ||| train_loss = 0.01750 ----
LR: [0.0027554105092066706]
---- EP [1/5] | BTCH [1798/3634] ||| train_loss = 0.00761 ----
LR: [0.002757792102564087]
---- EP [1/5] | BTCH [1799/3634] ||| train_loss = 0.00970 ----
LR: [0.002760174507423065]
---- EP [1/5] | BTCH [1800/3634] ||| train_loss = 0.01404 ----
LR: [0.002762557722991975]
---- EP [1/5] | BTCH [1801/3634] ||| train_loss = 0.00767 ----
LR: [0.0027649417484789185]
---- EP [1/5] | BTCH [1802/3634] ||| train_loss = 0.01020 ----
LR: [0.0027673265830917247]
---- EP [1/5] | BTCH [1803/3634] ||| train_loss = 0.01472 ----
LR: [0.002769712226037958]
---- EP [1/5] | BTCH [1804/3634] ||| train_loss = 0.01233 ----
LR: [0.0027720986765249096]
---- EP [1/5] | BTCH [1805/3634] ||| train_loss = 0.00914 ----
LR: [0.002774485933759609]
---- EP [1/5] | BTCH [1806/3634] ||| train_loss = 0.00971 ----
LR: [0.0027768739969488126]
---- EP [1/5] | BTCH [1807/3634] ||| train_loss = 0.01576 ----
LR: [0.002779262865299008]
---- EP [1/5] | BTCH [1808/3634] ||| train_loss = 0.01603 ----
LR: [0.0027816525380164187]
---- EP [1/5] | BTCH [1809/3634] ||| train_loss = 0.00933 ----
LR: [0.0027840430143070017]
---- EP [1/5] | BTCH [1810/3634] ||| train_loss = 0.01330 ----
VAL ||| loss = 0.013565653715532264, psnr = 30.696475982666016, ssim = 0.9070406556129456
LR: [0.002786434293376441]
---- EP [1/5] | BTCH [1811/3634] ||| train_loss = 0.01645 ----
LR: [0.002788826374430161]
---- EP [1/5] | BTCH [1812/3634] ||| train_loss = 0.01515 ----
LR: [0.0027912192566733156]
---- EP [1/5] | BTCH [1813/3634] ||| train_loss = 0.00818 ----
LR: [0.0027936129393107915]
---- EP [1/5] | BTCH [1814/3634] ||| train_loss = 0.00894 ----
LR: [0.0027960074215472117]
---- EP [1/5] | BTCH [1815/3634] ||| train_loss = 0.01067 ----
LR: [0.002798402702586935]
---- EP [1/5] | BTCH [1816/3634] ||| train_loss = 0.01573 ----
LR: [0.002800798781634053]
---- EP [1/5] | BTCH [1817/3634] ||| train_loss = 0.01478 ----
LR: [0.0028031956578923878]
---- EP [1/5] | BTCH [1818/3634] ||| train_loss = 0.01070 ----
LR: [0.002805593330565505]
---- EP [1/5] | BTCH [1819/3634] ||| train_loss = 0.01485 ----
LR: [0.0028079917988566997]
---- EP [1/5] | BTCH [1820/3634] ||| train_loss = 0.01795 ----
LR: [0.0028103910619690035]
---- EP [1/5] | BTCH [1821/3634] ||| train_loss = 0.01640 ----
LR: [0.002812791119105186]
---- EP [1/5] | BTCH [1822/3634] ||| train_loss = 0.01580 ----
LR: [0.0028151919694677525]
---- EP [1/5] | BTCH [1823/3634] ||| train_loss = 0.00919 ----
LR: [0.002817593612258939]
---- EP [1/5] | BTCH [1824/3634] ||| train_loss = 0.01384 ----
LR: [0.0028199960466807287]
---- EP [1/5] | BTCH [1825/3634] ||| train_loss = 0.01848 ----
LR: [0.002822399271934833]
---- EP [1/5] | BTCH [1826/3634] ||| train_loss = 0.01436 ----
LR: [0.002824803287222704]
---- EP [1/5] | BTCH [1827/3634] ||| train_loss = 0.01664 ----
LR: [0.0028272080917455308]
---- EP [1/5] | BTCH [1828/3634] ||| train_loss = 0.01495 ----
LR: [0.002829613684704241]
---- EP [1/5] | BTCH [1829/3634] ||| train_loss = 0.01022 ----
LR: [0.0028320200652994978]
---- EP [1/5] | BTCH [1830/3634] ||| train_loss = 0.00684 ----
LR: [0.0028344272327317068]
---- EP [1/5] | BTCH [1831/3634] ||| train_loss = 0.02357 ----
LR: [0.002836835186201009]
---- EP [1/5] | BTCH [1832/3634] ||| train_loss = 0.01703 ----
LR: [0.0028392439249072844]
---- EP [1/5] | BTCH [1833/3634] ||| train_loss = 0.00925 ----
LR: [0.002841653448050151]
---- EP [1/5] | BTCH [1834/3634] ||| train_loss = 0.01338 ----
LR: [0.00284406375482897]
---- EP [1/5] | BTCH [1835/3634] ||| train_loss = 0.00837 ----
LR: [0.00284647484444284]
---- EP [1/5] | BTCH [1836/3634] ||| train_loss = 0.00705 ----
LR: [0.002848886716090601]
---- EP [1/5] | BTCH [1837/3634] ||| train_loss = 0.01225 ----
LR: [0.0028512993689708294]
---- EP [1/5] | BTCH [1838/3634] ||| train_loss = 0.00879 ----
LR: [0.002853712802281842]
---- EP [1/5] | BTCH [1839/3634] ||| train_loss = 0.01795 ----
LR: [0.0028561270152217023]
---- EP [1/5] | BTCH [1840/3634] ||| train_loss = 0.01491 ----
LR: [0.0028585420069882107]
---- EP [1/5] | BTCH [1841/3634] ||| train_loss = 0.00749 ----
LR: [0.002860957776778906]
---- EP [1/5] | BTCH [1842/3634] ||| train_loss = 0.01292 ----
LR: [0.0028633743237910757]
---- EP [1/5] | BTCH [1843/3634] ||| train_loss = 0.01670 ----
LR: [0.002865791647221741]
---- EP [1/5] | BTCH [1844/3634] ||| train_loss = 0.01934 ----
LR: [0.002868209746267672]
---- EP [1/5] | BTCH [1845/3634] ||| train_loss = 0.01217 ----
LR: [0.0028706286201253765]
---- EP [1/5] | BTCH [1846/3634] ||| train_loss = 0.00722 ----
LR: [0.002873048267991107]
---- EP [1/5] | BTCH [1847/3634] ||| train_loss = 0.01377 ----
LR: [0.0028754686890608587]
---- EP [1/5] | BTCH [1848/3634] ||| train_loss = 0.01618 ----
LR: [0.002877889882530368]
---- EP [1/5] | BTCH [1849/3634] ||| train_loss = 0.01274 ----
LR: [0.0028803118475951156]
---- EP [1/5] | BTCH [1850/3634] ||| train_loss = 0.01510 ----
LR: [0.0028827345834503294]
---- EP [1/5] | BTCH [1851/3634] ||| train_loss = 0.00898 ----
LR: [0.0028851580892909744]
---- EP [1/5] | BTCH [1852/3634] ||| train_loss = 0.02296 ----
LR: [0.002887582364311766]
---- EP [1/5] | BTCH [1853/3634] ||| train_loss = 0.00586 ----
LR: [0.0028900074077071597]
---- EP [1/5] | BTCH [1854/3634] ||| train_loss = 0.01076 ----
LR: [0.0028924332186713586]
---- EP [1/5] | BTCH [1855/3634] ||| train_loss = 0.00859 ----
LR: [0.0028948597963983098]
---- EP [1/5] | BTCH [1856/3634] ||| train_loss = 0.01187 ----
LR: [0.002897287140081705]
---- EP [1/5] | BTCH [1857/3634] ||| train_loss = 0.01346 ----
LR: [0.0028997152489149804]
---- EP [1/5] | BTCH [1858/3634] ||| train_loss = 0.01288 ----
LR: [0.002902144122091321]
---- EP [1/5] | BTCH [1859/3634] ||| train_loss = 0.01084 ----
LR: [0.002904573758803655]
---- EP [1/5] | BTCH [1860/3634] ||| train_loss = 0.00978 ----
LR: [0.002907004158244659]
---- EP [1/5] | BTCH [1861/3634] ||| train_loss = 0.01554 ----
LR: [0.0029094353196067544]
---- EP [1/5] | BTCH [1862/3634] ||| train_loss = 0.01325 ----
LR: [0.00291186724208211]
---- EP [1/5] | BTCH [1863/3634] ||| train_loss = 0.01350 ----
LR: [0.0029142999248626417]
---- EP [1/5] | BTCH [1864/3634] ||| train_loss = 0.01272 ----
LR: [0.002916733367140015]
---- EP [1/5] | BTCH [1865/3634] ||| train_loss = 0.01396 ----
LR: [0.0029191675681056383]
---- EP [1/5] | BTCH [1866/3634] ||| train_loss = 0.01125 ----
LR: [0.0029216025269506746]
---- EP [1/5] | BTCH [1867/3634] ||| train_loss = 0.00745 ----
LR: [0.0029240382428660254]
---- EP [1/5] | BTCH [1868/3634] ||| train_loss = 0.00956 ----
LR: [0.00292647471504235]
---- EP [1/5] | BTCH [1869/3634] ||| train_loss = 0.01266 ----
LR: [0.0029289119426700533]
---- EP [1/5] | BTCH [1870/3634] ||| train_loss = 0.00867 ----
LR: [0.0029313499249392855]
---- EP [1/5] | BTCH [1871/3634] ||| train_loss = 0.01186 ----
LR: [0.0029337886610399525]
---- EP [1/5] | BTCH [1872/3634] ||| train_loss = 0.01017 ----
LR: [0.002936228150161704]
---- EP [1/5] | BTCH [1873/3634] ||| train_loss = 0.01409 ----
LR: [0.0029386683914939425]
---- EP [1/5] | BTCH [1874/3634] ||| train_loss = 0.02115 ----
LR: [0.0029411093842258203]
---- EP [1/5] | BTCH [1875/3634] ||| train_loss = 0.00769 ----
LR: [0.002943551127546239]
---- EP [1/5] | BTCH [1876/3634] ||| train_loss = 0.01171 ----
LR: [0.0029459936206438523]
---- EP [1/5] | BTCH [1877/3634] ||| train_loss = 0.01077 ----
LR: [0.0029484368627070634]
---- EP [1/5] | BTCH [1878/3634] ||| train_loss = 0.01100 ----
LR: [0.002950880852924026]
---- EP [1/5] | BTCH [1879/3634] ||| train_loss = 0.00973 ----
LR: [0.0029533255904826486]
---- EP [1/5] | BTCH [1880/3634] ||| train_loss = 0.01186 ----
LR: [0.002955771074570586]
---- EP [1/5] | BTCH [1881/3634] ||| train_loss = 0.01370 ----
LR: [0.0029582173043752524]
---- EP [1/5] | BTCH [1882/3634] ||| train_loss = 0.01018 ----
LR: [0.0029606642790838047]
---- EP [1/5] | BTCH [1883/3634] ||| train_loss = 0.01064 ----
LR: [0.0029631119978831616]
---- EP [1/5] | BTCH [1884/3634] ||| train_loss = 0.00993 ----
LR: [0.0029655604599599875]
---- EP [1/5] | BTCH [1885/3634] ||| train_loss = 0.02158 ----
LR: [0.002968009664500705]
---- EP [1/5] | BTCH [1886/3634] ||| train_loss = 0.01063 ----
LR: [0.002970459610691487]
---- EP [1/5] | BTCH [1887/3634] ||| train_loss = 0.01423 ----
LR: [0.0029729102977182585]
---- EP [1/5] | BTCH [1888/3634] ||| train_loss = 0.01103 ----
LR: [0.0029753617247667025]
---- EP [1/5] | BTCH [1889/3634] ||| train_loss = 0.01600 ----
LR: [0.0029778138910222553]
---- EP [1/5] | BTCH [1890/3634] ||| train_loss = 0.00783 ----
LR: [0.0029802667956701032]
---- EP [1/5] | BTCH [1891/3634] ||| train_loss = 0.00852 ----
LR: [0.0029827204378951927]
---- EP [1/5] | BTCH [1892/3634] ||| train_loss = 0.00614 ----
LR: [0.0029851748168822217]
---- EP [1/5] | BTCH [1893/3634] ||| train_loss = 0.00942 ----
LR: [0.002987629931815646]
---- EP [1/5] | BTCH [1894/3634] ||| train_loss = 0.01609 ----
LR: [0.002990085781879673]
---- EP [1/5] | BTCH [1895/3634] ||| train_loss = 0.01194 ----
LR: [0.0029925423662582685]
---- EP [1/5] | BTCH [1896/3634] ||| train_loss = 0.01172 ----
LR: [0.0029949996841351556]
---- EP [1/5] | BTCH [1897/3634] ||| train_loss = 0.01122 ----
LR: [0.0029974577346938104]
---- EP [1/5] | BTCH [1898/3634] ||| train_loss = 0.02042 ----
LR: [0.002999916517117467]
---- EP [1/5] | BTCH [1899/3634] ||| train_loss = 0.01661 ----
LR: [0.0030023760305891182]
---- EP [1/5] | BTCH [1900/3634] ||| train_loss = 0.01818 ----
LR: [0.00300483627429151]
---- EP [1/5] | BTCH [1901/3634] ||| train_loss = 0.01568 ----
LR: [0.0030072972474071494]
---- EP [1/5] | BTCH [1902/3634] ||| train_loss = 0.01694 ----
LR: [0.0030097589491182982]
---- EP [1/5] | BTCH [1903/3634] ||| train_loss = 0.00965 ----
LR: [0.003012221378606978]
---- EP [1/5] | BTCH [1904/3634] ||| train_loss = 0.00909 ----
LR: [0.0030146845350549683]
---- EP [1/5] | BTCH [1905/3634] ||| train_loss = 0.01435 ----
LR: [0.0030171484176438074]
---- EP [1/5] | BTCH [1906/3634] ||| train_loss = 0.01025 ----
LR: [0.003019613025554791]
---- EP [1/5] | BTCH [1907/3634] ||| train_loss = 0.01028 ----
LR: [0.003022078357968973]
---- EP [1/5] | BTCH [1908/3634] ||| train_loss = 0.01043 ----
LR: [0.0030245444140671674]
---- EP [1/5] | BTCH [1909/3634] ||| train_loss = 0.02122 ----
LR: [0.0030270111930299527]
---- EP [1/5] | BTCH [1910/3634] ||| train_loss = 0.02121 ----
LR: [0.0030294786940376593]
---- EP [1/5] | BTCH [1911/3634] ||| train_loss = 0.02273 ----
LR: [0.0030319469162703814]
---- EP [1/5] | BTCH [1912/3634] ||| train_loss = 0.01147 ----
LR: [0.0030344158589079746]
---- EP [1/5] | BTCH [1913/3634] ||| train_loss = 0.01731 ----
LR: [0.0030368855211300528]
---- EP [1/5] | BTCH [1914/3634] ||| train_loss = 0.01122 ----
LR: [0.0030393559021159927]
---- EP [1/5] | BTCH [1915/3634] ||| train_loss = 0.01078 ----
LR: [0.00304182700104493]
---- EP [1/5] | BTCH [1916/3634] ||| train_loss = 0.00807 ----
LR: [0.003044298817095767]
---- EP [1/5] | BTCH [1917/3634] ||| train_loss = 0.00959 ----
LR: [0.0030467713494471563]
---- EP [1/5] | BTCH [1918/3634] ||| train_loss = 0.00985 ----
LR: [0.003049244597277528]
---- EP [1/5] | BTCH [1919/3634] ||| train_loss = 0.01900 ----
LR: [0.0030517185597650626]
---- EP [1/5] | BTCH [1920/3634] ||| train_loss = 0.00841 ----
LR: [0.0030541932360877077]
---- EP [1/5] | BTCH [1921/3634] ||| train_loss = 0.01105 ----
LR: [0.0030566686254231736]
---- EP [1/5] | BTCH [1922/3634] ||| train_loss = 0.01189 ----
LR: [0.0030591447269489314]
---- EP [1/5] | BTCH [1923/3634] ||| train_loss = 0.01897 ----
LR: [0.003061621539842219]
---- EP [1/5] | BTCH [1924/3634] ||| train_loss = 0.01203 ----
LR: [0.0030640990632800347]
---- EP [1/5] | BTCH [1925/3634] ||| train_loss = 0.00583 ----
LR: [0.003066577296439145]
---- EP [1/5] | BTCH [1926/3634] ||| train_loss = 0.01388 ----
LR: [0.0030690562384960767]
---- EP [1/5] | BTCH [1927/3634] ||| train_loss = 0.01213 ----
LR: [0.0030715358886271183]
---- EP [1/5] | BTCH [1928/3634] ||| train_loss = 0.01480 ----
LR: [0.0030740162460083324]
---- EP [1/5] | BTCH [1929/3634] ||| train_loss = 0.01946 ----
LR: [0.0030764973098155396]
---- EP [1/5] | BTCH [1930/3634] ||| train_loss = 0.01102 ----
LR: [0.003078979079224326]
---- EP [1/5] | BTCH [1931/3634] ||| train_loss = 0.00774 ----
LR: [0.0030814615534100432]
---- EP [1/5] | BTCH [1932/3634] ||| train_loss = 0.00739 ----
LR: [0.003083944731547812]
---- EP [1/5] | BTCH [1933/3634] ||| train_loss = 0.00752 ----
LR: [0.0030864286128125164]
---- EP [1/5] | BTCH [1934/3634] ||| train_loss = 0.01454 ----
LR: [0.0030889131963788077]
---- EP [1/5] | BTCH [1935/3634] ||| train_loss = 0.01227 ----
LR: [0.0030913984814211048]
---- EP [1/5] | BTCH [1936/3634] ||| train_loss = 0.01266 ----
LR: [0.0030938844671135925]
---- EP [1/5] | BTCH [1937/3634] ||| train_loss = 0.01357 ----
LR: [0.003096371152630218]
---- EP [1/5] | BTCH [1938/3634] ||| train_loss = 0.00612 ----
LR: [0.003098858537144706]
---- EP [1/5] | BTCH [1939/3634] ||| train_loss = 0.00683 ----
LR: [0.0031013466198305424]
---- EP [1/5] | BTCH [1940/3634] ||| train_loss = 0.00742 ----
LR: [0.0031038353998609804]
---- EP [1/5] | BTCH [1941/3634] ||| train_loss = 0.00591 ----
LR: [0.0031063248764090457]
---- EP [1/5] | BTCH [1942/3634] ||| train_loss = 0.00928 ----
LR: [0.003108815048647528]
---- EP [1/5] | BTCH [1943/3634] ||| train_loss = 0.01049 ----
LR: [0.0031113059157489888]
---- EP [1/5] | BTCH [1944/3634] ||| train_loss = 0.01872 ----
LR: [0.003113797476885759]
---- EP [1/5] | BTCH [1945/3634] ||| train_loss = 0.00698 ----
LR: [0.0031162897312299364]
---- EP [1/5] | BTCH [1946/3634] ||| train_loss = 0.01231 ----
LR: [0.0031187826779533927]
---- EP [1/5] | BTCH [1947/3634] ||| train_loss = 0.00643 ----
LR: [0.003121276316227762]
---- EP [1/5] | BTCH [1948/3634] ||| train_loss = 0.00756 ----
LR: [0.003123770645224457]
---- EP [1/5] | BTCH [1949/3634] ||| train_loss = 0.00997 ----
LR: [0.003126265664114657]
---- EP [1/5] | BTCH [1950/3634] ||| train_loss = 0.01423 ----
LR: [0.003128761372069312]
---- EP [1/5] | BTCH [1951/3634] ||| train_loss = 0.01671 ----
LR: [0.0031312577682591413]
---- EP [1/5] | BTCH [1952/3634] ||| train_loss = 0.01231 ----
LR: [0.0031337548518546397]
---- EP [1/5] | BTCH [1953/3634] ||| train_loss = 0.01183 ----
LR: [0.0031362526220260704]
---- EP [1/5] | BTCH [1954/3634] ||| train_loss = 0.01309 ----
LR: [0.0031387510779434706]
---- EP [1/5] | BTCH [1955/3634] ||| train_loss = 0.01014 ----
LR: [0.003141250218776648]
---- EP [1/5] | BTCH [1956/3634] ||| train_loss = 0.01277 ----
LR: [0.0031437500436951836]
---- EP [1/5] | BTCH [1957/3634] ||| train_loss = 0.01140 ----
LR: [0.0031462505518684283]
---- EP [1/5] | BTCH [1958/3634] ||| train_loss = 0.01496 ----
LR: [0.003148751742465512]
---- EP [1/5] | BTCH [1959/3634] ||| train_loss = 0.00899 ----
LR: [0.0031512536146553333]
---- EP [1/5] | BTCH [1960/3634] ||| train_loss = 0.01577 ----
LR: [0.003153756167606564]
---- EP [1/5] | BTCH [1961/3634] ||| train_loss = 0.01326 ----
LR: [0.0031562594004876507]
---- EP [1/5] | BTCH [1962/3634] ||| train_loss = 0.00962 ----
LR: [0.0031587633124668156]
---- EP [1/5] | BTCH [1963/3634] ||| train_loss = 0.01503 ----
LR: [0.003161267902712054]
---- EP [1/5] | BTCH [1964/3634] ||| train_loss = 0.01163 ----
LR: [0.003163773170391135]
---- EP [1/5] | BTCH [1965/3634] ||| train_loss = 0.01303 ----
LR: [0.003166279114671605]
---- EP [1/5] | BTCH [1966/3634] ||| train_loss = 0.00986 ----
LR: [0.003168785734720781]
---- EP [1/5] | BTCH [1967/3634] ||| train_loss = 0.01324 ----
LR: [0.0031712930297057617]
---- EP [1/5] | BTCH [1968/3634] ||| train_loss = 0.01026 ----
LR: [0.003173800998793416]
---- EP [1/5] | BTCH [1969/3634] ||| train_loss = 0.00825 ----
LR: [0.0031763096411503936]
---- EP [1/5] | BTCH [1970/3634] ||| train_loss = 0.01259 ----
LR: [0.0031788189559431145]
---- EP [1/5] | BTCH [1971/3634] ||| train_loss = 0.01698 ----
LR: [0.0031813289423377814]
---- EP [1/5] | BTCH [1972/3634] ||| train_loss = 0.00789 ----
LR: [0.003183839599500371]
---- EP [1/5] | BTCH [1973/3634] ||| train_loss = 0.00902 ----
LR: [0.0031863509265966355]
---- EP [1/5] | BTCH [1974/3634] ||| train_loss = 0.00747 ----
LR: [0.0031888629227921064]
---- EP [1/5] | BTCH [1975/3634] ||| train_loss = 0.01360 ----
LR: [0.0031913755872520965]
---- EP [1/5] | BTCH [1976/3634] ||| train_loss = 0.02067 ----
LR: [0.003193888919141687]
---- EP [1/5] | BTCH [1977/3634] ||| train_loss = 0.01657 ----
LR: [0.003196402917625747]
---- EP [1/5] | BTCH [1978/3634] ||| train_loss = 0.00918 ----
LR: [0.003198917581868921]
---- EP [1/5] | BTCH [1979/3634] ||| train_loss = 0.01804 ----
LR: [0.0032014329110356286]
---- EP [1/5] | BTCH [1980/3634] ||| train_loss = 0.01371 ----
LR: [0.0032039489042900732]
---- EP [1/5] | BTCH [1981/3634] ||| train_loss = 0.01094 ----
LR: [0.0032064655607962345]
---- EP [1/5] | BTCH [1982/3634] ||| train_loss = 0.00947 ----
LR: [0.003208982879717874]
---- EP [1/5] | BTCH [1983/3634] ||| train_loss = 0.01034 ----
LR: [0.0032115008602185318]
---- EP [1/5] | BTCH [1984/3634] ||| train_loss = 0.00847 ----
LR: [0.003214019501461528]
---- EP [1/5] | BTCH [1985/3634] ||| train_loss = 0.01518 ----
LR: [0.0032165388026099634]
---- EP [1/5] | BTCH [1986/3634] ||| train_loss = 0.00905 ----
LR: [0.0032190587628267205]
---- EP [1/5] | BTCH [1987/3634] ||| train_loss = 0.01227 ----
LR: [0.003221579381274462]
---- EP [1/5] | BTCH [1988/3634] ||| train_loss = 0.01142 ----
LR: [0.0032241006571156333]
---- EP [1/5] | BTCH [1989/3634] ||| train_loss = 0.01453 ----
LR: [0.003226622589512459]
---- EP [1/5] | BTCH [1990/3634] ||| train_loss = 0.01374 ----
LR: [0.0032291451776269436]
---- EP [1/5] | BTCH [1991/3634] ||| train_loss = 0.01910 ----
VAL ||| loss = 0.013323534542357286, psnr = 30.72427749633789, ssim = 0.9079275727272034
LR: [0.0032316684206208793]
---- EP [1/5] | BTCH [1992/3634] ||| train_loss = 0.01656 ----
LR: [0.0032341923176558394]
---- EP [1/5] | BTCH [1993/3634] ||| train_loss = 0.01100 ----
LR: [0.0032367168678931763]
---- EP [1/5] | BTCH [1994/3634] ||| train_loss = 0.00994 ----
LR: [0.003239242070494027]
---- EP [1/5] | BTCH [1995/3634] ||| train_loss = 0.00880 ----
LR: [0.0032417679246193147]
---- EP [1/5] | BTCH [1996/3634] ||| train_loss = 0.02018 ----
LR: [0.0032442944294297426]
---- EP [1/5] | BTCH [1997/3634] ||| train_loss = 0.00645 ----
LR: [0.0032468215840857984]
---- EP [1/5] | BTCH [1998/3634] ||| train_loss = 0.01054 ----
LR: [0.0032493493877477544]
---- EP [1/5] | BTCH [1999/3634] ||| train_loss = 0.01198 ----
LR: [0.0032518778395756688]
---- EP [1/5] | BTCH [2000/3634] ||| train_loss = 0.01171 ----
LR: [0.0032544069387293794]
---- EP [1/5] | BTCH [2001/3634] ||| train_loss = 0.01315 ----
LR: [0.003256936684368515]
---- EP [1/5] | BTCH [2002/3634] ||| train_loss = 0.00994 ----
LR: [0.0032594670756524854]
---- EP [1/5] | BTCH [2003/3634] ||| train_loss = 0.00979 ----
LR: [0.003261998111740488]
---- EP [1/5] | BTCH [2004/3634] ||| train_loss = 0.01215 ----
LR: [0.003264529791791505]
---- EP [1/5] | BTCH [2005/3634] ||| train_loss = 0.00779 ----
LR: [0.003267062114964305]
---- EP [1/5] | BTCH [2006/3634] ||| train_loss = 0.01685 ----
LR: [0.003269595080417442]
---- EP [1/5] | BTCH [2007/3634] ||| train_loss = 0.01185 ----
LR: [0.003272128687309259]
---- EP [1/5] | BTCH [2008/3634] ||| train_loss = 0.01481 ----
LR: [0.0032746629347978826]
---- EP [1/5] | BTCH [2009/3634] ||| train_loss = 0.00629 ----
LR: [0.0032771978220412293]
---- EP [1/5] | BTCH [2010/3634] ||| train_loss = 0.00627 ----
LR: [0.0032797333481970007]
---- EP [1/5] | BTCH [2011/3634] ||| train_loss = 0.01042 ----
LR: [0.0032822695124226867]
---- EP [1/5] | BTCH [2012/3634] ||| train_loss = 0.02102 ----
LR: [0.00328480631387557]
---- EP [1/5] | BTCH [2013/3634] ||| train_loss = 0.00897 ----
LR: [0.003287343751712712]
---- EP [1/5] | BTCH [2014/3634] ||| train_loss = 0.00934 ----
LR: [0.003289881825090971]
---- EP [1/5] | BTCH [2015/3634] ||| train_loss = 0.02353 ----
LR: [0.0032924205331669896]
---- EP [1/5] | BTCH [2016/3634] ||| train_loss = 0.01384 ----
LR: [0.0032949598750972014]
---- EP [1/5] | BTCH [2017/3634] ||| train_loss = 0.02129 ----
LR: [0.00329749985003783]
---- EP [1/5] | BTCH [2018/3634] ||| train_loss = 0.01416 ----
LR: [0.003300040457144887]
---- EP [1/5] | BTCH [2019/3634] ||| train_loss = 0.01856 ----
LR: [0.0033025816955741744]
---- EP [1/5] | BTCH [2020/3634] ||| train_loss = 0.01397 ----
LR: [0.003305123564481283]
---- EP [1/5] | BTCH [2021/3634] ||| train_loss = 0.01322 ----
LR: [0.0033076660630215965]
---- EP [1/5] | BTCH [2022/3634] ||| train_loss = 0.00891 ----
LR: [0.0033102091903502925]
---- EP [1/5] | BTCH [2023/3634] ||| train_loss = 0.01108 ----
LR: [0.003312752945622331]
---- EP [1/5] | BTCH [2024/3634] ||| train_loss = 0.01258 ----
LR: [0.003315297327992469]
---- EP [1/5] | BTCH [2025/3634] ||| train_loss = 0.00842 ----
LR: [0.003317842336615256]
---- EP [1/5] | BTCH [2026/3634] ||| train_loss = 0.00664 ----
LR: [0.003320387970645029]
---- EP [1/5] | BTCH [2027/3634] ||| train_loss = 0.01014 ----
LR: [0.0033229342292359215]
---- EP [1/5] | BTCH [2028/3634] ||| train_loss = 0.01362 ----
LR: [0.003325481111541859]
---- EP [1/5] | BTCH [2029/3634] ||| train_loss = 0.01463 ----
LR: [0.0033280286167165557]
---- EP [1/5] | BTCH [2030/3634] ||| train_loss = 0.02070 ----
LR: [0.0033305767439135237]
---- EP [1/5] | BTCH [2031/3634] ||| train_loss = 0.01461 ----
LR: [0.0033331254922860645]
---- EP [1/5] | BTCH [2032/3634] ||| train_loss = 0.01384 ----
LR: [0.0033356748609872774]
---- EP [1/5] | BTCH [2033/3634] ||| train_loss = 0.00875 ----
LR: [0.003338224849170052]
---- EP [1/5] | BTCH [2034/3634] ||| train_loss = 0.00884 ----
LR: [0.0033407754559870717]
---- EP [1/5] | BTCH [2035/3634] ||| train_loss = 0.00723 ----
LR: [0.0033433266805908187]
---- EP [1/5] | BTCH [2036/3634] ||| train_loss = 0.01838 ----
LR: [0.0033458785221335673]
---- EP [1/5] | BTCH [2037/3634] ||| train_loss = 0.01081 ----
LR: [0.003348430979767383]
---- EP [1/5] | BTCH [2038/3634] ||| train_loss = 0.00905 ----
LR: [0.0033509840526441334]
---- EP [1/5] | BTCH [2039/3634] ||| train_loss = 0.01102 ----
LR: [0.0033535377399154798]
---- EP [1/5] | BTCH [2040/3634] ||| train_loss = 0.01629 ----
LR: [0.0033560920407328734]
---- EP [1/5] | BTCH [2041/3634] ||| train_loss = 0.00908 ----
LR: [0.003358646954247569]
---- EP [1/5] | BTCH [2042/3634] ||| train_loss = 0.01345 ----
LR: [0.0033612024796106157]
---- EP [1/5] | BTCH [2043/3634] ||| train_loss = 0.01927 ----
LR: [0.0033637586159728575]
---- EP [1/5] | BTCH [2044/3634] ||| train_loss = 0.00724 ----
LR: [0.003366315362484938]
---- EP [1/5] | BTCH [2045/3634] ||| train_loss = 0.01002 ----
LR: [0.0033688727182972925]
---- EP [1/5] | BTCH [2046/3634] ||| train_loss = 0.01924 ----
LR: [0.003371430682560162]
---- EP [1/5] | BTCH [2047/3634] ||| train_loss = 0.01545 ----
LR: [0.0033739892544235785]
---- EP [1/5] | BTCH [2048/3634] ||| train_loss = 0.00916 ----
LR: [0.0033765484330373777]
---- EP [1/5] | BTCH [2049/3634] ||| train_loss = 0.00871 ----
LR: [0.0033791082175511885]
---- EP [1/5] | BTCH [2050/3634] ||| train_loss = 0.00644 ----
LR: [0.003381668607114441]
---- EP [1/5] | BTCH [2051/3634] ||| train_loss = 0.00970 ----
LR: [0.003384229600876364]
---- EP [1/5] | BTCH [2052/3634] ||| train_loss = 0.01125 ----
LR: [0.003386791197985987]
---- EP [1/5] | BTCH [2053/3634] ||| train_loss = 0.01234 ----
LR: [0.0033893533975921358]
---- EP [1/5] | BTCH [2054/3634] ||| train_loss = 0.01419 ----
LR: [0.003391916198843439]
---- EP [1/5] | BTCH [2055/3634] ||| train_loss = 0.00960 ----
LR: [0.0033944796008883223]
---- EP [1/5] | BTCH [2056/3634] ||| train_loss = 0.01140 ----
LR: [0.0033970436028750153]
---- EP [1/5] | BTCH [2057/3634] ||| train_loss = 0.01185 ----
LR: [0.003399608203951546]
---- EP [1/5] | BTCH [2058/3634] ||| train_loss = 0.01055 ----
LR: [0.0034021734032657434]
---- EP [1/5] | BTCH [2059/3634] ||| train_loss = 0.01185 ----
LR: [0.0034047391999652383]
---- EP [1/5] | BTCH [2060/3634] ||| train_loss = 0.00984 ----
LR: [0.0034073055931974627]
---- EP [1/5] | BTCH [2061/3634] ||| train_loss = 0.00840 ----
LR: [0.00340987258210965]
---- EP [1/5] | BTCH [2062/3634] ||| train_loss = 0.01016 ----
LR: [0.00341244016584884]
---- EP [1/5] | BTCH [2063/3634] ||| train_loss = 0.00998 ----
LR: [0.0034150083435618645]
---- EP [1/5] | BTCH [2064/3634] ||| train_loss = 0.01426 ----
LR: [0.003417577114395369]
---- EP [1/5] | BTCH [2065/3634] ||| train_loss = 0.01031 ----
LR: [0.003420146477495796]
---- EP [1/5] | BTCH [2066/3634] ||| train_loss = 0.01463 ----
LR: [0.003422716432009392]
---- EP [1/5] | BTCH [2067/3634] ||| train_loss = 0.01532 ----
LR: [0.003425286977082209]
---- EP [1/5] | BTCH [2068/3634] ||| train_loss = 0.00669 ----
LR: [0.003427858111860101]
---- EP [1/5] | BTCH [2069/3634] ||| train_loss = 0.01558 ----
LR: [0.0034304298354887255]
---- EP [1/5] | BTCH [2070/3634] ||| train_loss = 0.01288 ----
LR: [0.0034330021471135445]
---- EP [1/5] | BTCH [2071/3634] ||| train_loss = 0.02266 ----
LR: [0.0034355750458798275]
---- EP [1/5] | BTCH [2072/3634] ||| train_loss = 0.02229 ----
LR: [0.003438148530932647]
---- EP [1/5] | BTCH [2073/3634] ||| train_loss = 0.00961 ----
LR: [0.0034407226014168766]
---- EP [1/5] | BTCH [2074/3634] ||| train_loss = 0.01257 ----
LR: [0.003443297256477203]
---- EP [1/5] | BTCH [2075/3634] ||| train_loss = 0.00568 ----
LR: [0.0034458724952581123]
---- EP [1/5] | BTCH [2076/3634] ||| train_loss = 0.00449 ----
LR: [0.003448448316903902]
---- EP [1/5] | BTCH [2077/3634] ||| train_loss = 0.01440 ----
LR: [0.0034510247205586705]
---- EP [1/5] | BTCH [2078/3634] ||| train_loss = 0.00942 ----
LR: [0.003453601705366326]
---- EP [1/5] | BTCH [2079/3634] ||| train_loss = 0.01012 ----
LR: [0.0034561792704705854]
---- EP [1/5] | BTCH [2080/3634] ||| train_loss = 0.00639 ----
LR: [0.003458757415014965]
---- EP [1/5] | BTCH [2081/3634] ||| train_loss = 0.01067 ----
LR: [0.003461336138142799]
---- EP [1/5] | BTCH [2082/3634] ||| train_loss = 0.01620 ----
LR: [0.0034639154389972237]
---- EP [1/5] | BTCH [2083/3634] ||| train_loss = 0.00940 ----
LR: [0.0034664953167211823]
---- EP [1/5] | BTCH [2084/3634] ||| train_loss = 0.01189 ----
LR: [0.003469075770457428]
---- EP [1/5] | BTCH [2085/3634] ||| train_loss = 0.01817 ----
LR: [0.003471656799348525]
---- EP [1/5] | BTCH [2086/3634] ||| train_loss = 0.01008 ----
LR: [0.00347423840253684]
---- EP [1/5] | BTCH [2087/3634] ||| train_loss = 0.01336 ----
LR: [0.003476820579164557]
---- EP [1/5] | BTCH [2088/3634] ||| train_loss = 0.01374 ----
LR: [0.0034794033283736614]
---- EP [1/5] | BTCH [2089/3634] ||| train_loss = 0.00996 ----
LR: [0.0034819866493059574]
---- EP [1/5] | BTCH [2090/3634] ||| train_loss = 0.00846 ----
LR: [0.003484570541103049]
---- EP [1/5] | BTCH [2091/3634] ||| train_loss = 0.01836 ----
LR: [0.003487155002906358]
---- EP [1/5] | BTCH [2092/3634] ||| train_loss = 0.01597 ----
LR: [0.0034897400338571166]
---- EP [1/5] | BTCH [2093/3634] ||| train_loss = 0.01644 ----
LR: [0.003492325633096362]
---- EP [1/5] | BTCH [2094/3634] ||| train_loss = 0.00997 ----
LR: [0.003494911799764947]
---- EP [1/5] | BTCH [2095/3634] ||| train_loss = 0.00919 ----
LR: [0.003497498533003537]
---- EP [1/5] | BTCH [2096/3634] ||| train_loss = 0.02113 ----
LR: [0.003500085831952605]
---- EP [1/5] | BTCH [2097/3634] ||| train_loss = 0.00596 ----
LR: [0.0035026736957524396]
---- EP [1/5] | BTCH [2098/3634] ||| train_loss = 0.01144 ----
LR: [0.0035052621235431413]
---- EP [1/5] | BTCH [2099/3634] ||| train_loss = 0.01288 ----
LR: [0.0035078511144646203]
---- EP [1/5] | BTCH [2100/3634] ||| train_loss = 0.01300 ----
LR: [0.003510440667656603]
---- EP [1/5] | BTCH [2101/3634] ||| train_loss = 0.01129 ----
LR: [0.0035130307822586263]
---- EP [1/5] | BTCH [2102/3634] ||| train_loss = 0.02144 ----
LR: [0.003515621457410044]
---- EP [1/5] | BTCH [2103/3634] ||| train_loss = 0.01131 ----
LR: [0.003518212692250021]
---- EP [1/5] | BTCH [2104/3634] ||| train_loss = 0.01026 ----
LR: [0.003520804485917535]
---- EP [1/5] | BTCH [2105/3634] ||| train_loss = 0.01359 ----
LR: [0.0035233968375513814]
---- EP [1/5] | BTCH [2106/3634] ||| train_loss = 0.01842 ----
LR: [0.0035259897462901688]
---- EP [1/5] | BTCH [2107/3634] ||| train_loss = 0.01177 ----
LR: [0.003528583211272319]
---- EP [1/5] | BTCH [2108/3634] ||| train_loss = 0.01140 ----
LR: [0.0035311772316360722]
---- EP [1/5] | BTCH [2109/3634] ||| train_loss = 0.01239 ----
LR: [0.0035337718065194803]
---- EP [1/5] | BTCH [2110/3634] ||| train_loss = 0.01433 ----
LR: [0.0035363669350604145]
---- EP [1/5] | BTCH [2111/3634] ||| train_loss = 0.00713 ----
LR: [0.00353896261639656]
---- EP [1/5] | BTCH [2112/3634] ||| train_loss = 0.01168 ----
LR: [0.0035415588496654216]
---- EP [1/5] | BTCH [2113/3634] ||| train_loss = 0.01228 ----
LR: [0.003544155634004312]
---- EP [1/5] | BTCH [2114/3634] ||| train_loss = 0.01177 ----
LR: [0.0035467529685503704]
---- EP [1/5] | BTCH [2115/3634] ||| train_loss = 0.01265 ----
LR: [0.0035493508524405476]
---- EP [1/5] | BTCH [2116/3634] ||| train_loss = 0.01239 ----
LR: [0.0035519492848116174]
---- EP [1/5] | BTCH [2117/3634] ||| train_loss = 0.01598 ----
LR: [0.003554548264800164]
---- EP [1/5] | BTCH [2118/3634] ||| train_loss = 0.01051 ----
LR: [0.0035571477915425937]
---- EP [1/5] | BTCH [2119/3634] ||| train_loss = 0.01176 ----
LR: [0.0035597478641751336]
---- EP [1/5] | BTCH [2120/3634] ||| train_loss = 0.01006 ----
LR: [0.0035623484818338227]
---- EP [1/5] | BTCH [2121/3634] ||| train_loss = 0.00865 ----
LR: [0.003564949643654526]
---- EP [1/5] | BTCH [2122/3634] ||| train_loss = 0.01107 ----
LR: [0.0035675513487729233]
---- EP [1/5] | BTCH [2123/3634] ||| train_loss = 0.02079 ----
LR: [0.0035701535963245127]
---- EP [1/5] | BTCH [2124/3634] ||| train_loss = 0.01112 ----
LR: [0.003572756385444617]
---- EP [1/5] | BTCH [2125/3634] ||| train_loss = 0.00972 ----
LR: [0.003575359715268376]
---- EP [1/5] | BTCH [2126/3634] ||| train_loss = 0.01297 ----
LR: [0.0035779635849307505]
---- EP [1/5] | BTCH [2127/3634] ||| train_loss = 0.01499 ----
LR: [0.0035805679935665205]
---- EP [1/5] | BTCH [2128/3634] ||| train_loss = 0.01030 ----
LR: [0.0035831729403102888]
---- EP [1/5] | BTCH [2129/3634] ||| train_loss = 0.01223 ----
LR: [0.003585778424296477]
---- EP [1/5] | BTCH [2130/3634] ||| train_loss = 0.01246 ----
LR: [0.0035883844446593337]
---- EP [1/5] | BTCH [2131/3634] ||| train_loss = 0.01251 ----
LR: [0.0035909910005329218]
---- EP [1/5] | BTCH [2132/3634] ||| train_loss = 0.01476 ----
LR: [0.0035935980910511327]
---- EP [1/5] | BTCH [2133/3634] ||| train_loss = 0.01495 ----
LR: [0.003596205715347674]
---- EP [1/5] | BTCH [2134/3634] ||| train_loss = 0.02108 ----
LR: [0.0035988138725560814]
---- EP [1/5] | BTCH [2135/3634] ||| train_loss = 0.00991 ----
LR: [0.0036014225618097107]
---- EP [1/5] | BTCH [2136/3634] ||| train_loss = 0.01005 ----
LR: [0.0036040317822417425]
---- EP [1/5] | BTCH [2137/3634] ||| train_loss = 0.01043 ----
LR: [0.0036066415329851793]
---- EP [1/5] | BTCH [2138/3634] ||| train_loss = 0.01428 ----
LR: [0.0036092518131728485]
---- EP [1/5] | BTCH [2139/3634] ||| train_loss = 0.01102 ----
LR: [0.0036118626219374004]
---- EP [1/5] | BTCH [2140/3634] ||| train_loss = 0.01081 ----
LR: [0.0036144739584113112]
---- EP [1/5] | BTCH [2141/3634] ||| train_loss = 0.02285 ----
LR: [0.00361708582172688]
---- EP [1/5] | BTCH [2142/3634] ||| train_loss = 0.00739 ----
LR: [0.003619698211016234]
---- EP [1/5] | BTCH [2143/3634] ||| train_loss = 0.01634 ----
LR: [0.0036223111254113207]
---- EP [1/5] | BTCH [2144/3634] ||| train_loss = 0.01113 ----
LR: [0.0036249245640439165]
---- EP [1/5] | BTCH [2145/3634] ||| train_loss = 0.00925 ----
LR: [0.0036275385260456225]
---- EP [1/5] | BTCH [2146/3634] ||| train_loss = 0.01448 ----
LR: [0.0036301530105478695]
---- EP [1/5] | BTCH [2147/3634] ||| train_loss = 0.00777 ----
LR: [0.0036327680166819082]
---- EP [1/5] | BTCH [2148/3634] ||| train_loss = 0.00871 ----
LR: [0.0036353835435788216]
---- EP [1/5] | BTCH [2149/3634] ||| train_loss = 0.00953 ----
LR: [0.0036379995903695157]
---- EP [1/5] | BTCH [2150/3634] ||| train_loss = 0.01399 ----
LR: [0.003640616156184724]
---- EP [1/5] | BTCH [2151/3634] ||| train_loss = 0.01073 ----
LR: [0.003643233240155013]
---- EP [1/5] | BTCH [2152/3634] ||| train_loss = 0.01528 ----
LR: [0.0036458508414107717]
---- EP [1/5] | BTCH [2153/3634] ||| train_loss = 0.01168 ----
LR: [0.0036484689590822166]
---- EP [1/5] | BTCH [2154/3634] ||| train_loss = 0.01086 ----
LR: [0.0036510875922993943]
---- EP [1/5] | BTCH [2155/3634] ||| train_loss = 0.01051 ----
LR: [0.0036537067401921823]
---- EP [1/5] | BTCH [2156/3634] ||| train_loss = 0.00846 ----
LR: [0.0036563264018902855]
---- EP [1/5] | BTCH [2157/3634] ||| train_loss = 0.00583 ----
LR: [0.003658946576523235]
---- EP [1/5] | BTCH [2158/3634] ||| train_loss = 0.01107 ----
LR: [0.003661567263220397]
---- EP [1/5] | BTCH [2159/3634] ||| train_loss = 0.01017 ----
LR: [0.0036641884611109616]
---- EP [1/5] | BTCH [2160/3634] ||| train_loss = 0.00621 ----
LR: [0.0036668101693239545]
---- EP [1/5] | BTCH [2161/3634] ||| train_loss = 0.01414 ----
LR: [0.003669432386988229]
---- EP [1/5] | BTCH [2162/3634] ||| train_loss = 0.00768 ----
LR: [0.003672055113232469]
---- EP [1/5] | BTCH [2163/3634] ||| train_loss = 0.01129 ----
LR: [0.00367467834718519]
---- EP [1/5] | BTCH [2164/3634] ||| train_loss = 0.01365 ----
LR: [0.003677302087974738]
---- EP [1/5] | BTCH [2165/3634] ||| train_loss = 0.01093 ----
LR: [0.003679926334729293]
---- EP [1/5] | BTCH [2166/3634] ||| train_loss = 0.01205 ----
LR: [0.0036825510865768664]
---- EP [1/5] | BTCH [2167/3634] ||| train_loss = 0.01355 ----
LR: [0.003685176342645296]
---- EP [1/5] | BTCH [2168/3634] ||| train_loss = 0.01325 ----
LR: [0.00368780210206226]
---- EP [1/5] | BTCH [2169/3634] ||| train_loss = 0.01154 ----
LR: [0.003690428363955265]
---- EP [1/5] | BTCH [2170/3634] ||| train_loss = 0.00823 ----
LR: [0.003693055127451653]
---- EP [1/5] | BTCH [2171/3634] ||| train_loss = 0.01244 ----
LR: [0.0036956823916785963]
---- EP [1/5] | BTCH [2172/3634] ||| train_loss = 0.01179 ----
VAL ||| loss = 0.013281615715584817, psnr = 30.726442337036133, ssim = 0.9077713489532471
LR: [0.0036983101557631027]
---- EP [1/5] | BTCH [2173/3634] ||| train_loss = 0.00683 ----
LR: [0.003700938418832014]
---- EP [1/5] | BTCH [2174/3634] ||| train_loss = 0.01313 ----
LR: [0.003703567180012005]
---- EP [1/5] | BTCH [2175/3634] ||| train_loss = 0.01597 ----
LR: [0.003706196438429587]
---- EP [1/5] | BTCH [2176/3634] ||| train_loss = 0.01598 ----
LR: [0.003708826193211107]
---- EP [1/5] | BTCH [2177/3634] ||| train_loss = 0.01291 ----
LR: [0.003711456443482741]
---- EP [1/5] | BTCH [2178/3634] ||| train_loss = 0.00827 ----
LR: [0.0037140871883705046]
---- EP [1/5] | BTCH [2179/3634] ||| train_loss = 0.01570 ----
LR: [0.003716718427000252]
---- EP [1/5] | BTCH [2180/3634] ||| train_loss = 0.01824 ----
LR: [0.003719350158497668]
---- EP [1/5] | BTCH [2181/3634] ||| train_loss = 0.01351 ----
LR: [0.0037219823819882748]
---- EP [1/5] | BTCH [2182/3634] ||| train_loss = 0.01724 ----
LR: [0.0037246150965974346]
---- EP [1/5] | BTCH [2183/3634] ||| train_loss = 0.00729 ----
LR: [0.003727248301450343]
---- EP [1/5] | BTCH [2184/3634] ||| train_loss = 0.00833 ----
LR: [0.003729881995672031]
---- EP [1/5] | BTCH [2185/3634] ||| train_loss = 0.01222 ----
LR: [0.0037325161783873743]
---- EP [1/5] | BTCH [2186/3634] ||| train_loss = 0.01533 ----
LR: [0.003735150848721079]
---- EP [1/5] | BTCH [2187/3634] ||| train_loss = 0.00623 ----
LR: [0.0037377860057976903]
---- EP [1/5] | BTCH [2188/3634] ||| train_loss = 0.00944 ----
LR: [0.003740421648741596]
---- EP [1/5] | BTCH [2189/3634] ||| train_loss = 0.00927 ----
LR: [0.003743057776677017]
---- EP [1/5] | BTCH [2190/3634] ||| train_loss = 0.02235 ----
LR: [0.0037456943887280176]
---- EP [1/5] | BTCH [2191/3634] ||| train_loss = 0.00910 ----
LR: [0.0037483314840184986]
---- EP [1/5] | BTCH [2192/3634] ||| train_loss = 0.00942 ----
LR: [0.003750969061672201]
---- EP [1/5] | BTCH [2193/3634] ||| train_loss = 0.01484 ----
LR: [0.0037536071208127053]
---- EP [1/5] | BTCH [2194/3634] ||| train_loss = 0.01401 ----
LR: [0.0037562456605634304]
---- EP [1/5] | BTCH [2195/3634] ||| train_loss = 0.00823 ----
LR: [0.003758884680047641]
---- EP [1/5] | BTCH [2196/3634] ||| train_loss = 0.01385 ----
LR: [0.0037615241783884364]
---- EP [1/5] | BTCH [2197/3634] ||| train_loss = 0.01342 ----
LR: [0.0037641641547087575]
---- EP [1/5] | BTCH [2198/3634] ||| train_loss = 0.00695 ----
LR: [0.0037668046081313893]
---- EP [1/5] | BTCH [2199/3634] ||| train_loss = 0.00891 ----
LR: [0.0037694455377789583]
---- EP [1/5] | BTCH [2200/3634] ||| train_loss = 0.01954 ----
LR: [0.0037720869427739284]
---- EP [1/5] | BTCH [2201/3634] ||| train_loss = 0.01026 ----
LR: [0.0037747288222386103]
---- EP [1/5] | BTCH [2202/3634] ||| train_loss = 0.00690 ----
LR: [0.003777371175295156]
---- EP [1/5] | BTCH [2203/3634] ||| train_loss = 0.01380 ----
LR: [0.0037800140010655564]
---- EP [1/5] | BTCH [2204/3634] ||| train_loss = 0.01478 ----
LR: [0.003782657298671651]
---- EP [1/5] | BTCH [2205/3634] ||| train_loss = 0.01055 ----
LR: [0.003785301067235118]
---- EP [1/5] | BTCH [2206/3634] ||| train_loss = 0.01218 ----
LR: [0.003787945305877483]
---- EP [1/5] | BTCH [2207/3634] ||| train_loss = 0.01143 ----
LR: [0.003790590013720111]
---- EP [1/5] | BTCH [2208/3634] ||| train_loss = 0.01347 ----
LR: [0.003793235189884215]
---- EP [1/5] | BTCH [2209/3634] ||| train_loss = 0.00753 ----
LR: [0.003795880833490849]
---- EP [1/5] | BTCH [2210/3634] ||| train_loss = 0.01022 ----
LR: [0.003798526943660915]
---- EP [1/5] | BTCH [2211/3634] ||| train_loss = 0.01306 ----
LR: [0.003801173519515157]
---- EP [1/5] | BTCH [2212/3634] ||| train_loss = 0.00817 ----
LR: [0.003803820560174167]
---- EP [1/5] | BTCH [2213/3634] ||| train_loss = 0.01018 ----
LR: [0.0038064680647583804]
---- EP [1/5] | BTCH [2214/3634] ||| train_loss = 0.01656 ----
LR: [0.0038091160323880805]
---- EP [1/5] | BTCH [2215/3634] ||| train_loss = 0.00685 ----
LR: [0.0038117644621833936]
---- EP [1/5] | BTCH [2216/3634] ||| train_loss = 0.01066 ----
LR: [0.0038144133532642954]
---- EP [1/5] | BTCH [2217/3634] ||| train_loss = 0.01383 ----
LR: [0.003817062704750608]
---- EP [1/5] | BTCH [2218/3634] ||| train_loss = 0.01019 ----
LR: [0.0038197125157619976]
---- EP [1/5] | BTCH [2219/3634] ||| train_loss = 0.01183 ----
LR: [0.0038223627854179817]
---- EP [1/5] | BTCH [2220/3634] ||| train_loss = 0.01820 ----
LR: [0.0038250135128379227]
---- EP [1/5] | BTCH [2221/3634] ||| train_loss = 0.01576 ----
LR: [0.003827664697141033]
---- EP [1/5] | BTCH [2222/3634] ||| train_loss = 0.01038 ----
LR: [0.0038303163374463697]
---- EP [1/5] | BTCH [2223/3634] ||| train_loss = 0.01012 ----
LR: [0.0038329684328728426]
---- EP [1/5] | BTCH [2224/3634] ||| train_loss = 0.02009 ----
LR: [0.0038356209825392085]
---- EP [1/5] | BTCH [2225/3634] ||| train_loss = 0.01435 ----
LR: [0.003838273985564071]
---- EP [1/5] | BTCH [2226/3634] ||| train_loss = 0.01759 ----
LR: [0.003840927441065888]
---- EP [1/5] | BTCH [2227/3634] ||| train_loss = 0.01712 ----
LR: [0.0038435813481629616]
---- EP [1/5] | BTCH [2228/3634] ||| train_loss = 0.01136 ----
LR: [0.003846235705973447]
---- EP [1/5] | BTCH [2229/3634] ||| train_loss = 0.01887 ----
LR: [0.0038488905136153497]
---- EP [1/5] | BTCH [2230/3634] ||| train_loss = 0.00973 ----
LR: [0.003851545770206524]
---- EP [1/5] | BTCH [2231/3634] ||| train_loss = 0.01384 ----
LR: [0.0038542014748646786]
---- EP [1/5] | BTCH [2232/3634] ||| train_loss = 0.01066 ----
LR: [0.0038568576267073683]
---- EP [1/5] | BTCH [2233/3634] ||| train_loss = 0.00902 ----
LR: [0.003859514224852003]
---- EP [1/5] | BTCH [2234/3634] ||| train_loss = 0.02191 ----
LR: [0.003862171268415842]
---- EP [1/5] | BTCH [2235/3634] ||| train_loss = 0.01368 ----
LR: [0.003864828756515999]
---- EP [1/5] | BTCH [2236/3634] ||| train_loss = 0.00953 ----
LR: [0.0038674866882694395]
---- EP [1/5] | BTCH [2237/3634] ||| train_loss = 0.01771 ----
LR: [0.0038701450627929785]
---- EP [1/5] | BTCH [2238/3634] ||| train_loss = 0.01552 ----
LR: [0.003872803879203286]
---- EP [1/5] | BTCH [2239/3634] ||| train_loss = 0.01070 ----
LR: [0.003875463136616888]
---- EP [1/5] | BTCH [2240/3634] ||| train_loss = 0.01507 ----
LR: [0.00387812283415016]
---- EP [1/5] | BTCH [2241/3634] ||| train_loss = 0.00776 ----
LR: [0.003880782970919332]
---- EP [1/5] | BTCH [2242/3634] ||| train_loss = 0.01181 ----
LR: [0.0038834435460404883]
---- EP [1/5] | BTCH [2243/3634] ||| train_loss = 0.00863 ----
LR: [0.0038861045586295684]
---- EP [1/5] | BTCH [2244/3634] ||| train_loss = 0.00705 ----
LR: [0.0038887660078023674]
---- EP [1/5] | BTCH [2245/3634] ||| train_loss = 0.01846 ----
LR: [0.0038914278926745318]
---- EP [1/5] | BTCH [2246/3634] ||| train_loss = 0.01061 ----
LR: [0.003894090212361567]
---- EP [1/5] | BTCH [2247/3634] ||| train_loss = 0.00992 ----
LR: [0.0038967529659788306]
---- EP [1/5] | BTCH [2248/3634] ||| train_loss = 0.00709 ----
LR: [0.0038994161526415376]
---- EP [1/5] | BTCH [2249/3634] ||| train_loss = 0.01614 ----
LR: [0.003902079771464762]
---- EP [1/5] | BTCH [2250/3634] ||| train_loss = 0.01125 ----
LR: [0.003904743821563428]
---- EP [1/5] | BTCH [2251/3634] ||| train_loss = 0.01146 ----
LR: [0.003907408302052322]
---- EP [1/5] | BTCH [2252/3634] ||| train_loss = 0.01878 ----
LR: [0.003910073212046084]
---- EP [1/5] | BTCH [2253/3634] ||| train_loss = 0.01140 ----
LR: [0.0039127385506592125]
---- EP [1/5] | BTCH [2254/3634] ||| train_loss = 0.00681 ----
LR: [0.0039154043170060646]
---- EP [1/5] | BTCH [2255/3634] ||| train_loss = 0.01041 ----
LR: [0.003918070510200854]
---- EP [1/5] | BTCH [2256/3634] ||| train_loss = 0.01557 ----
LR: [0.0039207371293576545]
---- EP [1/5] | BTCH [2257/3634] ||| train_loss = 0.01333 ----
LR: [0.003923404173590392]
---- EP [1/5] | BTCH [2258/3634] ||| train_loss = 0.01130 ----
LR: [0.003926071642012861]
---- EP [1/5] | BTCH [2259/3634] ||| train_loss = 0.01275 ----
LR: [0.003928739533738707]
---- EP [1/5] | BTCH [2260/3634] ||| train_loss = 0.01155 ----
LR: [0.003931407847881439]
---- EP [1/5] | BTCH [2261/3634] ||| train_loss = 0.01737 ----
LR: [0.003934076583554424]
---- EP [1/5] | BTCH [2262/3634] ||| train_loss = 0.01010 ----
LR: [0.0039367457398708896]
---- EP [1/5] | BTCH [2263/3634] ||| train_loss = 0.01284 ----
LR: [0.003939415315943922]
---- EP [1/5] | BTCH [2264/3634] ||| train_loss = 0.01312 ----
LR: [0.003942085310886472]
---- EP [1/5] | BTCH [2265/3634] ||| train_loss = 0.01381 ----
LR: [0.003944755723811345]
---- EP [1/5] | BTCH [2266/3634] ||| train_loss = 0.01424 ----
LR: [0.0039474265538312165]
---- EP [1/5] | BTCH [2267/3634] ||| train_loss = 0.01664 ----
LR: [0.003950097800058612]
---- EP [1/5] | BTCH [2268/3634] ||| train_loss = 0.00886 ----
LR: [0.003952769461605927]
---- EP [1/5] | BTCH [2269/3634] ||| train_loss = 0.01025 ----
LR: [0.003955441537585418]
---- EP [1/5] | BTCH [2270/3634] ||| train_loss = 0.00901 ----
LR: [0.0039581140271092]
---- EP [1/5] | BTCH [2271/3634] ||| train_loss = 0.01910 ----
LR: [0.003960786929289253]
---- EP [1/5] | BTCH [2272/3634] ||| train_loss = 0.00863 ----
LR: [0.0039634602432374235]
---- EP [1/5] | BTCH [2273/3634] ||| train_loss = 0.00940 ----
LR: [0.0039661339680654144]
---- EP [1/5] | BTCH [2274/3634] ||| train_loss = 0.01229 ----
LR: [0.003968808102884795]
---- EP [1/5] | BTCH [2275/3634] ||| train_loss = 0.00868 ----
LR: [0.003971482646807001]
---- EP [1/5] | BTCH [2276/3634] ||| train_loss = 0.01348 ----
LR: [0.003974157598943329]
---- EP [1/5] | BTCH [2277/3634] ||| train_loss = 0.00589 ----
LR: [0.003976832958404938]
---- EP [1/5] | BTCH [2278/3634] ||| train_loss = 0.01153 ----
LR: [0.003979508724302857]
---- EP [1/5] | BTCH [2279/3634] ||| train_loss = 0.01107 ----
LR: [0.003982184895747977]
---- EP [1/5] | BTCH [2280/3634] ||| train_loss = 0.01743 ----
LR: [0.003984861471851055]
---- EP [1/5] | BTCH [2281/3634] ||| train_loss = 0.01353 ----
LR: [0.003987538451722712]
---- EP [1/5] | BTCH [2282/3634] ||| train_loss = 0.01047 ----
LR: [0.003990215834473437]
---- EP [1/5] | BTCH [2283/3634] ||| train_loss = 0.01209 ----
LR: [0.003992893619213583]
---- EP [1/5] | BTCH [2284/3634] ||| train_loss = 0.01221 ----
LR: [0.003995571805053372]
---- EP [1/5] | BTCH [2285/3634] ||| train_loss = 0.01675 ----
LR: [0.003998250391102889]
---- EP [1/5] | BTCH [2286/3634] ||| train_loss = 0.01070 ----
LR: [0.00400092937647209]
---- EP [1/5] | BTCH [2287/3634] ||| train_loss = 0.01564 ----
LR: [0.0040036087602707965]
---- EP [1/5] | BTCH [2288/3634] ||| train_loss = 0.01151 ----
LR: [0.004006288541608696]
---- EP [1/5] | BTCH [2289/3634] ||| train_loss = 0.01409 ----
LR: [0.0040089687195953485]
---- EP [1/5] | BTCH [2290/3634] ||| train_loss = 0.01436 ----
LR: [0.004011649293340177]
---- EP [1/5] | BTCH [2291/3634] ||| train_loss = 0.00879 ----
LR: [0.004014330261952475]
---- EP [1/5] | BTCH [2292/3634] ||| train_loss = 0.01280 ----
LR: [0.004017011624541407]
---- EP [1/5] | BTCH [2293/3634] ||| train_loss = 0.00919 ----
LR: [0.004019693380216003]
---- EP [1/5] | BTCH [2294/3634] ||| train_loss = 0.00955 ----
LR: [0.004022375528085166]
---- EP [1/5] | BTCH [2295/3634] ||| train_loss = 0.01168 ----
LR: [0.004025058067257664]
---- EP [1/5] | BTCH [2296/3634] ||| train_loss = 0.00682 ----
LR: [0.004027740996842141]
---- EP [1/5] | BTCH [2297/3634] ||| train_loss = 0.00756 ----
LR: [0.004030424315947104]
---- EP [1/5] | BTCH [2298/3634] ||| train_loss = 0.00737 ----
LR: [0.004033108023680936]
---- EP [1/5] | BTCH [2299/3634] ||| train_loss = 0.00840 ----
LR: [0.004035792119151892]
---- EP [1/5] | BTCH [2300/3634] ||| train_loss = 0.01537 ----
LR: [0.004038476601468093]
---- EP [1/5] | BTCH [2301/3634] ||| train_loss = 0.01285 ----
LR: [0.004041161469737534]
---- EP [1/5] | BTCH [2302/3634] ||| train_loss = 0.00732 ----
LR: [0.004043846723068083]
---- EP [1/5] | BTCH [2303/3634] ||| train_loss = 0.01194 ----
LR: [0.004046532360567478]
---- EP [1/5] | BTCH [2304/3634] ||| train_loss = 0.01777 ----
LR: [0.0040492183813433304]
---- EP [1/5] | BTCH [2305/3634] ||| train_loss = 0.01663 ----
LR: [0.004051904784503123]
---- EP [1/5] | BTCH [2306/3634] ||| train_loss = 0.01229 ----
LR: [0.0040545915691542166]
---- EP [1/5] | BTCH [2307/3634] ||| train_loss = 0.01523 ----
LR: [0.004057278734403834]
---- EP [1/5] | BTCH [2308/3634] ||| train_loss = 0.01128 ----
LR: [0.004059966279359086]
---- EP [1/5] | BTCH [2309/3634] ||| train_loss = 0.00650 ----
LR: [0.004062654203126946]
---- EP [1/5] | BTCH [2310/3634] ||| train_loss = 0.01124 ----
LR: [0.004065342504814266]
---- EP [1/5] | BTCH [2311/3634] ||| train_loss = 0.00840 ----
LR: [0.0040680311835277734]
---- EP [1/5] | BTCH [2312/3634] ||| train_loss = 0.00810 ----
LR: [0.004070720238374067]
---- EP [1/5] | BTCH [2313/3634] ||| train_loss = 0.00901 ----
LR: [0.004073409668459622]
---- EP [1/5] | BTCH [2314/3634] ||| train_loss = 0.01157 ----
LR: [0.004076099472890792]
---- EP [1/5] | BTCH [2315/3634] ||| train_loss = 0.00717 ----
LR: [0.004078789650773802]
---- EP [1/5] | BTCH [2316/3634] ||| train_loss = 0.01175 ----
LR: [0.004081480201214755]
---- EP [1/5] | BTCH [2317/3634] ||| train_loss = 0.01533 ----
LR: [0.004084171123319627]
---- EP [1/5] | BTCH [2318/3634] ||| train_loss = 0.01020 ----
LR: [0.004086862416194277]
---- EP [1/5] | BTCH [2319/3634] ||| train_loss = 0.01077 ----
LR: [0.004089554078944437]
---- EP [1/5] | BTCH [2320/3634] ||| train_loss = 0.01578 ----
LR: [0.004092246110675713]
---- EP [1/5] | BTCH [2321/3634] ||| train_loss = 0.01260 ----
LR: [0.004094938510493594]
---- EP [1/5] | BTCH [2322/3634] ||| train_loss = 0.01535 ----
LR: [0.004097631277503442]
---- EP [1/5] | BTCH [2323/3634] ||| train_loss = 0.01356 ----
LR: [0.004100324410810501]
---- EP [1/5] | BTCH [2324/3634] ||| train_loss = 0.01166 ----
LR: [0.004103017909519891]
---- EP [1/5] | BTCH [2325/3634] ||| train_loss = 0.01749 ----
LR: [0.004105711772736611]
---- EP [1/5] | BTCH [2326/3634] ||| train_loss = 0.01234 ----
LR: [0.0041084059995655405]
---- EP [1/5] | BTCH [2327/3634] ||| train_loss = 0.01596 ----
LR: [0.004111100589111433]
---- EP [1/5] | BTCH [2328/3634] ||| train_loss = 0.01256 ----
LR: [0.004113795540478926]
---- EP [1/5] | BTCH [2329/3634] ||| train_loss = 0.00981 ----
LR: [0.0041164908527725405]
---- EP [1/5] | BTCH [2330/3634] ||| train_loss = 0.01225 ----
LR: [0.004119186525096668]
---- EP [1/5] | BTCH [2331/3634] ||| train_loss = 0.01015 ----
LR: [0.004121882556555585]
---- EP [1/5] | BTCH [2332/3634] ||| train_loss = 0.01149 ----
LR: [0.004124578946253452]
---- EP [1/5] | BTCH [2333/3634] ||| train_loss = 0.00978 ----
LR: [0.004127275693294305]
---- EP [1/5] | BTCH [2334/3634] ||| train_loss = 0.00946 ----
LR: [0.004129972796782066]
---- EP [1/5] | BTCH [2335/3634] ||| train_loss = 0.01303 ----
LR: [0.004132670255820533]
---- EP [1/5] | BTCH [2336/3634] ||| train_loss = 0.01015 ----
LR: [0.004135368069513393]
---- EP [1/5] | BTCH [2337/3634] ||| train_loss = 0.00883 ----
LR: [0.004138066236964207]
---- EP [1/5] | BTCH [2338/3634] ||| train_loss = 0.01822 ----
LR: [0.004140764757276426]
---- EP [1/5] | BTCH [2339/3634] ||| train_loss = 0.01237 ----
LR: [0.004143463629553381]
---- EP [1/5] | BTCH [2340/3634] ||| train_loss = 0.01219 ----
LR: [0.0041461628528982825]
---- EP [1/5] | BTCH [2341/3634] ||| train_loss = 0.01459 ----
LR: [0.004148862426414229]
---- EP [1/5] | BTCH [2342/3634] ||| train_loss = 0.01389 ----
LR: [0.004151562349204199]
---- EP [1/5] | BTCH [2343/3634] ||| train_loss = 0.01123 ----
LR: [0.0041542626203710615]
---- EP [1/5] | BTCH [2344/3634] ||| train_loss = 0.01144 ----
LR: [0.0041569632390175614]
---- EP [1/5] | BTCH [2345/3634] ||| train_loss = 0.01307 ----
LR: [0.004159664204246332]
---- EP [1/5] | BTCH [2346/3634] ||| train_loss = 0.01119 ----
LR: [0.004162365515159894]
---- EP [1/5] | BTCH [2347/3634] ||| train_loss = 0.01235 ----
LR: [0.0041650671708606465]
---- EP [1/5] | BTCH [2348/3634] ||| train_loss = 0.00613 ----
LR: [0.004167769170450882]
---- EP [1/5] | BTCH [2349/3634] ||| train_loss = 0.01585 ----
LR: [0.004170471513032774]
---- EP [1/5] | BTCH [2350/3634] ||| train_loss = 0.01568 ----
LR: [0.004173174197708381]
---- EP [1/5] | BTCH [2351/3634] ||| train_loss = 0.01215 ----
LR: [0.004175877223579651]
---- EP [1/5] | BTCH [2352/3634] ||| train_loss = 0.00757 ----
LR: [0.004178580589748416]
---- EP [1/5] | BTCH [2353/3634] ||| train_loss = 0.01126 ----
VAL ||| loss = 0.013398200322044251, psnr = 30.690183639526367, ssim = 0.9067326784133911
LR: [0.0041812842953164]
---- EP [1/5] | BTCH [2354/3634] ||| train_loss = 0.01648 ----
LR: [0.004183988339385206]
---- EP [1/5] | BTCH [2355/3634] ||| train_loss = 0.01141 ----
LR: [0.004186692721056332]
---- EP [1/5] | BTCH [2356/3634] ||| train_loss = 0.01529 ----
LR: [0.004189397439431159]
---- EP [1/5] | BTCH [2357/3634] ||| train_loss = 0.01001 ----
LR: [0.004192102493610959]
---- EP [1/5] | BTCH [2358/3634] ||| train_loss = 0.00845 ----
LR: [0.004194807882696892]
---- EP [1/5] | BTCH [2359/3634] ||| train_loss = 0.00735 ----
LR: [0.004197513605790005]
---- EP [1/5] | BTCH [2360/3634] ||| train_loss = 0.01947 ----
LR: [0.004200219661991235]
---- EP [1/5] | BTCH [2361/3634] ||| train_loss = 0.01001 ----
LR: [0.004202926050401409]
---- EP [1/5] | BTCH [2362/3634] ||| train_loss = 0.00999 ----
LR: [0.004205632770121241]
---- EP [1/5] | BTCH [2363/3634] ||| train_loss = 0.00931 ----
LR: [0.004208339820251341]
---- EP [1/5] | BTCH [2364/3634] ||| train_loss = 0.01734 ----
LR: [0.004211047199892202]
---- EP [1/5] | BTCH [2365/3634] ||| train_loss = 0.01263 ----
LR: [0.004213754908144211]
---- EP [1/5] | BTCH [2366/3634] ||| train_loss = 0.01845 ----
LR: [0.004216462944107646]
---- EP [1/5] | BTCH [2367/3634] ||| train_loss = 0.01158 ----
LR: [0.004219171306882675]
---- EP [1/5] | BTCH [2368/3634] ||| train_loss = 0.01690 ----
LR: [0.00422187999556936]
---- EP [1/5] | BTCH [2369/3634] ||| train_loss = 0.00929 ----
LR: [0.004224589009267652]
---- EP [1/5] | BTCH [2370/3634] ||| train_loss = 0.00814 ----
LR: [0.004227298347077392]
---- EP [1/5] | BTCH [2371/3634] ||| train_loss = 0.01189 ----
LR: [0.004230008008098318]
---- EP [1/5] | BTCH [2372/3634] ||| train_loss = 0.00900 ----
LR: [0.004232717991430058]
---- EP [1/5] | BTCH [2373/3634] ||| train_loss = 0.01528 ----
LR: [0.004235428296172136]
---- EP [1/5] | BTCH [2374/3634] ||| train_loss = 0.00937 ----
LR: [0.004238138921423963]
---- EP [1/5] | BTCH [2375/3634] ||| train_loss = 0.01696 ----
LR: [0.004240849866284849]
---- EP [1/5] | BTCH [2376/3634] ||| train_loss = 0.01294 ----
LR: [0.004243561129853997]
---- EP [1/5] | BTCH [2377/3634] ||| train_loss = 0.01436 ----
LR: [0.004246272711230501]
---- EP [1/5] | BTCH [2378/3634] ||| train_loss = 0.00811 ----
LR: [0.004248984609513353]
---- EP [1/5] | BTCH [2379/3634] ||| train_loss = 0.01828 ----
LR: [0.004251696823801438]
---- EP [1/5] | BTCH [2380/3634] ||| train_loss = 0.01126 ----
LR: [0.004254409353193535]
---- EP [1/5] | BTCH [2381/3634] ||| train_loss = 0.01314 ----
LR: [0.00425712219678832]
---- EP [1/5] | BTCH [2382/3634] ||| train_loss = 0.01354 ----
LR: [0.004259835353684365]
---- EP [1/5] | BTCH [2383/3634] ||| train_loss = 0.01592 ----
LR: [0.004262548822980138]
---- EP [1/5] | BTCH [2384/3634] ||| train_loss = 0.01047 ----
LR: [0.004265262603773998]
---- EP [1/5] | BTCH [2385/3634] ||| train_loss = 0.01718 ----
LR: [0.004267976695164209]
---- EP [1/5] | BTCH [2386/3634] ||| train_loss = 0.01264 ----
LR: [0.004270691096248925]
---- EP [1/5] | BTCH [2387/3634] ||| train_loss = 0.01568 ----
LR: [0.0042734058061262]
---- EP [1/5] | BTCH [2388/3634] ||| train_loss = 0.01341 ----
LR: [0.004276120823893986]
---- EP [1/5] | BTCH [2389/3634] ||| train_loss = 0.01458 ----
LR: [0.0042788361486501315]
---- EP [1/5] | BTCH [2390/3634] ||| train_loss = 0.01374 ----
LR: [0.004281551779492381]
---- EP [1/5] | BTCH [2391/3634] ||| train_loss = 0.01244 ----
LR: [0.00428426771551838]
---- EP [1/5] | BTCH [2392/3634] ||| train_loss = 0.01139 ----
LR: [0.004286983955825675]
---- EP [1/5] | BTCH [2393/3634] ||| train_loss = 0.00509 ----
LR: [0.004289700499511707]
---- EP [1/5] | BTCH [2394/3634] ||| train_loss = 0.01556 ----
LR: [0.004292417345673816]
---- EP [1/5] | BTCH [2395/3634] ||| train_loss = 0.01117 ----
LR: [0.004295134493409244]
---- EP [1/5] | BTCH [2396/3634] ||| train_loss = 0.00696 ----
LR: [0.004297851941815132]
---- EP [1/5] | BTCH [2397/3634] ||| train_loss = 0.01096 ----
LR: [0.004300569689988521]
---- EP [1/5] | BTCH [2398/3634] ||| train_loss = 0.00821 ----
LR: [0.0043032877370263525]
---- EP [1/5] | BTCH [2399/3634] ||| train_loss = 0.01698 ----
LR: [0.004306006082025469]
---- EP [1/5] | BTCH [2400/3634] ||| train_loss = 0.01516 ----
LR: [0.004308724724082613]
---- EP [1/5] | BTCH [2401/3634] ||| train_loss = 0.01317 ----
LR: [0.0043114436622944275]
---- EP [1/5] | BTCH [2402/3634] ||| train_loss = 0.01696 ----
LR: [0.004314162895757461]
---- EP [1/5] | BTCH [2403/3634] ||| train_loss = 0.01219 ----
LR: [0.004316882423568161]
---- EP [1/5] | BTCH [2404/3634] ||| train_loss = 0.01068 ----
LR: [0.004319602244822875]
---- EP [1/5] | BTCH [2405/3634] ||| train_loss = 0.02122 ----
LR: [0.0043223223586178585]
---- EP [1/5] | BTCH [2406/3634] ||| train_loss = 0.00967 ----
LR: [0.004325042764049265]
---- EP [1/5] | BTCH [2407/3634] ||| train_loss = 0.01307 ----
LR: [0.004327763460213153]
---- EP [1/5] | BTCH [2408/3634] ||| train_loss = 0.01315 ----
LR: [0.004330484446205486]
---- EP [1/5] | BTCH [2409/3634] ||| train_loss = 0.01917 ----
LR: [0.00433320572112213]
---- EP [1/5] | BTCH [2410/3634] ||| train_loss = 0.00661 ----
LR: [0.00433592728405885]
---- EP [1/5] | BTCH [2411/3634] ||| train_loss = 0.00712 ----
LR: [0.004338649134111323]
---- EP [1/5] | BTCH [2412/3634] ||| train_loss = 0.01432 ----
LR: [0.004341371270375127]
---- EP [1/5] | BTCH [2413/3634] ||| train_loss = 0.00548 ----
LR: [0.004344093691945747]
---- EP [1/5] | BTCH [2414/3634] ||| train_loss = 0.00912 ----
LR: [0.004346816397918568]
---- EP [1/5] | BTCH [2415/3634] ||| train_loss = 0.02345 ----
LR: [0.004349539387388887]
---- EP [1/5] | BTCH [2416/3634] ||| train_loss = 0.02297 ----
LR: [0.004352262659451902]
---- EP [1/5] | BTCH [2417/3634] ||| train_loss = 0.01160 ----
LR: [0.004354986213202719]
---- EP [1/5] | BTCH [2418/3634] ||| train_loss = 0.01321 ----
LR: [0.004357710047736353]
---- EP [1/5] | BTCH [2419/3634] ||| train_loss = 0.00947 ----
LR: [0.00436043416214772]
---- EP [1/5] | BTCH [2420/3634] ||| train_loss = 0.01686 ----
LR: [0.004363158555531646]
---- EP [1/5] | BTCH [2421/3634] ||| train_loss = 0.01456 ----
LR: [0.004365883226982865]
---- EP [1/5] | BTCH [2422/3634] ||| train_loss = 0.00930 ----
LR: [0.004368608175596018]
---- EP [1/5] | BTCH [2423/3634] ||| train_loss = 0.01805 ----
LR: [0.004371333400465655]
---- EP [1/5] | BTCH [2424/3634] ||| train_loss = 0.01368 ----
LR: [0.004374058900686232]
---- EP [1/5] | BTCH [2425/3634] ||| train_loss = 0.00832 ----
LR: [0.004376784675352114]
---- EP [1/5] | BTCH [2426/3634] ||| train_loss = 0.01168 ----
LR: [0.0043795107235575755]
---- EP [1/5] | BTCH [2427/3634] ||| train_loss = 0.01354 ----
LR: [0.0043822370443968]
---- EP [1/5] | BTCH [2428/3634] ||| train_loss = 0.00616 ----
LR: [0.0043849636369638805]
---- EP [1/5] | BTCH [2429/3634] ||| train_loss = 0.01026 ----
LR: [0.0043876905003528205]
---- EP [1/5] | BTCH [2430/3634] ||| train_loss = 0.01567 ----
LR: [0.004390417633657531]
---- EP [1/5] | BTCH [2431/3634] ||| train_loss = 0.00976 ----
LR: [0.004393145035971833]
---- EP [1/5] | BTCH [2432/3634] ||| train_loss = 0.00806 ----
LR: [0.0043958727063894655]
---- EP [1/5] | BTCH [2433/3634] ||| train_loss = 0.02430 ----
LR: [0.0043986006440040705]
---- EP [1/5] | BTCH [2434/3634] ||| train_loss = 0.01167 ----
LR: [0.004401328847909201]
---- EP [1/5] | BTCH [2435/3634] ||| train_loss = 0.01745 ----
LR: [0.004404057317198326]
---- EP [1/5] | BTCH [2436/3634] ||| train_loss = 0.01102 ----
LR: [0.0044067860509648255]
---- EP [1/5] | BTCH [2437/3634] ||| train_loss = 0.00702 ----
LR: [0.004409515048301988]
---- EP [1/5] | BTCH [2438/3634] ||| train_loss = 0.01451 ----
LR: [0.00441224430830302]
---- EP [1/5] | BTCH [2439/3634] ||| train_loss = 0.01387 ----
LR: [0.004414973830061037]
---- EP [1/5] | BTCH [2440/3634] ||| train_loss = 0.01004 ----
LR: [0.004417703612669066]
---- EP [1/5] | BTCH [2441/3634] ||| train_loss = 0.01056 ----
LR: [0.0044204336552200515]
---- EP [1/5] | BTCH [2442/3634] ||| train_loss = 0.00889 ----
LR: [0.00442316395680685]
---- EP [1/5] | BTCH [2443/3634] ||| train_loss = 0.01884 ----
LR: [0.004425894516522231]
---- EP [1/5] | BTCH [2444/3634] ||| train_loss = 0.02077 ----
LR: [0.004428625333458877]
---- EP [1/5] | BTCH [2445/3634] ||| train_loss = 0.00925 ----
LR: [0.00443135640670939]
---- EP [1/5] | BTCH [2446/3634] ||| train_loss = 0.00905 ----
LR: [0.004434087735366282]
---- EP [1/5] | BTCH [2447/3634] ||| train_loss = 0.00718 ----
LR: [0.004436819318521983]
---- EP [1/5] | BTCH [2448/3634] ||| train_loss = 0.01408 ----
LR: [0.004439551155268834]
---- EP [1/5] | BTCH [2449/3634] ||| train_loss = 0.01638 ----
LR: [0.0044422832446991]
---- EP [1/5] | BTCH [2450/3634] ||| train_loss = 0.01239 ----
LR: [0.004445015585904953]
---- EP [1/5] | BTCH [2451/3634] ||| train_loss = 0.01639 ----
LR: [0.0044477481779784875]
---- EP [1/5] | BTCH [2452/3634] ||| train_loss = 0.01381 ----
LR: [0.004450481020011711]
---- EP [1/5] | BTCH [2453/3634] ||| train_loss = 0.00766 ----
LR: [0.004453214111096552]
---- EP [1/5] | BTCH [2454/3634] ||| train_loss = 0.01651 ----
LR: [0.00445594745032485]
---- EP [1/5] | BTCH [2455/3634] ||| train_loss = 0.01720 ----
LR: [0.004458681036788369]
---- EP [1/5] | BTCH [2456/3634] ||| train_loss = 0.00954 ----
LR: [0.004461414869578787]
---- EP [1/5] | BTCH [2457/3634] ||| train_loss = 0.01105 ----
LR: [0.004464148947787699]
---- EP [1/5] | BTCH [2458/3634] ||| train_loss = 0.01212 ----
LR: [0.004466883270506621]
---- EP [1/5] | BTCH [2459/3634] ||| train_loss = 0.01035 ----
LR: [0.004469617836826989]
---- EP [1/5] | BTCH [2460/3634] ||| train_loss = 0.01208 ----
LR: [0.004472352645840153]
---- EP [1/5] | BTCH [2461/3634] ||| train_loss = 0.01280 ----
LR: [0.004475087696637386]
---- EP [1/5] | BTCH [2462/3634] ||| train_loss = 0.00966 ----
LR: [0.004477822988309881]
---- EP [1/5] | BTCH [2463/3634] ||| train_loss = 0.01418 ----
LR: [0.004480558519948752]
---- EP [1/5] | BTCH [2464/3634] ||| train_loss = 0.00926 ----
LR: [0.004483294290645027]
---- EP [1/5] | BTCH [2465/3634] ||| train_loss = 0.01552 ----
LR: [0.004486030299489662]
---- EP [1/5] | BTCH [2466/3634] ||| train_loss = 0.01133 ----
LR: [0.004488766545573528]
---- EP [1/5] | BTCH [2467/3634] ||| train_loss = 0.01987 ----
LR: [0.004491503027987421]
---- EP [1/5] | BTCH [2468/3634] ||| train_loss = 0.00760 ----
LR: [0.00449423974582206]
---- EP [1/5] | BTCH [2469/3634] ||| train_loss = 0.01599 ----
LR: [0.0044969766981680795]
---- EP [1/5] | BTCH [2470/3634] ||| train_loss = 0.01308 ----
LR: [0.00449971388411604]
---- EP [1/5] | BTCH [2471/3634] ||| train_loss = 0.01212 ----
LR: [0.004502451302756426]
---- EP [1/5] | BTCH [2472/3634] ||| train_loss = 0.01003 ----
LR: [0.004505188953179642]
---- EP [1/5] | BTCH [2473/3634] ||| train_loss = 0.01662 ----
LR: [0.004507926834476018]
---- EP [1/5] | BTCH [2474/3634] ||| train_loss = 0.01816 ----
LR: [0.004510664945735801]
---- EP [1/5] | BTCH [2475/3634] ||| train_loss = 0.00825 ----
LR: [0.004513403286049168]
---- EP [1/5] | BTCH [2476/3634] ||| train_loss = 0.00929 ----
LR: [0.00451614185450622]
---- EP [1/5] | BTCH [2477/3634] ||| train_loss = 0.02103 ----
LR: [0.004518880650196978]
---- EP [1/5] | BTCH [2478/3634] ||| train_loss = 0.01357 ----
LR: [0.00452161967221139]
---- EP [1/5] | BTCH [2479/3634] ||| train_loss = 0.00918 ----
LR: [0.004524358919639332]
---- EP [1/5] | BTCH [2480/3634] ||| train_loss = 0.00868 ----
LR: [0.004527098391570595]
---- EP [1/5] | BTCH [2481/3634] ||| train_loss = 0.01180 ----
LR: [0.004529838087094906]
---- EP [1/5] | BTCH [2482/3634] ||| train_loss = 0.00632 ----
LR: [0.004532578005301913]
---- EP [1/5] | BTCH [2483/3634] ||| train_loss = 0.00964 ----
LR: [0.0045353181452811924]
---- EP [1/5] | BTCH [2484/3634] ||| train_loss = 0.01309 ----
LR: [0.004538058506122243]
---- EP [1/5] | BTCH [2485/3634] ||| train_loss = 0.01257 ----
LR: [0.004540799086914492]
---- EP [1/5] | BTCH [2486/3634] ||| train_loss = 0.01274 ----
LR: [0.004543539886747297]
---- EP [1/5] | BTCH [2487/3634] ||| train_loss = 0.00992 ----
LR: [0.004546280904709936]
---- EP [1/5] | BTCH [2488/3634] ||| train_loss = 0.00851 ----
LR: [0.004549022139891621]
---- EP [1/5] | BTCH [2489/3634] ||| train_loss = 0.01212 ----
LR: [0.0045517635913814875]
---- EP [1/5] | BTCH [2490/3634] ||| train_loss = 0.01593 ----
LR: [0.0045545052582686]
---- EP [1/5] | BTCH [2491/3634] ||| train_loss = 0.01684 ----
LR: [0.004557247139641954]
---- EP [1/5] | BTCH [2492/3634] ||| train_loss = 0.01264 ----
LR: [0.004559989234590472]
---- EP [1/5] | BTCH [2493/3634] ||| train_loss = 0.01173 ----
LR: [0.004562731542203004]
---- EP [1/5] | BTCH [2494/3634] ||| train_loss = 0.01846 ----
LR: [0.004565474061568332]
---- EP [1/5] | BTCH [2495/3634] ||| train_loss = 0.01331 ----
LR: [0.004568216791775163]
---- EP [1/5] | BTCH [2496/3634] ||| train_loss = 0.00949 ----
LR: [0.004570959731912143]
---- EP [1/5] | BTCH [2497/3634] ||| train_loss = 0.01265 ----
LR: [0.004573702881067838]
---- EP [1/5] | BTCH [2498/3634] ||| train_loss = 0.00863 ----
LR: [0.0045764462383307515]
---- EP [1/5] | BTCH [2499/3634] ||| train_loss = 0.00860 ----
LR: [0.004579189802789313]
---- EP [1/5] | BTCH [2500/3634] ||| train_loss = 0.00927 ----
LR: [0.0045819335735318885]
---- EP [1/5] | BTCH [2501/3634] ||| train_loss = 0.01743 ----
LR: [0.0045846775496467705]
---- EP [1/5] | BTCH [2502/3634] ||| train_loss = 0.01121 ----
LR: [0.004587421730222186]
---- EP [1/5] | BTCH [2503/3634] ||| train_loss = 0.01925 ----
LR: [0.004590166114346294]
---- EP [1/5] | BTCH [2504/3634] ||| train_loss = 0.01049 ----
LR: [0.004592910701107185]
---- EP [1/5] | BTCH [2505/3634] ||| train_loss = 0.01110 ----
LR: [0.00459565548959288]
---- EP [1/5] | BTCH [2506/3634] ||| train_loss = 0.01201 ----
LR: [0.00459840047889134]
---- EP [1/5] | BTCH [2507/3634] ||| train_loss = 0.00971 ----
LR: [0.004601145668090449]
---- EP [1/5] | BTCH [2508/3634] ||| train_loss = 0.01160 ----
LR: [0.004603891056278036]
---- EP [1/5] | BTCH [2509/3634] ||| train_loss = 0.00716 ----
LR: [0.004606636642541853]
---- EP [1/5] | BTCH [2510/3634] ||| train_loss = 0.01300 ----
LR: [0.004609382425969596]
---- EP [1/5] | BTCH [2511/3634] ||| train_loss = 0.01240 ----
LR: [0.004612128405648887]
---- EP [1/5] | BTCH [2512/3634] ||| train_loss = 0.00425 ----
LR: [0.004614874580667287]
---- EP [1/5] | BTCH [2513/3634] ||| train_loss = 0.01240 ----
LR: [0.0046176209501122955]
---- EP [1/5] | BTCH [2514/3634] ||| train_loss = 0.02287 ----
LR: [0.004620367513071339]
---- EP [1/5] | BTCH [2515/3634] ||| train_loss = 0.01318 ----
LR: [0.004623114268631785]
---- EP [1/5] | BTCH [2516/3634] ||| train_loss = 0.01270 ----
LR: [0.004625861215880938]
---- EP [1/5] | BTCH [2517/3634] ||| train_loss = 0.01219 ----
LR: [0.004628608353906037]
---- EP [1/5] | BTCH [2518/3634] ||| train_loss = 0.00706 ----
LR: [0.004631355681794257]
---- EP [1/5] | BTCH [2519/3634] ||| train_loss = 0.01385 ----
LR: [0.004634103198632709]
---- EP [1/5] | BTCH [2520/3634] ||| train_loss = 0.01224 ----
LR: [0.004636850903508445]
---- EP [1/5] | BTCH [2521/3634] ||| train_loss = 0.01183 ----
LR: [0.004639598795508452]
---- EP [1/5] | BTCH [2522/3634] ||| train_loss = 0.00719 ----
LR: [0.004642346873719653]
---- EP [1/5] | BTCH [2523/3634] ||| train_loss = 0.01549 ----
LR: [0.004645095137228917]
---- EP [1/5] | BTCH [2524/3634] ||| train_loss = 0.01676 ----
LR: [0.004647843585123039]
---- EP [1/5] | BTCH [2525/3634] ||| train_loss = 0.00769 ----
LR: [0.00465059221648876]
---- EP [1/5] | BTCH [2526/3634] ||| train_loss = 0.01221 ----
LR: [0.004653341030412765]
---- EP [1/5] | BTCH [2527/3634] ||| train_loss = 0.00963 ----
LR: [0.004656090025981668]
---- EP [1/5] | BTCH [2528/3634] ||| train_loss = 0.01225 ----
LR: [0.0046588392022820285]
---- EP [1/5] | BTCH [2529/3634] ||| train_loss = 0.01464 ----
LR: [0.004661588558400345]
---- EP [1/5] | BTCH [2530/3634] ||| train_loss = 0.01694 ----
LR: [0.004664338093423057]
---- EP [1/5] | BTCH [2531/3634] ||| train_loss = 0.00760 ----
LR: [0.004667087806436544]
---- EP [1/5] | BTCH [2532/3634] ||| train_loss = 0.02067 ----
LR: [0.004669837696527123]
---- EP [1/5] | BTCH [2533/3634] ||| train_loss = 0.01062 ----
LR: [0.004672587762781059]
---- EP [1/5] | BTCH [2534/3634] ||| train_loss = 0.00847 ----
VAL ||| loss = 0.013259905571852887, psnr = 30.77944564819336, ssim = 0.9085239171981812
LR: [0.00467533800428455]
---- EP [1/5] | BTCH [2535/3634] ||| train_loss = 0.01290 ----
LR: [0.004678088420123745]
---- EP [1/5] | BTCH [2536/3634] ||| train_loss = 0.00811 ----
LR: [0.004680839009384731]
---- EP [1/5] | BTCH [2537/3634] ||| train_loss = 0.01944 ----
LR: [0.0046835897711535335]
---- EP [1/5] | BTCH [2538/3634] ||| train_loss = 0.00985 ----
LR: [0.004686340704516124]
---- EP [1/5] | BTCH [2539/3634] ||| train_loss = 0.01148 ----
LR: [0.004689091808558419]
---- EP [1/5] | BTCH [2540/3634] ||| train_loss = 0.00948 ----
LR: [0.004691843082366275]
---- EP [1/5] | BTCH [2541/3634] ||| train_loss = 0.01790 ----
LR: [0.004694594525025495]
---- EP [1/5] | BTCH [2542/3634] ||| train_loss = 0.01224 ----
LR: [0.0046973461356218235]
---- EP [1/5] | BTCH [2543/3634] ||| train_loss = 0.01161 ----
LR: [0.00470009791324095]
---- EP [1/5] | BTCH [2544/3634] ||| train_loss = 0.01032 ----
LR: [0.004702849856968506]
---- EP [1/5] | BTCH [2545/3634] ||| train_loss = 0.01409 ----
LR: [0.004705601965890076]
---- EP [1/5] | BTCH [2546/3634] ||| train_loss = 0.01053 ----
LR: [0.00470835423909118]
---- EP [1/5] | BTCH [2547/3634] ||| train_loss = 0.01083 ----
LR: [0.004711106675657287]
---- EP [1/5] | BTCH [2548/3634] ||| train_loss = 0.00601 ----
LR: [0.004713859274673813]
---- EP [1/5] | BTCH [2549/3634] ||| train_loss = 0.01271 ----
LR: [0.00471661203522612]
---- EP [1/5] | BTCH [2550/3634] ||| train_loss = 0.01315 ----
LR: [0.004719364956399513]
---- EP [1/5] | BTCH [2551/3634] ||| train_loss = 0.01244 ----
LR: [0.004722118037279248]
---- EP [1/5] | BTCH [2552/3634] ||| train_loss = 0.01136 ----
LR: [0.004724871276950527]
---- EP [1/5] | BTCH [2553/3634] ||| train_loss = 0.01278 ----
LR: [0.004727624674498497]
---- EP [1/5] | BTCH [2554/3634] ||| train_loss = 0.00918 ----
LR: [0.00473037822900825]
---- EP [1/5] | BTCH [2555/3634] ||| train_loss = 0.00988 ----
LR: [0.004733131939564836]
---- EP [1/5] | BTCH [2556/3634] ||| train_loss = 0.01366 ----
LR: [0.004735885805253245]
---- EP [1/5] | BTCH [2557/3634] ||| train_loss = 0.01408 ----
LR: [0.004738639825158413]
---- EP [1/5] | BTCH [2558/3634] ||| train_loss = 0.00562 ----
LR: [0.004741393998365233]
---- EP [1/5] | BTCH [2559/3634] ||| train_loss = 0.02085 ----
LR: [0.004744148323958542]
---- EP [1/5] | BTCH [2560/3634] ||| train_loss = 0.01613 ----
LR: [0.004746902801023127]
---- EP [1/5] | BTCH [2561/3634] ||| train_loss = 0.00957 ----
LR: [0.0047496574286437256]
---- EP [1/5] | BTCH [2562/3634] ||| train_loss = 0.02317 ----
LR: [0.004752412205905024]
---- EP [1/5] | BTCH [2563/3634] ||| train_loss = 0.01115 ----
LR: [0.004755167131891662]
---- EP [1/5] | BTCH [2564/3634] ||| train_loss = 0.01019 ----
LR: [0.004757922205688222]
---- EP [1/5] | BTCH [2565/3634] ||| train_loss = 0.01168 ----
LR: [0.004760677426379248]
---- EP [1/5] | BTCH [2566/3634] ||| train_loss = 0.01154 ----
LR: [0.00476343279304923]
---- EP [1/5] | BTCH [2567/3634] ||| train_loss = 0.02241 ----
LR: [0.004766188304782606]
---- EP [1/5] | BTCH [2568/3634] ||| train_loss = 0.01692 ----
LR: [0.00476894396066377]
---- EP [1/5] | BTCH [2569/3634] ||| train_loss = 0.02218 ----
LR: [0.004771699759777069]
---- EP [1/5] | BTCH [2570/3634] ||| train_loss = 0.01850 ----
LR: [0.0047744557012068]
---- EP [1/5] | BTCH [2571/3634] ||| train_loss = 0.01201 ----
LR: [0.004777211784037213]
---- EP [1/5] | BTCH [2572/3634] ||| train_loss = 0.01653 ----
LR: [0.004779968007352511]
---- EP [1/5] | BTCH [2573/3634] ||| train_loss = 0.00652 ----
LR: [0.004782724370236854]
---- EP [1/5] | BTCH [2574/3634] ||| train_loss = 0.01540 ----
LR: [0.004785480871774347]
---- EP [1/5] | BTCH [2575/3634] ||| train_loss = 0.01130 ----
LR: [0.004788237511049059]
---- EP [1/5] | BTCH [2576/3634] ||| train_loss = 0.00973 ----
LR: [0.004790994287145009]
---- EP [1/5] | BTCH [2577/3634] ||| train_loss = 0.01220 ----
LR: [0.0047937511991461654]
---- EP [1/5] | BTCH [2578/3634] ||| train_loss = 0.01072 ----
LR: [0.00479650824613646]
---- EP [1/5] | BTCH [2579/3634] ||| train_loss = 0.00931 ----
LR: [0.004799265427199773]
---- EP [1/5] | BTCH [2580/3634] ||| train_loss = 0.01211 ----
LR: [0.004802022741419946]
---- EP [1/5] | BTCH [2581/3634] ||| train_loss = 0.01678 ----
LR: [0.0048047801878807715]
---- EP [1/5] | BTCH [2582/3634] ||| train_loss = 0.01479 ----
LR: [0.004807537765666]
---- EP [1/5] | BTCH [2583/3634] ||| train_loss = 0.01075 ----
LR: [0.004810295473859341]
---- EP [1/5] | BTCH [2584/3634] ||| train_loss = 0.01180 ----
LR: [0.004813053311544451]
---- EP [1/5] | BTCH [2585/3634] ||| train_loss = 0.01545 ----
LR: [0.0048158112778049576]
---- EP [1/5] | BTCH [2586/3634] ||| train_loss = 0.01429 ----
LR: [0.004818569371724437]
---- EP [1/5] | BTCH [2587/3634] ||| train_loss = 0.01944 ----
LR: [0.00482132759238642]
---- EP [1/5] | BTCH [2588/3634] ||| train_loss = 0.01276 ----
LR: [0.004824085938874405]
---- EP [1/5] | BTCH [2589/3634] ||| train_loss = 0.00975 ----
LR: [0.004826844410271839]
---- EP [1/5] | BTCH [2590/3634] ||| train_loss = 0.01483 ----
LR: [0.004829603005662135]
---- EP [1/5] | BTCH [2591/3634] ||| train_loss = 0.01331 ----
LR: [0.004832361724128661]
---- EP [1/5] | BTCH [2592/3634] ||| train_loss = 0.02195 ----
LR: [0.004835120564754742]
---- EP [1/5] | BTCH [2593/3634] ||| train_loss = 0.01102 ----
LR: [0.004837879526623669]
---- EP [1/5] | BTCH [2594/3634] ||| train_loss = 0.01850 ----
LR: [0.004840638608818687]
---- EP [1/5] | BTCH [2595/3634] ||| train_loss = 0.01021 ----
LR: [0.004843397810423002]
---- EP [1/5] | BTCH [2596/3634] ||| train_loss = 0.01358 ----
LR: [0.004846157130519784]
---- EP [1/5] | BTCH [2597/3634] ||| train_loss = 0.01111 ----
LR: [0.004848916568192157]
---- EP [1/5] | BTCH [2598/3634] ||| train_loss = 0.01653 ----
LR: [0.004851676122523211]
---- EP [1/5] | BTCH [2599/3634] ||| train_loss = 0.00700 ----
LR: [0.004854435792595998]
---- EP [1/5] | BTCH [2600/3634] ||| train_loss = 0.00977 ----
LR: [0.004857195577493527]
---- EP [1/5] | BTCH [2601/3634] ||| train_loss = 0.00579 ----
LR: [0.004859955476298773]
---- EP [1/5] | BTCH [2602/3634] ||| train_loss = 0.00677 ----
LR: [0.004862715488094669]
---- EP [1/5] | BTCH [2603/3634] ||| train_loss = 0.01177 ----
LR: [0.004865475611964116]
---- EP [1/5] | BTCH [2604/3634] ||| train_loss = 0.00722 ----
LR: [0.004868235846989974]
---- EP [1/5] | BTCH [2605/3634] ||| train_loss = 0.01328 ----
LR: [0.004870996192255065]
---- EP [1/5] | BTCH [2606/3634] ||| train_loss = 0.00468 ----
LR: [0.00487375664684218]
---- EP [1/5] | BTCH [2607/3634] ||| train_loss = 0.01574 ----
LR: [0.0048765172098340645]
---- EP [1/5] | BTCH [2608/3634] ||| train_loss = 0.01237 ----
LR: [0.004879277880313436]
---- EP [1/5] | BTCH [2609/3634] ||| train_loss = 0.01464 ----
LR: [0.004882038657362975]
---- EP [1/5] | BTCH [2610/3634] ||| train_loss = 0.01092 ----
LR: [0.004884799540065322]
---- EP [1/5] | BTCH [2611/3634] ||| train_loss = 0.00740 ----
LR: [0.004887560527503089]
---- EP [1/5] | BTCH [2612/3634] ||| train_loss = 0.00670 ----
LR: [0.004890321618758847]
---- EP [1/5] | BTCH [2613/3634] ||| train_loss = 0.01141 ----
LR: [0.004893082812915136]
---- EP [1/5] | BTCH [2614/3634] ||| train_loss = 0.02125 ----
LR: [0.004895844109054462]
---- EP [1/5] | BTCH [2615/3634] ||| train_loss = 0.00816 ----
LR: [0.004898605506259295]
---- EP [1/5] | BTCH [2616/3634] ||| train_loss = 0.01223 ----
LR: [0.004901367003612074]
---- EP [1/5] | BTCH [2617/3634] ||| train_loss = 0.01523 ----
LR: [0.0049041286001952015]
---- EP [1/5] | BTCH [2618/3634] ||| train_loss = 0.00904 ----
LR: [0.00490689029509105]
---- EP [1/5] | BTCH [2619/3634] ||| train_loss = 0.00990 ----
LR: [0.004909652087381958]
---- EP [1/5] | BTCH [2620/3634] ||| train_loss = 0.01222 ----
LR: [0.004912413976150232]
---- EP [1/5] | BTCH [2621/3634] ||| train_loss = 0.01440 ----
LR: [0.004915175960478146]
---- EP [1/5] | BTCH [2622/3634] ||| train_loss = 0.01409 ----
LR: [0.004917938039447942]
---- EP [1/5] | BTCH [2623/3634] ||| train_loss = 0.01811 ----
LR: [0.004920700212141832]
---- EP [1/5] | BTCH [2624/3634] ||| train_loss = 0.00819 ----
LR: [0.004923462477641995]
---- EP [1/5] | BTCH [2625/3634] ||| train_loss = 0.00933 ----
LR: [0.004926224835030581]
---- EP [1/5] | BTCH [2626/3634] ||| train_loss = 0.01638 ----
LR: [0.004928987283389709]
---- EP [1/5] | BTCH [2627/3634] ||| train_loss = 0.01007 ----
LR: [0.0049317498218014654]
---- EP [1/5] | BTCH [2628/3634] ||| train_loss = 0.01248 ----
LR: [0.004934512449347909]
---- EP [1/5] | BTCH [2629/3634] ||| train_loss = 0.00858 ----
LR: [0.004937275165111071]
---- EP [1/5] | BTCH [2630/3634] ||| train_loss = 0.00987 ----
LR: [0.0049400379681729485]
---- EP [1/5] | BTCH [2631/3634] ||| train_loss = 0.01369 ----
LR: [0.004942800857615512]
---- EP [1/5] | BTCH [2632/3634] ||| train_loss = 0.01092 ----
LR: [0.0049455638325207035]
---- EP [1/5] | BTCH [2633/3634] ||| train_loss = 0.01198 ----
LR: [0.004948326891970437]
---- EP [1/5] | BTCH [2634/3634] ||| train_loss = 0.01177 ----
LR: [0.0049510900350465984]
---- EP [1/5] | BTCH [2635/3634] ||| train_loss = 0.01556 ----
LR: [0.004953853260831043]
---- EP [1/5] | BTCH [2636/3634] ||| train_loss = 0.01310 ----
LR: [0.004956616568405604]
---- EP [1/5] | BTCH [2637/3634] ||| train_loss = 0.01046 ----
LR: [0.004959379956852081]
---- EP [1/5] | BTCH [2638/3634] ||| train_loss = 0.01120 ----
LR: [0.00496214342525225]
---- EP [1/5] | BTCH [2639/3634] ||| train_loss = 0.01206 ----
LR: [0.004964906972687863]
---- EP [1/5] | BTCH [2640/3634] ||| train_loss = 0.00772 ----
LR: [0.004967670598240641]
---- EP [1/5] | BTCH [2641/3634] ||| train_loss = 0.01146 ----
LR: [0.004970434300992282]
---- EP [1/5] | BTCH [2642/3634] ||| train_loss = 0.01045 ----
LR: [0.0049731980800244565]
---- EP [1/5] | BTCH [2643/3634] ||| train_loss = 0.00661 ----
LR: [0.004975961934418812]
---- EP [1/5] | BTCH [2644/3634] ||| train_loss = 0.01000 ----
LR: [0.00497872586325697]
---- EP [1/5] | BTCH [2645/3634] ||| train_loss = 0.00716 ----
LR: [0.004981489865620524]
---- EP [1/5] | BTCH [2646/3634] ||| train_loss = 0.01199 ----
LR: [0.0049842539405910505]
---- EP [1/5] | BTCH [2647/3634] ||| train_loss = 0.00803 ----
LR: [0.004987018087250093]
---- EP [1/5] | BTCH [2648/3634] ||| train_loss = 0.01735 ----
LR: [0.004989782304679178]
---- EP [1/5] | BTCH [2649/3634] ||| train_loss = 0.01291 ----
LR: [0.004992546591959805]
---- EP [1/5] | BTCH [2650/3634] ||| train_loss = 0.01258 ----
LR: [0.0049953109481734505]
---- EP [1/5] | BTCH [2651/3634] ||| train_loss = 0.01153 ----
LR: [0.004998075372401572]
---- EP [1/5] | BTCH [2652/3634] ||| train_loss = 0.02100 ----
LR: [0.005000839863725598]
---- EP [1/5] | BTCH [2653/3634] ||| train_loss = 0.01986 ----
LR: [0.005003604421226938]
---- EP [1/5] | BTCH [2654/3634] ||| train_loss = 0.01126 ----
LR: [0.005006369043986982]
---- EP [1/5] | BTCH [2655/3634] ||| train_loss = 0.01495 ----
LR: [0.005009133731087094]
---- EP [1/5] | BTCH [2656/3634] ||| train_loss = 0.01559 ----
LR: [0.005011898481608621]
---- EP [1/5] | BTCH [2657/3634] ||| train_loss = 0.01524 ----
LR: [0.005014663294632881]
---- EP [1/5] | BTCH [2658/3634] ||| train_loss = 0.00939 ----
LR: [0.00501742816924118]
---- EP [1/5] | BTCH [2659/3634] ||| train_loss = 0.01402 ----
LR: [0.005020193104514802]
---- EP [1/5] | BTCH [2660/3634] ||| train_loss = 0.01240 ----
LR: [0.005022958099535005]
---- EP [1/5] | BTCH [2661/3634] ||| train_loss = 0.00743 ----
LR: [0.005025723153383035]
---- EP [1/5] | BTCH [2662/3634] ||| train_loss = 0.01762 ----
LR: [0.005028488265140111]
---- EP [1/5] | BTCH [2663/3634] ||| train_loss = 0.00789 ----
LR: [0.005031253433887438]
---- EP [1/5] | BTCH [2664/3634] ||| train_loss = 0.01277 ----
LR: [0.005034018658706201]
---- EP [1/5] | BTCH [2665/3634] ||| train_loss = 0.01258 ----
LR: [0.005036783938677564]
---- EP [1/5] | BTCH [2666/3634] ||| train_loss = 0.01208 ----
LR: [0.005039549272882677]
---- EP [1/5] | BTCH [2667/3634] ||| train_loss = 0.00873 ----
LR: [0.005042314660402667]
---- EP [1/5] | BTCH [2668/3634] ||| train_loss = 0.00650 ----
LR: [0.005045080100318644]
---- EP [1/5] | BTCH [2669/3634] ||| train_loss = 0.01165 ----
LR: [0.005047845591711709]
---- EP [1/5] | BTCH [2670/3634] ||| train_loss = 0.00863 ----
LR: [0.005050611133662933]
---- EP [1/5] | BTCH [2671/3634] ||| train_loss = 0.01479 ----
LR: [0.005053376725253378]
---- EP [1/5] | BTCH [2672/3634] ||| train_loss = 0.00940 ----
LR: [0.005056142365564088]
---- EP [1/5] | BTCH [2673/3634] ||| train_loss = 0.01333 ----
LR: [0.005058908053676092]
---- EP [1/5] | BTCH [2674/3634] ||| train_loss = 0.01397 ----
LR: [0.005061673788670401]
---- EP [1/5] | BTCH [2675/3634] ||| train_loss = 0.00920 ----
LR: [0.005064439569628008]
---- EP [1/5] | BTCH [2676/3634] ||| train_loss = 0.01275 ----
LR: [0.0050672053956299]
---- EP [1/5] | BTCH [2677/3634] ||| train_loss = 0.01187 ----
LR: [0.00506997126575704]
---- EP [1/5] | BTCH [2678/3634] ||| train_loss = 0.01445 ----
LR: [0.005072737179090377]
---- EP [1/5] | BTCH [2679/3634] ||| train_loss = 0.00987 ----
LR: [0.005075503134710852]
---- EP [1/5] | BTCH [2680/3634] ||| train_loss = 0.01086 ----
LR: [0.005078269131699386]
---- EP [1/5] | BTCH [2681/3634] ||| train_loss = 0.00838 ----
LR: [0.005081035169136887]
---- EP [1/5] | BTCH [2682/3634] ||| train_loss = 0.02597 ----
LR: [0.005083801246104253]
---- EP [1/5] | BTCH [2683/3634] ||| train_loss = 0.01185 ----
LR: [0.005086567361682365]
---- EP [1/5] | BTCH [2684/3634] ||| train_loss = 0.00941 ----
LR: [0.0050893335149520946]
---- EP [1/5] | BTCH [2685/3634] ||| train_loss = 0.01315 ----
LR: [0.005092099704994296]
---- EP [1/5] | BTCH [2686/3634] ||| train_loss = 0.00839 ----
LR: [0.005094865930889819]
---- EP [1/5] | BTCH [2687/3634] ||| train_loss = 0.00836 ----
LR: [0.00509763219171949]
---- EP [1/5] | BTCH [2688/3634] ||| train_loss = 0.01361 ----
LR: [0.005100398486564135]
---- EP [1/5] | BTCH [2689/3634] ||| train_loss = 0.01015 ----
LR: [0.0051031648145045665]
---- EP [1/5] | BTCH [2690/3634] ||| train_loss = 0.01854 ----
LR: [0.005105931174621579]
---- EP [1/5] | BTCH [2691/3634] ||| train_loss = 0.01025 ----
LR: [0.005108697565995962]
---- EP [1/5] | BTCH [2692/3634] ||| train_loss = 0.01512 ----
LR: [0.005111463987708494]
---- EP [1/5] | BTCH [2693/3634] ||| train_loss = 0.00795 ----
LR: [0.0051142304388399435]
---- EP [1/5] | BTCH [2694/3634] ||| train_loss = 0.01069 ----
LR: [0.005116996918471069]
---- EP [1/5] | BTCH [2695/3634] ||| train_loss = 0.00808 ----
LR: [0.00511976342568262]
---- EP [1/5] | BTCH [2696/3634] ||| train_loss = 0.01477 ----
LR: [0.005122529959555334]
---- EP [1/5] | BTCH [2697/3634] ||| train_loss = 0.01413 ----
LR: [0.005125296519169942]
---- EP [1/5] | BTCH [2698/3634] ||| train_loss = 0.01019 ----
LR: [0.0051280631036071675]
---- EP [1/5] | BTCH [2699/3634] ||| train_loss = 0.01884 ----
LR: [0.005130829711947725]
---- EP [1/5] | BTCH [2700/3634] ||| train_loss = 0.01195 ----
LR: [0.005133596343272319]
---- EP [1/5] | BTCH [2701/3634] ||| train_loss = 0.01064 ----
LR: [0.005136362996661649]
---- EP [1/5] | BTCH [2702/3634] ||| train_loss = 0.01461 ----
LR: [0.005139129671196404]
---- EP [1/5] | BTCH [2703/3634] ||| train_loss = 0.01635 ----
LR: [0.0051418963659572705]
---- EP [1/5] | BTCH [2704/3634] ||| train_loss = 0.01230 ----
LR: [0.005144663080024926]
---- EP [1/5] | BTCH [2705/3634] ||| train_loss = 0.01232 ----
LR: [0.005147429812480038]
---- EP [1/5] | BTCH [2706/3634] ||| train_loss = 0.00913 ----
LR: [0.005150196562403275]
---- EP [1/5] | BTCH [2707/3634] ||| train_loss = 0.02216 ----
LR: [0.005152963328875293]
---- EP [1/5] | BTCH [2708/3634] ||| train_loss = 0.01424 ----
LR: [0.0051557301109767485]
---- EP [1/5] | BTCH [2709/3634] ||| train_loss = 0.02124 ----
LR: [0.005158496907788289]
---- EP [1/5] | BTCH [2710/3634] ||| train_loss = 0.01702 ----
LR: [0.005161263718390556]
---- EP [1/5] | BTCH [2711/3634] ||| train_loss = 0.01521 ----
LR: [0.00516403054186419]
---- EP [1/5] | BTCH [2712/3634] ||| train_loss = 0.00746 ----
LR: [0.005166797377289825]
---- EP [1/5] | BTCH [2713/3634] ||| train_loss = 0.01313 ----
LR: [0.005169564223748091]
---- EP [1/5] | BTCH [2714/3634] ||| train_loss = 0.01110 ----
LR: [0.005172331080319616]
---- EP [1/5] | BTCH [2715/3634] ||| train_loss = 0.00940 ----
VAL ||| loss = 0.013345708154262073, psnr = 30.75792121887207, ssim = 0.907587468624115
LR: [0.005175097946085023]
---- EP [1/5] | BTCH [2716/3634] ||| train_loss = 0.01424 ----
LR: [0.005177864820124934]
---- EP [1/5] | BTCH [2717/3634] ||| train_loss = 0.00968 ----
LR: [0.005180631701519963]
---- EP [1/5] | BTCH [2718/3634] ||| train_loss = 0.01174 ----
LR: [0.0051833985893507285]
---- EP [1/5] | BTCH [2719/3634] ||| train_loss = 0.02102 ----
LR: [0.005186165482697844]
---- EP [1/5] | BTCH [2720/3634] ||| train_loss = 0.01698 ----
LR: [0.005188932380641919]
---- EP [1/5] | BTCH [2721/3634] ||| train_loss = 0.01058 ----
LR: [0.005191699282263563]
---- EP [1/5] | BTCH [2722/3634] ||| train_loss = 0.01042 ----
LR: [0.0051944661866433865]
---- EP [1/5] | BTCH [2723/3634] ||| train_loss = 0.01154 ----
LR: [0.005197233092861997]
---- EP [1/5] | BTCH [2724/3634] ||| train_loss = 0.01145 ----
LR: [0.0052]
---- EP [1/5] | BTCH [2725/3634] ||| train_loss = 0.00998 ----
LR: [0.005202766907138003]
---- EP [1/5] | BTCH [2726/3634] ||| train_loss = 0.00905 ----
LR: [0.005205533813356612]
---- EP [1/5] | BTCH [2727/3634] ||| train_loss = 0.00988 ----
LR: [0.005208300717736435]
---- EP [1/5] | BTCH [2728/3634] ||| train_loss = 0.02190 ----
LR: [0.005211067619358081]
---- EP [1/5] | BTCH [2729/3634] ||| train_loss = 0.00603 ----
LR: [0.005213834517302154]
---- EP [1/5] | BTCH [2730/3634] ||| train_loss = 0.00952 ----
LR: [0.00521660141064927]
---- EP [1/5] | BTCH [2731/3634] ||| train_loss = 0.01835 ----
LR: [0.005219368298480036]
---- EP [1/5] | BTCH [2732/3634] ||| train_loss = 0.00688 ----
LR: [0.005222135179875065]
---- EP [1/5] | BTCH [2733/3634] ||| train_loss = 0.01298 ----
LR: [0.005224902053914976]
---- EP [1/5] | BTCH [2734/3634] ||| train_loss = 0.00820 ----
LR: [0.005227668919680382]
---- EP [1/5] | BTCH [2735/3634] ||| train_loss = 0.02551 ----
LR: [0.005230435776251908]
---- EP [1/5] | BTCH [2736/3634] ||| train_loss = 0.01404 ----
LR: [0.005233202622710174]
---- EP [1/5] | BTCH [2737/3634] ||| train_loss = 0.01086 ----
LR: [0.00523596945813581]
---- EP [1/5] | BTCH [2738/3634] ||| train_loss = 0.01909 ----
LR: [0.005238736281609443]
---- EP [1/5] | BTCH [2739/3634] ||| train_loss = 0.02172 ----
LR: [0.005241503092211711]
---- EP [1/5] | BTCH [2740/3634] ||| train_loss = 0.00981 ----
LR: [0.005244269889023249]
---- EP [1/5] | BTCH [2741/3634] ||| train_loss = 0.00871 ----
LR: [0.005247036671124705]
---- EP [1/5] | BTCH [2742/3634] ||| train_loss = 0.00846 ----
LR: [0.005249803437596724]
---- EP [1/5] | BTCH [2743/3634] ||| train_loss = 0.00904 ----
LR: [0.0052525701875199594]
---- EP [1/5] | BTCH [2744/3634] ||| train_loss = 0.01177 ----
LR: [0.005255336919975074]
---- EP [1/5] | BTCH [2745/3634] ||| train_loss = 0.00949 ----
LR: [0.005258103634042729]
---- EP [1/5] | BTCH [2746/3634] ||| train_loss = 0.00959 ----
LR: [0.0052608703288035946]
---- EP [1/5] | BTCH [2747/3634] ||| train_loss = 0.01863 ----
LR: [0.00526363700333835]
---- EP [1/5] | BTCH [2748/3634] ||| train_loss = 0.01079 ----
LR: [0.00526640365672768]
---- EP [1/5] | BTCH [2749/3634] ||| train_loss = 0.01473 ----
LR: [0.005269170288052273]
---- EP [1/5] | BTCH [2750/3634] ||| train_loss = 0.01593 ----
LR: [0.005271936896392831]
---- EP [1/5] | BTCH [2751/3634] ||| train_loss = 0.01736 ----
LR: [0.005274703480830058]
---- EP [1/5] | BTCH [2752/3634] ||| train_loss = 0.01126 ----
LR: [0.005277470040444665]
---- EP [1/5] | BTCH [2753/3634] ||| train_loss = 0.01353 ----
LR: [0.00528023657431738]
---- EP [1/5] | BTCH [2754/3634] ||| train_loss = 0.01246 ----
LR: [0.005283003081528928]
---- EP [1/5] | BTCH [2755/3634] ||| train_loss = 0.01020 ----
LR: [0.005285769561160055]
---- EP [1/5] | BTCH [2756/3634] ||| train_loss = 0.00574 ----
LR: [0.0052885360122915046]
---- EP [1/5] | BTCH [2757/3634] ||| train_loss = 0.01696 ----
LR: [0.005291302434004037]
---- EP [1/5] | BTCH [2758/3634] ||| train_loss = 0.00816 ----
LR: [0.005294068825378421]
---- EP [1/5] | BTCH [2759/3634] ||| train_loss = 0.00867 ----
LR: [0.005296835185495434]
---- EP [1/5] | BTCH [2760/3634] ||| train_loss = 0.01571 ----
LR: [0.005299601513435862]
---- EP [1/5] | BTCH [2761/3634] ||| train_loss = 0.01225 ----
LR: [0.005302367808280509]
---- EP [1/5] | BTCH [2762/3634] ||| train_loss = 0.01058 ----
LR: [0.0053051340691101815]
---- EP [1/5] | BTCH [2763/3634] ||| train_loss = 0.01408 ----
LR: [0.005307900295005701]
---- EP [1/5] | BTCH [2764/3634] ||| train_loss = 0.01128 ----
LR: [0.005310666485047905]
---- EP [1/5] | BTCH [2765/3634] ||| train_loss = 0.01634 ----
LR: [0.005313432638317635]
---- EP [1/5] | BTCH [2766/3634] ||| train_loss = 0.00913 ----
LR: [0.005316198753895746]
---- EP [1/5] | BTCH [2767/3634] ||| train_loss = 0.01173 ----
LR: [0.005318964830863112]
---- EP [1/5] | BTCH [2768/3634] ||| train_loss = 0.01202 ----
LR: [0.005321730868300614]
---- EP [1/5] | BTCH [2769/3634] ||| train_loss = 0.01840 ----
LR: [0.0053244968652891465]
---- EP [1/5] | BTCH [2770/3634] ||| train_loss = 0.01063 ----
LR: [0.005327262820909622]
---- EP [1/5] | BTCH [2771/3634] ||| train_loss = 0.01643 ----
LR: [0.0053300287342429595]
---- EP [1/5] | BTCH [2772/3634] ||| train_loss = 0.01251 ----
LR: [0.0053327946043700974]
---- EP [1/5] | BTCH [2773/3634] ||| train_loss = 0.01227 ----
LR: [0.005335560430371989]
---- EP [1/5] | BTCH [2774/3634] ||| train_loss = 0.01721 ----
LR: [0.005338326211329598]
---- EP [1/5] | BTCH [2775/3634] ||| train_loss = 0.00758 ----
LR: [0.005341091946323907]
---- EP [1/5] | BTCH [2776/3634] ||| train_loss = 0.01075 ----
LR: [0.0053438576344359105]
---- EP [1/5] | BTCH [2777/3634] ||| train_loss = 0.01491 ----
LR: [0.00534662327474662]
---- EP [1/5] | BTCH [2778/3634] ||| train_loss = 0.01202 ----
LR: [0.005349388866337066]
---- EP [1/5] | BTCH [2779/3634] ||| train_loss = 0.01558 ----
LR: [0.005352154408288291]
---- EP [1/5] | BTCH [2780/3634] ||| train_loss = 0.00989 ----
LR: [0.005354919899681353]
---- EP [1/5] | BTCH [2781/3634] ||| train_loss = 0.01024 ----
LR: [0.005357685339597332]
---- EP [1/5] | BTCH [2782/3634] ||| train_loss = 0.01643 ----
LR: [0.005360450727117323]
---- EP [1/5] | BTCH [2783/3634] ||| train_loss = 0.01317 ----
LR: [0.005363216061322434]
---- EP [1/5] | BTCH [2784/3634] ||| train_loss = 0.00972 ----
LR: [0.0053659813412937985]
---- EP [1/5] | BTCH [2785/3634] ||| train_loss = 0.01493 ----
LR: [0.005368746566112561]
---- EP [1/5] | BTCH [2786/3634] ||| train_loss = 0.01784 ----
LR: [0.005371511734859888]
---- EP [1/5] | BTCH [2787/3634] ||| train_loss = 0.00750 ----
LR: [0.005374276846616964]
---- EP [1/5] | BTCH [2788/3634] ||| train_loss = 0.01445 ----
LR: [0.005377041900464994]
---- EP [1/5] | BTCH [2789/3634] ||| train_loss = 0.00696 ----
LR: [0.005379806895485196]
---- EP [1/5] | BTCH [2790/3634] ||| train_loss = 0.01525 ----
LR: [0.0053825718307588186]
---- EP [1/5] | BTCH [2791/3634] ||| train_loss = 0.01994 ----
LR: [0.005385336705367119]
---- EP [1/5] | BTCH [2792/3634] ||| train_loss = 0.01101 ----
LR: [0.005388101518391379]
---- EP [1/5] | BTCH [2793/3634] ||| train_loss = 0.00874 ----
LR: [0.005390866268912905]
---- EP [1/5] | BTCH [2794/3634] ||| train_loss = 0.01210 ----
LR: [0.005393630956013016]
---- EP [1/5] | BTCH [2795/3634] ||| train_loss = 0.00870 ----
LR: [0.005396395578773061]
---- EP [1/5] | BTCH [2796/3634] ||| train_loss = 0.01739 ----
LR: [0.0053991601362744016]
---- EP [1/5] | BTCH [2797/3634] ||| train_loss = 0.01022 ----
LR: [0.005401924627598426]
---- EP [1/5] | BTCH [2798/3634] ||| train_loss = 0.02070 ----
LR: [0.005404689051826548]
---- EP [1/5] | BTCH [2799/3634] ||| train_loss = 0.01597 ----
LR: [0.005407453408040195]
---- EP [1/5] | BTCH [2800/3634] ||| train_loss = 0.01489 ----
LR: [0.005410217695320821]
---- EP [1/5] | BTCH [2801/3634] ||| train_loss = 0.00790 ----
LR: [0.005412981912749906]
---- EP [1/5] | BTCH [2802/3634] ||| train_loss = 0.01112 ----
LR: [0.005415746059408949]
---- EP [1/5] | BTCH [2803/3634] ||| train_loss = 0.01780 ----
LR: [0.005418510134379473]
---- EP [1/5] | BTCH [2804/3634] ||| train_loss = 0.01484 ----
LR: [0.0054212741367430295]
---- EP [1/5] | BTCH [2805/3634] ||| train_loss = 0.01225 ----
LR: [0.005424038065581187]
---- EP [1/5] | BTCH [2806/3634] ||| train_loss = 0.00923 ----
LR: [0.005426801919975543]
---- EP [1/5] | BTCH [2807/3634] ||| train_loss = 0.00954 ----
LR: [0.005429565699007718]
---- EP [1/5] | BTCH [2808/3634] ||| train_loss = 0.01368 ----
LR: [0.00543232940175936]
---- EP [1/5] | BTCH [2809/3634] ||| train_loss = 0.01407 ----
LR: [0.005435093027312136]
---- EP [1/5] | BTCH [2810/3634] ||| train_loss = 0.01132 ----
LR: [0.00543785657474775]
---- EP [1/5] | BTCH [2811/3634] ||| train_loss = 0.00892 ----
LR: [0.0054406200431479194]
---- EP [1/5] | BTCH [2812/3634] ||| train_loss = 0.01195 ----
LR: [0.005443383431594395]
---- EP [1/5] | BTCH [2813/3634] ||| train_loss = 0.01360 ----
LR: [0.005446146739168955]
---- EP [1/5] | BTCH [2814/3634] ||| train_loss = 0.01734 ----
LR: [0.005448909964953399]
---- EP [1/5] | BTCH [2815/3634] ||| train_loss = 0.01009 ----
LR: [0.005451673108029561]
---- EP [1/5] | BTCH [2816/3634] ||| train_loss = 0.00941 ----
LR: [0.005454436167479294]
---- EP [1/5] | BTCH [2817/3634] ||| train_loss = 0.01211 ----
LR: [0.0054571991423844855]
---- EP [1/5] | BTCH [2818/3634] ||| train_loss = 0.01864 ----
LR: [0.005459962031827051]
---- EP [1/5] | BTCH [2819/3634] ||| train_loss = 0.01070 ----
LR: [0.005462724834888929]
---- EP [1/5] | BTCH [2820/3634] ||| train_loss = 0.00911 ----
LR: [0.005465487550652089]
---- EP [1/5] | BTCH [2821/3634] ||| train_loss = 0.01326 ----
LR: [0.005468250178198533]
---- EP [1/5] | BTCH [2822/3634] ||| train_loss = 0.01194 ----
LR: [0.005471012716610291]
---- EP [1/5] | BTCH [2823/3634] ||| train_loss = 0.01739 ----
LR: [0.005473775164969417]
---- EP [1/5] | BTCH [2824/3634] ||| train_loss = 0.01114 ----
LR: [0.005476537522358004]
---- EP [1/5] | BTCH [2825/3634] ||| train_loss = 0.00671 ----
LR: [0.005479299787858168]
---- EP [1/5] | BTCH [2826/3634] ||| train_loss = 0.01270 ----
LR: [0.005482061960552056]
---- EP [1/5] | BTCH [2827/3634] ||| train_loss = 0.00839 ----
LR: [0.005484824039521854]
---- EP [1/5] | BTCH [2828/3634] ||| train_loss = 0.00842 ----
LR: [0.0054875860238497685]
---- EP [1/5] | BTCH [2829/3634] ||| train_loss = 0.00952 ----
LR: [0.005490347912618041]
---- EP [1/5] | BTCH [2830/3634] ||| train_loss = 0.01489 ----
LR: [0.005493109704908949]
---- EP [1/5] | BTCH [2831/3634] ||| train_loss = 0.00756 ----
LR: [0.005495871399804798]
---- EP [1/5] | BTCH [2832/3634] ||| train_loss = 0.01396 ----
LR: [0.005498632996387924]
---- EP [1/5] | BTCH [2833/3634] ||| train_loss = 0.00793 ----
LR: [0.005501394493740704]
---- EP [1/5] | BTCH [2834/3634] ||| train_loss = 0.00868 ----
LR: [0.005504155890945536]
---- EP [1/5] | BTCH [2835/3634] ||| train_loss = 0.01335 ----
LR: [0.005506917187084862]
---- EP [1/5] | BTCH [2836/3634] ||| train_loss = 0.01152 ----
LR: [0.005509678381241152]
---- EP [1/5] | BTCH [2837/3634] ||| train_loss = 0.01025 ----
LR: [0.005512439472496909]
---- EP [1/5] | BTCH [2838/3634] ||| train_loss = 0.01195 ----
LR: [0.005515200459934676]
---- EP [1/5] | BTCH [2839/3634] ||| train_loss = 0.01005 ----
LR: [0.005517961342637026]
---- EP [1/5] | BTCH [2840/3634] ||| train_loss = 0.01708 ----
LR: [0.0055207221196865615]
---- EP [1/5] | BTCH [2841/3634] ||| train_loss = 0.00532 ----
LR: [0.005523482790165934]
---- EP [1/5] | BTCH [2842/3634] ||| train_loss = 0.00827 ----
LR: [0.00552624335315782]
---- EP [1/5] | BTCH [2843/3634] ||| train_loss = 0.01153 ----
LR: [0.005529003807744932]
---- EP [1/5] | BTCH [2844/3634] ||| train_loss = 0.01231 ----
LR: [0.005531764153010025]
---- EP [1/5] | BTCH [2845/3634] ||| train_loss = 0.01959 ----
LR: [0.005534524388035882]
---- EP [1/5] | BTCH [2846/3634] ||| train_loss = 0.01405 ----
LR: [0.005537284511905328]
---- EP [1/5] | BTCH [2847/3634] ||| train_loss = 0.00917 ----
LR: [0.0055400445237012265]
---- EP [1/5] | BTCH [2848/3634] ||| train_loss = 0.00893 ----
LR: [0.0055428044225064735]
---- EP [1/5] | BTCH [2849/3634] ||| train_loss = 0.01026 ----
LR: [0.005545564207404001]
---- EP [1/5] | BTCH [2850/3634] ||| train_loss = 0.01739 ----
LR: [0.005548323877476787]
---- EP [1/5] | BTCH [2851/3634] ||| train_loss = 0.01417 ----
LR: [0.005551083431807844]
---- EP [1/5] | BTCH [2852/3634] ||| train_loss = 0.01270 ----
LR: [0.005553842869480215]
---- EP [1/5] | BTCH [2853/3634] ||| train_loss = 0.01520 ----
LR: [0.005556602189576996]
---- EP [1/5] | BTCH [2854/3634] ||| train_loss = 0.01299 ----
LR: [0.005559361391181311]
---- EP [1/5] | BTCH [2855/3634] ||| train_loss = 0.01217 ----
LR: [0.00556212047337633]
---- EP [1/5] | BTCH [2856/3634] ||| train_loss = 0.01032 ----
LR: [0.0055648794352452565]
---- EP [1/5] | BTCH [2857/3634] ||| train_loss = 0.01727 ----
LR: [0.005567638275871338]
---- EP [1/5] | BTCH [2858/3634] ||| train_loss = 0.01590 ----
LR: [0.005570396994337864]
---- EP [1/5] | BTCH [2859/3634] ||| train_loss = 0.01505 ----
LR: [0.00557315558972816]
---- EP [1/5] | BTCH [2860/3634] ||| train_loss = 0.01703 ----
LR: [0.0055759140611255946]
---- EP [1/5] | BTCH [2861/3634] ||| train_loss = 0.01455 ----
LR: [0.005578672407613578]
---- EP [1/5] | BTCH [2862/3634] ||| train_loss = 0.01857 ----
LR: [0.005581430628275564]
---- EP [1/5] | BTCH [2863/3634] ||| train_loss = 0.01428 ----
LR: [0.00558418872219504]
---- EP [1/5] | BTCH [2864/3634] ||| train_loss = 0.01277 ----
LR: [0.0055869466884555475]
---- EP [1/5] | BTCH [2865/3634] ||| train_loss = 0.01252 ----
LR: [0.00558970452614066]
---- EP [1/5] | BTCH [2866/3634] ||| train_loss = 0.01720 ----
LR: [0.005592462234333998]
---- EP [1/5] | BTCH [2867/3634] ||| train_loss = 0.00999 ----
LR: [0.005595219812119227]
---- EP [1/5] | BTCH [2868/3634] ||| train_loss = 0.00826 ----
LR: [0.005597977258580054]
---- EP [1/5] | BTCH [2869/3634] ||| train_loss = 0.01367 ----
LR: [0.005600734572800225]
---- EP [1/5] | BTCH [2870/3634] ||| train_loss = 0.01557 ----
LR: [0.00560349175386354]
---- EP [1/5] | BTCH [2871/3634] ||| train_loss = 0.01328 ----
LR: [0.005606248800853835]
---- EP [1/5] | BTCH [2872/3634] ||| train_loss = 0.00684 ----
LR: [0.0056090057128549906]
---- EP [1/5] | BTCH [2873/3634] ||| train_loss = 0.01455 ----
LR: [0.00561176248895094]
---- EP [1/5] | BTCH [2874/3634] ||| train_loss = 0.01423 ----
LR: [0.005614519128225651]
---- EP [1/5] | BTCH [2875/3634] ||| train_loss = 0.00966 ----
LR: [0.005617275629763145]
---- EP [1/5] | BTCH [2876/3634] ||| train_loss = 0.01571 ----
LR: [0.005620031992647488]
---- EP [1/5] | BTCH [2877/3634] ||| train_loss = 0.00866 ----
LR: [0.005622788215962785]
---- EP [1/5] | BTCH [2878/3634] ||| train_loss = 0.00952 ----
LR: [0.005625544298793199]
---- EP [1/5] | BTCH [2879/3634] ||| train_loss = 0.01237 ----
LR: [0.00562830024022293]
---- EP [1/5] | BTCH [2880/3634] ||| train_loss = 0.00946 ----
LR: [0.005631056039336229]
---- EP [1/5] | BTCH [2881/3634] ||| train_loss = 0.01697 ----
LR: [0.005633811695217393]
---- EP [1/5] | BTCH [2882/3634] ||| train_loss = 0.01489 ----
LR: [0.00563656720695077]
---- EP [1/5] | BTCH [2883/3634] ||| train_loss = 0.00809 ----
LR: [0.005639322573620749]
---- EP [1/5] | BTCH [2884/3634] ||| train_loss = 0.01009 ----
LR: [0.005642077794311777]
---- EP [1/5] | BTCH [2885/3634] ||| train_loss = 0.01167 ----
LR: [0.0056448328681083385]
---- EP [1/5] | BTCH [2886/3634] ||| train_loss = 0.00999 ----
LR: [0.005647587794094974]
---- EP [1/5] | BTCH [2887/3634] ||| train_loss = 0.00908 ----
LR: [0.005650342571356273]
---- EP [1/5] | BTCH [2888/3634] ||| train_loss = 0.02534 ----
LR: [0.0056530971989768725]
---- EP [1/5] | BTCH [2889/3634] ||| train_loss = 0.01015 ----
LR: [0.005655851676041457]
---- EP [1/5] | BTCH [2890/3634] ||| train_loss = 0.01160 ----
LR: [0.005658606001634766]
---- EP [1/5] | BTCH [2891/3634] ||| train_loss = 0.01664 ----
LR: [0.005661360174841586]
---- EP [1/5] | BTCH [2892/3634] ||| train_loss = 0.02494 ----
LR: [0.005664114194746755]
---- EP [1/5] | BTCH [2893/3634] ||| train_loss = 0.00897 ----
LR: [0.005666868060435162]
---- EP [1/5] | BTCH [2894/3634] ||| train_loss = 0.01496 ----
LR: [0.005669621770991747]
---- EP [1/5] | BTCH [2895/3634] ||| train_loss = 0.01852 ----
LR: [0.005672375325501502]
---- EP [1/5] | BTCH [2896/3634] ||| train_loss = 0.01695 ----
VAL ||| loss = 0.013511092864235784, psnr = 30.677698135375977, ssim = 0.9060789942741394
LR: [0.005675128723049472]
---- EP [1/5] | BTCH [2897/3634] ||| train_loss = 0.01339 ----
LR: [0.005677881962720749]
---- EP [1/5] | BTCH [2898/3634] ||| train_loss = 0.01217 ----
LR: [0.005680635043600485]
---- EP [1/5] | BTCH [2899/3634] ||| train_loss = 0.00816 ----
LR: [0.0056833879647738795]
---- EP [1/5] | BTCH [2900/3634] ||| train_loss = 0.00977 ----
LR: [0.0056861407253261855]
---- EP [1/5] | BTCH [2901/3634] ||| train_loss = 0.01292 ----
LR: [0.005688893324342712]
---- EP [1/5] | BTCH [2902/3634] ||| train_loss = 0.00725 ----
LR: [0.005691645760908821]
---- EP [1/5] | BTCH [2903/3634] ||| train_loss = 0.01510 ----
LR: [0.005694398034109922]
---- EP [1/5] | BTCH [2904/3634] ||| train_loss = 0.01300 ----
LR: [0.005697150143031492]
---- EP [1/5] | BTCH [2905/3634] ||| train_loss = 0.01057 ----
LR: [0.00569990208675905]
---- EP [1/5] | BTCH [2906/3634] ||| train_loss = 0.00781 ----
LR: [0.005702653864378175]
---- EP [1/5] | BTCH [2907/3634] ||| train_loss = 0.02081 ----
LR: [0.005705405474974504]
---- EP [1/5] | BTCH [2908/3634] ||| train_loss = 0.01916 ----
LR: [0.005708156917633725]
---- EP [1/5] | BTCH [2909/3634] ||| train_loss = 0.01086 ----
LR: [0.00571090819144158]
---- EP [1/5] | BTCH [2910/3634] ||| train_loss = 0.01424 ----
LR: [0.0057136592954838755]
---- EP [1/5] | BTCH [2911/3634] ||| train_loss = 0.00724 ----
LR: [0.005716410228846467]
---- EP [1/5] | BTCH [2912/3634] ||| train_loss = 0.01802 ----
LR: [0.005719160990615268]
---- EP [1/5] | BTCH [2913/3634] ||| train_loss = 0.01369 ----
LR: [0.005721911579876253]
---- EP [1/5] | BTCH [2914/3634] ||| train_loss = 0.01799 ----
LR: [0.005724661995715447]
---- EP [1/5] | BTCH [2915/3634] ||| train_loss = 0.01302 ----
LR: [0.00572741223721894]
---- EP [1/5] | BTCH [2916/3634] ||| train_loss = 0.01324 ----
LR: [0.005730162303472876]
---- EP [1/5] | BTCH [2917/3634] ||| train_loss = 0.00863 ----
LR: [0.005732912193563455]
---- EP [1/5] | BTCH [2918/3634] ||| train_loss = 0.01191 ----
LR: [0.0057356619065769415]
---- EP [1/5] | BTCH [2919/3634] ||| train_loss = 0.00768 ----
LR: [0.005738411441599653]
---- EP [1/5] | BTCH [2920/3634] ||| train_loss = 0.01325 ----
LR: [0.005741160797717968]
---- EP [1/5] | BTCH [2921/3634] ||| train_loss = 0.01328 ----
LR: [0.005743909974018331]
---- EP [1/5] | BTCH [2922/3634] ||| train_loss = 0.01614 ----
LR: [0.005746658969587235]
---- EP [1/5] | BTCH [2923/3634] ||| train_loss = 0.01007 ----
LR: [0.0057494077835112374]
---- EP [1/5] | BTCH [2924/3634] ||| train_loss = 0.00871 ----
LR: [0.0057521564148769605]
---- EP [1/5] | BTCH [2925/3634] ||| train_loss = 0.01349 ----
LR: [0.005754904862771084]
---- EP [1/5] | BTCH [2926/3634] ||| train_loss = 0.02091 ----
LR: [0.0057576531262803436]
---- EP [1/5] | BTCH [2927/3634] ||| train_loss = 0.01231 ----
LR: [0.005760401204491547]
---- EP [1/5] | BTCH [2928/3634] ||| train_loss = 0.01694 ----
LR: [0.005763149096491554]
---- EP [1/5] | BTCH [2929/3634] ||| train_loss = 0.00751 ----
LR: [0.00576589680136729]
---- EP [1/5] | BTCH [2930/3634] ||| train_loss = 0.00822 ----
LR: [0.005768644318205742]
---- EP [1/5] | BTCH [2931/3634] ||| train_loss = 0.00741 ----
LR: [0.005771391646093963]
---- EP [1/5] | BTCH [2932/3634] ||| train_loss = 0.02065 ----
LR: [0.00577413878411906]
---- EP [1/5] | BTCH [2933/3634] ||| train_loss = 0.01467 ----
LR: [0.005776885731368214]
---- EP [1/5] | BTCH [2934/3634] ||| train_loss = 0.01325 ----
LR: [0.00577963248692866]
---- EP [1/5] | BTCH [2935/3634] ||| train_loss = 0.01497 ----
LR: [0.005782379049887703]
---- EP [1/5] | BTCH [2936/3634] ||| train_loss = 0.01412 ----
LR: [0.005785125419332711]
---- EP [1/5] | BTCH [2937/3634] ||| train_loss = 0.00841 ----
LR: [0.005787871594351112]
---- EP [1/5] | BTCH [2938/3634] ||| train_loss = 0.00758 ----
LR: [0.005790617574030404]
---- EP [1/5] | BTCH [2939/3634] ||| train_loss = 0.00600 ----
LR: [0.005793363357458145]
---- EP [1/5] | BTCH [2940/3634] ||| train_loss = 0.00892 ----
LR: [0.005796108943721962]
---- EP [1/5] | BTCH [2941/3634] ||| train_loss = 0.01585 ----
LR: [0.005798854331909549]
---- EP [1/5] | BTCH [2942/3634] ||| train_loss = 0.01459 ----
LR: [0.005801599521108661]
---- EP [1/5] | BTCH [2943/3634] ||| train_loss = 0.01111 ----
LR: [0.005804344510407118]
---- EP [1/5] | BTCH [2944/3634] ||| train_loss = 0.01354 ----
LR: [0.005807089298892815]
---- EP [1/5] | BTCH [2945/3634] ||| train_loss = 0.01487 ----
LR: [0.005809833885653705]
---- EP [1/5] | BTCH [2946/3634] ||| train_loss = 0.01160 ----
LR: [0.005812578269777812]
---- EP [1/5] | BTCH [2947/3634] ||| train_loss = 0.00652 ----
LR: [0.005815322450353228]
---- EP [1/5] | BTCH [2948/3634] ||| train_loss = 0.01305 ----
LR: [0.00581806642646811]
---- EP [1/5] | BTCH [2949/3634] ||| train_loss = 0.01174 ----
LR: [0.005820810197210685]
---- EP [1/5] | BTCH [2950/3634] ||| train_loss = 0.00948 ----
LR: [0.005823553761669248]
---- EP [1/5] | BTCH [2951/3634] ||| train_loss = 0.01178 ----
LR: [0.005826297118932162]
---- EP [1/5] | BTCH [2952/3634] ||| train_loss = 0.01117 ----
LR: [0.0058290402680878555]
---- EP [1/5] | BTCH [2953/3634] ||| train_loss = 0.00967 ----
LR: [0.005831783208224836]
---- EP [1/5] | BTCH [2954/3634] ||| train_loss = 0.01377 ----
LR: [0.005834525938431668]
---- EP [1/5] | BTCH [2955/3634] ||| train_loss = 0.01112 ----
LR: [0.005837268457796994]
---- EP [1/5] | BTCH [2956/3634] ||| train_loss = 0.01595 ----
LR: [0.005840010765409528]
---- EP [1/5] | BTCH [2957/3634] ||| train_loss = 0.01617 ----
LR: [0.005842752860358044]
---- EP [1/5] | BTCH [2958/3634] ||| train_loss = 0.01382 ----
LR: [0.005845494741731399]
---- EP [1/5] | BTCH [2959/3634] ||| train_loss = 0.01204 ----
LR: [0.005848236408618512]
---- EP [1/5] | BTCH [2960/3634] ||| train_loss = 0.00776 ----
LR: [0.005850977860108377]
---- EP [1/5] | BTCH [2961/3634] ||| train_loss = 0.01392 ----
LR: [0.005853719095290063]
---- EP [1/5] | BTCH [2962/3634] ||| train_loss = 0.01489 ----
LR: [0.005856460113252703]
---- EP [1/5] | BTCH [2963/3634] ||| train_loss = 0.01466 ----
LR: [0.005859200913085506]
---- EP [1/5] | BTCH [2964/3634] ||| train_loss = 0.01030 ----
LR: [0.005861941493877755]
---- EP [1/5] | BTCH [2965/3634] ||| train_loss = 0.00919 ----
LR: [0.005864681854718807]
---- EP [1/5] | BTCH [2966/3634] ||| train_loss = 0.00688 ----
LR: [0.005867421994698085]
---- EP [1/5] | BTCH [2967/3634] ||| train_loss = 0.00814 ----
LR: [0.005870161912905093]
---- EP [1/5] | BTCH [2968/3634] ||| train_loss = 0.01913 ----
LR: [0.005872901608429405]
---- EP [1/5] | BTCH [2969/3634] ||| train_loss = 0.01417 ----
LR: [0.005875641080360668]
---- EP [1/5] | BTCH [2970/3634] ||| train_loss = 0.01425 ----
LR: [0.005878380327788608]
---- EP [1/5] | BTCH [2971/3634] ||| train_loss = 0.01133 ----
LR: [0.005881119349803022]
---- EP [1/5] | BTCH [2972/3634] ||| train_loss = 0.01233 ----
LR: [0.00588385814549378]
---- EP [1/5] | BTCH [2973/3634] ||| train_loss = 0.01466 ----
LR: [0.005886596713950831]
---- EP [1/5] | BTCH [2974/3634] ||| train_loss = 0.00704 ----
LR: [0.005889335054264199]
---- EP [1/5] | BTCH [2975/3634] ||| train_loss = 0.01168 ----
LR: [0.005892073165523982]
---- EP [1/5] | BTCH [2976/3634] ||| train_loss = 0.01803 ----
LR: [0.005894811046820356]
---- EP [1/5] | BTCH [2977/3634] ||| train_loss = 0.01004 ----
LR: [0.005897548697243572]
---- EP [1/5] | BTCH [2978/3634] ||| train_loss = 0.01138 ----
LR: [0.005900286115883958]
---- EP [1/5] | BTCH [2979/3634] ||| train_loss = 0.01526 ----
LR: [0.00590302330183192]
---- EP [1/5] | BTCH [2980/3634] ||| train_loss = 0.01082 ----
LR: [0.005905760254177939]
---- EP [1/5] | BTCH [2981/3634] ||| train_loss = 0.01713 ----
LR: [0.005908496972012576]
---- EP [1/5] | BTCH [2982/3634] ||| train_loss = 0.00959 ----
LR: [0.005911233454426472]
---- EP [1/5] | BTCH [2983/3634] ||| train_loss = 0.01694 ----
LR: [0.005913969700510338]
---- EP [1/5] | BTCH [2984/3634] ||| train_loss = 0.00911 ----
LR: [0.005916705709354971]
---- EP [1/5] | BTCH [2985/3634] ||| train_loss = 0.01220 ----
LR: [0.005919441480051248]
---- EP [1/5] | BTCH [2986/3634] ||| train_loss = 0.01144 ----
LR: [0.005922177011690116]
---- EP [1/5] | BTCH [2987/3634] ||| train_loss = 0.00788 ----
LR: [0.005924912303362613]
---- EP [1/5] | BTCH [2988/3634] ||| train_loss = 0.01633 ----
LR: [0.005927647354159847]
---- EP [1/5] | BTCH [2989/3634] ||| train_loss = 0.01749 ----
LR: [0.00593038216317301]
---- EP [1/5] | BTCH [2990/3634] ||| train_loss = 0.01526 ----
LR: [0.005933116729493378]
---- EP [1/5] | BTCH [2991/3634] ||| train_loss = 0.01048 ----
LR: [0.005935851052212301]
---- EP [1/5] | BTCH [2992/3634] ||| train_loss = 0.01200 ----
LR: [0.005938585130421213]
---- EP [1/5] | BTCH [2993/3634] ||| train_loss = 0.01498 ----
LR: [0.0059413189632116295]
---- EP [1/5] | BTCH [2994/3634] ||| train_loss = 0.01342 ----
LR: [0.005944052549675147]
---- EP [1/5] | BTCH [2995/3634] ||| train_loss = 0.01073 ----
LR: [0.005946785888903447]
---- EP [1/5] | BTCH [2996/3634] ||| train_loss = 0.00796 ----
LR: [0.0059495189799882876]
---- EP [1/5] | BTCH [2997/3634] ||| train_loss = 0.01294 ----
LR: [0.00595225182202151]
---- EP [1/5] | BTCH [2998/3634] ||| train_loss = 0.01231 ----
LR: [0.0059549844140950456]
---- EP [1/5] | BTCH [2999/3634] ||| train_loss = 0.00974 ----
LR: [0.005957716755300899]
---- EP [1/5] | BTCH [3000/3634] ||| train_loss = 0.00836 ----
LR: [0.005960448844731163]
---- EP [1/5] | BTCH [3001/3634] ||| train_loss = 0.01794 ----
LR: [0.005963180681478017]
---- EP [1/5] | BTCH [3002/3634] ||| train_loss = 0.01366 ----
LR: [0.005965912264633718]
---- EP [1/5] | BTCH [3003/3634] ||| train_loss = 0.01519 ----
LR: [0.0059686435932906085]
---- EP [1/5] | BTCH [3004/3634] ||| train_loss = 0.01524 ----
LR: [0.005971374666541121]
---- EP [1/5] | BTCH [3005/3634] ||| train_loss = 0.01686 ----
LR: [0.0059741054834777695]
---- EP [1/5] | BTCH [3006/3634] ||| train_loss = 0.01639 ----
LR: [0.005976836043193149]
---- EP [1/5] | BTCH [3007/3634] ||| train_loss = 0.01214 ----
LR: [0.005979566344779948]
---- EP [1/5] | BTCH [3008/3634] ||| train_loss = 0.01067 ----
LR: [0.005982296387330933]
---- EP [1/5] | BTCH [3009/3634] ||| train_loss = 0.01495 ----
LR: [0.005985026169938961]
---- EP [1/5] | BTCH [3010/3634] ||| train_loss = 0.01593 ----
LR: [0.005987755691696979]
---- EP [1/5] | BTCH [3011/3634] ||| train_loss = 0.02042 ----
LR: [0.005990484951698011]
---- EP [1/5] | BTCH [3012/3634] ||| train_loss = 0.01137 ----
LR: [0.005993213949035174]
---- EP [1/5] | BTCH [3013/3634] ||| train_loss = 0.01148 ----
LR: [0.0059959426828016735]
---- EP [1/5] | BTCH [3014/3634] ||| train_loss = 0.00710 ----
LR: [0.005998671152090797]
---- EP [1/5] | BTCH [3015/3634] ||| train_loss = 0.01809 ----
LR: [0.006001399355995929]
---- EP [1/5] | BTCH [3016/3634] ||| train_loss = 0.00933 ----
LR: [0.006004127293610534]
---- EP [1/5] | BTCH [3017/3634] ||| train_loss = 0.01155 ----
LR: [0.006006854964028164]
---- EP [1/5] | BTCH [3018/3634] ||| train_loss = 0.01570 ----
LR: [0.006009582366342468]
---- EP [1/5] | BTCH [3019/3634] ||| train_loss = 0.01500 ----
LR: [0.00601230949964718]
---- EP [1/5] | BTCH [3020/3634] ||| train_loss = 0.01271 ----
LR: [0.006015036363036117]
---- EP [1/5] | BTCH [3021/3634] ||| train_loss = 0.01205 ----
LR: [0.006017762955603198]
---- EP [1/5] | BTCH [3022/3634] ||| train_loss = 0.01380 ----
LR: [0.006020489276442423]
---- EP [1/5] | BTCH [3023/3634] ||| train_loss = 0.00928 ----
LR: [0.006023215324647885]
---- EP [1/5] | BTCH [3024/3634] ||| train_loss = 0.02831 ----
LR: [0.006025941099313766]
---- EP [1/5] | BTCH [3025/3634] ||| train_loss = 0.02637 ----
LR: [0.006028666599534344]
---- EP [1/5] | BTCH [3026/3634] ||| train_loss = 0.03325 ----
LR: [0.00603139182440398]
---- EP [1/5] | BTCH [3027/3634] ||| train_loss = 0.02663 ----
LR: [0.006034116773017134]
---- EP [1/5] | BTCH [3028/3634] ||| train_loss = 0.03761 ----
LR: [0.006036841444468354]
---- EP [1/5] | BTCH [3029/3634] ||| train_loss = 0.01539 ----
LR: [0.006039565837852279]
---- EP [1/5] | BTCH [3030/3634] ||| train_loss = 0.02517 ----
LR: [0.006042289952263647]
---- EP [1/5] | BTCH [3031/3634] ||| train_loss = 0.09587 ----
LR: [0.00604501378679728]
---- EP [1/5] | BTCH [3032/3634] ||| train_loss = 0.02574 ----
LR: [0.006047737340548097]
---- EP [1/5] | BTCH [3033/3634] ||| train_loss = 0.02067 ----
LR: [0.006050460612611112]
---- EP [1/5] | BTCH [3034/3634] ||| train_loss = 0.03524 ----
LR: [0.00605318360208143]
---- EP [1/5] | BTCH [3035/3634] ||| train_loss = 0.01832 ----
LR: [0.006055906308054253]
---- EP [1/5] | BTCH [3036/3634] ||| train_loss = 0.02631 ----
LR: [0.006058628729624873]
---- EP [1/5] | BTCH [3037/3634] ||| train_loss = 0.01605 ----
LR: [0.006061350865888676]
---- EP [1/5] | BTCH [3038/3634] ||| train_loss = 0.03739 ----
LR: [0.0060640727159411495]
---- EP [1/5] | BTCH [3039/3634] ||| train_loss = 0.01977 ----
LR: [0.006066794278877871]
---- EP [1/5] | BTCH [3040/3634] ||| train_loss = 0.01573 ----
LR: [0.006069515553794512]
---- EP [1/5] | BTCH [3041/3634] ||| train_loss = 0.02175 ----
LR: [0.006072236539786845]
---- EP [1/5] | BTCH [3042/3634] ||| train_loss = 0.02639 ----
LR: [0.006074957235950734]
---- EP [1/5] | BTCH [3043/3634] ||| train_loss = 0.02752 ----
LR: [0.006077677641382141]
---- EP [1/5] | BTCH [3044/3634] ||| train_loss = nan ----
LR: [0.0060803977551771235]
---- EP [1/5] | BTCH [3045/3634] ||| train_loss = nan ----
LR: [0.00608311757643184]
---- EP [1/5] | BTCH [3046/3634] ||| train_loss = nan ----
LR: [0.0060858371042425375]
---- EP [1/5] | BTCH [3047/3634] ||| train_loss = nan ----
LR: [0.006088556337705572]
---- EP [1/5] | BTCH [3048/3634] ||| train_loss = nan ----
LR: [0.006091275275917387]
---- EP [1/5] | BTCH [3049/3634] ||| train_loss = nan ----
LR: [0.0060939939179745295]
---- EP [1/5] | BTCH [3050/3634] ||| train_loss = nan ----
LR: [0.006096712262973647]
---- EP [1/5] | BTCH [3051/3634] ||| train_loss = nan ----
LR: [0.0060994303100114795]
---- EP [1/5] | BTCH [3052/3634] ||| train_loss = nan ----
LR: [0.006102148058184867]
---- EP [1/5] | BTCH [3053/3634] ||| train_loss = nan ----
LR: [0.006104865506590755]
---- EP [1/5] | BTCH [3054/3634] ||| train_loss = nan ----
LR: [0.006107582654326182]
---- EP [1/5] | BTCH [3055/3634] ||| train_loss = nan ----
LR: [0.006110299500488292]
---- EP [1/5] | BTCH [3056/3634] ||| train_loss = nan ----
LR: [0.006113016044174324]
---- EP [1/5] | BTCH [3057/3634] ||| train_loss = nan ----
LR: [0.0061157322844816175]
---- EP [1/5] | BTCH [3058/3634] ||| train_loss = nan ----
LR: [0.006118448220507618]
---- EP [1/5] | BTCH [3059/3634] ||| train_loss = nan ----
LR: [0.006121163851349869]
---- EP [1/5] | BTCH [3060/3634] ||| train_loss = nan ----
LR: [0.006123879176106012]
---- EP [1/5] | BTCH [3061/3634] ||| train_loss = nan ----
LR: [0.006126594193873798]
---- EP [1/5] | BTCH [3062/3634] ||| train_loss = nan ----
LR: [0.006129308903751074]
---- EP [1/5] | BTCH [3063/3634] ||| train_loss = nan ----
LR: [0.006132023304835789]
---- EP [1/5] | BTCH [3064/3634] ||| train_loss = nan ----
LR: [0.006134737396226001]
---- EP [1/5] | BTCH [3065/3634] ||| train_loss = nan ----
LR: [0.006137451177019863]
---- EP [1/5] | BTCH [3066/3634] ||| train_loss = nan ----
LR: [0.006140164646315633]
---- EP [1/5] | BTCH [3067/3634] ||| train_loss = nan ----
LR: [0.0061428778032116774]
---- EP [1/5] | BTCH [3068/3634] ||| train_loss = nan ----
LR: [0.0061455906468064645]
---- EP [1/5] | BTCH [3069/3634] ||| train_loss = nan ----
LR: [0.006148303176198561]
---- EP [1/5] | BTCH [3070/3634] ||| train_loss = nan ----
LR: [0.006151015390486647]
---- EP [1/5] | BTCH [3071/3634] ||| train_loss = nan ----
LR: [0.006153727288769499]
---- EP [1/5] | BTCH [3072/3634] ||| train_loss = nan ----
LR: [0.006156438870146002]
---- EP [1/5] | BTCH [3073/3634] ||| train_loss = nan ----
LR: [0.006159150133715149]
---- EP [1/5] | BTCH [3074/3634] ||| train_loss = nan ----
LR: [0.006161861078576034]
---- EP [1/5] | BTCH [3075/3634] ||| train_loss = nan ----
LR: [0.006164571703827863]
---- EP [1/5] | BTCH [3076/3634] ||| train_loss = nan ----
LR: [0.006167282008569941]
---- EP [1/5] | BTCH [3077/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.00616999199190168]
---- EP [1/5] | BTCH [3078/3634] ||| train_loss = nan ----
LR: [0.006172701652922607]
---- EP [1/5] | BTCH [3079/3634] ||| train_loss = nan ----
LR: [0.006175410990732348]
---- EP [1/5] | BTCH [3080/3634] ||| train_loss = nan ----
LR: [0.006178120004430638]
---- EP [1/5] | BTCH [3081/3634] ||| train_loss = nan ----
LR: [0.006180828693117323]
---- EP [1/5] | BTCH [3082/3634] ||| train_loss = nan ----
LR: [0.006183537055892353]
---- EP [1/5] | BTCH [3083/3634] ||| train_loss = nan ----
LR: [0.006186245091855787]
---- EP [1/5] | BTCH [3084/3634] ||| train_loss = nan ----
LR: [0.006188952800107797]
---- EP [1/5] | BTCH [3085/3634] ||| train_loss = nan ----
LR: [0.006191660179748659]
---- EP [1/5] | BTCH [3086/3634] ||| train_loss = nan ----
LR: [0.006194367229878758]
---- EP [1/5] | BTCH [3087/3634] ||| train_loss = nan ----
LR: [0.00619707394959859]
---- EP [1/5] | BTCH [3088/3634] ||| train_loss = nan ----
LR: [0.006199780338008765]
---- EP [1/5] | BTCH [3089/3634] ||| train_loss = nan ----
LR: [0.006202486394209994]
---- EP [1/5] | BTCH [3090/3634] ||| train_loss = nan ----
LR: [0.006205192117303107]
---- EP [1/5] | BTCH [3091/3634] ||| train_loss = nan ----
LR: [0.00620789750638904]
---- EP [1/5] | BTCH [3092/3634] ||| train_loss = nan ----
LR: [0.0062106025605688404]
---- EP [1/5] | BTCH [3093/3634] ||| train_loss = nan ----
LR: [0.006213307278943667]
---- EP [1/5] | BTCH [3094/3634] ||| train_loss = nan ----
LR: [0.006216011660614792]
---- EP [1/5] | BTCH [3095/3634] ||| train_loss = nan ----
LR: [0.006218715704683599]
---- EP [1/5] | BTCH [3096/3634] ||| train_loss = nan ----
LR: [0.006221419410251583]
---- EP [1/5] | BTCH [3097/3634] ||| train_loss = nan ----
LR: [0.006224122776420348]
---- EP [1/5] | BTCH [3098/3634] ||| train_loss = nan ----
LR: [0.006226825802291618]
---- EP [1/5] | BTCH [3099/3634] ||| train_loss = nan ----
LR: [0.006229528486967226]
---- EP [1/5] | BTCH [3100/3634] ||| train_loss = nan ----
LR: [0.006232230829549115]
---- EP [1/5] | BTCH [3101/3634] ||| train_loss = nan ----
LR: [0.006234932829139352]
---- EP [1/5] | BTCH [3102/3634] ||| train_loss = nan ----
LR: [0.006237634484840106]
---- EP [1/5] | BTCH [3103/3634] ||| train_loss = nan ----
LR: [0.006240335795753666]
---- EP [1/5] | BTCH [3104/3634] ||| train_loss = nan ----
LR: [0.006243036760982437]
---- EP [1/5] | BTCH [3105/3634] ||| train_loss = nan ----
LR: [0.006245737379628938]
---- EP [1/5] | BTCH [3106/3634] ||| train_loss = nan ----
LR: [0.006248437650795798]
---- EP [1/5] | BTCH [3107/3634] ||| train_loss = nan ----
LR: [0.00625113757358577]
---- EP [1/5] | BTCH [3108/3634] ||| train_loss = nan ----
LR: [0.006253837147101718]
---- EP [1/5] | BTCH [3109/3634] ||| train_loss = nan ----
LR: [0.006256536370446618]
---- EP [1/5] | BTCH [3110/3634] ||| train_loss = nan ----
LR: [0.006259235242723572]
---- EP [1/5] | BTCH [3111/3634] ||| train_loss = nan ----
LR: [0.006261933763035792]
---- EP [1/5] | BTCH [3112/3634] ||| train_loss = nan ----
LR: [0.006264631930486606]
---- EP [1/5] | BTCH [3113/3634] ||| train_loss = nan ----
LR: [0.006267329744179466]
---- EP [1/5] | BTCH [3114/3634] ||| train_loss = nan ----
LR: [0.006270027203217933]
---- EP [1/5] | BTCH [3115/3634] ||| train_loss = nan ----
LR: [0.006272724306705694]
---- EP [1/5] | BTCH [3116/3634] ||| train_loss = nan ----
LR: [0.006275421053746548]
---- EP [1/5] | BTCH [3117/3634] ||| train_loss = nan ----
LR: [0.006278117443444414]
---- EP [1/5] | BTCH [3118/3634] ||| train_loss = nan ----
LR: [0.006280813474903332]
---- EP [1/5] | BTCH [3119/3634] ||| train_loss = nan ----
LR: [0.006283509147227459]
---- EP [1/5] | BTCH [3120/3634] ||| train_loss = nan ----
LR: [0.006286204459521071]
---- EP [1/5] | BTCH [3121/3634] ||| train_loss = nan ----
LR: [0.006288899410888567]
---- EP [1/5] | BTCH [3122/3634] ||| train_loss = nan ----
LR: [0.006291594000434459]
---- EP [1/5] | BTCH [3123/3634] ||| train_loss = nan ----
LR: [0.0062942882272633855]
---- EP [1/5] | BTCH [3124/3634] ||| train_loss = nan ----
LR: [0.006296982090480107]
---- EP [1/5] | BTCH [3125/3634] ||| train_loss = nan ----
LR: [0.006299675589189499]
---- EP [1/5] | BTCH [3126/3634] ||| train_loss = nan ----
LR: [0.0063023687224965565]
---- EP [1/5] | BTCH [3127/3634] ||| train_loss = nan ----
LR: [0.006305061489506405]
---- EP [1/5] | BTCH [3128/3634] ||| train_loss = nan ----
LR: [0.006307753889324286]
---- EP [1/5] | BTCH [3129/3634] ||| train_loss = nan ----
LR: [0.006310445921055562]
---- EP [1/5] | BTCH [3130/3634] ||| train_loss = nan ----
LR: [0.006313137583805721]
---- EP [1/5] | BTCH [3131/3634] ||| train_loss = nan ----
LR: [0.006315828876680371]
---- EP [1/5] | BTCH [3132/3634] ||| train_loss = nan ----
LR: [0.006318519798785244]
---- EP [1/5] | BTCH [3133/3634] ||| train_loss = nan ----
LR: [0.006321210349226197]
---- EP [1/5] | BTCH [3134/3634] ||| train_loss = nan ----
LR: [0.006323900527109206]
---- EP [1/5] | BTCH [3135/3634] ||| train_loss = nan ----
LR: [0.006326590331540377]
---- EP [1/5] | BTCH [3136/3634] ||| train_loss = nan ----
LR: [0.006329279761625933]
---- EP [1/5] | BTCH [3137/3634] ||| train_loss = nan ----
LR: [0.006331968816472226]
---- EP [1/5] | BTCH [3138/3634] ||| train_loss = nan ----
LR: [0.006334657495185732]
---- EP [1/5] | BTCH [3139/3634] ||| train_loss = nan ----
LR: [0.006337345796873053]
---- EP [1/5] | BTCH [3140/3634] ||| train_loss = nan ----
LR: [0.006340033720640912]
---- EP [1/5] | BTCH [3141/3634] ||| train_loss = nan ----
LR: [0.006342721265596164]
---- EP [1/5] | BTCH [3142/3634] ||| train_loss = nan ----
LR: [0.006345408430845783]
---- EP [1/5] | BTCH [3143/3634] ||| train_loss = nan ----
LR: [0.006348095215496874]
---- EP [1/5] | BTCH [3144/3634] ||| train_loss = nan ----
LR: [0.006350781618656669]
---- EP [1/5] | BTCH [3145/3634] ||| train_loss = nan ----
LR: [0.0063534676394325215]
---- EP [1/5] | BTCH [3146/3634] ||| train_loss = nan ----
LR: [0.0063561532769319164]
---- EP [1/5] | BTCH [3147/3634] ||| train_loss = nan ----
LR: [0.0063588385302624645]
---- EP [1/5] | BTCH [3148/3634] ||| train_loss = nan ----
LR: [0.006361523398531906]
---- EP [1/5] | BTCH [3149/3634] ||| train_loss = nan ----
LR: [0.0063642078808481065]
---- EP [1/5] | BTCH [3150/3634] ||| train_loss = nan ----
LR: [0.0063668919763190624]
---- EP [1/5] | BTCH [3151/3634] ||| train_loss = nan ----
LR: [0.006369575684052896]
---- EP [1/5] | BTCH [3152/3634] ||| train_loss = nan ----
LR: [0.006372259003157858]
---- EP [1/5] | BTCH [3153/3634] ||| train_loss = nan ----
LR: [0.006374941932742335]
---- EP [1/5] | BTCH [3154/3634] ||| train_loss = nan ----
LR: [0.006377624471914832]
---- EP [1/5] | BTCH [3155/3634] ||| train_loss = nan ----
LR: [0.0063803066197839955]
---- EP [1/5] | BTCH [3156/3634] ||| train_loss = nan ----
LR: [0.006382988375458591]
---- EP [1/5] | BTCH [3157/3634] ||| train_loss = nan ----
LR: [0.0063856697380475225]
---- EP [1/5] | BTCH [3158/3634] ||| train_loss = nan ----
LR: [0.006388350706659822]
---- EP [1/5] | BTCH [3159/3634] ||| train_loss = nan ----
LR: [0.006391031280404651]
---- EP [1/5] | BTCH [3160/3634] ||| train_loss = nan ----
LR: [0.006393711458391302]
---- EP [1/5] | BTCH [3161/3634] ||| train_loss = nan ----
LR: [0.006396391239729203]
---- EP [1/5] | BTCH [3162/3634] ||| train_loss = nan ----
LR: [0.00639907062352791]
---- EP [1/5] | BTCH [3163/3634] ||| train_loss = nan ----
LR: [0.00640174960889711]
---- EP [1/5] | BTCH [3164/3634] ||| train_loss = nan ----
LR: [0.0064044281949466285]
---- EP [1/5] | BTCH [3165/3634] ||| train_loss = nan ----
LR: [0.0064071063807864155]
---- EP [1/5] | BTCH [3166/3634] ||| train_loss = nan ----
LR: [0.006409784165526562]
---- EP [1/5] | BTCH [3167/3634] ||| train_loss = nan ----
LR: [0.006412461548277287]
---- EP [1/5] | BTCH [3168/3634] ||| train_loss = nan ----
LR: [0.006415138528148945]
---- EP [1/5] | BTCH [3169/3634] ||| train_loss = nan ----
LR: [0.0064178151042520205]
---- EP [1/5] | BTCH [3170/3634] ||| train_loss = nan ----
LR: [0.006420491275697143]
---- EP [1/5] | BTCH [3171/3634] ||| train_loss = nan ----
LR: [0.006423167041595062]
---- EP [1/5] | BTCH [3172/3634] ||| train_loss = nan ----
LR: [0.006425842401056671]
---- EP [1/5] | BTCH [3173/3634] ||| train_loss = nan ----
LR: [0.006428517353192998]
---- EP [1/5] | BTCH [3174/3634] ||| train_loss = nan ----
LR: [0.006431191897115203]
---- EP [1/5] | BTCH [3175/3634] ||| train_loss = nan ----
LR: [0.006433866031934585]
---- EP [1/5] | BTCH [3176/3634] ||| train_loss = nan ----
LR: [0.006436539756762575]
---- EP [1/5] | BTCH [3177/3634] ||| train_loss = nan ----
LR: [0.006439213070710744]
---- EP [1/5] | BTCH [3178/3634] ||| train_loss = nan ----
LR: [0.006441885972890799]
---- EP [1/5] | BTCH [3179/3634] ||| train_loss = nan ----
LR: [0.006444558462414583]
---- EP [1/5] | BTCH [3180/3634] ||| train_loss = nan ----
LR: [0.0064472305383940715]
---- EP [1/5] | BTCH [3181/3634] ||| train_loss = nan ----
LR: [0.006449902199941387]
---- EP [1/5] | BTCH [3182/3634] ||| train_loss = nan ----
LR: [0.006452573446168784]
---- EP [1/5] | BTCH [3183/3634] ||| train_loss = nan ----
LR: [0.0064552442761886515]
---- EP [1/5] | BTCH [3184/3634] ||| train_loss = nan ----
LR: [0.006457914689113527]
---- EP [1/5] | BTCH [3185/3634] ||| train_loss = nan ----
LR: [0.006460584684056077]
---- EP [1/5] | BTCH [3186/3634] ||| train_loss = nan ----
LR: [0.006463254260129109]
---- EP [1/5] | BTCH [3187/3634] ||| train_loss = nan ----
LR: [0.006465923416445575]
---- EP [1/5] | BTCH [3188/3634] ||| train_loss = nan ----
LR: [0.00646859215211856]
---- EP [1/5] | BTCH [3189/3634] ||| train_loss = nan ----
LR: [0.006471260466261291]
---- EP [1/5] | BTCH [3190/3634] ||| train_loss = nan ----
LR: [0.0064739283579871385]
---- EP [1/5] | BTCH [3191/3634] ||| train_loss = nan ----
LR: [0.006476595826409607]
---- EP [1/5] | BTCH [3192/3634] ||| train_loss = nan ----
LR: [0.006479262870642345]
---- EP [1/5] | BTCH [3193/3634] ||| train_loss = nan ----
LR: [0.006481929489799145]
---- EP [1/5] | BTCH [3194/3634] ||| train_loss = nan ----
LR: [0.006484595682993933]
---- EP [1/5] | BTCH [3195/3634] ||| train_loss = nan ----
LR: [0.006487261449340787]
---- EP [1/5] | BTCH [3196/3634] ||| train_loss = nan ----
LR: [0.006489926787953916]
---- EP [1/5] | BTCH [3197/3634] ||| train_loss = nan ----
LR: [0.006492591697947676]
---- EP [1/5] | BTCH [3198/3634] ||| train_loss = nan ----
LR: [0.006495256178436571]
---- EP [1/5] | BTCH [3199/3634] ||| train_loss = nan ----
LR: [0.006497920228535238]
---- EP [1/5] | BTCH [3200/3634] ||| train_loss = nan ----
LR: [0.00650058384735846]
---- EP [1/5] | BTCH [3201/3634] ||| train_loss = nan ----
LR: [0.006503247034021168]
---- EP [1/5] | BTCH [3202/3634] ||| train_loss = nan ----
LR: [0.006505909787638433]
---- EP [1/5] | BTCH [3203/3634] ||| train_loss = nan ----
LR: [0.006508572107325465]
---- EP [1/5] | BTCH [3204/3634] ||| train_loss = nan ----
LR: [0.006511233992197631]
---- EP [1/5] | BTCH [3205/3634] ||| train_loss = nan ----
LR: [0.00651389544137043]
---- EP [1/5] | BTCH [3206/3634] ||| train_loss = nan ----
LR: [0.00651655645395951]
---- EP [1/5] | BTCH [3207/3634] ||| train_loss = nan ----
LR: [0.0065192170290806675]
---- EP [1/5] | BTCH [3208/3634] ||| train_loss = nan ----
LR: [0.0065218771658498405]
---- EP [1/5] | BTCH [3209/3634] ||| train_loss = nan ----
LR: [0.006524536863383111]
---- EP [1/5] | BTCH [3210/3634] ||| train_loss = nan ----
LR: [0.006527196120796713]
---- EP [1/5] | BTCH [3211/3634] ||| train_loss = nan ----
LR: [0.006529854937207022]
---- EP [1/5] | BTCH [3212/3634] ||| train_loss = nan ----
LR: [0.00653251331173056]
---- EP [1/5] | BTCH [3213/3634] ||| train_loss = nan ----
LR: [0.006535171243484]
---- EP [1/5] | BTCH [3214/3634] ||| train_loss = nan ----
LR: [0.006537828731584156]
---- EP [1/5] | BTCH [3215/3634] ||| train_loss = nan ----
LR: [0.0065404857751479965]
---- EP [1/5] | BTCH [3216/3634] ||| train_loss = nan ----
LR: [0.00654314237329263]
---- EP [1/5] | BTCH [3217/3634] ||| train_loss = nan ----
LR: [0.006545798525135319]
---- EP [1/5] | BTCH [3218/3634] ||| train_loss = nan ----
LR: [0.006548454229793475]
---- EP [1/5] | BTCH [3219/3634] ||| train_loss = nan ----
LR: [0.006551109486384651]
---- EP [1/5] | BTCH [3220/3634] ||| train_loss = nan ----
LR: [0.0065537642940265515]
---- EP [1/5] | BTCH [3221/3634] ||| train_loss = nan ----
LR: [0.006556418651837037]
---- EP [1/5] | BTCH [3222/3634] ||| train_loss = nan ----
LR: [0.006559072558934112]
---- EP [1/5] | BTCH [3223/3634] ||| train_loss = nan ----
LR: [0.006561726014435927]
---- EP [1/5] | BTCH [3224/3634] ||| train_loss = nan ----
LR: [0.006564379017460791]
---- EP [1/5] | BTCH [3225/3634] ||| train_loss = nan ----
LR: [0.006567031567127155]
---- EP [1/5] | BTCH [3226/3634] ||| train_loss = nan ----
LR: [0.006569683662553628]
---- EP [1/5] | BTCH [3227/3634] ||| train_loss = nan ----
LR: [0.006572335302858966]
---- EP [1/5] | BTCH [3228/3634] ||| train_loss = nan ----
LR: [0.006574986487162077]
---- EP [1/5] | BTCH [3229/3634] ||| train_loss = nan ----
LR: [0.006577637214582017]
---- EP [1/5] | BTCH [3230/3634] ||| train_loss = nan ----
LR: [0.006580287484238001]
---- EP [1/5] | BTCH [3231/3634] ||| train_loss = nan ----
LR: [0.006582937295249392]
---- EP [1/5] | BTCH [3232/3634] ||| train_loss = nan ----
LR: [0.006585586646735702]
---- EP [1/5] | BTCH [3233/3634] ||| train_loss = nan ----
LR: [0.006588235537816606]
---- EP [1/5] | BTCH [3234/3634] ||| train_loss = nan ----
LR: [0.006590883967611918]
---- EP [1/5] | BTCH [3235/3634] ||| train_loss = nan ----
LR: [0.006593531935241618]
---- EP [1/5] | BTCH [3236/3634] ||| train_loss = nan ----
LR: [0.006596179439825832]
---- EP [1/5] | BTCH [3237/3634] ||| train_loss = nan ----
LR: [0.0065988264804848415]
---- EP [1/5] | BTCH [3238/3634] ||| train_loss = nan ----
LR: [0.0066014730563390845]
---- EP [1/5] | BTCH [3239/3634] ||| train_loss = nan ----
LR: [0.0066041191665091505]
---- EP [1/5] | BTCH [3240/3634] ||| train_loss = nan ----
LR: [0.0066067648101157846]
---- EP [1/5] | BTCH [3241/3634] ||| train_loss = nan ----
LR: [0.006609409986279888]
---- EP [1/5] | BTCH [3242/3634] ||| train_loss = nan ----
LR: [0.006612054694122516]
---- EP [1/5] | BTCH [3243/3634] ||| train_loss = nan ----
LR: [0.00661469893276488]
---- EP [1/5] | BTCH [3244/3634] ||| train_loss = nan ----
LR: [0.006617342701328348]
---- EP [1/5] | BTCH [3245/3634] ||| train_loss = nan ----
LR: [0.006619985998934442]
---- EP [1/5] | BTCH [3246/3634] ||| train_loss = nan ----
LR: [0.006622628824704843]
---- EP [1/5] | BTCH [3247/3634] ||| train_loss = nan ----
LR: [0.006625271177761388]
---- EP [1/5] | BTCH [3248/3634] ||| train_loss = nan ----
LR: [0.006627913057226072]
---- EP [1/5] | BTCH [3249/3634] ||| train_loss = nan ----
LR: [0.006630554462221041]
---- EP [1/5] | BTCH [3250/3634] ||| train_loss = nan ----
LR: [0.006633195391868609]
---- EP [1/5] | BTCH [3251/3634] ||| train_loss = nan ----
LR: [0.006635835845291243]
---- EP [1/5] | BTCH [3252/3634] ||| train_loss = nan ----
LR: [0.006638475821611563]
---- EP [1/5] | BTCH [3253/3634] ||| train_loss = nan ----
LR: [0.006641115319952359]
---- EP [1/5] | BTCH [3254/3634] ||| train_loss = nan ----
LR: [0.006643754339436567]
---- EP [1/5] | BTCH [3255/3634] ||| train_loss = nan ----
LR: [0.006646392879187293]
---- EP [1/5] | BTCH [3256/3634] ||| train_loss = nan ----
LR: [0.006649030938327798]
---- EP [1/5] | BTCH [3257/3634] ||| train_loss = nan ----
LR: [0.006651668515981498]
---- EP [1/5] | BTCH [3258/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.006654305611271981]
---- EP [1/5] | BTCH [3259/3634] ||| train_loss = nan ----
LR: [0.0066569422233229815]
---- EP [1/5] | BTCH [3260/3634] ||| train_loss = nan ----
LR: [0.006659578351258404]
---- EP [1/5] | BTCH [3261/3634] ||| train_loss = nan ----
LR: [0.006662213994202308]
---- EP [1/5] | BTCH [3262/3634] ||| train_loss = nan ----
LR: [0.006664849151278922]
---- EP [1/5] | BTCH [3263/3634] ||| train_loss = nan ----
LR: [0.006667483821612624]
---- EP [1/5] | BTCH [3264/3634] ||| train_loss = nan ----
LR: [0.006670118004327968]
---- EP [1/5] | BTCH [3265/3634] ||| train_loss = nan ----
LR: [0.0066727516985496576]
---- EP [1/5] | BTCH [3266/3634] ||| train_loss = nan ----
LR: [0.006675384903402564]
---- EP [1/5] | BTCH [3267/3634] ||| train_loss = nan ----
LR: [0.006678017618011725]
---- EP [1/5] | BTCH [3268/3634] ||| train_loss = nan ----
LR: [0.006680649841502333]
---- EP [1/5] | BTCH [3269/3634] ||| train_loss = nan ----
LR: [0.006683281572999748]
---- EP [1/5] | BTCH [3270/3634] ||| train_loss = nan ----
LR: [0.006685912811629493]
---- EP [1/5] | BTCH [3271/3634] ||| train_loss = nan ----
LR: [0.0066885435565172575]
---- EP [1/5] | BTCH [3272/3634] ||| train_loss = nan ----
LR: [0.0066911738067888926]
---- EP [1/5] | BTCH [3273/3634] ||| train_loss = nan ----
LR: [0.006693803561570412]
---- EP [1/5] | BTCH [3274/3634] ||| train_loss = nan ----
LR: [0.006696432819987993]
---- EP [1/5] | BTCH [3275/3634] ||| train_loss = nan ----
LR: [0.0066990615811679845]
---- EP [1/5] | BTCH [3276/3634] ||| train_loss = nan ----
LR: [0.006701689844236897]
---- EP [1/5] | BTCH [3277/3634] ||| train_loss = nan ----
LR: [0.006704317608321402]
---- EP [1/5] | BTCH [3278/3634] ||| train_loss = nan ----
LR: [0.006706944872548346]
---- EP [1/5] | BTCH [3279/3634] ||| train_loss = nan ----
LR: [0.0067095716360447335]
---- EP [1/5] | BTCH [3280/3634] ||| train_loss = nan ----
LR: [0.006712197897937739]
---- EP [1/5] | BTCH [3281/3634] ||| train_loss = nan ----
LR: [0.006714823657354703]
---- EP [1/5] | BTCH [3282/3634] ||| train_loss = nan ----
LR: [0.006717448913423135]
---- EP [1/5] | BTCH [3283/3634] ||| train_loss = nan ----
LR: [0.006720073665270705]
---- EP [1/5] | BTCH [3284/3634] ||| train_loss = nan ----
LR: [0.006722697912025261]
---- EP [1/5] | BTCH [3285/3634] ||| train_loss = nan ----
LR: [0.006725321652814809]
---- EP [1/5] | BTCH [3286/3634] ||| train_loss = nan ----
LR: [0.00672794488676753]
---- EP [1/5] | BTCH [3287/3634] ||| train_loss = nan ----
LR: [0.0067305676130117705]
---- EP [1/5] | BTCH [3288/3634] ||| train_loss = nan ----
LR: [0.006733189830676046]
---- EP [1/5] | BTCH [3289/3634] ||| train_loss = nan ----
LR: [0.006735811538889037]
---- EP [1/5] | BTCH [3290/3634] ||| train_loss = nan ----
LR: [0.006738432736779603]
---- EP [1/5] | BTCH [3291/3634] ||| train_loss = nan ----
LR: [0.006741053423476763]
---- EP [1/5] | BTCH [3292/3634] ||| train_loss = nan ----
LR: [0.006743673598109713]
---- EP [1/5] | BTCH [3293/3634] ||| train_loss = nan ----
LR: [0.006746293259807816]
---- EP [1/5] | BTCH [3294/3634] ||| train_loss = nan ----
LR: [0.0067489124077006035]
---- EP [1/5] | BTCH [3295/3634] ||| train_loss = nan ----
LR: [0.006751531040917783]
---- EP [1/5] | BTCH [3296/3634] ||| train_loss = nan ----
LR: [0.006754149158589228]
---- EP [1/5] | BTCH [3297/3634] ||| train_loss = nan ----
LR: [0.006756766759844985]
---- EP [1/5] | BTCH [3298/3634] ||| train_loss = nan ----
LR: [0.006759383843815274]
---- EP [1/5] | BTCH [3299/3634] ||| train_loss = nan ----
LR: [0.006762000409630485]
---- EP [1/5] | BTCH [3300/3634] ||| train_loss = nan ----
LR: [0.006764616456421176]
---- EP [1/5] | BTCH [3301/3634] ||| train_loss = nan ----
LR: [0.0067672319833180904]
---- EP [1/5] | BTCH [3302/3634] ||| train_loss = nan ----
LR: [0.00676984698945213]
---- EP [1/5] | BTCH [3303/3634] ||| train_loss = nan ----
LR: [0.006772461473954375]
---- EP [1/5] | BTCH [3304/3634] ||| train_loss = nan ----
LR: [0.006775075435956082]
---- EP [1/5] | BTCH [3305/3634] ||| train_loss = nan ----
LR: [0.00677768887458868]
---- EP [1/5] | BTCH [3306/3634] ||| train_loss = nan ----
LR: [0.006780301788983765]
---- EP [1/5] | BTCH [3307/3634] ||| train_loss = nan ----
LR: [0.006782914178273119]
---- EP [1/5] | BTCH [3308/3634] ||| train_loss = nan ----
LR: [0.006785526041588689]
---- EP [1/5] | BTCH [3309/3634] ||| train_loss = nan ----
LR: [0.006788137378062598]
---- EP [1/5] | BTCH [3310/3634] ||| train_loss = nan ----
LR: [0.00679074818682715]
---- EP [1/5] | BTCH [3311/3634] ||| train_loss = nan ----
LR: [0.0067933584670148185]
---- EP [1/5] | BTCH [3312/3634] ||| train_loss = nan ----
LR: [0.006795968217758256]
---- EP [1/5] | BTCH [3313/3634] ||| train_loss = nan ----
LR: [0.006798577438190289]
---- EP [1/5] | BTCH [3314/3634] ||| train_loss = nan ----
LR: [0.006801186127443917]
---- EP [1/5] | BTCH [3315/3634] ||| train_loss = nan ----
LR: [0.0068037942846523244]
---- EP [1/5] | BTCH [3316/3634] ||| train_loss = nan ----
LR: [0.006806401908948868]
---- EP [1/5] | BTCH [3317/3634] ||| train_loss = nan ----
LR: [0.006809008999467076]
---- EP [1/5] | BTCH [3318/3634] ||| train_loss = nan ----
LR: [0.006811615555340666]
---- EP [1/5] | BTCH [3319/3634] ||| train_loss = nan ----
LR: [0.006814221575703522]
---- EP [1/5] | BTCH [3320/3634] ||| train_loss = nan ----
LR: [0.006816827059689709]
---- EP [1/5] | BTCH [3321/3634] ||| train_loss = nan ----
LR: [0.006819432006433479]
---- EP [1/5] | BTCH [3322/3634] ||| train_loss = nan ----
LR: [0.00682203641506925]
---- EP [1/5] | BTCH [3323/3634] ||| train_loss = nan ----
LR: [0.006824640284731622]
---- EP [1/5] | BTCH [3324/3634] ||| train_loss = nan ----
LR: [0.006827243614555382]
---- EP [1/5] | BTCH [3325/3634] ||| train_loss = nan ----
LR: [0.006829846403675486]
---- EP [1/5] | BTCH [3326/3634] ||| train_loss = nan ----
LR: [0.006832448651227075]
---- EP [1/5] | BTCH [3327/3634] ||| train_loss = nan ----
LR: [0.006835050356345473]
---- EP [1/5] | BTCH [3328/3634] ||| train_loss = nan ----
LR: [0.006837651518166175]
---- EP [1/5] | BTCH [3329/3634] ||| train_loss = nan ----
LR: [0.006840252135824865]
---- EP [1/5] | BTCH [3330/3634] ||| train_loss = nan ----
LR: [0.006842852208457404]
---- EP [1/5] | BTCH [3331/3634] ||| train_loss = nan ----
LR: [0.006845451735199834]
---- EP [1/5] | BTCH [3332/3634] ||| train_loss = nan ----
LR: [0.006848050715188381]
---- EP [1/5] | BTCH [3333/3634] ||| train_loss = nan ----
LR: [0.006850649147559451]
---- EP [1/5] | BTCH [3334/3634] ||| train_loss = nan ----
LR: [0.006853247031449628]
---- EP [1/5] | BTCH [3335/3634] ||| train_loss = nan ----
LR: [0.006855844365995687]
---- EP [1/5] | BTCH [3336/3634] ||| train_loss = nan ----
LR: [0.006858441150334579]
---- EP [1/5] | BTCH [3337/3634] ||| train_loss = nan ----
LR: [0.006861037383603437]
---- EP [1/5] | BTCH [3338/3634] ||| train_loss = nan ----
LR: [0.006863633064939584]
---- EP [1/5] | BTCH [3339/3634] ||| train_loss = nan ----
LR: [0.006866228193480518]
---- EP [1/5] | BTCH [3340/3634] ||| train_loss = nan ----
LR: [0.006868822768363926]
---- EP [1/5] | BTCH [3341/3634] ||| train_loss = nan ----
LR: [0.00687141678872768]
---- EP [1/5] | BTCH [3342/3634] ||| train_loss = nan ----
LR: [0.006874010253709832]
---- EP [1/5] | BTCH [3343/3634] ||| train_loss = nan ----
LR: [0.006876603162448617]
---- EP [1/5] | BTCH [3344/3634] ||| train_loss = nan ----
LR: [0.0068791955140824635]
---- EP [1/5] | BTCH [3345/3634] ||| train_loss = nan ----
LR: [0.0068817873077499795]
---- EP [1/5] | BTCH [3346/3634] ||| train_loss = nan ----
LR: [0.006884378542589954]
---- EP [1/5] | BTCH [3347/3634] ||| train_loss = nan ----
LR: [0.006886969217741372]
---- EP [1/5] | BTCH [3348/3634] ||| train_loss = nan ----
LR: [0.0068895593323433976]
---- EP [1/5] | BTCH [3349/3634] ||| train_loss = nan ----
LR: [0.006892148885535378]
---- EP [1/5] | BTCH [3350/3634] ||| train_loss = nan ----
LR: [0.006894737876456858]
---- EP [1/5] | BTCH [3351/3634] ||| train_loss = nan ----
LR: [0.006897326304247558]
---- EP [1/5] | BTCH [3352/3634] ||| train_loss = nan ----
LR: [0.006899914168047394]
---- EP [1/5] | BTCH [3353/3634] ||| train_loss = nan ----
LR: [0.0069025014669964625]
---- EP [1/5] | BTCH [3354/3634] ||| train_loss = nan ----
LR: [0.006905088200235052]
---- EP [1/5] | BTCH [3355/3634] ||| train_loss = nan ----
LR: [0.006907674366903638]
---- EP [1/5] | BTCH [3356/3634] ||| train_loss = nan ----
LR: [0.006910259966142883]
---- EP [1/5] | BTCH [3357/3634] ||| train_loss = nan ----
LR: [0.00691284499709364]
---- EP [1/5] | BTCH [3358/3634] ||| train_loss = nan ----
LR: [0.006915429458896951]
---- EP [1/5] | BTCH [3359/3634] ||| train_loss = nan ----
LR: [0.006918013350694042]
---- EP [1/5] | BTCH [3360/3634] ||| train_loss = nan ----
LR: [0.0069205966716263355]
---- EP [1/5] | BTCH [3361/3634] ||| train_loss = nan ----
LR: [0.006923179420835443]
---- EP [1/5] | BTCH [3362/3634] ||| train_loss = nan ----
LR: [0.0069257615974631604]
---- EP [1/5] | BTCH [3363/3634] ||| train_loss = nan ----
LR: [0.006928343200651475]
---- EP [1/5] | BTCH [3364/3634] ||| train_loss = nan ----
LR: [0.0069309242295425705]
---- EP [1/5] | BTCH [3365/3634] ||| train_loss = nan ----
LR: [0.006933504683278817]
---- EP [1/5] | BTCH [3366/3634] ||| train_loss = nan ----
LR: [0.006936084561002775]
---- EP [1/5] | BTCH [3367/3634] ||| train_loss = nan ----
LR: [0.0069386638618572]
---- EP [1/5] | BTCH [3368/3634] ||| train_loss = nan ----
LR: [0.006941242584985034]
---- EP [1/5] | BTCH [3369/3634] ||| train_loss = nan ----
LR: [0.006943820729529414]
---- EP [1/5] | BTCH [3370/3634] ||| train_loss = nan ----
LR: [0.006946398294633673]
---- EP [1/5] | BTCH [3371/3634] ||| train_loss = nan ----
LR: [0.006948975279441327]
---- EP [1/5] | BTCH [3372/3634] ||| train_loss = nan ----
LR: [0.006951551683096097]
---- EP [1/5] | BTCH [3373/3634] ||| train_loss = nan ----
LR: [0.006954127504741886]
---- EP [1/5] | BTCH [3374/3634] ||| train_loss = nan ----
LR: [0.006956702743522796]
---- EP [1/5] | BTCH [3375/3634] ||| train_loss = nan ----
LR: [0.006959277398583122]
---- EP [1/5] | BTCH [3376/3634] ||| train_loss = nan ----
LR: [0.006961851469067354]
---- EP [1/5] | BTCH [3377/3634] ||| train_loss = nan ----
LR: [0.00696442495412017]
---- EP [1/5] | BTCH [3378/3634] ||| train_loss = nan ----
LR: [0.006966997852886454]
---- EP [1/5] | BTCH [3379/3634] ||| train_loss = nan ----
LR: [0.006969570164511274]
---- EP [1/5] | BTCH [3380/3634] ||| train_loss = nan ----
LR: [0.006972141888139898]
---- EP [1/5] | BTCH [3381/3634] ||| train_loss = nan ----
LR: [0.00697471302291779]
---- EP [1/5] | BTCH [3382/3634] ||| train_loss = nan ----
LR: [0.006977283567990607]
---- EP [1/5] | BTCH [3383/3634] ||| train_loss = nan ----
LR: [0.0069798535225042025]
---- EP [1/5] | BTCH [3384/3634] ||| train_loss = nan ----
LR: [0.00698242288560463]
---- EP [1/5] | BTCH [3385/3634] ||| train_loss = nan ----
LR: [0.006984991656438135]
---- EP [1/5] | BTCH [3386/3634] ||| train_loss = nan ----
LR: [0.0069875598341511596]
---- EP [1/5] | BTCH [3387/3634] ||| train_loss = nan ----
LR: [0.006990127417890348]
---- EP [1/5] | BTCH [3388/3634] ||| train_loss = nan ----
LR: [0.006992694406802536]
---- EP [1/5] | BTCH [3389/3634] ||| train_loss = nan ----
LR: [0.00699526080003476]
---- EP [1/5] | BTCH [3390/3634] ||| train_loss = nan ----
LR: [0.006997826596734255]
---- EP [1/5] | BTCH [3391/3634] ||| train_loss = nan ----
LR: [0.007000391796048453]
---- EP [1/5] | BTCH [3392/3634] ||| train_loss = nan ----
LR: [0.007002956397124983]
---- EP [1/5] | BTCH [3393/3634] ||| train_loss = nan ----
LR: [0.007005520399111676]
---- EP [1/5] | BTCH [3394/3634] ||| train_loss = nan ----
LR: [0.0070080838011565595]
---- EP [1/5] | BTCH [3395/3634] ||| train_loss = nan ----
LR: [0.007010646602407863]
---- EP [1/5] | BTCH [3396/3634] ||| train_loss = nan ----
LR: [0.0070132088020140124]
---- EP [1/5] | BTCH [3397/3634] ||| train_loss = nan ----
LR: [0.0070157703991236345]
---- EP [1/5] | BTCH [3398/3634] ||| train_loss = nan ----
LR: [0.007018331392885557]
---- EP [1/5] | BTCH [3399/3634] ||| train_loss = nan ----
LR: [0.007020891782448811]
---- EP [1/5] | BTCH [3400/3634] ||| train_loss = nan ----
LR: [0.007023451566962621]
---- EP [1/5] | BTCH [3401/3634] ||| train_loss = nan ----
LR: [0.007026010745576419]
---- EP [1/5] | BTCH [3402/3634] ||| train_loss = nan ----
LR: [0.0070285693174398384]
---- EP [1/5] | BTCH [3403/3634] ||| train_loss = nan ----
LR: [0.007031127281702706]
---- EP [1/5] | BTCH [3404/3634] ||| train_loss = nan ----
LR: [0.007033684637515062]
---- EP [1/5] | BTCH [3405/3634] ||| train_loss = nan ----
LR: [0.007036241384027142]
---- EP [1/5] | BTCH [3406/3634] ||| train_loss = nan ----
LR: [0.007038797520389383]
---- EP [1/5] | BTCH [3407/3634] ||| train_loss = nan ----
LR: [0.00704135304575243]
---- EP [1/5] | BTCH [3408/3634] ||| train_loss = nan ----
LR: [0.007043907959267126]
---- EP [1/5] | BTCH [3409/3634] ||| train_loss = nan ----
LR: [0.00704646226008452]
---- EP [1/5] | BTCH [3410/3634] ||| train_loss = nan ----
LR: [0.007049015947355865]
---- EP [1/5] | BTCH [3411/3634] ||| train_loss = nan ----
LR: [0.007051569020232615]
---- EP [1/5] | BTCH [3412/3634] ||| train_loss = nan ----
LR: [0.007054121477866432]
---- EP [1/5] | BTCH [3413/3634] ||| train_loss = nan ----
LR: [0.007056673319409179]
---- EP [1/5] | BTCH [3414/3634] ||| train_loss = nan ----
LR: [0.007059224544012926]
---- EP [1/5] | BTCH [3415/3634] ||| train_loss = nan ----
LR: [0.007061775150829948]
---- EP [1/5] | BTCH [3416/3634] ||| train_loss = nan ----
LR: [0.007064325139012723]
---- EP [1/5] | BTCH [3417/3634] ||| train_loss = nan ----
LR: [0.007066874507713934]
---- EP [1/5] | BTCH [3418/3634] ||| train_loss = nan ----
LR: [0.007069423256086475]
---- EP [1/5] | BTCH [3419/3634] ||| train_loss = nan ----
LR: [0.007071971383283443]
---- EP [1/5] | BTCH [3420/3634] ||| train_loss = nan ----
LR: [0.00707451888845814]
---- EP [1/5] | BTCH [3421/3634] ||| train_loss = nan ----
LR: [0.007077065770764076]
---- EP [1/5] | BTCH [3422/3634] ||| train_loss = nan ----
LR: [0.007079612029354969]
---- EP [1/5] | BTCH [3423/3634] ||| train_loss = nan ----
LR: [0.007082157663384743]
---- EP [1/5] | BTCH [3424/3634] ||| train_loss = nan ----
LR: [0.0070847026720075295]
---- EP [1/5] | BTCH [3425/3634] ||| train_loss = nan ----
LR: [0.007087247054377669]
---- EP [1/5] | BTCH [3426/3634] ||| train_loss = nan ----
LR: [0.007089790809649707]
---- EP [1/5] | BTCH [3427/3634] ||| train_loss = nan ----
LR: [0.007092333936978402]
---- EP [1/5] | BTCH [3428/3634] ||| train_loss = nan ----
LR: [0.007094876435518717]
---- EP [1/5] | BTCH [3429/3634] ||| train_loss = nan ----
LR: [0.007097418304425825]
---- EP [1/5] | BTCH [3430/3634] ||| train_loss = nan ----
LR: [0.007099959542855113]
---- EP [1/5] | BTCH [3431/3634] ||| train_loss = nan ----
LR: [0.007102500149962168]
---- EP [1/5] | BTCH [3432/3634] ||| train_loss = nan ----
LR: [0.007105040124902798]
---- EP [1/5] | BTCH [3433/3634] ||| train_loss = nan ----
LR: [0.007107579466833009]
---- EP [1/5] | BTCH [3434/3634] ||| train_loss = nan ----
LR: [0.007110118174909028]
---- EP [1/5] | BTCH [3435/3634] ||| train_loss = nan ----
LR: [0.007112656248287287]
---- EP [1/5] | BTCH [3436/3634] ||| train_loss = nan ----
LR: [0.00711519368612443]
---- EP [1/5] | BTCH [3437/3634] ||| train_loss = nan ----
LR: [0.007117730487577311]
---- EP [1/5] | BTCH [3438/3634] ||| train_loss = nan ----
LR: [0.007120266651802998]
---- EP [1/5] | BTCH [3439/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.007122802177958771]
---- EP [1/5] | BTCH [3440/3634] ||| train_loss = nan ----
LR: [0.007125337065202115]
---- EP [1/5] | BTCH [3441/3634] ||| train_loss = nan ----
LR: [0.0071278713126907405]
---- EP [1/5] | BTCH [3442/3634] ||| train_loss = nan ----
LR: [0.007130404919582557]
---- EP [1/5] | BTCH [3443/3634] ||| train_loss = nan ----
LR: [0.007132937885035693]
---- EP [1/5] | BTCH [3444/3634] ||| train_loss = nan ----
LR: [0.0071354702082084935]
---- EP [1/5] | BTCH [3445/3634] ||| train_loss = nan ----
LR: [0.007138001888259512]
---- EP [1/5] | BTCH [3446/3634] ||| train_loss = nan ----
LR: [0.007140532924347513]
---- EP [1/5] | BTCH [3447/3634] ||| train_loss = nan ----
LR: [0.007143063315631484]
---- EP [1/5] | BTCH [3448/3634] ||| train_loss = nan ----
LR: [0.00714559306127062]
---- EP [1/5] | BTCH [3449/3634] ||| train_loss = nan ----
LR: [0.00714812216042433]
---- EP [1/5] | BTCH [3450/3634] ||| train_loss = nan ----
LR: [0.007150650612252244]
---- EP [1/5] | BTCH [3451/3634] ||| train_loss = nan ----
LR: [0.0071531784159142]
---- EP [1/5] | BTCH [3452/3634] ||| train_loss = nan ----
LR: [0.007155705570570256]
---- EP [1/5] | BTCH [3453/3634] ||| train_loss = nan ----
LR: [0.007158232075380683]
---- EP [1/5] | BTCH [3454/3634] ||| train_loss = nan ----
LR: [0.007160757929505971]
---- EP [1/5] | BTCH [3455/3634] ||| train_loss = nan ----
LR: [0.007163283132106823]
---- EP [1/5] | BTCH [3456/3634] ||| train_loss = nan ----
LR: [0.007165807682344161]
---- EP [1/5] | BTCH [3457/3634] ||| train_loss = nan ----
LR: [0.007168331579379119]
---- EP [1/5] | BTCH [3458/3634] ||| train_loss = nan ----
LR: [0.007170854822373056]
---- EP [1/5] | BTCH [3459/3634] ||| train_loss = nan ----
LR: [0.007173377410487541]
---- EP [1/5] | BTCH [3460/3634] ||| train_loss = nan ----
LR: [0.007175899342884365]
---- EP [1/5] | BTCH [3461/3634] ||| train_loss = nan ----
LR: [0.007178420618725536]
---- EP [1/5] | BTCH [3462/3634] ||| train_loss = nan ----
LR: [0.007180941237173278]
---- EP [1/5] | BTCH [3463/3634] ||| train_loss = nan ----
LR: [0.007183461197390035]
---- EP [1/5] | BTCH [3464/3634] ||| train_loss = nan ----
LR: [0.0071859804985384725]
---- EP [1/5] | BTCH [3465/3634] ||| train_loss = nan ----
LR: [0.007188499139781469]
---- EP [1/5] | BTCH [3466/3634] ||| train_loss = nan ----
LR: [0.0071910171202821255]
---- EP [1/5] | BTCH [3467/3634] ||| train_loss = nan ----
LR: [0.007193534439203765]
---- EP [1/5] | BTCH [3468/3634] ||| train_loss = nan ----
LR: [0.007196051095709926]
---- EP [1/5] | BTCH [3469/3634] ||| train_loss = nan ----
LR: [0.00719856708896437]
---- EP [1/5] | BTCH [3470/3634] ||| train_loss = nan ----
LR: [0.007201082418131078]
---- EP [1/5] | BTCH [3471/3634] ||| train_loss = nan ----
LR: [0.007203597082374249]
---- EP [1/5] | BTCH [3472/3634] ||| train_loss = nan ----
LR: [0.007206111080858311]
---- EP [1/5] | BTCH [3473/3634] ||| train_loss = nan ----
LR: [0.007208624412747904]
---- EP [1/5] | BTCH [3474/3634] ||| train_loss = nan ----
LR: [0.0072111370772078905]
---- EP [1/5] | BTCH [3475/3634] ||| train_loss = nan ----
LR: [0.007213649073403364]
---- EP [1/5] | BTCH [3476/3634] ||| train_loss = nan ----
LR: [0.007216160400499629]
---- EP [1/5] | BTCH [3477/3634] ||| train_loss = nan ----
LR: [0.0072186710576622164]
---- EP [1/5] | BTCH [3478/3634] ||| train_loss = nan ----
LR: [0.007221181044056885]
---- EP [1/5] | BTCH [3479/3634] ||| train_loss = nan ----
LR: [0.007223690358849605]
---- EP [1/5] | BTCH [3480/3634] ||| train_loss = nan ----
LR: [0.00722619900120658]
---- EP [1/5] | BTCH [3481/3634] ||| train_loss = nan ----
LR: [0.007228706970294237]
---- EP [1/5] | BTCH [3482/3634] ||| train_loss = nan ----
LR: [0.007231214265279217]
---- EP [1/5] | BTCH [3483/3634] ||| train_loss = nan ----
LR: [0.007233720885328393]
---- EP [1/5] | BTCH [3484/3634] ||| train_loss = nan ----
LR: [0.0072362268296088635]
---- EP [1/5] | BTCH [3485/3634] ||| train_loss = nan ----
LR: [0.007238732097287946]
---- EP [1/5] | BTCH [3486/3634] ||| train_loss = nan ----
LR: [0.007241236687533183]
---- EP [1/5] | BTCH [3487/3634] ||| train_loss = nan ----
LR: [0.007243740599512349]
---- EP [1/5] | BTCH [3488/3634] ||| train_loss = nan ----
LR: [0.0072462438323934375]
---- EP [1/5] | BTCH [3489/3634] ||| train_loss = nan ----
LR: [0.007248746385344666]
---- EP [1/5] | BTCH [3490/3634] ||| train_loss = nan ----
LR: [0.007251248257534486]
---- EP [1/5] | BTCH [3491/3634] ||| train_loss = nan ----
LR: [0.007253749448131569]
---- EP [1/5] | BTCH [3492/3634] ||| train_loss = nan ----
LR: [0.007256249956304815]
---- EP [1/5] | BTCH [3493/3634] ||| train_loss = nan ----
LR: [0.007258749781223352]
---- EP [1/5] | BTCH [3494/3634] ||| train_loss = nan ----
LR: [0.007261248922056528]
---- EP [1/5] | BTCH [3495/3634] ||| train_loss = nan ----
LR: [0.007263747377973928]
---- EP [1/5] | BTCH [3496/3634] ||| train_loss = nan ----
LR: [0.00726624514814536]
---- EP [1/5] | BTCH [3497/3634] ||| train_loss = nan ----
LR: [0.007268742231740857]
---- EP [1/5] | BTCH [3498/3634] ||| train_loss = nan ----
LR: [0.0072712386279306885]
---- EP [1/5] | BTCH [3499/3634] ||| train_loss = nan ----
LR: [0.007273734335885341]
---- EP [1/5] | BTCH [3500/3634] ||| train_loss = nan ----
LR: [0.00727622935477554]
---- EP [1/5] | BTCH [3501/3634] ||| train_loss = nan ----
LR: [0.007278723683772236]
---- EP [1/5] | BTCH [3502/3634] ||| train_loss = nan ----
LR: [0.007281217322046608]
---- EP [1/5] | BTCH [3503/3634] ||| train_loss = nan ----
LR: [0.007283710268770061]
---- EP [1/5] | BTCH [3504/3634] ||| train_loss = nan ----
LR: [0.00728620252311424]
---- EP [1/5] | BTCH [3505/3634] ||| train_loss = nan ----
LR: [0.007288694084251011]
---- EP [1/5] | BTCH [3506/3634] ||| train_loss = nan ----
LR: [0.007291184951352472]
---- EP [1/5] | BTCH [3507/3634] ||| train_loss = nan ----
LR: [0.007293675123590955]
---- EP [1/5] | BTCH [3508/3634] ||| train_loss = nan ----
LR: [0.007296164600139018]
---- EP [1/5] | BTCH [3509/3634] ||| train_loss = nan ----
LR: [0.007298653380169457]
---- EP [1/5] | BTCH [3510/3634] ||| train_loss = nan ----
LR: [0.007301141462855293]
---- EP [1/5] | BTCH [3511/3634] ||| train_loss = nan ----
LR: [0.00730362884736978]
---- EP [1/5] | BTCH [3512/3634] ||| train_loss = nan ----
LR: [0.007306115532886407]
---- EP [1/5] | BTCH [3513/3634] ||| train_loss = nan ----
LR: [0.007308601518578895]
---- EP [1/5] | BTCH [3514/3634] ||| train_loss = nan ----
LR: [0.00731108680362119]
---- EP [1/5] | BTCH [3515/3634] ||| train_loss = nan ----
LR: [0.007313571387187482]
---- EP [1/5] | BTCH [3516/3634] ||| train_loss = nan ----
LR: [0.0073160552684521886]
---- EP [1/5] | BTCH [3517/3634] ||| train_loss = nan ----
LR: [0.007318538446589956]
---- EP [1/5] | BTCH [3518/3634] ||| train_loss = nan ----
LR: [0.0073210209207756755]
---- EP [1/5] | BTCH [3519/3634] ||| train_loss = nan ----
LR: [0.007323502690184459]
---- EP [1/5] | BTCH [3520/3634] ||| train_loss = nan ----
LR: [0.0073259837539916646]
---- EP [1/5] | BTCH [3521/3634] ||| train_loss = nan ----
LR: [0.0073284641113728795]
---- EP [1/5] | BTCH [3522/3634] ||| train_loss = nan ----
LR: [0.007330943761503924]
---- EP [1/5] | BTCH [3523/3634] ||| train_loss = nan ----
LR: [0.007333422703560853]
---- EP [1/5] | BTCH [3524/3634] ||| train_loss = nan ----
LR: [0.007335900936719963]
---- EP [1/5] | BTCH [3525/3634] ||| train_loss = nan ----
LR: [0.007338378460157781]
---- EP [1/5] | BTCH [3526/3634] ||| train_loss = nan ----
LR: [0.007340855273051068]
---- EP [1/5] | BTCH [3527/3634] ||| train_loss = nan ----
LR: [0.007343331374576828]
---- EP [1/5] | BTCH [3528/3634] ||| train_loss = nan ----
LR: [0.007345806763912291]
---- EP [1/5] | BTCH [3529/3634] ||| train_loss = nan ----
LR: [0.007348281440234937]
---- EP [1/5] | BTCH [3530/3634] ||| train_loss = nan ----
LR: [0.0073507554027224704]
---- EP [1/5] | BTCH [3531/3634] ||| train_loss = nan ----
LR: [0.007353228650552841]
---- EP [1/5] | BTCH [3532/3634] ||| train_loss = nan ----
LR: [0.007355701182904233]
---- EP [1/5] | BTCH [3533/3634] ||| train_loss = nan ----
LR: [0.0073581729989550685]
---- EP [1/5] | BTCH [3534/3634] ||| train_loss = nan ----
LR: [0.007360644097884005]
---- EP [1/5] | BTCH [3535/3634] ||| train_loss = nan ----
LR: [0.007363114478869946]
---- EP [1/5] | BTCH [3536/3634] ||| train_loss = nan ----
LR: [0.007365584141092025]
---- EP [1/5] | BTCH [3537/3634] ||| train_loss = nan ----
LR: [0.007368053083729617]
---- EP [1/5] | BTCH [3538/3634] ||| train_loss = nan ----
LR: [0.00737052130596234]
---- EP [1/5] | BTCH [3539/3634] ||| train_loss = nan ----
LR: [0.007372988806970046]
---- EP [1/5] | BTCH [3540/3634] ||| train_loss = nan ----
LR: [0.0073754555859328295]
---- EP [1/5] | BTCH [3541/3634] ||| train_loss = nan ----
LR: [0.007377921642031026]
---- EP [1/5] | BTCH [3542/3634] ||| train_loss = nan ----
LR: [0.0073803869744452095]
---- EP [1/5] | BTCH [3543/3634] ||| train_loss = nan ----
LR: [0.007382851582356191]
---- EP [1/5] | BTCH [3544/3634] ||| train_loss = nan ----
LR: [0.00738531546494503]
---- EP [1/5] | BTCH [3545/3634] ||| train_loss = nan ----
LR: [0.0073877786213930215]
---- EP [1/5] | BTCH [3546/3634] ||| train_loss = nan ----
LR: [0.0073902410508817]
---- EP [1/5] | BTCH [3547/3634] ||| train_loss = nan ----
LR: [0.00739270275259285]
---- EP [1/5] | BTCH [3548/3634] ||| train_loss = nan ----
LR: [0.007395163725708489]
---- EP [1/5] | BTCH [3549/3634] ||| train_loss = nan ----
LR: [0.0073976239694108804]
---- EP [1/5] | BTCH [3550/3634] ||| train_loss = nan ----
LR: [0.007400083482882531]
---- EP [1/5] | BTCH [3551/3634] ||| train_loss = nan ----
LR: [0.007402542265306188]
---- EP [1/5] | BTCH [3552/3634] ||| train_loss = nan ----
LR: [0.007405000315864843]
---- EP [1/5] | BTCH [3553/3634] ||| train_loss = nan ----
LR: [0.007407457633741731]
---- EP [1/5] | BTCH [3554/3634] ||| train_loss = nan ----
LR: [0.007409914218120326]
---- EP [1/5] | BTCH [3555/3634] ||| train_loss = nan ----
LR: [0.007412370068184354]
---- EP [1/5] | BTCH [3556/3634] ||| train_loss = nan ----
LR: [0.007414825183117778]
---- EP [1/5] | BTCH [3557/3634] ||| train_loss = nan ----
LR: [0.007417279562104806]
---- EP [1/5] | BTCH [3558/3634] ||| train_loss = nan ----
LR: [0.007419733204329896]
---- EP [1/5] | BTCH [3559/3634] ||| train_loss = nan ----
LR: [0.007422186108977744]
---- EP [1/5] | BTCH [3560/3634] ||| train_loss = nan ----
LR: [0.007424638275233295]
---- EP [1/5] | BTCH [3561/3634] ||| train_loss = nan ----
LR: [0.00742708970228174]
---- EP [1/5] | BTCH [3562/3634] ||| train_loss = nan ----
LR: [0.0074295403893085135]
---- EP [1/5] | BTCH [3563/3634] ||| train_loss = nan ----
LR: [0.007431990335499294]
---- EP [1/5] | BTCH [3564/3634] ||| train_loss = nan ----
LR: [0.007434439540040011]
---- EP [1/5] | BTCH [3565/3634] ||| train_loss = nan ----
LR: [0.007436888002116839]
---- EP [1/5] | BTCH [3566/3634] ||| train_loss = nan ----
LR: [0.007439335720916193]
---- EP [1/5] | BTCH [3567/3634] ||| train_loss = nan ----
LR: [0.007441782695624748]
---- EP [1/5] | BTCH [3568/3634] ||| train_loss = nan ----
LR: [0.007444228925429413]
---- EP [1/5] | BTCH [3569/3634] ||| train_loss = nan ----
LR: [0.007446674409517349]
---- EP [1/5] | BTCH [3570/3634] ||| train_loss = nan ----
LR: [0.007449119147075972]
---- EP [1/5] | BTCH [3571/3634] ||| train_loss = nan ----
LR: [0.007451563137292934]
---- EP [1/5] | BTCH [3572/3634] ||| train_loss = nan ----
LR: [0.007454006379356146]
---- EP [1/5] | BTCH [3573/3634] ||| train_loss = nan ----
LR: [0.0074564488724537595]
---- EP [1/5] | BTCH [3574/3634] ||| train_loss = nan ----
LR: [0.0074588906157741774]
---- EP [1/5] | BTCH [3575/3634] ||| train_loss = nan ----
LR: [0.007461331608506056]
---- EP [1/5] | BTCH [3576/3634] ||| train_loss = nan ----
LR: [0.007463771849838296]
---- EP [1/5] | BTCH [3577/3634] ||| train_loss = nan ----
LR: [0.007466211338960046]
---- EP [1/5] | BTCH [3578/3634] ||| train_loss = nan ----
LR: [0.007468650075060713]
---- EP [1/5] | BTCH [3579/3634] ||| train_loss = nan ----
LR: [0.007471088057329945]
---- EP [1/5] | BTCH [3580/3634] ||| train_loss = nan ----
LR: [0.007473525284957647]
---- EP [1/5] | BTCH [3581/3634] ||| train_loss = nan ----
LR: [0.007475961757133973]
---- EP [1/5] | BTCH [3582/3634] ||| train_loss = nan ----
LR: [0.007478397473049326]
---- EP [1/5] | BTCH [3583/3634] ||| train_loss = nan ----
LR: [0.007480832431894359]
---- EP [1/5] | BTCH [3584/3634] ||| train_loss = nan ----
LR: [0.007483266632859984]
---- EP [1/5] | BTCH [3585/3634] ||| train_loss = nan ----
LR: [0.007485700075137358]
---- EP [1/5] | BTCH [3586/3634] ||| train_loss = nan ----
LR: [0.00748813275791789]
---- EP [1/5] | BTCH [3587/3634] ||| train_loss = nan ----
LR: [0.007490564680393247]
---- EP [1/5] | BTCH [3588/3634] ||| train_loss = nan ----
LR: [0.007492995841755341]
---- EP [1/5] | BTCH [3589/3634] ||| train_loss = nan ----
LR: [0.007495426241196344]
---- EP [1/5] | BTCH [3590/3634] ||| train_loss = nan ----
LR: [0.0074978558779086775]
---- EP [1/5] | BTCH [3591/3634] ||| train_loss = nan ----
LR: [0.007500284751085017]
---- EP [1/5] | BTCH [3592/3634] ||| train_loss = nan ----
LR: [0.0075027128599182945]
---- EP [1/5] | BTCH [3593/3634] ||| train_loss = nan ----
LR: [0.007505140203601689]
---- EP [1/5] | BTCH [3594/3634] ||| train_loss = nan ----
LR: [0.007507566781328639]
---- EP [1/5] | BTCH [3595/3634] ||| train_loss = nan ----
LR: [0.007509992592292838]
---- EP [1/5] | BTCH [3596/3634] ||| train_loss = nan ----
LR: [0.007512417635688234]
---- EP [1/5] | BTCH [3597/3634] ||| train_loss = nan ----
LR: [0.007514841910709025]
---- EP [1/5] | BTCH [3598/3634] ||| train_loss = nan ----
LR: [0.007517265416549669]
---- EP [1/5] | BTCH [3599/3634] ||| train_loss = nan ----
LR: [0.007519688152404882]
---- EP [1/5] | BTCH [3600/3634] ||| train_loss = nan ----
LR: [0.007522110117469631]
---- EP [1/5] | BTCH [3601/3634] ||| train_loss = nan ----
LR: [0.007524531310939141]
---- EP [1/5] | BTCH [3602/3634] ||| train_loss = nan ----
LR: [0.007526951732008892]
---- EP [1/5] | BTCH [3603/3634] ||| train_loss = nan ----
LR: [0.007529371379874622]
---- EP [1/5] | BTCH [3604/3634] ||| train_loss = nan ----
LR: [0.007531790253732327]
---- EP [1/5] | BTCH [3605/3634] ||| train_loss = nan ----
LR: [0.0075342083527782586]
---- EP [1/5] | BTCH [3606/3634] ||| train_loss = nan ----
LR: [0.007536625676208924]
---- EP [1/5] | BTCH [3607/3634] ||| train_loss = nan ----
LR: [0.007539042223221094]
---- EP [1/5] | BTCH [3608/3634] ||| train_loss = nan ----
LR: [0.007541457993011789]
---- EP [1/5] | BTCH [3609/3634] ||| train_loss = nan ----
LR: [0.0075438729847782954]
---- EP [1/5] | BTCH [3610/3634] ||| train_loss = nan ----
LR: [0.0075462871977181566]
---- EP [1/5] | BTCH [3611/3634] ||| train_loss = nan ----
LR: [0.007548700631029169]
---- EP [1/5] | BTCH [3612/3634] ||| train_loss = nan ----
LR: [0.007551113283909398]
---- EP [1/5] | BTCH [3613/3634] ||| train_loss = nan ----
LR: [0.007553525155557158]
---- EP [1/5] | BTCH [3614/3634] ||| train_loss = nan ----
LR: [0.007555936245171027]
---- EP [1/5] | BTCH [3615/3634] ||| train_loss = nan ----
LR: [0.007558346551949848]
---- EP [1/5] | BTCH [3616/3634] ||| train_loss = nan ----
LR: [0.007560756075092717]
---- EP [1/5] | BTCH [3617/3634] ||| train_loss = nan ----
LR: [0.007563164813798991]
---- EP [1/5] | BTCH [3618/3634] ||| train_loss = nan ----
LR: [0.007565572767268292]
---- EP [1/5] | BTCH [3619/3634] ||| train_loss = nan ----
LR: [0.0075679799347005]
---- EP [1/5] | BTCH [3620/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.0075703863152957575]
---- EP [1/5] | BTCH [3621/3634] ||| train_loss = nan ----
LR: [0.007572791908254468]
---- EP [1/5] | BTCH [3622/3634] ||| train_loss = nan ----
LR: [0.007575196712777297]
---- EP [1/5] | BTCH [3623/3634] ||| train_loss = nan ----
LR: [0.007577600728065166]
---- EP [1/5] | BTCH [3624/3634] ||| train_loss = nan ----
LR: [0.007580003953319271]
---- EP [1/5] | BTCH [3625/3634] ||| train_loss = nan ----
LR: [0.0075824063877410605]
---- EP [1/5] | BTCH [3626/3634] ||| train_loss = nan ----
LR: [0.007584808030532248]
---- EP [1/5] | BTCH [3627/3634] ||| train_loss = nan ----
LR: [0.0075872088808948135]
---- EP [1/5] | BTCH [3628/3634] ||| train_loss = nan ----
LR: [0.007589608938030994]
---- EP [1/5] | BTCH [3629/3634] ||| train_loss = nan ----
LR: [0.007592008201143298]
---- EP [1/5] | BTCH [3630/3634] ||| train_loss = nan ----
LR: [0.007594406669434494]
---- EP [1/5] | BTCH [3631/3634] ||| train_loss = nan ----
LR: [0.00759680434210761]
---- EP [1/5] | BTCH [3632/3634] ||| train_loss = nan ----
LR: [0.007599201218365947]
---- EP [1/5] | BTCH [3633/3634] ||| train_loss = nan ----
LR: [0.0076015972974130645]
---- EP [1/5] | BTCH [3634/3634] ||| train_loss = nan ----
LR: [0.007603992578452786]
---- EP [2/5] | BTCH [1/3634] ||| train_loss = nan ----
LR: [0.007606387060689208]
---- EP [2/5] | BTCH [2/3634] ||| train_loss = nan ----
LR: [0.007608780743326686]
---- EP [2/5] | BTCH [3/3634] ||| train_loss = nan ----
LR: [0.007611173625569838]
---- EP [2/5] | BTCH [4/3634] ||| train_loss = nan ----
LR: [0.0076135657066235575]
---- EP [2/5] | BTCH [5/3634] ||| train_loss = nan ----
LR: [0.007615956985692998]
---- EP [2/5] | BTCH [6/3634] ||| train_loss = nan ----
LR: [0.007618347461983578]
---- EP [2/5] | BTCH [7/3634] ||| train_loss = nan ----
LR: [0.007620737134700991]
---- EP [2/5] | BTCH [8/3634] ||| train_loss = nan ----
LR: [0.007623126003051187]
---- EP [2/5] | BTCH [9/3634] ||| train_loss = nan ----
LR: [0.007625514066240388]
---- EP [2/5] | BTCH [10/3634] ||| train_loss = nan ----
LR: [0.007627901323475089]
---- EP [2/5] | BTCH [11/3634] ||| train_loss = nan ----
LR: [0.007630287773962043]
---- EP [2/5] | BTCH [12/3634] ||| train_loss = nan ----
LR: [0.007632673416908275]
---- EP [2/5] | BTCH [13/3634] ||| train_loss = nan ----
LR: [0.00763505825152108]
---- EP [2/5] | BTCH [14/3634] ||| train_loss = nan ----
LR: [0.007637442277008024]
---- EP [2/5] | BTCH [15/3634] ||| train_loss = nan ----
LR: [0.007639825492576933]
---- EP [2/5] | BTCH [16/3634] ||| train_loss = nan ----
LR: [0.007642207897435912]
---- EP [2/5] | BTCH [17/3634] ||| train_loss = nan ----
LR: [0.007644589490793327]
---- EP [2/5] | BTCH [18/3634] ||| train_loss = nan ----
LR: [0.007646970271857822]
---- EP [2/5] | BTCH [19/3634] ||| train_loss = nan ----
LR: [0.007649350239838304]
---- EP [2/5] | BTCH [20/3634] ||| train_loss = nan ----
LR: [0.00765172939394395]
---- EP [2/5] | BTCH [21/3634] ||| train_loss = nan ----
LR: [0.007654107733384215]
---- EP [2/5] | BTCH [22/3634] ||| train_loss = nan ----
LR: [0.007656485257368818]
---- EP [2/5] | BTCH [23/3634] ||| train_loss = nan ----
LR: [0.007658861965107748]
---- EP [2/5] | BTCH [24/3634] ||| train_loss = nan ----
LR: [0.00766123785581127]
---- EP [2/5] | BTCH [25/3634] ||| train_loss = nan ----
LR: [0.00766361292868992]
---- EP [2/5] | BTCH [26/3634] ||| train_loss = nan ----
LR: [0.007665987182954502]
---- EP [2/5] | BTCH [27/3634] ||| train_loss = nan ----
LR: [0.007668360617816096]
---- EP [2/5] | BTCH [28/3634] ||| train_loss = nan ----
LR: [0.007670733232486053]
---- EP [2/5] | BTCH [29/3634] ||| train_loss = nan ----
LR: [0.0076731050261759914]
---- EP [2/5] | BTCH [30/3634] ||| train_loss = nan ----
LR: [0.007675475998097812]
---- EP [2/5] | BTCH [31/3634] ||| train_loss = nan ----
LR: [0.007677846147463682]
---- EP [2/5] | BTCH [32/3634] ||| train_loss = nan ----
LR: [0.007680215473486042]
---- EP [2/5] | BTCH [33/3634] ||| train_loss = nan ----
LR: [0.007682583975377608]
---- EP [2/5] | BTCH [34/3634] ||| train_loss = nan ----
LR: [0.007684951652351373]
---- EP [2/5] | BTCH [35/3634] ||| train_loss = nan ----
LR: [0.007687318503620597]
---- EP [2/5] | BTCH [36/3634] ||| train_loss = nan ----
LR: [0.007689684528398822]
---- EP [2/5] | BTCH [37/3634] ||| train_loss = nan ----
LR: [0.007692049725899855]
---- EP [2/5] | BTCH [38/3634] ||| train_loss = nan ----
LR: [0.00769441409533779]
---- EP [2/5] | BTCH [39/3634] ||| train_loss = nan ----
LR: [0.007696777635926986]
---- EP [2/5] | BTCH [40/3634] ||| train_loss = nan ----
LR: [0.00769914034688208]
---- EP [2/5] | BTCH [41/3634] ||| train_loss = nan ----
LR: [0.00770150222741799]
---- EP [2/5] | BTCH [42/3634] ||| train_loss = nan ----
LR: [0.007703863276749902]
---- EP [2/5] | BTCH [43/3634] ||| train_loss = nan ----
LR: [0.007706223494093282]
---- EP [2/5] | BTCH [44/3634] ||| train_loss = nan ----
LR: [0.007708582878663875]
---- EP [2/5] | BTCH [45/3634] ||| train_loss = nan ----
LR: [0.007710941429677699]
---- EP [2/5] | BTCH [46/3634] ||| train_loss = nan ----
LR: [0.007713299146351049]
---- EP [2/5] | BTCH [47/3634] ||| train_loss = nan ----
LR: [0.007715656027900501]
---- EP [2/5] | BTCH [48/3634] ||| train_loss = nan ----
LR: [0.007718012073542904]
---- EP [2/5] | BTCH [49/3634] ||| train_loss = nan ----
LR: [0.007720367282495385]
---- EP [2/5] | BTCH [50/3634] ||| train_loss = nan ----
LR: [0.007722721653975355]
---- EP [2/5] | BTCH [51/3634] ||| train_loss = nan ----
LR: [0.007725075187200496]
---- EP [2/5] | BTCH [52/3634] ||| train_loss = nan ----
LR: [0.0077274278813887695]
---- EP [2/5] | BTCH [53/3634] ||| train_loss = nan ----
LR: [0.00772977973575842]
---- EP [2/5] | BTCH [54/3634] ||| train_loss = nan ----
LR: [0.007732130749527972]
---- EP [2/5] | BTCH [55/3634] ||| train_loss = nan ----
LR: [0.00773448092191622]
---- EP [2/5] | BTCH [56/3634] ||| train_loss = nan ----
LR: [0.007736830252142248]
---- EP [2/5] | BTCH [57/3634] ||| train_loss = nan ----
LR: [0.007739178739425414]
---- EP [2/5] | BTCH [58/3634] ||| train_loss = nan ----
LR: [0.007741526382985361]
---- EP [2/5] | BTCH [59/3634] ||| train_loss = nan ----
LR: [0.0077438731820420065]
---- EP [2/5] | BTCH [60/3634] ||| train_loss = nan ----
LR: [0.007746219135815553]
---- EP [2/5] | BTCH [61/3634] ||| train_loss = nan ----
LR: [0.007748564243526482]
---- EP [2/5] | BTCH [62/3634] ||| train_loss = nan ----
LR: [0.007750908504395556]
---- EP [2/5] | BTCH [63/3634] ||| train_loss = nan ----
LR: [0.007753251917643821]
---- EP [2/5] | BTCH [64/3634] ||| train_loss = nan ----
LR: [0.007755594482492601]
---- EP [2/5] | BTCH [65/3634] ||| train_loss = nan ----
LR: [0.007757936198163507]
---- EP [2/5] | BTCH [66/3634] ||| train_loss = nan ----
LR: [0.007760277063878426]
---- EP [2/5] | BTCH [67/3634] ||| train_loss = nan ----
LR: [0.007762617078859533]
---- EP [2/5] | BTCH [68/3634] ||| train_loss = nan ----
LR: [0.007764956242329283]
---- EP [2/5] | BTCH [69/3634] ||| train_loss = nan ----
LR: [0.007767294553510412]
---- EP [2/5] | BTCH [70/3634] ||| train_loss = nan ----
LR: [0.007769632011625945]
---- EP [2/5] | BTCH [71/3634] ||| train_loss = nan ----
LR: [0.007771968615899185]
---- EP [2/5] | BTCH [72/3634] ||| train_loss = nan ----
LR: [0.0077743043655537185]
---- EP [2/5] | BTCH [73/3634] ||| train_loss = nan ----
LR: [0.00777663925981342]
---- EP [2/5] | BTCH [74/3634] ||| train_loss = nan ----
LR: [0.007778973297902449]
---- EP [2/5] | BTCH [75/3634] ||| train_loss = nan ----
LR: [0.007781306479045241]
---- EP [2/5] | BTCH [76/3634] ||| train_loss = nan ----
LR: [0.007783638802466528]
---- EP [2/5] | BTCH [77/3634] ||| train_loss = nan ----
LR: [0.007785970267391317]
---- EP [2/5] | BTCH [78/3634] ||| train_loss = nan ----
LR: [0.007788300873044907]
---- EP [2/5] | BTCH [79/3634] ||| train_loss = nan ----
LR: [0.007790630618652879]
---- EP [2/5] | BTCH [80/3634] ||| train_loss = nan ----
LR: [0.007792959503441098]
---- EP [2/5] | BTCH [81/3634] ||| train_loss = nan ----
LR: [0.007795287526635723]
---- EP [2/5] | BTCH [82/3634] ||| train_loss = nan ----
LR: [0.007797614687463187]
---- EP [2/5] | BTCH [83/3634] ||| train_loss = nan ----
LR: [0.0077999409851502235]
---- EP [2/5] | BTCH [84/3634] ||| train_loss = nan ----
LR: [0.0078022664189238405]
---- EP [2/5] | BTCH [85/3634] ||| train_loss = nan ----
LR: [0.007804590988011341]
---- EP [2/5] | BTCH [86/3634] ||| train_loss = nan ----
LR: [0.007806914691640313]
---- EP [2/5] | BTCH [87/3634] ||| train_loss = nan ----
LR: [0.007809237529038631]
---- EP [2/5] | BTCH [88/3634] ||| train_loss = nan ----
LR: [0.007811559499434458]
---- EP [2/5] | BTCH [89/3634] ||| train_loss = nan ----
LR: [0.007813880602056244]
---- EP [2/5] | BTCH [90/3634] ||| train_loss = nan ----
LR: [0.007816200836132731]
---- EP [2/5] | BTCH [91/3634] ||| train_loss = nan ----
LR: [0.007818520200892947]
---- EP [2/5] | BTCH [92/3634] ||| train_loss = nan ----
LR: [0.007820838695566205]
---- EP [2/5] | BTCH [93/3634] ||| train_loss = nan ----
LR: [0.007823156319382116]
---- EP [2/5] | BTCH [94/3634] ||| train_loss = nan ----
LR: [0.007825473071570574]
---- EP [2/5] | BTCH [95/3634] ||| train_loss = nan ----
LR: [0.00782778895136176]
---- EP [2/5] | BTCH [96/3634] ||| train_loss = nan ----
LR: [0.007830103957986157]
---- EP [2/5] | BTCH [97/3634] ||| train_loss = nan ----
LR: [0.007832418090674524]
---- EP [2/5] | BTCH [98/3634] ||| train_loss = nan ----
LR: [0.007834731348657918]
---- EP [2/5] | BTCH [99/3634] ||| train_loss = nan ----
LR: [0.007837043731167687]
---- EP [2/5] | BTCH [100/3634] ||| train_loss = nan ----
LR: [0.007839355237435463]
---- EP [2/5] | BTCH [101/3634] ||| train_loss = nan ----
LR: [0.007841665866693182]
---- EP [2/5] | BTCH [102/3634] ||| train_loss = nan ----
LR: [0.007843975618173056]
---- EP [2/5] | BTCH [103/3634] ||| train_loss = nan ----
LR: [0.0078462844911076]
---- EP [2/5] | BTCH [104/3634] ||| train_loss = nan ----
LR: [0.007848592484729617]
---- EP [2/5] | BTCH [105/3634] ||| train_loss = nan ----
LR: [0.007850899598272204]
---- EP [2/5] | BTCH [106/3634] ||| train_loss = nan ----
LR: [0.007853205830968745]
---- EP [2/5] | BTCH [107/3634] ||| train_loss = nan ----
LR: [0.007855511182052926]
---- EP [2/5] | BTCH [108/3634] ||| train_loss = nan ----
LR: [0.007857815650758715]
---- EP [2/5] | BTCH [109/3634] ||| train_loss = nan ----
LR: [0.007860119236320379]
---- EP [2/5] | BTCH [110/3634] ||| train_loss = nan ----
LR: [0.007862421937972482]
---- EP [2/5] | BTCH [111/3634] ||| train_loss = nan ----
LR: [0.007864723754949876]
---- EP [2/5] | BTCH [112/3634] ||| train_loss = nan ----
LR: [0.007867024686487709]
---- EP [2/5] | BTCH [113/3634] ||| train_loss = nan ----
LR: [0.00786932473182142]
---- EP [2/5] | BTCH [114/3634] ||| train_loss = nan ----
LR: [0.007871623890186752]
---- EP [2/5] | BTCH [115/3634] ||| train_loss = nan ----
LR: [0.00787392216081973]
---- EP [2/5] | BTCH [116/3634] ||| train_loss = nan ----
LR: [0.007876219542956683]
---- EP [2/5] | BTCH [117/3634] ||| train_loss = nan ----
LR: [0.00787851603583423]
---- EP [2/5] | BTCH [118/3634] ||| train_loss = nan ----
LR: [0.007880811638689294]
---- EP [2/5] | BTCH [119/3634] ||| train_loss = nan ----
LR: [0.007883106350759082]
---- EP [2/5] | BTCH [120/3634] ||| train_loss = nan ----
LR: [0.007885400171281101]
---- EP [2/5] | BTCH [121/3634] ||| train_loss = nan ----
LR: [0.007887693099493163]
---- EP [2/5] | BTCH [122/3634] ||| train_loss = nan ----
LR: [0.007889985134633362]
---- EP [2/5] | BTCH [123/3634] ||| train_loss = nan ----
LR: [0.0078922762759401]
---- EP [2/5] | BTCH [124/3634] ||| train_loss = nan ----
LR: [0.007894566522652077]
---- EP [2/5] | BTCH [125/3634] ||| train_loss = nan ----
LR: [0.007896855874008277]
---- EP [2/5] | BTCH [126/3634] ||| train_loss = nan ----
LR: [0.00789914432924799]
---- EP [2/5] | BTCH [127/3634] ||| train_loss = nan ----
LR: [0.00790143188761081]
---- EP [2/5] | BTCH [128/3634] ||| train_loss = nan ----
LR: [0.00790371854833662]
---- EP [2/5] | BTCH [129/3634] ||| train_loss = nan ----
LR: [0.0079060043106656]
---- EP [2/5] | BTCH [130/3634] ||| train_loss = nan ----
LR: [0.007908289173838238]
---- EP [2/5] | BTCH [131/3634] ||| train_loss = nan ----
LR: [0.007910573137095311]
---- EP [2/5] | BTCH [132/3634] ||| train_loss = nan ----
LR: [0.007912856199677904]
---- EP [2/5] | BTCH [133/3634] ||| train_loss = nan ----
LR: [0.007915138360827391]
---- EP [2/5] | BTCH [134/3634] ||| train_loss = nan ----
LR: [0.007917419619785458]
---- EP [2/5] | BTCH [135/3634] ||| train_loss = nan ----
LR: [0.007919699975794075]
---- EP [2/5] | BTCH [136/3634] ||| train_loss = nan ----
LR: [0.007921979428095529]
---- EP [2/5] | BTCH [137/3634] ||| train_loss = nan ----
LR: [0.007924257975932394]
---- EP [2/5] | BTCH [138/3634] ||| train_loss = nan ----
LR: [0.007926535618547552]
---- EP [2/5] | BTCH [139/3634] ||| train_loss = nan ----
LR: [0.007928812355184185]
---- EP [2/5] | BTCH [140/3634] ||| train_loss = nan ----
LR: [0.00793108818508577]
---- EP [2/5] | BTCH [141/3634] ||| train_loss = nan ----
LR: [0.007933363107496094]
---- EP [2/5] | BTCH [142/3634] ||| train_loss = nan ----
LR: [0.007935637121659239]
---- EP [2/5] | BTCH [143/3634] ||| train_loss = nan ----
LR: [0.007937910226819592]
---- EP [2/5] | BTCH [144/3634] ||| train_loss = nan ----
LR: [0.007940182422221841]
---- EP [2/5] | BTCH [145/3634] ||| train_loss = nan ----
LR: [0.00794245370711098]
---- EP [2/5] | BTCH [146/3634] ||| train_loss = nan ----
LR: [0.007944724080732296]
---- EP [2/5] | BTCH [147/3634] ||| train_loss = nan ----
LR: [0.007946993542331388]
---- EP [2/5] | BTCH [148/3634] ||| train_loss = nan ----
LR: [0.007949262091154156]
---- EP [2/5] | BTCH [149/3634] ||| train_loss = nan ----
LR: [0.007951529726446799]
---- EP [2/5] | BTCH [150/3634] ||| train_loss = nan ----
LR: [0.007953796447455825]
---- EP [2/5] | BTCH [151/3634] ||| train_loss = nan ----
LR: [0.007956062253428042]
---- EP [2/5] | BTCH [152/3634] ||| train_loss = nan ----
LR: [0.007958327143610566]
---- EP [2/5] | BTCH [153/3634] ||| train_loss = nan ----
LR: [0.007960591117250814]
---- EP [2/5] | BTCH [154/3634] ||| train_loss = nan ----
LR: [0.00796285417359651]
---- EP [2/5] | BTCH [155/3634] ||| train_loss = nan ----
LR: [0.007965116311895675]
---- EP [2/5] | BTCH [156/3634] ||| train_loss = nan ----
LR: [0.00796737753139665]
---- EP [2/5] | BTCH [157/3634] ||| train_loss = nan ----
LR: [0.007969637831348065]
---- EP [2/5] | BTCH [158/3634] ||| train_loss = nan ----
LR: [0.007971897210998868]
---- EP [2/5] | BTCH [159/3634] ||| train_loss = nan ----
LR: [0.007974155669598307]
---- EP [2/5] | BTCH [160/3634] ||| train_loss = nan ----
LR: [0.007976413206395937]
---- EP [2/5] | BTCH [161/3634] ||| train_loss = nan ----
LR: [0.007978669820641618]
---- EP [2/5] | BTCH [162/3634] ||| train_loss = nan ----
LR: [0.007980925511585517]
---- EP [2/5] | BTCH [163/3634] ||| train_loss = nan ----
LR: [0.00798318027847811]
---- EP [2/5] | BTCH [164/3634] ||| train_loss = nan ----
LR: [0.007985434120570182]
---- EP [2/5] | BTCH [165/3634] ||| train_loss = nan ----
LR: [0.007987687037112817]
---- EP [2/5] | BTCH [166/3634] ||| train_loss = nan ----
LR: [0.007989939027357413]
---- EP [2/5] | BTCH [167/3634] ||| train_loss = nan ----
LR: [0.007992190090555677]
---- EP [2/5] | BTCH [168/3634] ||| train_loss = nan ----
LR: [0.007994440225959618]
---- EP [2/5] | BTCH [169/3634] ||| train_loss = nan ----
LR: [0.007996689432821558]
---- EP [2/5] | BTCH [170/3634] ||| train_loss = nan ----
LR: [0.007998937710394127]
---- EP [2/5] | BTCH [171/3634] ||| train_loss = nan ----
LR: [0.008001185057930259]
---- EP [2/5] | BTCH [172/3634] ||| train_loss = nan ----
LR: [0.008003431474683204]
---- EP [2/5] | BTCH [173/3634] ||| train_loss = nan ----
LR: [0.008005676959906522]
---- EP [2/5] | BTCH [174/3634] ||| train_loss = nan ----
LR: [0.008007921512854075]
---- EP [2/5] | BTCH [175/3634] ||| train_loss = nan ----
LR: [0.008010165132780035]
---- EP [2/5] | BTCH [176/3634] ||| train_loss = nan ----
LR: [0.008012407818938895]
---- EP [2/5] | BTCH [177/3634] ||| train_loss = nan ----
LR: [0.008014649570585446]
---- EP [2/5] | BTCH [178/3634] ||| train_loss = nan ----
LR: [0.008016890386974795]
---- EP [2/5] | BTCH [179/3634] ||| train_loss = nan ----
LR: [0.00801913026736236]
---- EP [2/5] | BTCH [180/3634] ||| train_loss = nan ----
LR: [0.008021369211003871]
---- EP [2/5] | BTCH [181/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.008023607217155365]
---- EP [2/5] | BTCH [182/3634] ||| train_loss = nan ----
LR: [0.008025844285073191]
---- EP [2/5] | BTCH [183/3634] ||| train_loss = nan ----
LR: [0.008028080414014017]
---- EP [2/5] | BTCH [184/3634] ||| train_loss = nan ----
LR: [0.008030315603234816]
---- EP [2/5] | BTCH [185/3634] ||| train_loss = nan ----
LR: [0.008032549851992872]
---- EP [2/5] | BTCH [186/3634] ||| train_loss = nan ----
LR: [0.008034783159545787]
---- EP [2/5] | BTCH [187/3634] ||| train_loss = nan ----
LR: [0.008037015525151474]
---- EP [2/5] | BTCH [188/3634] ||| train_loss = nan ----
LR: [0.008039246948068157]
---- EP [2/5] | BTCH [189/3634] ||| train_loss = nan ----
LR: [0.008041477427554372]
---- EP [2/5] | BTCH [190/3634] ||| train_loss = nan ----
LR: [0.008043706962868977]
---- EP [2/5] | BTCH [191/3634] ||| train_loss = nan ----
LR: [0.008045935553271133]
---- EP [2/5] | BTCH [192/3634] ||| train_loss = nan ----
LR: [0.00804816319802032]
---- EP [2/5] | BTCH [193/3634] ||| train_loss = nan ----
LR: [0.008050389896376332]
---- EP [2/5] | BTCH [194/3634] ||| train_loss = nan ----
LR: [0.00805261564759928]
---- EP [2/5] | BTCH [195/3634] ||| train_loss = nan ----
LR: [0.008054840450949586]
---- EP [2/5] | BTCH [196/3634] ||| train_loss = nan ----
LR: [0.008057064305687986]
---- EP [2/5] | BTCH [197/3634] ||| train_loss = nan ----
LR: [0.008059287211075534]
---- EP [2/5] | BTCH [198/3634] ||| train_loss = nan ----
LR: [0.008061509166373602]
---- EP [2/5] | BTCH [199/3634] ||| train_loss = nan ----
LR: [0.00806373017084387]
---- EP [2/5] | BTCH [200/3634] ||| train_loss = nan ----
LR: [0.00806595022374834]
---- EP [2/5] | BTCH [201/3634] ||| train_loss = nan ----
LR: [0.008068169324349327]
---- EP [2/5] | BTCH [202/3634] ||| train_loss = nan ----
LR: [0.008070387471909468]
---- EP [2/5] | BTCH [203/3634] ||| train_loss = nan ----
LR: [0.008072604665691707]
---- EP [2/5] | BTCH [204/3634] ||| train_loss = nan ----
LR: [0.008074820904959316]
---- EP [2/5] | BTCH [205/3634] ||| train_loss = nan ----
LR: [0.008077036188975878]
---- EP [2/5] | BTCH [206/3634] ||| train_loss = nan ----
LR: [0.008079250517005289]
---- EP [2/5] | BTCH [207/3634] ||| train_loss = nan ----
LR: [0.008081463888311774]
---- EP [2/5] | BTCH [208/3634] ||| train_loss = nan ----
LR: [0.008083676302159866]
---- EP [2/5] | BTCH [209/3634] ||| train_loss = nan ----
LR: [0.008085887757814422]
---- EP [2/5] | BTCH [210/3634] ||| train_loss = nan ----
LR: [0.008088098254540613]
---- EP [2/5] | BTCH [211/3634] ||| train_loss = nan ----
LR: [0.008090307791603931]
---- EP [2/5] | BTCH [212/3634] ||| train_loss = nan ----
LR: [0.008092516368270188]
---- EP [2/5] | BTCH [213/3634] ||| train_loss = nan ----
LR: [0.008094723983805516]
---- EP [2/5] | BTCH [214/3634] ||| train_loss = nan ----
LR: [0.008096930637476359]
---- EP [2/5] | BTCH [215/3634] ||| train_loss = nan ----
LR: [0.008099136328549491]
---- EP [2/5] | BTCH [216/3634] ||| train_loss = nan ----
LR: [0.008101341056291999]
---- EP [2/5] | BTCH [217/3634] ||| train_loss = nan ----
LR: [0.00810354481997129]
---- EP [2/5] | BTCH [218/3634] ||| train_loss = nan ----
LR: [0.008105747618855096]
---- EP [2/5] | BTCH [219/3634] ||| train_loss = nan ----
LR: [0.008107949452211462]
---- EP [2/5] | BTCH [220/3634] ||| train_loss = nan ----
LR: [0.008110150319308763]
---- EP [2/5] | BTCH [221/3634] ||| train_loss = nan ----
LR: [0.00811235021941569]
---- EP [2/5] | BTCH [222/3634] ||| train_loss = nan ----
LR: [0.008114549151801254]
---- EP [2/5] | BTCH [223/3634] ||| train_loss = nan ----
LR: [0.008116747115734792]
---- EP [2/5] | BTCH [224/3634] ||| train_loss = nan ----
LR: [0.008118944110485958]
---- EP [2/5] | BTCH [225/3634] ||| train_loss = nan ----
LR: [0.008121140135324733]
---- EP [2/5] | BTCH [226/3634] ||| train_loss = nan ----
LR: [0.008123335189521415]
---- EP [2/5] | BTCH [227/3634] ||| train_loss = nan ----
LR: [0.008125529272346629]
---- EP [2/5] | BTCH [228/3634] ||| train_loss = nan ----
LR: [0.00812772238307132]
---- EP [2/5] | BTCH [229/3634] ||| train_loss = nan ----
LR: [0.008129914520966756]
---- EP [2/5] | BTCH [230/3634] ||| train_loss = nan ----
LR: [0.00813210568530453]
---- EP [2/5] | BTCH [231/3634] ||| train_loss = nan ----
LR: [0.008134295875356558]
---- EP [2/5] | BTCH [232/3634] ||| train_loss = nan ----
LR: [0.00813648509039508]
---- EP [2/5] | BTCH [233/3634] ||| train_loss = nan ----
LR: [0.008138673329692658]
---- EP [2/5] | BTCH [234/3634] ||| train_loss = nan ----
LR: [0.00814086059252218]
---- EP [2/5] | BTCH [235/3634] ||| train_loss = nan ----
LR: [0.008143046878156859]
---- EP [2/5] | BTCH [236/3634] ||| train_loss = nan ----
LR: [0.008145232185870231]
---- EP [2/5] | BTCH [237/3634] ||| train_loss = nan ----
LR: [0.008147416514936157]
---- EP [2/5] | BTCH [238/3634] ||| train_loss = nan ----
LR: [0.008149599864628827]
---- EP [2/5] | BTCH [239/3634] ||| train_loss = nan ----
LR: [0.00815178223422275]
---- EP [2/5] | BTCH [240/3634] ||| train_loss = nan ----
LR: [0.008153963622992765]
---- EP [2/5] | BTCH [241/3634] ||| train_loss = nan ----
LR: [0.008156144030214035]
---- EP [2/5] | BTCH [242/3634] ||| train_loss = nan ----
LR: [0.008158323455162052]
---- EP [2/5] | BTCH [243/3634] ||| train_loss = nan ----
LR: [0.008160501897112631]
---- EP [2/5] | BTCH [244/3634] ||| train_loss = nan ----
LR: [0.008162679355341918]
---- EP [2/5] | BTCH [245/3634] ||| train_loss = nan ----
LR: [0.008164855829126379]
---- EP [2/5] | BTCH [246/3634] ||| train_loss = nan ----
LR: [0.008167031317742813]
---- EP [2/5] | BTCH [247/3634] ||| train_loss = nan ----
LR: [0.008169205820468345]
---- EP [2/5] | BTCH [248/3634] ||| train_loss = nan ----
LR: [0.008171379336580426]
---- EP [2/5] | BTCH [249/3634] ||| train_loss = nan ----
LR: [0.008173551865356834]
---- EP [2/5] | BTCH [250/3634] ||| train_loss = nan ----
LR: [0.00817572340607568]
---- EP [2/5] | BTCH [251/3634] ||| train_loss = nan ----
LR: [0.0081778939580154]
---- EP [2/5] | BTCH [252/3634] ||| train_loss = nan ----
LR: [0.008180063520454757]
---- EP [2/5] | BTCH [253/3634] ||| train_loss = nan ----
LR: [0.008182232092672846]
---- EP [2/5] | BTCH [254/3634] ||| train_loss = nan ----
LR: [0.00818439967394909]
---- EP [2/5] | BTCH [255/3634] ||| train_loss = nan ----
LR: [0.00818656626356324]
---- EP [2/5] | BTCH [256/3634] ||| train_loss = nan ----
LR: [0.008188731860795379]
---- EP [2/5] | BTCH [257/3634] ||| train_loss = nan ----
LR: [0.008190896464925913]
---- EP [2/5] | BTCH [258/3634] ||| train_loss = nan ----
LR: [0.00819306007523559]
---- EP [2/5] | BTCH [259/3634] ||| train_loss = nan ----
LR: [0.008195222691005479]
---- EP [2/5] | BTCH [260/3634] ||| train_loss = nan ----
LR: [0.00819738431151698]
---- EP [2/5] | BTCH [261/3634] ||| train_loss = nan ----
LR: [0.008199544936051824]
---- EP [2/5] | BTCH [262/3634] ||| train_loss = nan ----
LR: [0.008201704563892081]
---- EP [2/5] | BTCH [263/3634] ||| train_loss = nan ----
LR: [0.008203863194320139]
---- EP [2/5] | BTCH [264/3634] ||| train_loss = nan ----
LR: [0.00820602082661873]
---- EP [2/5] | BTCH [265/3634] ||| train_loss = nan ----
LR: [0.008208177460070909]
---- EP [2/5] | BTCH [266/3634] ||| train_loss = nan ----
LR: [0.008210333093960062]
---- EP [2/5] | BTCH [267/3634] ||| train_loss = nan ----
LR: [0.008212487727569917]
---- EP [2/5] | BTCH [268/3634] ||| train_loss = nan ----
LR: [0.008214641360184525]
---- EP [2/5] | BTCH [269/3634] ||| train_loss = nan ----
LR: [0.008216793991088272]
---- EP [2/5] | BTCH [270/3634] ||| train_loss = nan ----
LR: [0.00821894561956588]
---- EP [2/5] | BTCH [271/3634] ||| train_loss = nan ----
LR: [0.0082210962449024]
---- EP [2/5] | BTCH [272/3634] ||| train_loss = nan ----
LR: [0.008223245866383217]
---- EP [2/5] | BTCH [273/3634] ||| train_loss = nan ----
LR: [0.008225394483294056]
---- EP [2/5] | BTCH [274/3634] ||| train_loss = nan ----
LR: [0.008227542094920964]
---- EP [2/5] | BTCH [275/3634] ||| train_loss = nan ----
LR: [0.008229688700550332]
---- EP [2/5] | BTCH [276/3634] ||| train_loss = nan ----
LR: [0.008231834299468882]
---- EP [2/5] | BTCH [277/3634] ||| train_loss = nan ----
LR: [0.008233978890963667]
---- EP [2/5] | BTCH [278/3634] ||| train_loss = nan ----
LR: [0.008236122474322082]
---- EP [2/5] | BTCH [279/3634] ||| train_loss = nan ----
LR: [0.008238265048831852]
---- EP [2/5] | BTCH [280/3634] ||| train_loss = nan ----
LR: [0.008240406613781033]
---- EP [2/5] | BTCH [281/3634] ||| train_loss = nan ----
LR: [0.008242547168458028]
---- EP [2/5] | BTCH [282/3634] ||| train_loss = nan ----
LR: [0.008244686712151568]
---- EP [2/5] | BTCH [283/3634] ||| train_loss = nan ----
LR: [0.00824682524415072]
---- EP [2/5] | BTCH [284/3634] ||| train_loss = nan ----
LR: [0.00824896276374489]
---- EP [2/5] | BTCH [285/3634] ||| train_loss = nan ----
LR: [0.008251099270223819]
---- EP [2/5] | BTCH [286/3634] ||| train_loss = nan ----
LR: [0.00825323476287758]
---- EP [2/5] | BTCH [287/3634] ||| train_loss = nan ----
LR: [0.008255369240996593]
---- EP [2/5] | BTCH [288/3634] ||| train_loss = nan ----
LR: [0.008257502703871607]
---- EP [2/5] | BTCH [289/3634] ||| train_loss = nan ----
LR: [0.00825963515079371]
---- EP [2/5] | BTCH [290/3634] ||| train_loss = nan ----
LR: [0.00826176658105433]
---- EP [2/5] | BTCH [291/3634] ||| train_loss = nan ----
LR: [0.008263896993945231]
---- EP [2/5] | BTCH [292/3634] ||| train_loss = nan ----
LR: [0.008266026388758514]
---- EP [2/5] | BTCH [293/3634] ||| train_loss = nan ----
LR: [0.008268154764786623]
---- EP [2/5] | BTCH [294/3634] ||| train_loss = nan ----
LR: [0.008270282121322333]
---- EP [2/5] | BTCH [295/3634] ||| train_loss = nan ----
LR: [0.008272408457658764]
---- EP [2/5] | BTCH [296/3634] ||| train_loss = nan ----
LR: [0.008274533773089373]
---- EP [2/5] | BTCH [297/3634] ||| train_loss = nan ----
LR: [0.008276658066907954]
---- EP [2/5] | BTCH [298/3634] ||| train_loss = nan ----
LR: [0.008278781338408646]
---- EP [2/5] | BTCH [299/3634] ||| train_loss = nan ----
LR: [0.00828090358688592]
---- EP [2/5] | BTCH [300/3634] ||| train_loss = nan ----
LR: [0.008283024811634595]
---- EP [2/5] | BTCH [301/3634] ||| train_loss = nan ----
LR: [0.008285145011949824]
---- EP [2/5] | BTCH [302/3634] ||| train_loss = nan ----
LR: [0.008287264187127105]
---- EP [2/5] | BTCH [303/3634] ||| train_loss = nan ----
LR: [0.00828938233646227]
---- EP [2/5] | BTCH [304/3634] ||| train_loss = nan ----
LR: [0.0082914994592515]
---- EP [2/5] | BTCH [305/3634] ||| train_loss = nan ----
LR: [0.008293615554791314]
---- EP [2/5] | BTCH [306/3634] ||| train_loss = nan ----
LR: [0.008295730622378568]
---- EP [2/5] | BTCH [307/3634] ||| train_loss = nan ----
LR: [0.008297844661310469]
---- EP [2/5] | BTCH [308/3634] ||| train_loss = nan ----
LR: [0.008299957670884553]
---- EP [2/5] | BTCH [309/3634] ||| train_loss = nan ----
LR: [0.00830206965039871]
---- EP [2/5] | BTCH [310/3634] ||| train_loss = nan ----
LR: [0.008304180599151164]
---- EP [2/5] | BTCH [311/3634] ||| train_loss = nan ----
LR: [0.00830629051644049]
---- EP [2/5] | BTCH [312/3634] ||| train_loss = nan ----
LR: [0.008308399401565594]
---- EP [2/5] | BTCH [313/3634] ||| train_loss = nan ----
LR: [0.008310507253825738]
---- EP [2/5] | BTCH [314/3634] ||| train_loss = nan ----
LR: [0.008312614072520517]
---- EP [2/5] | BTCH [315/3634] ||| train_loss = nan ----
LR: [0.008314719856949874]
---- EP [2/5] | BTCH [316/3634] ||| train_loss = nan ----
LR: [0.008316824606414095]
---- EP [2/5] | BTCH [317/3634] ||| train_loss = nan ----
LR: [0.008318928320213807]
---- EP [2/5] | BTCH [318/3634] ||| train_loss = nan ----
LR: [0.00832103099764999]
---- EP [2/5] | BTCH [319/3634] ||| train_loss = nan ----
LR: [0.008323132638023955]
---- EP [2/5] | BTCH [320/3634] ||| train_loss = nan ----
LR: [0.008325233240637372]
---- EP [2/5] | BTCH [321/3634] ||| train_loss = nan ----
LR: [0.008327332804792245]
---- EP [2/5] | BTCH [322/3634] ||| train_loss = nan ----
LR: [0.008329431329790925]
---- EP [2/5] | BTCH [323/3634] ||| train_loss = nan ----
LR: [0.008331528814936113]
---- EP [2/5] | BTCH [324/3634] ||| train_loss = nan ----
LR: [0.008333625259530854]
---- EP [2/5] | BTCH [325/3634] ||| train_loss = nan ----
LR: [0.008335720662878535]
---- EP [2/5] | BTCH [326/3634] ||| train_loss = nan ----
LR: [0.008337815024282888]
---- EP [2/5] | BTCH [327/3634] ||| train_loss = nan ----
LR: [0.008339908343048]
---- EP [2/5] | BTCH [328/3634] ||| train_loss = nan ----
LR: [0.008342000618478299]
---- EP [2/5] | BTCH [329/3634] ||| train_loss = nan ----
LR: [0.008344091849878554]
---- EP [2/5] | BTCH [330/3634] ||| train_loss = nan ----
LR: [0.00834618203655389]
---- EP [2/5] | BTCH [331/3634] ||| train_loss = nan ----
LR: [0.00834827117780978]
---- EP [2/5] | BTCH [332/3634] ||| train_loss = nan ----
LR: [0.008350359272952032]
---- EP [2/5] | BTCH [333/3634] ||| train_loss = nan ----
LR: [0.008352446321286816]
---- EP [2/5] | BTCH [334/3634] ||| train_loss = nan ----
LR: [0.00835453232212064]
---- EP [2/5] | BTCH [335/3634] ||| train_loss = nan ----
LR: [0.008356617274760367]
---- EP [2/5] | BTCH [336/3634] ||| train_loss = nan ----
LR: [0.008358701178513202]
---- EP [2/5] | BTCH [337/3634] ||| train_loss = nan ----
LR: [0.008360784032686702]
---- EP [2/5] | BTCH [338/3634] ||| train_loss = nan ----
LR: [0.008362865836588773]
---- EP [2/5] | BTCH [339/3634] ||| train_loss = nan ----
LR: [0.008364946589527666]
---- EP [2/5] | BTCH [340/3634] ||| train_loss = nan ----
LR: [0.008367026290811989]
---- EP [2/5] | BTCH [341/3634] ||| train_loss = nan ----
LR: [0.008369104939750693]
---- EP [2/5] | BTCH [342/3634] ||| train_loss = nan ----
LR: [0.008371182535653082]
---- EP [2/5] | BTCH [343/3634] ||| train_loss = nan ----
LR: [0.008373259077828803]
---- EP [2/5] | BTCH [344/3634] ||| train_loss = nan ----
LR: [0.008375334565587866]
---- EP [2/5] | BTCH [345/3634] ||| train_loss = nan ----
LR: [0.008377408998240618]
---- EP [2/5] | BTCH [346/3634] ||| train_loss = nan ----
LR: [0.008379482375097766]
---- EP [2/5] | BTCH [347/3634] ||| train_loss = nan ----
LR: [0.008381554695470363]
---- EP [2/5] | BTCH [348/3634] ||| train_loss = nan ----
LR: [0.008383625958669812]
---- EP [2/5] | BTCH [349/3634] ||| train_loss = nan ----
LR: [0.008385696164007875]
---- EP [2/5] | BTCH [350/3634] ||| train_loss = nan ----
LR: [0.008387765310796656]
---- EP [2/5] | BTCH [351/3634] ||| train_loss = nan ----
LR: [0.008389833398348617]
---- EP [2/5] | BTCH [352/3634] ||| train_loss = nan ----
LR: [0.008391900425976567]
---- EP [2/5] | BTCH [353/3634] ||| train_loss = nan ----
LR: [0.008393966392993675]
---- EP [2/5] | BTCH [354/3634] ||| train_loss = nan ----
LR: [0.008396031298713453]
---- EP [2/5] | BTCH [355/3634] ||| train_loss = nan ----
LR: [0.008398095142449772]
---- EP [2/5] | BTCH [356/3634] ||| train_loss = nan ----
LR: [0.008400157923516855]
---- EP [2/5] | BTCH [357/3634] ||| train_loss = nan ----
LR: [0.008402219641229274]
---- EP [2/5] | BTCH [358/3634] ||| train_loss = nan ----
LR: [0.00840428029490196]
---- EP [2/5] | BTCH [359/3634] ||| train_loss = nan ----
LR: [0.008406339883850195]
---- EP [2/5] | BTCH [360/3634] ||| train_loss = nan ----
LR: [0.008408398407389613]
---- EP [2/5] | BTCH [361/3634] ||| train_loss = nan ----
LR: [0.008410455864836205]
---- EP [2/5] | BTCH [362/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.008412512255506316]
---- EP [2/5] | BTCH [363/3634] ||| train_loss = nan ----
LR: [0.008414567578716642]
---- EP [2/5] | BTCH [364/3634] ||| train_loss = nan ----
LR: [0.00841662183378424]
---- EP [2/5] | BTCH [365/3634] ||| train_loss = nan ----
LR: [0.008418675020026516]
---- EP [2/5] | BTCH [366/3634] ||| train_loss = nan ----
LR: [0.00842072713676123]
---- EP [2/5] | BTCH [367/3634] ||| train_loss = nan ----
LR: [0.008422778183306508]
---- EP [2/5] | BTCH [368/3634] ||| train_loss = nan ----
LR: [0.008424828158980817]
---- EP [2/5] | BTCH [369/3634] ||| train_loss = nan ----
LR: [0.008426877063102993]
---- EP [2/5] | BTCH [370/3634] ||| train_loss = nan ----
LR: [0.008428924894992217]
---- EP [2/5] | BTCH [371/3634] ||| train_loss = nan ----
LR: [0.008430971653968035]
---- EP [2/5] | BTCH [372/3634] ||| train_loss = nan ----
LR: [0.008433017339350344]
---- EP [2/5] | BTCH [373/3634] ||| train_loss = nan ----
LR: [0.008435061950459403]
---- EP [2/5] | BTCH [374/3634] ||| train_loss = nan ----
LR: [0.00843710548661582]
---- EP [2/5] | BTCH [375/3634] ||| train_loss = nan ----
LR: [0.00843914794714057]
---- EP [2/5] | BTCH [376/3634] ||| train_loss = nan ----
LR: [0.008441189331354976]
---- EP [2/5] | BTCH [377/3634] ||| train_loss = nan ----
LR: [0.008443229638580723]
---- EP [2/5] | BTCH [378/3634] ||| train_loss = nan ----
LR: [0.008445268868139857]
---- EP [2/5] | BTCH [379/3634] ||| train_loss = nan ----
LR: [0.008447307019354776]
---- EP [2/5] | BTCH [380/3634] ||| train_loss = nan ----
LR: [0.008449344091548239]
---- EP [2/5] | BTCH [381/3634] ||| train_loss = nan ----
LR: [0.008451380084043367]
---- EP [2/5] | BTCH [382/3634] ||| train_loss = nan ----
LR: [0.008453414996163634]
---- EP [2/5] | BTCH [383/3634] ||| train_loss = nan ----
LR: [0.008455448827232873]
---- EP [2/5] | BTCH [384/3634] ||| train_loss = nan ----
LR: [0.008457481576575285]
---- EP [2/5] | BTCH [385/3634] ||| train_loss = nan ----
LR: [0.008459513243515421]
---- EP [2/5] | BTCH [386/3634] ||| train_loss = nan ----
LR: [0.008461543827378192]
---- EP [2/5] | BTCH [387/3634] ||| train_loss = nan ----
LR: [0.008463573327488875]
---- EP [2/5] | BTCH [388/3634] ||| train_loss = nan ----
LR: [0.008465601743173103]
---- EP [2/5] | BTCH [389/3634] ||| train_loss = nan ----
LR: [0.008467629073756868]
---- EP [2/5] | BTCH [390/3634] ||| train_loss = nan ----
LR: [0.008469655318566529]
---- EP [2/5] | BTCH [391/3634] ||| train_loss = nan ----
LR: [0.008471680476928799]
---- EP [2/5] | BTCH [392/3634] ||| train_loss = nan ----
LR: [0.008473704548170754]
---- EP [2/5] | BTCH [393/3634] ||| train_loss = nan ----
LR: [0.008475727531619832]
---- EP [2/5] | BTCH [394/3634] ||| train_loss = nan ----
LR: [0.008477749426603832]
---- EP [2/5] | BTCH [395/3634] ||| train_loss = nan ----
LR: [0.008479770232450917]
---- EP [2/5] | BTCH [396/3634] ||| train_loss = nan ----
LR: [0.008481789948489606]
---- EP [2/5] | BTCH [397/3634] ||| train_loss = nan ----
LR: [0.008483808574048787]
---- EP [2/5] | BTCH [398/3634] ||| train_loss = nan ----
LR: [0.008485826108457706]
---- EP [2/5] | BTCH [399/3634] ||| train_loss = nan ----
LR: [0.008487842551045972]
---- EP [2/5] | BTCH [400/3634] ||| train_loss = nan ----
LR: [0.008489857901143557]
---- EP [2/5] | BTCH [401/3634] ||| train_loss = nan ----
LR: [0.0084918721580808]
---- EP [2/5] | BTCH [402/3634] ||| train_loss = nan ----
LR: [0.008493885321188398]
---- EP [2/5] | BTCH [403/3634] ||| train_loss = nan ----
LR: [0.008495897389797412]
---- EP [2/5] | BTCH [404/3634] ||| train_loss = nan ----
LR: [0.008497908363239269]
---- EP [2/5] | BTCH [405/3634] ||| train_loss = nan ----
LR: [0.00849991824084576]
---- EP [2/5] | BTCH [406/3634] ||| train_loss = nan ----
LR: [0.008501927021949036]
---- EP [2/5] | BTCH [407/3634] ||| train_loss = nan ----
LR: [0.008503934705881618]
---- EP [2/5] | BTCH [408/3634] ||| train_loss = nan ----
LR: [0.008505941291976387]
---- EP [2/5] | BTCH [409/3634] ||| train_loss = nan ----
LR: [0.008507946779566592]
---- EP [2/5] | BTCH [410/3634] ||| train_loss = nan ----
LR: [0.008509951167985846]
---- EP [2/5] | BTCH [411/3634] ||| train_loss = nan ----
LR: [0.008511954456568127]
---- EP [2/5] | BTCH [412/3634] ||| train_loss = nan ----
LR: [0.008513956644647776]
---- EP [2/5] | BTCH [413/3634] ||| train_loss = nan ----
LR: [0.008515957731559505]
---- EP [2/5] | BTCH [414/3634] ||| train_loss = nan ----
LR: [0.008517957716638387]
---- EP [2/5] | BTCH [415/3634] ||| train_loss = nan ----
LR: [0.008519956599219865]
---- EP [2/5] | BTCH [416/3634] ||| train_loss = nan ----
LR: [0.008521954378639746]
---- EP [2/5] | BTCH [417/3634] ||| train_loss = nan ----
LR: [0.0085239510542342]
---- EP [2/5] | BTCH [418/3634] ||| train_loss = nan ----
LR: [0.008525946625339774]
---- EP [2/5] | BTCH [419/3634] ||| train_loss = nan ----
LR: [0.008527941091293371]
---- EP [2/5] | BTCH [420/3634] ||| train_loss = nan ----
LR: [0.008529934451432268]
---- EP [2/5] | BTCH [421/3634] ||| train_loss = nan ----
LR: [0.008531926705094109]
---- EP [2/5] | BTCH [422/3634] ||| train_loss = nan ----
LR: [0.0085339178516169]
---- EP [2/5] | BTCH [423/3634] ||| train_loss = nan ----
LR: [0.008535907890339024]
---- EP [2/5] | BTCH [424/3634] ||| train_loss = nan ----
LR: [0.008537896820599224]
---- EP [2/5] | BTCH [425/3634] ||| train_loss = nan ----
LR: [0.008539884641736613]
---- EP [2/5] | BTCH [426/3634] ||| train_loss = nan ----
LR: [0.008541871353090676]
---- EP [2/5] | BTCH [427/3634] ||| train_loss = nan ----
LR: [0.008543856954001266]
---- EP [2/5] | BTCH [428/3634] ||| train_loss = nan ----
LR: [0.008545841443808601]
---- EP [2/5] | BTCH [429/3634] ||| train_loss = nan ----
LR: [0.008547824821853272]
---- EP [2/5] | BTCH [430/3634] ||| train_loss = nan ----
LR: [0.00854980708747624]
---- EP [2/5] | BTCH [431/3634] ||| train_loss = nan ----
LR: [0.00855178824001883]
---- EP [2/5] | BTCH [432/3634] ||| train_loss = nan ----
LR: [0.008553768278822744]
---- EP [2/5] | BTCH [433/3634] ||| train_loss = nan ----
LR: [0.008555747203230052]
---- EP [2/5] | BTCH [434/3634] ||| train_loss = nan ----
LR: [0.008557725012583188]
---- EP [2/5] | BTCH [435/3634] ||| train_loss = nan ----
LR: [0.008559701706224967]
---- EP [2/5] | BTCH [436/3634] ||| train_loss = nan ----
LR: [0.008561677283498569]
---- EP [2/5] | BTCH [437/3634] ||| train_loss = nan ----
LR: [0.00856365174374754]
---- EP [2/5] | BTCH [438/3634] ||| train_loss = nan ----
LR: [0.008565625086315807]
---- EP [2/5] | BTCH [439/3634] ||| train_loss = nan ----
LR: [0.008567597310547664]
---- EP [2/5] | BTCH [440/3634] ||| train_loss = nan ----
LR: [0.008569568415787775]
---- EP [2/5] | BTCH [441/3634] ||| train_loss = nan ----
LR: [0.008571538401381178]
---- EP [2/5] | BTCH [442/3634] ||| train_loss = nan ----
LR: [0.008573507266673285]
---- EP [2/5] | BTCH [443/3634] ||| train_loss = nan ----
LR: [0.008575475011009871]
---- EP [2/5] | BTCH [444/3634] ||| train_loss = nan ----
LR: [0.008577441633737096]
---- EP [2/5] | BTCH [445/3634] ||| train_loss = nan ----
LR: [0.008579407134201486]
---- EP [2/5] | BTCH [446/3634] ||| train_loss = nan ----
LR: [0.008581371511749937]
---- EP [2/5] | BTCH [447/3634] ||| train_loss = nan ----
LR: [0.008583334765729726]
---- EP [2/5] | BTCH [448/3634] ||| train_loss = nan ----
LR: [0.008585296895488497]
---- EP [2/5] | BTCH [449/3634] ||| train_loss = nan ----
LR: [0.008587257900374269]
---- EP [2/5] | BTCH [450/3634] ||| train_loss = nan ----
LR: [0.008589217779735439]
---- EP [2/5] | BTCH [451/3634] ||| train_loss = nan ----
LR: [0.008591176532920772]
---- EP [2/5] | BTCH [452/3634] ||| train_loss = nan ----
LR: [0.00859313415927941]
---- EP [2/5] | BTCH [453/3634] ||| train_loss = nan ----
LR: [0.00859509065816087]
---- EP [2/5] | BTCH [454/3634] ||| train_loss = nan ----
LR: [0.00859704602891504]
---- EP [2/5] | BTCH [455/3634] ||| train_loss = nan ----
LR: [0.00859900027089219]
---- EP [2/5] | BTCH [456/3634] ||| train_loss = nan ----
LR: [0.008600953383442956]
---- EP [2/5] | BTCH [457/3634] ||| train_loss = nan ----
LR: [0.008602905365918356]
---- EP [2/5] | BTCH [458/3634] ||| train_loss = nan ----
LR: [0.008604856217669783]
---- EP [2/5] | BTCH [459/3634] ||| train_loss = nan ----
LR: [0.008606805938049002]
---- EP [2/5] | BTCH [460/3634] ||| train_loss = nan ----
LR: [0.008608754526408156]
---- EP [2/5] | BTCH [461/3634] ||| train_loss = nan ----
LR: [0.008610701982099768]
---- EP [2/5] | BTCH [462/3634] ||| train_loss = nan ----
LR: [0.00861264830447673]
---- EP [2/5] | BTCH [463/3634] ||| train_loss = nan ----
LR: [0.008614593492892316]
---- EP [2/5] | BTCH [464/3634] ||| train_loss = nan ----
LR: [0.008616537546700173]
---- EP [2/5] | BTCH [465/3634] ||| train_loss = nan ----
LR: [0.00861848046525433]
---- EP [2/5] | BTCH [466/3634] ||| train_loss = nan ----
LR: [0.008620422247909187]
---- EP [2/5] | BTCH [467/3634] ||| train_loss = nan ----
LR: [0.008622362894019528]
---- EP [2/5] | BTCH [468/3634] ||| train_loss = nan ----
LR: [0.008624302402940508]
---- EP [2/5] | BTCH [469/3634] ||| train_loss = nan ----
LR: [0.008626240774027663]
---- EP [2/5] | BTCH [470/3634] ||| train_loss = nan ----
LR: [0.008628178006636913]
---- EP [2/5] | BTCH [471/3634] ||| train_loss = nan ----
LR: [0.008630114100124545]
---- EP [2/5] | BTCH [472/3634] ||| train_loss = nan ----
LR: [0.008632049053847233]
---- EP [2/5] | BTCH [473/3634] ||| train_loss = nan ----
LR: [0.008633982867162025]
---- EP [2/5] | BTCH [474/3634] ||| train_loss = nan ----
LR: [0.00863591553942635]
---- EP [2/5] | BTCH [475/3634] ||| train_loss = nan ----
LR: [0.008637847069998017]
---- EP [2/5] | BTCH [476/3634] ||| train_loss = nan ----
LR: [0.008639777458235213]
---- EP [2/5] | BTCH [477/3634] ||| train_loss = nan ----
LR: [0.008641706703496505]
---- EP [2/5] | BTCH [478/3634] ||| train_loss = nan ----
LR: [0.008643634805140837]
---- EP [2/5] | BTCH [479/3634] ||| train_loss = nan ----
LR: [0.00864556176252754]
---- EP [2/5] | BTCH [480/3634] ||| train_loss = nan ----
LR: [0.008647487575016318]
---- EP [2/5] | BTCH [481/3634] ||| train_loss = nan ----
LR: [0.00864941224196726]
---- EP [2/5] | BTCH [482/3634] ||| train_loss = nan ----
LR: [0.008651335762740832]
---- EP [2/5] | BTCH [483/3634] ||| train_loss = nan ----
LR: [0.008653258136697884]
---- EP [2/5] | BTCH [484/3634] ||| train_loss = nan ----
LR: [0.008655179363199646]
---- EP [2/5] | BTCH [485/3634] ||| train_loss = nan ----
LR: [0.008657099441607731]
---- EP [2/5] | BTCH [486/3634] ||| train_loss = nan ----
LR: [0.008659018371284126]
---- EP [2/5] | BTCH [487/3634] ||| train_loss = nan ----
LR: [0.00866093615159121]
---- EP [2/5] | BTCH [488/3634] ||| train_loss = nan ----
LR: [0.008662852781891738]
---- EP [2/5] | BTCH [489/3634] ||| train_loss = nan ----
LR: [0.008664768261548848]
---- EP [2/5] | BTCH [490/3634] ||| train_loss = nan ----
LR: [0.008666682589926061]
---- EP [2/5] | BTCH [491/3634] ||| train_loss = nan ----
LR: [0.008668595766387283]
---- EP [2/5] | BTCH [492/3634] ||| train_loss = nan ----
LR: [0.008670507790296794]
---- EP [2/5] | BTCH [493/3634] ||| train_loss = nan ----
LR: [0.008672418661019268]
---- EP [2/5] | BTCH [494/3634] ||| train_loss = nan ----
LR: [0.008674328377919755]
---- EP [2/5] | BTCH [495/3634] ||| train_loss = nan ----
LR: [0.008676236940363694]
---- EP [2/5] | BTCH [496/3634] ||| train_loss = nan ----
LR: [0.0086781443477169]
---- EP [2/5] | BTCH [497/3634] ||| train_loss = nan ----
LR: [0.008680050599345575]
---- EP [2/5] | BTCH [498/3634] ||| train_loss = nan ----
LR: [0.008681955694616309]
---- EP [2/5] | BTCH [499/3634] ||| train_loss = nan ----
LR: [0.008683859632896074]
---- EP [2/5] | BTCH [500/3634] ||| train_loss = nan ----
LR: [0.008685762413552223]
---- EP [2/5] | BTCH [501/3634] ||| train_loss = nan ----
LR: [0.008687664035952499]
---- EP [2/5] | BTCH [502/3634] ||| train_loss = nan ----
LR: [0.008689564499465027]
---- EP [2/5] | BTCH [503/3634] ||| train_loss = nan ----
LR: [0.008691463803458314]
---- EP [2/5] | BTCH [504/3634] ||| train_loss = nan ----
LR: [0.00869336194730126]
---- EP [2/5] | BTCH [505/3634] ||| train_loss = nan ----
LR: [0.008695258930363143]
---- EP [2/5] | BTCH [506/3634] ||| train_loss = nan ----
LR: [0.00869715475201363]
---- EP [2/5] | BTCH [507/3634] ||| train_loss = nan ----
LR: [0.008699049411622774]
---- EP [2/5] | BTCH [508/3634] ||| train_loss = nan ----
LR: [0.008700942908561016]
---- EP [2/5] | BTCH [509/3634] ||| train_loss = nan ----
LR: [0.008702835242199178]
---- EP [2/5] | BTCH [510/3634] ||| train_loss = nan ----
LR: [0.008704726411908476]
---- EP [2/5] | BTCH [511/3634] ||| train_loss = nan ----
LR: [0.008706616417060505]
---- EP [2/5] | BTCH [512/3634] ||| train_loss = nan ----
LR: [0.008708505257027249]
---- EP [2/5] | BTCH [513/3634] ||| train_loss = nan ----
LR: [0.008710392931181084]
---- EP [2/5] | BTCH [514/3634] ||| train_loss = nan ----
LR: [0.008712279438894768]
---- EP [2/5] | BTCH [515/3634] ||| train_loss = nan ----
LR: [0.008714164779541449]
---- EP [2/5] | BTCH [516/3634] ||| train_loss = nan ----
LR: [0.008716048952494665]
---- EP [2/5] | BTCH [517/3634] ||| train_loss = nan ----
LR: [0.008717931957128335]
---- EP [2/5] | BTCH [518/3634] ||| train_loss = nan ----
LR: [0.008719813792816772]
---- EP [2/5] | BTCH [519/3634] ||| train_loss = nan ----
LR: [0.008721694458934677]
---- EP [2/5] | BTCH [520/3634] ||| train_loss = nan ----
LR: [0.00872357395485714]
---- EP [2/5] | BTCH [521/3634] ||| train_loss = nan ----
LR: [0.008725452279959635]
---- EP [2/5] | BTCH [522/3634] ||| train_loss = nan ----
LR: [0.008727329433618031]
---- EP [2/5] | BTCH [523/3634] ||| train_loss = nan ----
LR: [0.008729205415208583]
---- EP [2/5] | BTCH [524/3634] ||| train_loss = nan ----
LR: [0.008731080224107936]
---- EP [2/5] | BTCH [525/3634] ||| train_loss = nan ----
LR: [0.008732953859693124]
---- EP [2/5] | BTCH [526/3634] ||| train_loss = nan ----
LR: [0.008734826321341574]
---- EP [2/5] | BTCH [527/3634] ||| train_loss = nan ----
LR: [0.008736697608431099]
---- EP [2/5] | BTCH [528/3634] ||| train_loss = nan ----
LR: [0.008738567720339905]
---- EP [2/5] | BTCH [529/3634] ||| train_loss = nan ----
LR: [0.008740436656446585]
---- EP [2/5] | BTCH [530/3634] ||| train_loss = nan ----
LR: [0.008742304416130131]
---- EP [2/5] | BTCH [531/3634] ||| train_loss = nan ----
LR: [0.008744170998769916]
---- EP [2/5] | BTCH [532/3634] ||| train_loss = nan ----
LR: [0.00874603640374571]
---- EP [2/5] | BTCH [533/3634] ||| train_loss = nan ----
LR: [0.00874790063043767]
---- EP [2/5] | BTCH [534/3634] ||| train_loss = nan ----
LR: [0.008749763678226349]
---- EP [2/5] | BTCH [535/3634] ||| train_loss = nan ----
LR: [0.00875162554649269]
---- EP [2/5] | BTCH [536/3634] ||| train_loss = nan ----
LR: [0.008753486234618028]
---- EP [2/5] | BTCH [537/3634] ||| train_loss = nan ----
LR: [0.008755345741984088]
---- EP [2/5] | BTCH [538/3634] ||| train_loss = nan ----
LR: [0.008757204067972993]
---- EP [2/5] | BTCH [539/3634] ||| train_loss = nan ----
LR: [0.008759061211967251]
---- EP [2/5] | BTCH [540/3634] ||| train_loss = nan ----
LR: [0.008760917173349769]
---- EP [2/5] | BTCH [541/3634] ||| train_loss = nan ----
LR: [0.008762771951503844]
---- EP [2/5] | BTCH [542/3634] ||| train_loss = nan ----
LR: [0.008764625545813167]
---- EP [2/5] | BTCH [543/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.00876647795566182]
---- EP [2/5] | BTCH [544/3634] ||| train_loss = nan ----
LR: [0.008768329180434284]
---- EP [2/5] | BTCH [545/3634] ||| train_loss = nan ----
LR: [0.00877017921951543]
---- EP [2/5] | BTCH [546/3634] ||| train_loss = nan ----
LR: [0.008772028072290518]
---- EP [2/5] | BTCH [547/3634] ||| train_loss = nan ----
LR: [0.008773875738145216]
---- EP [2/5] | BTCH [548/3634] ||| train_loss = nan ----
LR: [0.00877572221646557]
---- EP [2/5] | BTCH [549/3634] ||| train_loss = nan ----
LR: [0.008777567506638035]
---- EP [2/5] | BTCH [550/3634] ||| train_loss = nan ----
LR: [0.008779411608049452]
---- EP [2/5] | BTCH [551/3634] ||| train_loss = nan ----
LR: [0.008781254520087059]
---- EP [2/5] | BTCH [552/3634] ||| train_loss = nan ----
LR: [0.00878309624213849]
---- EP [2/5] | BTCH [553/3634] ||| train_loss = nan ----
LR: [0.008784936773591774]
---- EP [2/5] | BTCH [554/3634] ||| train_loss = nan ----
LR: [0.008786776113835335]
---- EP [2/5] | BTCH [555/3634] ||| train_loss = nan ----
LR: [0.008788614262257995]
---- EP [2/5] | BTCH [556/3634] ||| train_loss = nan ----
LR: [0.008790451218248969]
---- EP [2/5] | BTCH [557/3634] ||| train_loss = nan ----
LR: [0.008792286981197871]
---- EP [2/5] | BTCH [558/3634] ||| train_loss = nan ----
LR: [0.008794121550494707]
---- EP [2/5] | BTCH [559/3634] ||| train_loss = nan ----
LR: [0.008795954925529889]
---- EP [2/5] | BTCH [560/3634] ||| train_loss = nan ----
LR: [0.008797787105694213]
---- EP [2/5] | BTCH [561/3634] ||| train_loss = nan ----
LR: [0.008799618090378884]
---- EP [2/5] | BTCH [562/3634] ||| train_loss = nan ----
LR: [0.008801447878975494]
---- EP [2/5] | BTCH [563/3634] ||| train_loss = nan ----
LR: [0.00880327647087604]
---- EP [2/5] | BTCH [564/3634] ||| train_loss = nan ----
LR: [0.008805103865472914]
---- EP [2/5] | BTCH [565/3634] ||| train_loss = nan ----
LR: [0.008806930062158906]
---- EP [2/5] | BTCH [566/3634] ||| train_loss = nan ----
LR: [0.008808755060327203]
---- EP [2/5] | BTCH [567/3634] ||| train_loss = nan ----
LR: [0.00881057885937139]
---- EP [2/5] | BTCH [568/3634] ||| train_loss = nan ----
LR: [0.008812401458685453]
---- EP [2/5] | BTCH [569/3634] ||| train_loss = nan ----
LR: [0.008814222857663775]
---- EP [2/5] | BTCH [570/3634] ||| train_loss = nan ----
LR: [0.008816043055701139]
---- EP [2/5] | BTCH [571/3634] ||| train_loss = nan ----
LR: [0.008817862052192725]
---- EP [2/5] | BTCH [572/3634] ||| train_loss = nan ----
LR: [0.008819679846534112]
---- EP [2/5] | BTCH [573/3634] ||| train_loss = nan ----
LR: [0.008821496438121284]
---- EP [2/5] | BTCH [574/3634] ||| train_loss = nan ----
LR: [0.008823311826350613]
---- EP [2/5] | BTCH [575/3634] ||| train_loss = nan ----
LR: [0.008825126010618887]
---- EP [2/5] | BTCH [576/3634] ||| train_loss = nan ----
LR: [0.00882693899032328]
---- EP [2/5] | BTCH [577/3634] ||| train_loss = nan ----
LR: [0.008828750764861372]
---- EP [2/5] | BTCH [578/3634] ||| train_loss = nan ----
LR: [0.008830561333631144]
---- EP [2/5] | BTCH [579/3634] ||| train_loss = nan ----
LR: [0.008832370696030978]
---- EP [2/5] | BTCH [580/3634] ||| train_loss = nan ----
LR: [0.008834178851459653]
---- EP [2/5] | BTCH [581/3634] ||| train_loss = nan ----
LR: [0.008835985799316354]
---- EP [2/5] | BTCH [582/3634] ||| train_loss = nan ----
LR: [0.008837791539000663]
---- EP [2/5] | BTCH [583/3634] ||| train_loss = nan ----
LR: [0.008839596069912565]
---- EP [2/5] | BTCH [584/3634] ||| train_loss = nan ----
LR: [0.00884139939145245]
---- EP [2/5] | BTCH [585/3634] ||| train_loss = nan ----
LR: [0.008843201503021102]
---- EP [2/5] | BTCH [586/3634] ||| train_loss = nan ----
LR: [0.008845002404019718]
---- EP [2/5] | BTCH [587/3634] ||| train_loss = nan ----
LR: [0.008846802093849885]
---- EP [2/5] | BTCH [588/3634] ||| train_loss = nan ----
LR: [0.008848600571913603]
---- EP [2/5] | BTCH [589/3634] ||| train_loss = nan ----
LR: [0.008850397837613268]
---- EP [2/5] | BTCH [590/3634] ||| train_loss = nan ----
LR: [0.008852193890351683]
---- EP [2/5] | BTCH [591/3634] ||| train_loss = nan ----
LR: [0.00885398872953205]
---- EP [2/5] | BTCH [592/3634] ||| train_loss = nan ----
LR: [0.008855782354557976]
---- EP [2/5] | BTCH [593/3634] ||| train_loss = nan ----
LR: [0.008857574764833474]
---- EP [2/5] | BTCH [594/3634] ||| train_loss = nan ----
LR: [0.008859365959762958]
---- EP [2/5] | BTCH [595/3634] ||| train_loss = nan ----
LR: [0.008861155938751246]
---- EP [2/5] | BTCH [596/3634] ||| train_loss = nan ----
LR: [0.008862944701203558]
---- EP [2/5] | BTCH [597/3634] ||| train_loss = nan ----
LR: [0.008864732246525522]
---- EP [2/5] | BTCH [598/3634] ||| train_loss = nan ----
LR: [0.008866518574123173]
---- EP [2/5] | BTCH [599/3634] ||| train_loss = nan ----
LR: [0.008868303683402943]
---- EP [2/5] | BTCH [600/3634] ||| train_loss = nan ----
LR: [0.008870087573771671]
---- EP [2/5] | BTCH [601/3634] ||| train_loss = nan ----
LR: [0.008871870244636605]
---- EP [2/5] | BTCH [602/3634] ||| train_loss = nan ----
LR: [0.008873651695405394]
---- EP [2/5] | BTCH [603/3634] ||| train_loss = nan ----
LR: [0.008875431925486095]
---- EP [2/5] | BTCH [604/3634] ||| train_loss = nan ----
LR: [0.00887721093428717]
---- EP [2/5] | BTCH [605/3634] ||| train_loss = nan ----
LR: [0.008878988721217486]
---- EP [2/5] | BTCH [606/3634] ||| train_loss = nan ----
LR: [0.008880765285686317]
---- EP [2/5] | BTCH [607/3634] ||| train_loss = nan ----
LR: [0.008882540627103341]
---- EP [2/5] | BTCH [608/3634] ||| train_loss = nan ----
LR: [0.008884314744878647]
---- EP [2/5] | BTCH [609/3634] ||| train_loss = nan ----
LR: [0.008886087638422725]
---- EP [2/5] | BTCH [610/3634] ||| train_loss = nan ----
LR: [0.008887859307146476]
---- EP [2/5] | BTCH [611/3634] ||| train_loss = nan ----
LR: [0.008889629750461207]
---- EP [2/5] | BTCH [612/3634] ||| train_loss = nan ----
LR: [0.00889139896777863]
---- EP [2/5] | BTCH [613/3634] ||| train_loss = nan ----
LR: [0.008893166958510869]
---- EP [2/5] | BTCH [614/3634] ||| train_loss = nan ----
LR: [0.008894933722070448]
---- EP [2/5] | BTCH [615/3634] ||| train_loss = nan ----
LR: [0.008896699257870306]
---- EP [2/5] | BTCH [616/3634] ||| train_loss = nan ----
LR: [0.008898463565323788]
---- EP [2/5] | BTCH [617/3634] ||| train_loss = nan ----
LR: [0.008900226643844645]
---- EP [2/5] | BTCH [618/3634] ||| train_loss = nan ----
LR: [0.00890198849284704]
---- EP [2/5] | BTCH [619/3634] ||| train_loss = nan ----
LR: [0.00890374911174554]
---- EP [2/5] | BTCH [620/3634] ||| train_loss = nan ----
LR: [0.008905508499955125]
---- EP [2/5] | BTCH [621/3634] ||| train_loss = nan ----
LR: [0.00890726665689118]
---- EP [2/5] | BTCH [622/3634] ||| train_loss = nan ----
LR: [0.008909023581969506]
---- EP [2/5] | BTCH [623/3634] ||| train_loss = nan ----
LR: [0.008910779274606302]
---- EP [2/5] | BTCH [624/3634] ||| train_loss = nan ----
LR: [0.008912533734218187]
---- EP [2/5] | BTCH [625/3634] ||| train_loss = nan ----
LR: [0.008914286960222183]
---- EP [2/5] | BTCH [626/3634] ||| train_loss = nan ----
LR: [0.008916038952035727]
---- EP [2/5] | BTCH [627/3634] ||| train_loss = nan ----
LR: [0.008917789709076666]
---- EP [2/5] | BTCH [628/3634] ||| train_loss = nan ----
LR: [0.00891953923076325]
---- EP [2/5] | BTCH [629/3634] ||| train_loss = nan ----
LR: [0.008921287516514147]
---- EP [2/5] | BTCH [630/3634] ||| train_loss = nan ----
LR: [0.008923034565748434]
---- EP [2/5] | BTCH [631/3634] ||| train_loss = nan ----
LR: [0.008924780377885598]
---- EP [2/5] | BTCH [632/3634] ||| train_loss = nan ----
LR: [0.008926524952345536]
---- EP [2/5] | BTCH [633/3634] ||| train_loss = nan ----
LR: [0.008928268288548556]
---- EP [2/5] | BTCH [634/3634] ||| train_loss = nan ----
LR: [0.008930010385915382]
---- EP [2/5] | BTCH [635/3634] ||| train_loss = nan ----
LR: [0.008931751243867147]
---- EP [2/5] | BTCH [636/3634] ||| train_loss = nan ----
LR: [0.00893349086182539]
---- EP [2/5] | BTCH [637/3634] ||| train_loss = nan ----
LR: [0.008935229239212071]
---- EP [2/5] | BTCH [638/3634] ||| train_loss = nan ----
LR: [0.008936966375449561]
---- EP [2/5] | BTCH [639/3634] ||| train_loss = nan ----
LR: [0.008938702269960639]
---- EP [2/5] | BTCH [640/3634] ||| train_loss = nan ----
LR: [0.008940436922168497]
---- EP [2/5] | BTCH [641/3634] ||| train_loss = nan ----
LR: [0.008942170331496743]
---- EP [2/5] | BTCH [642/3634] ||| train_loss = nan ----
LR: [0.008943902497369396]
---- EP [2/5] | BTCH [643/3634] ||| train_loss = nan ----
LR: [0.008945633419210888]
---- EP [2/5] | BTCH [644/3634] ||| train_loss = nan ----
LR: [0.008947363096446066]
---- EP [2/5] | BTCH [645/3634] ||| train_loss = nan ----
LR: [0.008949091528500189]
---- EP [2/5] | BTCH [646/3634] ||| train_loss = nan ----
LR: [0.00895081871479893]
---- EP [2/5] | BTCH [647/3634] ||| train_loss = nan ----
LR: [0.008952544654768376]
---- EP [2/5] | BTCH [648/3634] ||| train_loss = nan ----
LR: [0.00895426934783503]
---- EP [2/5] | BTCH [649/3634] ||| train_loss = nan ----
LR: [0.008955992793425805]
---- EP [2/5] | BTCH [650/3634] ||| train_loss = nan ----
LR: [0.008957714990968035]
---- EP [2/5] | BTCH [651/3634] ||| train_loss = nan ----
LR: [0.008959435939889463]
---- EP [2/5] | BTCH [652/3634] ||| train_loss = nan ----
LR: [0.008961155639618246]
---- EP [2/5] | BTCH [653/3634] ||| train_loss = nan ----
LR: [0.008962874089582962]
---- EP [2/5] | BTCH [654/3634] ||| train_loss = nan ----
LR: [0.008964591289212597]
---- EP [2/5] | BTCH [655/3634] ||| train_loss = nan ----
LR: [0.008966307237936564]
---- EP [2/5] | BTCH [656/3634] ||| train_loss = nan ----
LR: [0.00896802193518468]
---- EP [2/5] | BTCH [657/3634] ||| train_loss = nan ----
LR: [0.008969735380387178]
---- EP [2/5] | BTCH [658/3634] ||| train_loss = nan ----
LR: [0.008971447572974718]
---- EP [2/5] | BTCH [659/3634] ||| train_loss = nan ----
LR: [0.008973158512378369]
---- EP [2/5] | BTCH [660/3634] ||| train_loss = nan ----
LR: [0.00897486819802961]
---- EP [2/5] | BTCH [661/3634] ||| train_loss = nan ----
LR: [0.008976576629360352]
---- EP [2/5] | BTCH [662/3634] ||| train_loss = nan ----
LR: [0.008978283805802907]
---- EP [2/5] | BTCH [663/3634] ||| train_loss = nan ----
LR: [0.008979989726790014]
---- EP [2/5] | BTCH [664/3634] ||| train_loss = nan ----
LR: [0.008981694391754828]
---- EP [2/5] | BTCH [665/3634] ||| train_loss = nan ----
LR: [0.008983397800130917]
---- EP [2/5] | BTCH [666/3634] ||| train_loss = nan ----
LR: [0.008985099951352268]
---- EP [2/5] | BTCH [667/3634] ||| train_loss = nan ----
LR: [0.008986800844853291]
---- EP [2/5] | BTCH [668/3634] ||| train_loss = nan ----
LR: [0.008988500480068808]
---- EP [2/5] | BTCH [669/3634] ||| train_loss = nan ----
LR: [0.00899019885643406]
---- EP [2/5] | BTCH [670/3634] ||| train_loss = nan ----
LR: [0.008991895973384708]
---- EP [2/5] | BTCH [671/3634] ||| train_loss = nan ----
LR: [0.00899359183035683]
---- EP [2/5] | BTCH [672/3634] ||| train_loss = nan ----
LR: [0.008995286426786925]
---- EP [2/5] | BTCH [673/3634] ||| train_loss = nan ----
LR: [0.008996979762111909]
---- EP [2/5] | BTCH [674/3634] ||| train_loss = nan ----
LR: [0.008998671835769113]
---- EP [2/5] | BTCH [675/3634] ||| train_loss = nan ----
LR: [0.009000362647196298]
---- EP [2/5] | BTCH [676/3634] ||| train_loss = nan ----
LR: [0.009002052195831634]
---- EP [2/5] | BTCH [677/3634] ||| train_loss = nan ----
LR: [0.009003740481113714]
---- EP [2/5] | BTCH [678/3634] ||| train_loss = nan ----
LR: [0.009005427502481555]
---- EP [2/5] | BTCH [679/3634] ||| train_loss = nan ----
LR: [0.009007113259374587]
---- EP [2/5] | BTCH [680/3634] ||| train_loss = nan ----
LR: [0.009008797751232664]
---- EP [2/5] | BTCH [681/3634] ||| train_loss = nan ----
LR: [0.009010480977496061]
---- EP [2/5] | BTCH [682/3634] ||| train_loss = nan ----
LR: [0.00901216293760547]
---- EP [2/5] | BTCH [683/3634] ||| train_loss = nan ----
LR: [0.009013843631002008]
---- EP [2/5] | BTCH [684/3634] ||| train_loss = nan ----
LR: [0.009015523057127212]
---- EP [2/5] | BTCH [685/3634] ||| train_loss = nan ----
LR: [0.009017201215423036]
---- EP [2/5] | BTCH [686/3634] ||| train_loss = nan ----
LR: [0.009018878105331859]
---- EP [2/5] | BTCH [687/3634] ||| train_loss = nan ----
LR: [0.009020553726296484]
---- EP [2/5] | BTCH [688/3634] ||| train_loss = nan ----
LR: [0.009022228077760128]
---- EP [2/5] | BTCH [689/3634] ||| train_loss = nan ----
LR: [0.009023901159166438]
---- EP [2/5] | BTCH [690/3634] ||| train_loss = nan ----
LR: [0.009025572969959476]
---- EP [2/5] | BTCH [691/3634] ||| train_loss = nan ----
LR: [0.009027243509583734]
---- EP [2/5] | BTCH [692/3634] ||| train_loss = nan ----
LR: [0.009028912777484115]
---- EP [2/5] | BTCH [693/3634] ||| train_loss = nan ----
LR: [0.009030580773105958]
---- EP [2/5] | BTCH [694/3634] ||| train_loss = nan ----
LR: [0.009032247495895013]
---- EP [2/5] | BTCH [695/3634] ||| train_loss = nan ----
LR: [0.009033912945297462]
---- EP [2/5] | BTCH [696/3634] ||| train_loss = nan ----
LR: [0.009035577120759905]
---- EP [2/5] | BTCH [697/3634] ||| train_loss = nan ----
LR: [0.009037240021729367]
---- EP [2/5] | BTCH [698/3634] ||| train_loss = nan ----
LR: [0.009038901647653296]
---- EP [2/5] | BTCH [699/3634] ||| train_loss = nan ----
LR: [0.009040561997979563]
---- EP [2/5] | BTCH [700/3634] ||| train_loss = nan ----
LR: [0.009042221072156463]
---- EP [2/5] | BTCH [701/3634] ||| train_loss = nan ----
LR: [0.009043878869632717]
---- EP [2/5] | BTCH [702/3634] ||| train_loss = nan ----
LR: [0.009045535389857468]
---- EP [2/5] | BTCH [703/3634] ||| train_loss = nan ----
LR: [0.009047190632280284]
---- EP [2/5] | BTCH [704/3634] ||| train_loss = nan ----
LR: [0.00904884459635116]
---- EP [2/5] | BTCH [705/3634] ||| train_loss = nan ----
LR: [0.009050497281520511]
---- EP [2/5] | BTCH [706/3634] ||| train_loss = nan ----
LR: [0.00905214868723918]
---- EP [2/5] | BTCH [707/3634] ||| train_loss = nan ----
LR: [0.009053798812958435]
---- EP [2/5] | BTCH [708/3634] ||| train_loss = nan ----
LR: [0.009055447658129972]
---- EP [2/5] | BTCH [709/3634] ||| train_loss = nan ----
LR: [0.009057095222205904]
---- EP [2/5] | BTCH [710/3634] ||| train_loss = nan ----
LR: [0.00905874150463878]
---- EP [2/5] | BTCH [711/3634] ||| train_loss = nan ----
LR: [0.009060386504881569]
---- EP [2/5] | BTCH [712/3634] ||| train_loss = nan ----
LR: [0.009062030222387664]
---- EP [2/5] | BTCH [713/3634] ||| train_loss = nan ----
LR: [0.009063672656610892]
---- EP [2/5] | BTCH [714/3634] ||| train_loss = nan ----
LR: [0.009065313807005497]
---- EP [2/5] | BTCH [715/3634] ||| train_loss = nan ----
LR: [0.009066953673026158]
---- EP [2/5] | BTCH [716/3634] ||| train_loss = nan ----
LR: [0.009068592254127978]
---- EP [2/5] | BTCH [717/3634] ||| train_loss = nan ----
LR: [0.009070229549766481]
---- EP [2/5] | BTCH [718/3634] ||| train_loss = nan ----
LR: [0.009071865559397627]
---- EP [2/5] | BTCH [719/3634] ||| train_loss = nan ----
LR: [0.009073500282477802]
---- EP [2/5] | BTCH [720/3634] ||| train_loss = nan ----
LR: [0.00907513371846381]
---- EP [2/5] | BTCH [721/3634] ||| train_loss = nan ----
LR: [0.009076765866812896]
---- EP [2/5] | BTCH [722/3634] ||| train_loss = nan ----
LR: [0.009078396726982725]
---- EP [2/5] | BTCH [723/3634] ||| train_loss = nan ----
LR: [0.009080026298431389]
---- EP [2/5] | BTCH [724/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.009081654580617412]
---- EP [2/5] | BTCH [725/3634] ||| train_loss = nan ----
LR: [0.009083281572999747]
---- EP [2/5] | BTCH [726/3634] ||| train_loss = nan ----
LR: [0.009084907275037774]
---- EP [2/5] | BTCH [727/3634] ||| train_loss = nan ----
LR: [0.0090865316861913]
---- EP [2/5] | BTCH [728/3634] ||| train_loss = nan ----
LR: [0.009088154805920562]
---- EP [2/5] | BTCH [729/3634] ||| train_loss = nan ----
LR: [0.009089776633686228]
---- EP [2/5] | BTCH [730/3634] ||| train_loss = nan ----
LR: [0.009091397168949394]
---- EP [2/5] | BTCH [731/3634] ||| train_loss = nan ----
LR: [0.009093016411171585]
---- EP [2/5] | BTCH [732/3634] ||| train_loss = nan ----
LR: [0.009094634359814755]
---- EP [2/5] | BTCH [733/3634] ||| train_loss = nan ----
LR: [0.009096251014341292]
---- EP [2/5] | BTCH [734/3634] ||| train_loss = nan ----
LR: [0.009097866374214007]
---- EP [2/5] | BTCH [735/3634] ||| train_loss = nan ----
LR: [0.009099480438896147]
---- EP [2/5] | BTCH [736/3634] ||| train_loss = nan ----
LR: [0.009101093207851388]
---- EP [2/5] | BTCH [737/3634] ||| train_loss = nan ----
LR: [0.009102704680543834]
---- EP [2/5] | BTCH [738/3634] ||| train_loss = nan ----
LR: [0.009104314856438025]
---- EP [2/5] | BTCH [739/3634] ||| train_loss = nan ----
LR: [0.009105923734998926]
---- EP [2/5] | BTCH [740/3634] ||| train_loss = nan ----
LR: [0.009107531315691936]
---- EP [2/5] | BTCH [741/3634] ||| train_loss = nan ----
LR: [0.009109137597982887]
---- EP [2/5] | BTCH [742/3634] ||| train_loss = nan ----
LR: [0.009110742581338038]
---- EP [2/5] | BTCH [743/3634] ||| train_loss = nan ----
LR: [0.009112346265224083]
---- EP [2/5] | BTCH [744/3634] ||| train_loss = nan ----
LR: [0.009113948649108146]
---- EP [2/5] | BTCH [745/3634] ||| train_loss = nan ----
LR: [0.009115549732457786]
---- EP [2/5] | BTCH [746/3634] ||| train_loss = nan ----
LR: [0.00911714951474099]
---- EP [2/5] | BTCH [747/3634] ||| train_loss = nan ----
LR: [0.009118747995426177]
---- EP [2/5] | BTCH [748/3634] ||| train_loss = nan ----
LR: [0.009120345173982207]
---- EP [2/5] | BTCH [749/3634] ||| train_loss = nan ----
LR: [0.009121941049878362]
---- EP [2/5] | BTCH [750/3634] ||| train_loss = nan ----
LR: [0.009123535622584361]
---- EP [2/5] | BTCH [751/3634] ||| train_loss = nan ----
LR: [0.009125128891570357]
---- EP [2/5] | BTCH [752/3634] ||| train_loss = nan ----
LR: [0.009126720856306938]
---- EP [2/5] | BTCH [753/3634] ||| train_loss = nan ----
LR: [0.009128311516265121]
---- EP [2/5] | BTCH [754/3634] ||| train_loss = nan ----
LR: [0.009129900870916356]
---- EP [2/5] | BTCH [755/3634] ||| train_loss = nan ----
LR: [0.009131488919732532]
---- EP [2/5] | BTCH [756/3634] ||| train_loss = nan ----
LR: [0.00913307566218597]
---- EP [2/5] | BTCH [757/3634] ||| train_loss = nan ----
LR: [0.00913466109774942]
---- EP [2/5] | BTCH [758/3634] ||| train_loss = nan ----
LR: [0.009136245225896076]
---- EP [2/5] | BTCH [759/3634] ||| train_loss = nan ----
LR: [0.009137828046099557]
---- EP [2/5] | BTCH [760/3634] ||| train_loss = nan ----
LR: [0.009139409557833919]
---- EP [2/5] | BTCH [761/3634] ||| train_loss = nan ----
LR: [0.00914098976057366]
---- EP [2/5] | BTCH [762/3634] ||| train_loss = nan ----
LR: [0.009142568653793703]
---- EP [2/5] | BTCH [763/3634] ||| train_loss = nan ----
LR: [0.00914414623696941]
---- EP [2/5] | BTCH [764/3634] ||| train_loss = nan ----
LR: [0.009145722509576577]
---- EP [2/5] | BTCH [765/3634] ||| train_loss = nan ----
LR: [0.009147297471091444]
---- EP [2/5] | BTCH [766/3634] ||| train_loss = nan ----
LR: [0.009148871120990673]
---- EP [2/5] | BTCH [767/3634] ||| train_loss = nan ----
LR: [0.009150443458751373]
---- EP [2/5] | BTCH [768/3634] ||| train_loss = nan ----
LR: [0.009152014483851082]
---- EP [2/5] | BTCH [769/3634] ||| train_loss = nan ----
LR: [0.009153584195767776]
---- EP [2/5] | BTCH [770/3634] ||| train_loss = nan ----
LR: [0.009155152593979872]
---- EP [2/5] | BTCH [771/3634] ||| train_loss = nan ----
LR: [0.009156719677966213]
---- EP [2/5] | BTCH [772/3634] ||| train_loss = nan ----
LR: [0.009158285447206094]
---- EP [2/5] | BTCH [773/3634] ||| train_loss = nan ----
LR: [0.00915984990117923]
---- EP [2/5] | BTCH [774/3634] ||| train_loss = nan ----
LR: [0.009161413039365787]
---- EP [2/5] | BTCH [775/3634] ||| train_loss = nan ----
LR: [0.009162974861246358]
---- EP [2/5] | BTCH [776/3634] ||| train_loss = nan ----
LR: [0.009164535366301981]
---- EP [2/5] | BTCH [777/3634] ||| train_loss = nan ----
LR: [0.009166094554014128]
---- EP [2/5] | BTCH [778/3634] ||| train_loss = nan ----
LR: [0.009167652423864707]
---- EP [2/5] | BTCH [779/3634] ||| train_loss = nan ----
LR: [0.00916920897533607]
---- EP [2/5] | BTCH [780/3634] ||| train_loss = nan ----
LR: [0.009170764207910997]
---- EP [2/5] | BTCH [781/3634] ||| train_loss = nan ----
LR: [0.00917231812107272]
---- EP [2/5] | BTCH [782/3634] ||| train_loss = nan ----
LR: [0.009173870714304895]
---- EP [2/5] | BTCH [783/3634] ||| train_loss = nan ----
LR: [0.009175421987091625]
---- EP [2/5] | BTCH [784/3634] ||| train_loss = nan ----
LR: [0.009176971938917452]
---- EP [2/5] | BTCH [785/3634] ||| train_loss = nan ----
LR: [0.009178520569267353]
---- EP [2/5] | BTCH [786/3634] ||| train_loss = nan ----
LR: [0.009180067877626747]
---- EP [2/5] | BTCH [787/3634] ||| train_loss = nan ----
LR: [0.009181613863481493]
---- EP [2/5] | BTCH [788/3634] ||| train_loss = nan ----
LR: [0.009183158526317887]
---- EP [2/5] | BTCH [789/3634] ||| train_loss = nan ----
LR: [0.009184701865622662]
---- EP [2/5] | BTCH [790/3634] ||| train_loss = nan ----
LR: [0.009186243880882999]
---- EP [2/5] | BTCH [791/3634] ||| train_loss = nan ----
LR: [0.00918778457158651]
---- EP [2/5] | BTCH [792/3634] ||| train_loss = nan ----
LR: [0.009189323937221255]
---- EP [2/5] | BTCH [793/3634] ||| train_loss = nan ----
LR: [0.009190861977275729]
---- EP [2/5] | BTCH [794/3634] ||| train_loss = nan ----
LR: [0.00919239869123887]
---- EP [2/5] | BTCH [795/3634] ||| train_loss = nan ----
LR: [0.009193934078600051]
---- EP [2/5] | BTCH [796/3634] ||| train_loss = nan ----
LR: [0.009195468138849099]
---- EP [2/5] | BTCH [797/3634] ||| train_loss = nan ----
LR: [0.009197000871476265]
---- EP [2/5] | BTCH [798/3634] ||| train_loss = nan ----
LR: [0.009198532275972256]
---- EP [2/5] | BTCH [799/3634] ||| train_loss = nan ----
LR: [0.009200062351828213]
---- EP [2/5] | BTCH [800/3634] ||| train_loss = nan ----
LR: [0.009201591098535715]
---- EP [2/5] | BTCH [801/3634] ||| train_loss = nan ----
LR: [0.00920311851558679]
---- EP [2/5] | BTCH [802/3634] ||| train_loss = nan ----
LR: [0.009204644602473906]
---- EP [2/5] | BTCH [803/3634] ||| train_loss = nan ----
LR: [0.00920616935868997]
---- EP [2/5] | BTCH [804/3634] ||| train_loss = nan ----
LR: [0.009207692783728334]
---- EP [2/5] | BTCH [805/3634] ||| train_loss = nan ----
LR: [0.009209214877082792]
---- EP [2/5] | BTCH [806/3634] ||| train_loss = nan ----
LR: [0.009210735638247577]
---- EP [2/5] | BTCH [807/3634] ||| train_loss = nan ----
LR: [0.009212255066717372]
---- EP [2/5] | BTCH [808/3634] ||| train_loss = nan ----
LR: [0.009213773161987295]
---- EP [2/5] | BTCH [809/3634] ||| train_loss = nan ----
LR: [0.009215289923552911]
---- EP [2/5] | BTCH [810/3634] ||| train_loss = nan ----
LR: [0.00921680535091023]
---- EP [2/5] | BTCH [811/3634] ||| train_loss = nan ----
LR: [0.009218319443555698]
---- EP [2/5] | BTCH [812/3634] ||| train_loss = nan ----
LR: [0.009219832200986215]
---- EP [2/5] | BTCH [813/3634] ||| train_loss = nan ----
LR: [0.009221343622699113]
---- EP [2/5] | BTCH [814/3634] ||| train_loss = nan ----
LR: [0.009222853708192178]
---- EP [2/5] | BTCH [815/3634] ||| train_loss = nan ----
LR: [0.009224362456963635]
---- EP [2/5] | BTCH [816/3634] ||| train_loss = nan ----
LR: [0.009225869868512156]
---- EP [2/5] | BTCH [817/3634] ||| train_loss = nan ----
LR: [0.00922737594233685]
---- EP [2/5] | BTCH [818/3634] ||| train_loss = nan ----
LR: [0.009228880677937283]
---- EP [2/5] | BTCH [819/3634] ||| train_loss = nan ----
LR: [0.009230384074813452]
---- EP [2/5] | BTCH [820/3634] ||| train_loss = nan ----
LR: [0.009231886132465809]
---- EP [2/5] | BTCH [821/3634] ||| train_loss = nan ----
LR: [0.009233386850395247]
---- EP [2/5] | BTCH [822/3634] ||| train_loss = nan ----
LR: [0.009234886228103104]
---- EP [2/5] | BTCH [823/3634] ||| train_loss = nan ----
LR: [0.009236384265091163]
---- EP [2/5] | BTCH [824/3634] ||| train_loss = nan ----
LR: [0.009237880960861655]
---- EP [2/5] | BTCH [825/3634] ||| train_loss = nan ----
LR: [0.009239376314917253]
---- EP [2/5] | BTCH [826/3634] ||| train_loss = nan ----
LR: [0.00924087032676108]
---- EP [2/5] | BTCH [827/3634] ||| train_loss = nan ----
LR: [0.009242362995896702]
---- EP [2/5] | BTCH [828/3634] ||| train_loss = nan ----
LR: [0.009243854321828135]
---- EP [2/5] | BTCH [829/3634] ||| train_loss = nan ----
LR: [0.009245344304059832]
---- EP [2/5] | BTCH [830/3634] ||| train_loss = nan ----
LR: [0.009246832942096703]
---- EP [2/5] | BTCH [831/3634] ||| train_loss = nan ----
LR: [0.009248320235444099]
---- EP [2/5] | BTCH [832/3634] ||| train_loss = nan ----
LR: [0.009249806183607821]
---- EP [2/5] | BTCH [833/3634] ||| train_loss = nan ----
LR: [0.009251290786094114]
---- EP [2/5] | BTCH [834/3634] ||| train_loss = nan ----
LR: [0.009252774042409671]
---- EP [2/5] | BTCH [835/3634] ||| train_loss = nan ----
LR: [0.009254255952061636]
---- EP [2/5] | BTCH [836/3634] ||| train_loss = nan ----
LR: [0.009255736514557593]
---- EP [2/5] | BTCH [837/3634] ||| train_loss = nan ----
LR: [0.009257215729405579]
---- EP [2/5] | BTCH [838/3634] ||| train_loss = nan ----
LR: [0.009258693596114078]
---- EP [2/5] | BTCH [839/3634] ||| train_loss = nan ----
LR: [0.009260170114192022]
---- EP [2/5] | BTCH [840/3634] ||| train_loss = nan ----
LR: [0.009261645283148792]
---- EP [2/5] | BTCH [841/3634] ||| train_loss = nan ----
LR: [0.009263119102494213]
---- EP [2/5] | BTCH [842/3634] ||| train_loss = nan ----
LR: [0.009264591571738562]
---- EP [2/5] | BTCH [843/3634] ||| train_loss = nan ----
LR: [0.009266062690392565]
---- EP [2/5] | BTCH [844/3634] ||| train_loss = nan ----
LR: [0.009267532457967397]
---- EP [2/5] | BTCH [845/3634] ||| train_loss = nan ----
LR: [0.009269000873974679]
---- EP [2/5] | BTCH [846/3634] ||| train_loss = nan ----
LR: [0.009270467937926482]
---- EP [2/5] | BTCH [847/3634] ||| train_loss = nan ----
LR: [0.009271933649335332]
---- EP [2/5] | BTCH [848/3634] ||| train_loss = nan ----
LR: [0.009273398007714194]
---- EP [2/5] | BTCH [849/3634] ||| train_loss = nan ----
LR: [0.009274861012576489]
---- EP [2/5] | BTCH [850/3634] ||| train_loss = nan ----
LR: [0.00927632266343609]
---- EP [2/5] | BTCH [851/3634] ||| train_loss = nan ----
LR: [0.009277782959807315]
---- EP [2/5] | BTCH [852/3634] ||| train_loss = nan ----
LR: [0.009279241901204934]
---- EP [2/5] | BTCH [853/3634] ||| train_loss = nan ----
LR: [0.009280699487144167]
---- EP [2/5] | BTCH [854/3634] ||| train_loss = nan ----
LR: [0.009282155717140684]
---- EP [2/5] | BTCH [855/3634] ||| train_loss = nan ----
LR: [0.009283610590710608]
---- EP [2/5] | BTCH [856/3634] ||| train_loss = nan ----
LR: [0.00928506410737051]
---- EP [2/5] | BTCH [857/3634] ||| train_loss = nan ----
LR: [0.00928651626663741]
---- EP [2/5] | BTCH [858/3634] ||| train_loss = nan ----
LR: [0.009287967068028787]
---- EP [2/5] | BTCH [859/3634] ||| train_loss = nan ----
LR: [0.00928941651106256]
---- EP [2/5] | BTCH [860/3634] ||| train_loss = nan ----
LR: [0.009290864595257109]
---- EP [2/5] | BTCH [861/3634] ||| train_loss = nan ----
LR: [0.009292311320131261]
---- EP [2/5] | BTCH [862/3634] ||| train_loss = nan ----
LR: [0.009293756685204295]
---- EP [2/5] | BTCH [863/3634] ||| train_loss = nan ----
LR: [0.009295200689995942]
---- EP [2/5] | BTCH [864/3634] ||| train_loss = nan ----
LR: [0.009296643334026387]
---- EP [2/5] | BTCH [865/3634] ||| train_loss = nan ----
LR: [0.009298084616816266]
---- EP [2/5] | BTCH [866/3634] ||| train_loss = nan ----
LR: [0.009299524537886662]
---- EP [2/5] | BTCH [867/3634] ||| train_loss = nan ----
LR: [0.00930096309675912]
---- EP [2/5] | BTCH [868/3634] ||| train_loss = nan ----
LR: [0.00930240029295563]
---- EP [2/5] | BTCH [869/3634] ||| train_loss = nan ----
LR: [0.009303836125998641]
---- EP [2/5] | BTCH [870/3634] ||| train_loss = nan ----
LR: [0.00930527059541105]
---- EP [2/5] | BTCH [871/3634] ||| train_loss = nan ----
LR: [0.009306703700716205]
---- EP [2/5] | BTCH [872/3634] ||| train_loss = nan ----
LR: [0.009308135441437916]
---- EP [2/5] | BTCH [873/3634] ||| train_loss = nan ----
LR: [0.00930956581710044]
---- EP [2/5] | BTCH [874/3634] ||| train_loss = nan ----
LR: [0.009310994827228488]
---- EP [2/5] | BTCH [875/3634] ||| train_loss = nan ----
LR: [0.009312422471347228]
---- EP [2/5] | BTCH [876/3634] ||| train_loss = nan ----
LR: [0.009313848748982277]
---- EP [2/5] | BTCH [877/3634] ||| train_loss = nan ----
LR: [0.00931527365965971]
---- EP [2/5] | BTCH [878/3634] ||| train_loss = nan ----
LR: [0.009316697202906055]
---- EP [2/5] | BTCH [879/3634] ||| train_loss = nan ----
LR: [0.009318119378248294]
---- EP [2/5] | BTCH [880/3634] ||| train_loss = nan ----
LR: [0.009319540185213863]
---- EP [2/5] | BTCH [881/3634] ||| train_loss = nan ----
LR: [0.009320959623330655]
---- EP [2/5] | BTCH [882/3634] ||| train_loss = nan ----
LR: [0.009322377692127017]
---- EP [2/5] | BTCH [883/3634] ||| train_loss = nan ----
LR: [0.009323794391131747]
---- EP [2/5] | BTCH [884/3634] ||| train_loss = nan ----
LR: [0.009325209719874104]
---- EP [2/5] | BTCH [885/3634] ||| train_loss = nan ----
LR: [0.0093266236778838]
---- EP [2/5] | BTCH [886/3634] ||| train_loss = nan ----
LR: [0.009328036264691003]
---- EP [2/5] | BTCH [887/3634] ||| train_loss = nan ----
LR: [0.009329447479826333]
---- EP [2/5] | BTCH [888/3634] ||| train_loss = nan ----
LR: [0.009330857322820872]
---- EP [2/5] | BTCH [889/3634] ||| train_loss = nan ----
LR: [0.009332265793206151]
---- EP [2/5] | BTCH [890/3634] ||| train_loss = nan ----
LR: [0.009333672890514164]
---- EP [2/5] | BTCH [891/3634] ||| train_loss = nan ----
LR: [0.009335078614277357]
---- EP [2/5] | BTCH [892/3634] ||| train_loss = nan ----
LR: [0.009336482964028631]
---- EP [2/5] | BTCH [893/3634] ||| train_loss = nan ----
LR: [0.009337885939301351]
---- EP [2/5] | BTCH [894/3634] ||| train_loss = nan ----
LR: [0.009339287539629329]
---- EP [2/5] | BTCH [895/3634] ||| train_loss = nan ----
LR: [0.00934068776454684]
---- EP [2/5] | BTCH [896/3634] ||| train_loss = nan ----
LR: [0.009342086613588617]
---- EP [2/5] | BTCH [897/3634] ||| train_loss = nan ----
LR: [0.009343484086289842]
---- EP [2/5] | BTCH [898/3634] ||| train_loss = nan ----
LR: [0.009344880182186167]
---- EP [2/5] | BTCH [899/3634] ||| train_loss = nan ----
LR: [0.009346274900813691]
---- EP [2/5] | BTCH [900/3634] ||| train_loss = nan ----
LR: [0.009347668241708972]
---- EP [2/5] | BTCH [901/3634] ||| train_loss = nan ----
LR: [0.009349060204409032]
---- EP [2/5] | BTCH [902/3634] ||| train_loss = nan ----
LR: [0.009350450788451346]
---- EP [2/5] | BTCH [903/3634] ||| train_loss = nan ----
LR: [0.009351839993373846]
---- EP [2/5] | BTCH [904/3634] ||| train_loss = nan ----
LR: [0.009353227818714926]
---- EP [2/5] | BTCH [905/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.009354614264013439]
---- EP [2/5] | BTCH [906/3634] ||| train_loss = nan ----
LR: [0.009355999328808689]
---- EP [2/5] | BTCH [907/3634] ||| train_loss = nan ----
LR: [0.009357383012640446]
---- EP [2/5] | BTCH [908/3634] ||| train_loss = nan ----
LR: [0.00935876531504894]
---- EP [2/5] | BTCH [909/3634] ||| train_loss = nan ----
LR: [0.009360146235574851]
---- EP [2/5] | BTCH [910/3634] ||| train_loss = nan ----
LR: [0.009361525773759332]
---- EP [2/5] | BTCH [911/3634] ||| train_loss = nan ----
LR: [0.00936290392914398]
---- EP [2/5] | BTCH [912/3634] ||| train_loss = nan ----
LR: [0.00936428070127086]
---- EP [2/5] | BTCH [913/3634] ||| train_loss = nan ----
LR: [0.009365656089682501]
---- EP [2/5] | BTCH [914/3634] ||| train_loss = nan ----
LR: [0.009367030093921879]
---- EP [2/5] | BTCH [915/3634] ||| train_loss = nan ----
LR: [0.009368402713532443]
---- EP [2/5] | BTCH [916/3634] ||| train_loss = nan ----
LR: [0.009369773948058095]
---- EP [2/5] | BTCH [917/3634] ||| train_loss = nan ----
LR: [0.009371143797043196]
---- EP [2/5] | BTCH [918/3634] ||| train_loss = nan ----
LR: [0.009372512260032571]
---- EP [2/5] | BTCH [919/3634] ||| train_loss = nan ----
LR: [0.009373879336571507]
---- EP [2/5] | BTCH [920/3634] ||| train_loss = nan ----
LR: [0.009375245026205745]
---- EP [2/5] | BTCH [921/3634] ||| train_loss = nan ----
LR: [0.009376609328481495]
---- EP [2/5] | BTCH [922/3634] ||| train_loss = nan ----
LR: [0.009377972242945419]
---- EP [2/5] | BTCH [923/3634] ||| train_loss = nan ----
LR: [0.00937933376914465]
---- EP [2/5] | BTCH [924/3634] ||| train_loss = nan ----
LR: [0.009380693906626776]
---- EP [2/5] | BTCH [925/3634] ||| train_loss = nan ----
LR: [0.009382052654939849]
---- EP [2/5] | BTCH [926/3634] ||| train_loss = nan ----
LR: [0.009383410013632378]
---- EP [2/5] | BTCH [927/3634] ||| train_loss = nan ----
LR: [0.009384765982253341]
---- EP [2/5] | BTCH [928/3634] ||| train_loss = nan ----
LR: [0.009386120560352172]
---- EP [2/5] | BTCH [929/3634] ||| train_loss = nan ----
LR: [0.009387473747478768]
---- EP [2/5] | BTCH [930/3634] ||| train_loss = nan ----
LR: [0.009388825543183493]
---- EP [2/5] | BTCH [931/3634] ||| train_loss = nan ----
LR: [0.009390175947017165]
---- EP [2/5] | BTCH [932/3634] ||| train_loss = nan ----
LR: [0.009391524958531074]
---- EP [2/5] | BTCH [933/3634] ||| train_loss = nan ----
LR: [0.009392872577276966]
---- EP [2/5] | BTCH [934/3634] ||| train_loss = nan ----
LR: [0.00939421880280705]
---- EP [2/5] | BTCH [935/3634] ||| train_loss = nan ----
LR: [0.009395563634674003]
---- EP [2/5] | BTCH [936/3634] ||| train_loss = nan ----
LR: [0.009396907072430958]
---- EP [2/5] | BTCH [937/3634] ||| train_loss = nan ----
LR: [0.009398249115631517]
---- EP [2/5] | BTCH [938/3634] ||| train_loss = nan ----
LR: [0.009399589763829742]
---- EP [2/5] | BTCH [939/3634] ||| train_loss = nan ----
LR: [0.009400929016580163]
---- EP [2/5] | BTCH [940/3634] ||| train_loss = nan ----
LR: [0.009402266873437766]
---- EP [2/5] | BTCH [941/3634] ||| train_loss = nan ----
LR: [0.009403603333958009]
---- EP [2/5] | BTCH [942/3634] ||| train_loss = nan ----
LR: [0.009404938397696808]
---- EP [2/5] | BTCH [943/3634] ||| train_loss = nan ----
LR: [0.009406272064210543]
---- EP [2/5] | BTCH [944/3634] ||| train_loss = nan ----
LR: [0.009407604333056069]
---- EP [2/5] | BTCH [945/3634] ||| train_loss = nan ----
LR: [0.009408935203790691]
---- EP [2/5] | BTCH [946/3634] ||| train_loss = nan ----
LR: [0.009410264675972184]
---- EP [2/5] | BTCH [947/3634] ||| train_loss = nan ----
LR: [0.009411592749158792]
---- EP [2/5] | BTCH [948/3634] ||| train_loss = nan ----
LR: [0.009412919422909219]
---- EP [2/5] | BTCH [949/3634] ||| train_loss = nan ----
LR: [0.009414244696782632]
---- EP [2/5] | BTCH [950/3634] ||| train_loss = nan ----
LR: [0.009415568570338671]
---- EP [2/5] | BTCH [951/3634] ||| train_loss = nan ----
LR: [0.009416891043137433]
---- EP [2/5] | BTCH [952/3634] ||| train_loss = nan ----
LR: [0.009418212114739487]
---- EP [2/5] | BTCH [953/3634] ||| train_loss = nan ----
LR: [0.009419531784705866]
---- EP [2/5] | BTCH [954/3634] ||| train_loss = nan ----
LR: [0.009420850052598063]
---- EP [2/5] | BTCH [955/3634] ||| train_loss = nan ----
LR: [0.009422166917978045]
---- EP [2/5] | BTCH [956/3634] ||| train_loss = nan ----
LR: [0.00942348238040824]
---- EP [2/5] | BTCH [957/3634] ||| train_loss = nan ----
LR: [0.009424796439451544]
---- EP [2/5] | BTCH [958/3634] ||| train_loss = nan ----
LR: [0.00942610909467132]
---- EP [2/5] | BTCH [959/3634] ||| train_loss = nan ----
LR: [0.009427420345631394]
---- EP [2/5] | BTCH [960/3634] ||| train_loss = nan ----
LR: [0.00942873019189606]
---- EP [2/5] | BTCH [961/3634] ||| train_loss = nan ----
LR: [0.009430038633030083]
---- EP [2/5] | BTCH [962/3634] ||| train_loss = nan ----
LR: [0.009431345668598693]
---- EP [2/5] | BTCH [963/3634] ||| train_loss = nan ----
LR: [0.00943265129816758]
---- EP [2/5] | BTCH [964/3634] ||| train_loss = nan ----
LR: [0.009433955521302911]
---- EP [2/5] | BTCH [965/3634] ||| train_loss = nan ----
LR: [0.009435258337571317]
---- EP [2/5] | BTCH [966/3634] ||| train_loss = nan ----
LR: [0.009436559746539891]
---- EP [2/5] | BTCH [967/3634] ||| train_loss = nan ----
LR: [0.009437859747776204]
---- EP [2/5] | BTCH [968/3634] ||| train_loss = nan ----
LR: [0.009439158340848287]
---- EP [2/5] | BTCH [969/3634] ||| train_loss = nan ----
LR: [0.009440455525324638]
---- EP [2/5] | BTCH [970/3634] ||| train_loss = nan ----
LR: [0.009441751300774228]
---- EP [2/5] | BTCH [971/3634] ||| train_loss = nan ----
LR: [0.009443045666766497]
---- EP [2/5] | BTCH [972/3634] ||| train_loss = nan ----
LR: [0.009444338622871347]
---- EP [2/5] | BTCH [973/3634] ||| train_loss = nan ----
LR: [0.009445630168659153]
---- EP [2/5] | BTCH [974/3634] ||| train_loss = nan ----
LR: [0.009446920303700757]
---- EP [2/5] | BTCH [975/3634] ||| train_loss = nan ----
LR: [0.009448209027567473]
---- EP [2/5] | BTCH [976/3634] ||| train_loss = nan ----
LR: [0.00944949633983108]
---- EP [2/5] | BTCH [977/3634] ||| train_loss = nan ----
LR: [0.009450782240063826]
---- EP [2/5] | BTCH [978/3634] ||| train_loss = nan ----
LR: [0.009452066727838432]
---- EP [2/5] | BTCH [979/3634] ||| train_loss = nan ----
LR: [0.009453349802728083]
---- EP [2/5] | BTCH [980/3634] ||| train_loss = nan ----
LR: [0.009454631464306439]
---- EP [2/5] | BTCH [981/3634] ||| train_loss = nan ----
LR: [0.009455911712147625]
---- EP [2/5] | BTCH [982/3634] ||| train_loss = nan ----
LR: [0.009457190545826239]
---- EP [2/5] | BTCH [983/3634] ||| train_loss = nan ----
LR: [0.009458467964917347]
---- EP [2/5] | BTCH [984/3634] ||| train_loss = nan ----
LR: [0.009459743968996489]
---- EP [2/5] | BTCH [985/3634] ||| train_loss = nan ----
LR: [0.009461018557639667]
---- EP [2/5] | BTCH [986/3634] ||| train_loss = nan ----
LR: [0.00946229173042336]
---- EP [2/5] | BTCH [987/3634] ||| train_loss = nan ----
LR: [0.009463563486924516]
---- EP [2/5] | BTCH [988/3634] ||| train_loss = nan ----
LR: [0.009464833826720554]
---- EP [2/5] | BTCH [989/3634] ||| train_loss = nan ----
LR: [0.009466102749389362]
---- EP [2/5] | BTCH [990/3634] ||| train_loss = nan ----
LR: [0.0094673702545093]
---- EP [2/5] | BTCH [991/3634] ||| train_loss = nan ----
LR: [0.009468636341659198]
---- EP [2/5] | BTCH [992/3634] ||| train_loss = nan ----
LR: [0.00946990101041836]
---- EP [2/5] | BTCH [993/3634] ||| train_loss = nan ----
LR: [0.00947116426036656]
---- EP [2/5] | BTCH [994/3634] ||| train_loss = nan ----
LR: [0.00947242609108404]
---- EP [2/5] | BTCH [995/3634] ||| train_loss = nan ----
LR: [0.009473686502151519]
---- EP [2/5] | BTCH [996/3634] ||| train_loss = nan ----
LR: [0.009474945493150184]
---- EP [2/5] | BTCH [997/3634] ||| train_loss = nan ----
LR: [0.009476203063661695]
---- EP [2/5] | BTCH [998/3634] ||| train_loss = nan ----
LR: [0.009477459213268185]
---- EP [2/5] | BTCH [999/3634] ||| train_loss = nan ----
LR: [0.009478713941552256]
---- EP [2/5] | BTCH [1000/3634] ||| train_loss = nan ----
LR: [0.009479967248096986]
---- EP [2/5] | BTCH [1001/3634] ||| train_loss = nan ----
LR: [0.009481219132485924]
---- EP [2/5] | BTCH [1002/3634] ||| train_loss = nan ----
LR: [0.009482469594303093]
---- EP [2/5] | BTCH [1003/3634] ||| train_loss = nan ----
LR: [0.009483718633132984]
---- EP [2/5] | BTCH [1004/3634] ||| train_loss = nan ----
LR: [0.009484966248560565]
---- EP [2/5] | BTCH [1005/3634] ||| train_loss = nan ----
LR: [0.009486212440171277]
---- EP [2/5] | BTCH [1006/3634] ||| train_loss = nan ----
LR: [0.009487457207551031]
---- EP [2/5] | BTCH [1007/3634] ||| train_loss = nan ----
LR: [0.009488700550286215]
---- EP [2/5] | BTCH [1008/3634] ||| train_loss = nan ----
LR: [0.00948994246796369]
---- EP [2/5] | BTCH [1009/3634] ||| train_loss = nan ----
LR: [0.009491182960170786]
---- EP [2/5] | BTCH [1010/3634] ||| train_loss = nan ----
LR: [0.00949242202649531]
---- EP [2/5] | BTCH [1011/3634] ||| train_loss = nan ----
LR: [0.009493659666525545]
---- EP [2/5] | BTCH [1012/3634] ||| train_loss = nan ----
LR: [0.009494895879850244]
---- EP [2/5] | BTCH [1013/3634] ||| train_loss = nan ----
LR: [0.009496130666058637]
---- EP [2/5] | BTCH [1014/3634] ||| train_loss = nan ----
LR: [0.009497364024740426]
---- EP [2/5] | BTCH [1015/3634] ||| train_loss = nan ----
LR: [0.009498595955485788]
---- EP [2/5] | BTCH [1016/3634] ||| train_loss = nan ----
LR: [0.009499826457885377]
---- EP [2/5] | BTCH [1017/3634] ||| train_loss = nan ----
LR: [0.009501055531530314]
---- EP [2/5] | BTCH [1018/3634] ||| train_loss = nan ----
LR: [0.009502283176012203]
---- EP [2/5] | BTCH [1019/3634] ||| train_loss = nan ----
LR: [0.009503509390923122]
---- EP [2/5] | BTCH [1020/3634] ||| train_loss = nan ----
LR: [0.009504734175855619]
---- EP [2/5] | BTCH [1021/3634] ||| train_loss = nan ----
LR: [0.009505957530402722]
---- EP [2/5] | BTCH [1022/3634] ||| train_loss = nan ----
LR: [0.009507179454157931]
---- EP [2/5] | BTCH [1023/3634] ||| train_loss = nan ----
LR: [0.009508399946715223]
---- EP [2/5] | BTCH [1024/3634] ||| train_loss = nan ----
LR: [0.009509619007669052]
---- EP [2/5] | BTCH [1025/3634] ||| train_loss = nan ----
LR: [0.009510836636614343]
---- EP [2/5] | BTCH [1026/3634] ||| train_loss = nan ----
LR: [0.009512052833146503]
---- EP [2/5] | BTCH [1027/3634] ||| train_loss = nan ----
LR: [0.00951326759686141]
---- EP [2/5] | BTCH [1028/3634] ||| train_loss = nan ----
LR: [0.00951448092735542]
---- EP [2/5] | BTCH [1029/3634] ||| train_loss = nan ----
LR: [0.009515692824225366]
---- EP [2/5] | BTCH [1030/3634] ||| train_loss = nan ----
LR: [0.009516903287068557]
---- EP [2/5] | BTCH [1031/3634] ||| train_loss = nan ----
LR: [0.009518112315482776]
---- EP [2/5] | BTCH [1032/3634] ||| train_loss = nan ----
LR: [0.009519319909066288]
---- EP [2/5] | BTCH [1033/3634] ||| train_loss = nan ----
LR: [0.009520526067417828]
---- EP [2/5] | BTCH [1034/3634] ||| train_loss = nan ----
LR: [0.009521730790136611]
---- EP [2/5] | BTCH [1035/3634] ||| train_loss = nan ----
LR: [0.009522934076822335]
---- EP [2/5] | BTCH [1036/3634] ||| train_loss = nan ----
LR: [0.009524135927075164]
---- EP [2/5] | BTCH [1037/3634] ||| train_loss = nan ----
LR: [0.009525336340495747]
---- EP [2/5] | BTCH [1038/3634] ||| train_loss = nan ----
LR: [0.009526535316685208]
---- EP [2/5] | BTCH [1039/3634] ||| train_loss = nan ----
LR: [0.009527732855245151]
---- EP [2/5] | BTCH [1040/3634] ||| train_loss = nan ----
LR: [0.00952892895577765]
---- EP [2/5] | BTCH [1041/3634] ||| train_loss = nan ----
LR: [0.009530123617885267]
---- EP [2/5] | BTCH [1042/3634] ||| train_loss = nan ----
LR: [0.009531316841171037]
---- EP [2/5] | BTCH [1043/3634] ||| train_loss = nan ----
LR: [0.009532508625238472]
---- EP [2/5] | BTCH [1044/3634] ||| train_loss = nan ----
LR: [0.009533698969691565]
---- EP [2/5] | BTCH [1045/3634] ||| train_loss = nan ----
LR: [0.009534887874134786]
---- EP [2/5] | BTCH [1046/3634] ||| train_loss = nan ----
LR: [0.009536075338173081]
---- EP [2/5] | BTCH [1047/3634] ||| train_loss = nan ----
LR: [0.009537261361411881]
---- EP [2/5] | BTCH [1048/3634] ||| train_loss = nan ----
LR: [0.00953844594345709]
---- EP [2/5] | BTCH [1049/3634] ||| train_loss = nan ----
LR: [0.009539629083915091]
---- EP [2/5] | BTCH [1050/3634] ||| train_loss = nan ----
LR: [0.00954081078239275]
---- EP [2/5] | BTCH [1051/3634] ||| train_loss = nan ----
LR: [0.00954199103849741]
---- EP [2/5] | BTCH [1052/3634] ||| train_loss = nan ----
LR: [0.009543169851836893]
---- EP [2/5] | BTCH [1053/3634] ||| train_loss = nan ----
LR: [0.009544347222019502]
---- EP [2/5] | BTCH [1054/3634] ||| train_loss = nan ----
LR: [0.009545523148654013]
---- EP [2/5] | BTCH [1055/3634] ||| train_loss = nan ----
LR: [0.009546697631349693]
---- EP [2/5] | BTCH [1056/3634] ||| train_loss = nan ----
LR: [0.00954787066971628]
---- EP [2/5] | BTCH [1057/3634] ||| train_loss = nan ----
LR: [0.009549042263363994]
---- EP [2/5] | BTCH [1058/3634] ||| train_loss = nan ----
LR: [0.009550212411903536]
---- EP [2/5] | BTCH [1059/3634] ||| train_loss = nan ----
LR: [0.009551381114946087]
---- EP [2/5] | BTCH [1060/3634] ||| train_loss = nan ----
LR: [0.009552548372103307]
---- EP [2/5] | BTCH [1061/3634] ||| train_loss = nan ----
LR: [0.00955371418298734]
---- EP [2/5] | BTCH [1062/3634] ||| train_loss = nan ----
LR: [0.009554878547210807]
---- EP [2/5] | BTCH [1063/3634] ||| train_loss = nan ----
LR: [0.009556041464386808]
---- EP [2/5] | BTCH [1064/3634] ||| train_loss = nan ----
LR: [0.009557202934128931]
---- EP [2/5] | BTCH [1065/3634] ||| train_loss = nan ----
LR: [0.009558362956051239]
---- EP [2/5] | BTCH [1066/3634] ||| train_loss = nan ----
LR: [0.009559521529768278]
---- EP [2/5] | BTCH [1067/3634] ||| train_loss = nan ----
LR: [0.009560678654895072]
---- EP [2/5] | BTCH [1068/3634] ||| train_loss = nan ----
LR: [0.009561834331047134]
---- EP [2/5] | BTCH [1069/3634] ||| train_loss = nan ----
LR: [0.009562988557840449]
---- EP [2/5] | BTCH [1070/3634] ||| train_loss = nan ----
LR: [0.00956414133489149]
---- EP [2/5] | BTCH [1071/3634] ||| train_loss = nan ----
LR: [0.009565292661817212]
---- EP [2/5] | BTCH [1072/3634] ||| train_loss = nan ----
LR: [0.009566442538235048]
---- EP [2/5] | BTCH [1073/3634] ||| train_loss = nan ----
LR: [0.009567590963762916]
---- EP [2/5] | BTCH [1074/3634] ||| train_loss = nan ----
LR: [0.009568737938019212]
---- EP [2/5] | BTCH [1075/3634] ||| train_loss = nan ----
LR: [0.00956988346062282]
---- EP [2/5] | BTCH [1076/3634] ||| train_loss = nan ----
LR: [0.009571027531193104]
---- EP [2/5] | BTCH [1077/3634] ||| train_loss = nan ----
LR: [0.009572170149349909]
---- EP [2/5] | BTCH [1078/3634] ||| train_loss = nan ----
LR: [0.009573311314713564]
---- EP [2/5] | BTCH [1079/3634] ||| train_loss = nan ----
LR: [0.009574451026904877]
---- EP [2/5] | BTCH [1080/3634] ||| train_loss = nan ----
LR: [0.009575589285545147]
---- EP [2/5] | BTCH [1081/3634] ||| train_loss = nan ----
LR: [0.009576726090256147]
---- EP [2/5] | BTCH [1082/3634] ||| train_loss = nan ----
LR: [0.009577861440660142]
---- EP [2/5] | BTCH [1083/3634] ||| train_loss = nan ----
LR: [0.009578995336379873]
---- EP [2/5] | BTCH [1084/3634] ||| train_loss = nan ----
LR: [0.009580127777038566]
---- EP [2/5] | BTCH [1085/3634] ||| train_loss = nan ----
LR: [0.009581258762259934]
---- EP [2/5] | BTCH [1086/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.00958238829166817]
---- EP [2/5] | BTCH [1087/3634] ||| train_loss = nan ----
LR: [0.00958351636488795]
---- EP [2/5] | BTCH [1088/3634] ||| train_loss = nan ----
LR: [0.009584642981544439]
---- EP [2/5] | BTCH [1089/3634] ||| train_loss = nan ----
LR: [0.009585768141263279]
---- EP [2/5] | BTCH [1090/3634] ||| train_loss = nan ----
LR: [0.0095868918436706]
---- EP [2/5] | BTCH [1091/3634] ||| train_loss = nan ----
LR: [0.009588014088393017]
---- EP [2/5] | BTCH [1092/3634] ||| train_loss = nan ----
LR: [0.009589134875057631]
---- EP [2/5] | BTCH [1093/3634] ||| train_loss = nan ----
LR: [0.009590254203292023]
---- EP [2/5] | BTCH [1094/3634] ||| train_loss = nan ----
LR: [0.00959137207272426]
---- EP [2/5] | BTCH [1095/3634] ||| train_loss = nan ----
LR: [0.009592488482982895]
---- EP [2/5] | BTCH [1096/3634] ||| train_loss = nan ----
LR: [0.009593603433696963]
---- EP [2/5] | BTCH [1097/3634] ||| train_loss = nan ----
LR: [0.009594716924495986]
---- EP [2/5] | BTCH [1098/3634] ||| train_loss = nan ----
LR: [0.009595828955009975]
---- EP [2/5] | BTCH [1099/3634] ||| train_loss = nan ----
LR: [0.009596939524869418]
---- EP [2/5] | BTCH [1100/3634] ||| train_loss = nan ----
LR: [0.009598048633705294]
---- EP [2/5] | BTCH [1101/3634] ||| train_loss = nan ----
LR: [0.009599156281149069]
---- EP [2/5] | BTCH [1102/3634] ||| train_loss = nan ----
LR: [0.009600262466832687]
---- EP [2/5] | BTCH [1103/3634] ||| train_loss = nan ----
LR: [0.009601367190388586]
---- EP [2/5] | BTCH [1104/3634] ||| train_loss = nan ----
LR: [0.009602470451449685]
---- EP [2/5] | BTCH [1105/3634] ||| train_loss = nan ----
LR: [0.009603572249649393]
---- EP [2/5] | BTCH [1106/3634] ||| train_loss = nan ----
LR: [0.009604672584621596]
---- EP [2/5] | BTCH [1107/3634] ||| train_loss = nan ----
LR: [0.009605771456000677]
---- EP [2/5] | BTCH [1108/3634] ||| train_loss = nan ----
LR: [0.009606868863421504]
---- EP [2/5] | BTCH [1109/3634] ||| train_loss = nan ----
LR: [0.00960796480651942]
---- EP [2/5] | BTCH [1110/3634] ||| train_loss = nan ----
LR: [0.00960905928493027]
---- EP [2/5] | BTCH [1111/3634] ||| train_loss = nan ----
LR: [0.009610152298290375]
---- EP [2/5] | BTCH [1112/3634] ||| train_loss = nan ----
LR: [0.009611243846236548]
---- EP [2/5] | BTCH [1113/3634] ||| train_loss = nan ----
LR: [0.009612333928406089]
---- EP [2/5] | BTCH [1114/3634] ||| train_loss = nan ----
LR: [0.009613422544436779]
---- EP [2/5] | BTCH [1115/3634] ||| train_loss = nan ----
LR: [0.009614509693966893]
---- EP [2/5] | BTCH [1116/3634] ||| train_loss = nan ----
LR: [0.009615595376635193]
---- EP [2/5] | BTCH [1117/3634] ||| train_loss = nan ----
LR: [0.00961667959208092]
---- EP [2/5] | BTCH [1118/3634] ||| train_loss = nan ----
LR: [0.009617762339943816]
---- EP [2/5] | BTCH [1119/3634] ||| train_loss = nan ----
LR: [0.0096188436198641]
---- EP [2/5] | BTCH [1120/3634] ||| train_loss = nan ----
LR: [0.00961992343148248]
---- EP [2/5] | BTCH [1121/3634] ||| train_loss = nan ----
LR: [0.009621001774440158]
---- EP [2/5] | BTCH [1122/3634] ||| train_loss = nan ----
LR: [0.00962207864837882]
---- EP [2/5] | BTCH [1123/3634] ||| train_loss = nan ----
LR: [0.009623154052940638]
---- EP [2/5] | BTCH [1124/3634] ||| train_loss = nan ----
LR: [0.009624227987768276]
---- EP [2/5] | BTCH [1125/3634] ||| train_loss = nan ----
LR: [0.009625300452504884]
---- EP [2/5] | BTCH [1126/3634] ||| train_loss = nan ----
LR: [0.0096263714467941]
---- EP [2/5] | BTCH [1127/3634] ||| train_loss = nan ----
LR: [0.009627440970280055]
---- EP [2/5] | BTCH [1128/3634] ||| train_loss = nan ----
LR: [0.009628509022607364]
---- EP [2/5] | BTCH [1129/3634] ||| train_loss = nan ----
LR: [0.009629575603421134]
---- EP [2/5] | BTCH [1130/3634] ||| train_loss = nan ----
LR: [0.009630640712366956]
---- EP [2/5] | BTCH [1131/3634] ||| train_loss = nan ----
LR: [0.009631704349090916]
---- EP [2/5] | BTCH [1132/3634] ||| train_loss = nan ----
LR: [0.009632766513239587]
---- EP [2/5] | BTCH [1133/3634] ||| train_loss = nan ----
LR: [0.009633827204460032]
---- EP [2/5] | BTCH [1134/3634] ||| train_loss = nan ----
LR: [0.009634886422399798]
---- EP [2/5] | BTCH [1135/3634] ||| train_loss = nan ----
LR: [0.009635944166706932]
---- EP [2/5] | BTCH [1136/3634] ||| train_loss = nan ----
LR: [0.00963700043702996]
---- EP [2/5] | BTCH [1137/3634] ||| train_loss = nan ----
LR: [0.009638055233017905]
---- EP [2/5] | BTCH [1138/3634] ||| train_loss = nan ----
LR: [0.009639108554320276]
---- EP [2/5] | BTCH [1139/3634] ||| train_loss = nan ----
LR: [0.009640160400587074]
---- EP [2/5] | BTCH [1140/3634] ||| train_loss = nan ----
LR: [0.009641210771468789]
---- EP [2/5] | BTCH [1141/3634] ||| train_loss = nan ----
LR: [0.009642259666616401]
---- EP [2/5] | BTCH [1142/3634] ||| train_loss = nan ----
LR: [0.009643307085681384]
---- EP [2/5] | BTCH [1143/3634] ||| train_loss = nan ----
LR: [0.009644353028315697]
---- EP [2/5] | BTCH [1144/3634] ||| train_loss = nan ----
LR: [0.009645397494171794]
---- EP [2/5] | BTCH [1145/3634] ||| train_loss = nan ----
LR: [0.009646440482902615]
---- EP [2/5] | BTCH [1146/3634] ||| train_loss = nan ----
LR: [0.009647481994161596]
---- EP [2/5] | BTCH [1147/3634] ||| train_loss = nan ----
LR: [0.009648522027602663]
---- EP [2/5] | BTCH [1148/3634] ||| train_loss = nan ----
LR: [0.009649560582880226]
---- EP [2/5] | BTCH [1149/3634] ||| train_loss = nan ----
LR: [0.009650597659649198]
---- EP [2/5] | BTCH [1150/3634] ||| train_loss = nan ----
LR: [0.009651633257564974]
---- EP [2/5] | BTCH [1151/3634] ||| train_loss = nan ----
LR: [0.009652667376283446]
---- EP [2/5] | BTCH [1152/3634] ||| train_loss = nan ----
LR: [0.009653700015460991]
---- EP [2/5] | BTCH [1153/3634] ||| train_loss = nan ----
LR: [0.009654731174754485]
---- EP [2/5] | BTCH [1154/3634] ||| train_loss = nan ----
LR: [0.00965576085382129]
---- EP [2/5] | BTCH [1155/3634] ||| train_loss = nan ----
LR: [0.009656789052319266]
---- EP [2/5] | BTCH [1156/3634] ||| train_loss = nan ----
LR: [0.009657815769906758]
---- EP [2/5] | BTCH [1157/3634] ||| train_loss = nan ----
LR: [0.009658841006242607]
---- EP [2/5] | BTCH [1158/3634] ||| train_loss = nan ----
LR: [0.009659864760986145]
---- EP [2/5] | BTCH [1159/3634] ||| train_loss = nan ----
LR: [0.009660887033797198]
---- EP [2/5] | BTCH [1160/3634] ||| train_loss = nan ----
LR: [0.009661907824336081]
---- EP [2/5] | BTCH [1161/3634] ||| train_loss = nan ----
LR: [0.009662927132263606]
---- EP [2/5] | BTCH [1162/3634] ||| train_loss = nan ----
LR: [0.009663944957241077]
---- EP [2/5] | BTCH [1163/3634] ||| train_loss = nan ----
LR: [0.009664961298930283]
---- EP [2/5] | BTCH [1164/3634] ||| train_loss = nan ----
LR: [0.009665976156993519]
---- EP [2/5] | BTCH [1165/3634] ||| train_loss = nan ----
LR: [0.009666989531093562]
---- EP [2/5] | BTCH [1166/3634] ||| train_loss = nan ----
LR: [0.009668001420893687]
---- EP [2/5] | BTCH [1167/3634] ||| train_loss = nan ----
LR: [0.009669011826057661]
---- EP [2/5] | BTCH [1168/3634] ||| train_loss = nan ----
LR: [0.009670020746249744]
---- EP [2/5] | BTCH [1169/3634] ||| train_loss = nan ----
LR: [0.009671028181134692]
---- EP [2/5] | BTCH [1170/3634] ||| train_loss = nan ----
LR: [0.009672034130377751]
---- EP [2/5] | BTCH [1171/3634] ||| train_loss = nan ----
LR: [0.009673038593644663]
---- EP [2/5] | BTCH [1172/3634] ||| train_loss = nan ----
LR: [0.009674041570601664]
---- EP [2/5] | BTCH [1173/3634] ||| train_loss = nan ----
LR: [0.009675043060915482]
---- EP [2/5] | BTCH [1174/3634] ||| train_loss = nan ----
LR: [0.009676043064253338]
---- EP [2/5] | BTCH [1175/3634] ||| train_loss = nan ----
LR: [0.009677041580282951]
---- EP [2/5] | BTCH [1176/3634] ||| train_loss = nan ----
LR: [0.00967803860867253]
---- EP [2/5] | BTCH [1177/3634] ||| train_loss = nan ----
LR: [0.009679034149090784]
---- EP [2/5] | BTCH [1178/3634] ||| train_loss = nan ----
LR: [0.00968002820120691]
---- EP [2/5] | BTCH [1179/3634] ||| train_loss = nan ----
LR: [0.009681020764690604]
---- EP [2/5] | BTCH [1180/3634] ||| train_loss = nan ----
LR: [0.009682011839212055]
---- EP [2/5] | BTCH [1181/3634] ||| train_loss = nan ----
LR: [0.009683001424441945]
---- EP [2/5] | BTCH [1182/3634] ||| train_loss = nan ----
LR: [0.009683989520051456]
---- EP [2/5] | BTCH [1183/3634] ||| train_loss = nan ----
LR: [0.009684976125712258]
---- EP [2/5] | BTCH [1184/3634] ||| train_loss = nan ----
LR: [0.009685961241096523]
---- EP [2/5] | BTCH [1185/3634] ||| train_loss = nan ----
LR: [0.009686944865876913]
---- EP [2/5] | BTCH [1186/3634] ||| train_loss = nan ----
LR: [0.009687926999726587]
---- EP [2/5] | BTCH [1187/3634] ||| train_loss = nan ----
LR: [0.009688907642319201]
---- EP [2/5] | BTCH [1188/3634] ||| train_loss = nan ----
LR: [0.009689886793328906]
---- EP [2/5] | BTCH [1189/3634] ||| train_loss = nan ----
LR: [0.009690864452430344]
---- EP [2/5] | BTCH [1190/3634] ||| train_loss = nan ----
LR: [0.009691840619298661]
---- EP [2/5] | BTCH [1191/3634] ||| train_loss = nan ----
LR: [0.00969281529360949]
---- EP [2/5] | BTCH [1192/3634] ||| train_loss = nan ----
LR: [0.009693788475038968]
---- EP [2/5] | BTCH [1193/3634] ||| train_loss = nan ----
LR: [0.009694760163263724]
---- EP [2/5] | BTCH [1194/3634] ||| train_loss = nan ----
LR: [0.009695730357960881]
---- EP [2/5] | BTCH [1195/3634] ||| train_loss = nan ----
LR: [0.009696699058808064]
---- EP [2/5] | BTCH [1196/3634] ||| train_loss = nan ----
LR: [0.00969766626548339]
---- EP [2/5] | BTCH [1197/3634] ||| train_loss = nan ----
LR: [0.009698631977665472]
---- EP [2/5] | BTCH [1198/3634] ||| train_loss = nan ----
LR: [0.009699596195033421]
---- EP [2/5] | BTCH [1199/3634] ||| train_loss = nan ----
LR: [0.009700558917266849]
---- EP [2/5] | BTCH [1200/3634] ||| train_loss = nan ----
LR: [0.009701520144045859]
---- EP [2/5] | BTCH [1201/3634] ||| train_loss = nan ----
LR: [0.00970247987505105]
---- EP [2/5] | BTCH [1202/3634] ||| train_loss = nan ----
LR: [0.009703438109963526]
---- EP [2/5] | BTCH [1203/3634] ||| train_loss = nan ----
LR: [0.009704394848464876]
---- EP [2/5] | BTCH [1204/3634] ||| train_loss = nan ----
LR: [0.0097053500902372]
---- EP [2/5] | BTCH [1205/3634] ||| train_loss = nan ----
LR: [0.009706303834963084]
---- EP [2/5] | BTCH [1206/3634] ||| train_loss = nan ----
LR: [0.009707256082325616]
---- EP [2/5] | BTCH [1207/3634] ||| train_loss = nan ----
LR: [0.009708206832008383]
---- EP [2/5] | BTCH [1208/3634] ||| train_loss = nan ----
LR: [0.009709156083695467]
---- EP [2/5] | BTCH [1209/3634] ||| train_loss = nan ----
LR: [0.009710103837071452]
---- EP [2/5] | BTCH [1210/3634] ||| train_loss = nan ----
LR: [0.009711050091821412]
---- EP [2/5] | BTCH [1211/3634] ||| train_loss = nan ----
LR: [0.009711994847630925]
---- EP [2/5] | BTCH [1212/3634] ||| train_loss = nan ----
LR: [0.009712938104186067]
---- EP [2/5] | BTCH [1213/3634] ||| train_loss = nan ----
LR: [0.009713879861173412]
---- EP [2/5] | BTCH [1214/3634] ||| train_loss = nan ----
LR: [0.009714820118280027]
---- EP [2/5] | BTCH [1215/3634] ||| train_loss = nan ----
LR: [0.009715758875193487]
---- EP [2/5] | BTCH [1216/3634] ||| train_loss = nan ----
LR: [0.009716696131601855]
---- EP [2/5] | BTCH [1217/3634] ||| train_loss = nan ----
LR: [0.009717631887193698]
---- EP [2/5] | BTCH [1218/3634] ||| train_loss = nan ----
LR: [0.009718566141658084]
---- EP [2/5] | BTCH [1219/3634] ||| train_loss = nan ----
LR: [0.009719498894684578]
---- EP [2/5] | BTCH [1220/3634] ||| train_loss = nan ----
LR: [0.00972043014596324]
---- EP [2/5] | BTCH [1221/3634] ||| train_loss = nan ----
LR: [0.009721359895184634]
---- EP [2/5] | BTCH [1222/3634] ||| train_loss = nan ----
LR: [0.009722288142039818]
---- EP [2/5] | BTCH [1223/3634] ||| train_loss = nan ----
LR: [0.009723214886220357]
---- EP [2/5] | BTCH [1224/3634] ||| train_loss = nan ----
LR: [0.009724140127418308]
---- EP [2/5] | BTCH [1225/3634] ||| train_loss = nan ----
LR: [0.009725063865326228]
---- EP [2/5] | BTCH [1226/3634] ||| train_loss = nan ----
LR: [0.00972598609963718]
---- EP [2/5] | BTCH [1227/3634] ||| train_loss = nan ----
LR: [0.009726906830044721]
---- EP [2/5] | BTCH [1228/3634] ||| train_loss = nan ----
LR: [0.009727826056242906]
---- EP [2/5] | BTCH [1229/3634] ||| train_loss = nan ----
LR: [0.009728743777926294]
---- EP [2/5] | BTCH [1230/3634] ||| train_loss = nan ----
LR: [0.009729659994789946]
---- EP [2/5] | BTCH [1231/3634] ||| train_loss = nan ----
LR: [0.009730574706529415]
---- EP [2/5] | BTCH [1232/3634] ||| train_loss = nan ----
LR: [0.009731487912840764]
---- EP [2/5] | BTCH [1233/3634] ||| train_loss = nan ----
LR: [0.009732399613420546]
---- EP [2/5] | BTCH [1234/3634] ||| train_loss = nan ----
LR: [0.00973330980796582]
---- EP [2/5] | BTCH [1235/3634] ||| train_loss = nan ----
LR: [0.009734218496174148]
---- EP [2/5] | BTCH [1236/3634] ||| train_loss = nan ----
LR: [0.009735125677743588]
---- EP [2/5] | BTCH [1237/3634] ||| train_loss = nan ----
LR: [0.009736031352372698]
---- EP [2/5] | BTCH [1238/3634] ||| train_loss = nan ----
LR: [0.00973693551976054]
---- EP [2/5] | BTCH [1239/3634] ||| train_loss = nan ----
LR: [0.009737838179606677]
---- EP [2/5] | BTCH [1240/3634] ||| train_loss = nan ----
LR: [0.009738739331611169]
---- EP [2/5] | BTCH [1241/3634] ||| train_loss = nan ----
LR: [0.009739638975474581]
---- EP [2/5] | BTCH [1242/3634] ||| train_loss = nan ----
LR: [0.009740537110897977]
---- EP [2/5] | BTCH [1243/3634] ||| train_loss = nan ----
LR: [0.009741433737582923]
---- EP [2/5] | BTCH [1244/3634] ||| train_loss = nan ----
LR: [0.009742328855231486]
---- EP [2/5] | BTCH [1245/3634] ||| train_loss = nan ----
LR: [0.009743222463546235]
---- EP [2/5] | BTCH [1246/3634] ||| train_loss = nan ----
LR: [0.00974411456223024]
---- EP [2/5] | BTCH [1247/3634] ||| train_loss = nan ----
LR: [0.009745005150987071]
---- EP [2/5] | BTCH [1248/3634] ||| train_loss = nan ----
LR: [0.009745894229520803]
---- EP [2/5] | BTCH [1249/3634] ||| train_loss = nan ----
LR: [0.009746781797536012]
---- EP [2/5] | BTCH [1250/3634] ||| train_loss = nan ----
LR: [0.009747667854737777]
---- EP [2/5] | BTCH [1251/3634] ||| train_loss = nan ----
LR: [0.00974855240083167]
---- EP [2/5] | BTCH [1252/3634] ||| train_loss = nan ----
LR: [0.009749435435523781]
---- EP [2/5] | BTCH [1253/3634] ||| train_loss = nan ----
LR: [0.009750316958520687]
---- EP [2/5] | BTCH [1254/3634] ||| train_loss = nan ----
LR: [0.009751196969529478]
---- EP [2/5] | BTCH [1255/3634] ||| train_loss = nan ----
LR: [0.009752075468257739]
---- EP [2/5] | BTCH [1256/3634] ||| train_loss = nan ----
LR: [0.009752952454413563]
---- EP [2/5] | BTCH [1257/3634] ||| train_loss = nan ----
LR: [0.009753827927705542]
---- EP [2/5] | BTCH [1258/3634] ||| train_loss = nan ----
LR: [0.009754701887842773]
---- EP [2/5] | BTCH [1259/3634] ||| train_loss = nan ----
LR: [0.009755574334534854]
---- EP [2/5] | BTCH [1260/3634] ||| train_loss = nan ----
LR: [0.009756445267491889]
---- EP [2/5] | BTCH [1261/3634] ||| train_loss = nan ----
LR: [0.00975731468642448]
---- EP [2/5] | BTCH [1262/3634] ||| train_loss = nan ----
LR: [0.009758182591043734]
---- EP [2/5] | BTCH [1263/3634] ||| train_loss = nan ----
LR: [0.009759048981061266]
---- EP [2/5] | BTCH [1264/3634] ||| train_loss = nan ----
LR: [0.009759913856189188]
---- EP [2/5] | BTCH [1265/3634] ||| train_loss = nan ----
LR: [0.009760777216140116]
---- EP [2/5] | BTCH [1266/3634] ||| train_loss = nan ----
LR: [0.009761639060627172]
---- EP [2/5] | BTCH [1267/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.009762499389363983]
---- EP [2/5] | BTCH [1268/3634] ||| train_loss = nan ----
LR: [0.009763358202064676]
---- EP [2/5] | BTCH [1269/3634] ||| train_loss = nan ----
LR: [0.009764215498443881]
---- EP [2/5] | BTCH [1270/3634] ||| train_loss = nan ----
LR: [0.009765071278216738]
---- EP [2/5] | BTCH [1271/3634] ||| train_loss = nan ----
LR: [0.009765925541098883]
---- EP [2/5] | BTCH [1272/3634] ||| train_loss = nan ----
LR: [0.00976677828680646]
---- EP [2/5] | BTCH [1273/3634] ||| train_loss = nan ----
LR: [0.00976762951505612]
---- EP [2/5] | BTCH [1274/3634] ||| train_loss = nan ----
LR: [0.009768479225565013]
---- EP [2/5] | BTCH [1275/3634] ||| train_loss = nan ----
LR: [0.009769327418050797]
---- EP [2/5] | BTCH [1276/3634] ||| train_loss = nan ----
LR: [0.00977017409223163]
---- EP [2/5] | BTCH [1277/3634] ||| train_loss = nan ----
LR: [0.00977101924782618]
---- EP [2/5] | BTCH [1278/3634] ||| train_loss = nan ----
LR: [0.009771862884553617]
---- EP [2/5] | BTCH [1279/3634] ||| train_loss = nan ----
LR: [0.009772705002133618]
---- EP [2/5] | BTCH [1280/3634] ||| train_loss = nan ----
LR: [0.009773545600286355]
---- EP [2/5] | BTCH [1281/3634] ||| train_loss = nan ----
LR: [0.00977438467873252]
---- EP [2/5] | BTCH [1282/3634] ||| train_loss = nan ----
LR: [0.0097752222371933]
---- EP [2/5] | BTCH [1283/3634] ||| train_loss = nan ----
LR: [0.009776058275390388]
---- EP [2/5] | BTCH [1284/3634] ||| train_loss = nan ----
LR: [0.009776892793045987]
---- EP [2/5] | BTCH [1285/3634] ||| train_loss = nan ----
LR: [0.009777725789882797]
---- EP [2/5] | BTCH [1286/3634] ||| train_loss = nan ----
LR: [0.009778557265624032]
---- EP [2/5] | BTCH [1287/3634] ||| train_loss = nan ----
LR: [0.009779387219993406]
---- EP [2/5] | BTCH [1288/3634] ||| train_loss = nan ----
LR: [0.00978021565271514]
---- EP [2/5] | BTCH [1289/3634] ||| train_loss = nan ----
LR: [0.009781042563513963]
---- EP [2/5] | BTCH [1290/3634] ||| train_loss = nan ----
LR: [0.009781867952115105]
---- EP [2/5] | BTCH [1291/3634] ||| train_loss = nan ----
LR: [0.009782691818244305]
---- EP [2/5] | BTCH [1292/3634] ||| train_loss = nan ----
LR: [0.009783514161627807]
---- EP [2/5] | BTCH [1293/3634] ||| train_loss = nan ----
LR: [0.009784334981992363]
---- EP [2/5] | BTCH [1294/3634] ||| train_loss = nan ----
LR: [0.009785154279065227]
---- EP [2/5] | BTCH [1295/3634] ||| train_loss = nan ----
LR: [0.00978597205257416]
---- EP [2/5] | BTCH [1296/3634] ||| train_loss = nan ----
LR: [0.009786788302247437]
---- EP [2/5] | BTCH [1297/3634] ||| train_loss = nan ----
LR: [0.009787603027813825]
---- EP [2/5] | BTCH [1298/3634] ||| train_loss = nan ----
LR: [0.00978841622900261]
---- EP [2/5] | BTCH [1299/3634] ||| train_loss = nan ----
LR: [0.009789227905543579]
---- EP [2/5] | BTCH [1300/3634] ||| train_loss = nan ----
LR: [0.009790038057167025]
---- EP [2/5] | BTCH [1301/3634] ||| train_loss = nan ----
LR: [0.009790846683603754]
---- EP [2/5] | BTCH [1302/3634] ||| train_loss = nan ----
LR: [0.00979165378458507]
---- EP [2/5] | BTCH [1303/3634] ||| train_loss = nan ----
LR: [0.009792459359842787]
---- EP [2/5] | BTCH [1304/3634] ||| train_loss = nan ----
LR: [0.00979326340910923]
---- EP [2/5] | BTCH [1305/3634] ||| train_loss = nan ----
LR: [0.009794065932117228]
---- EP [2/5] | BTCH [1306/3634] ||| train_loss = nan ----
LR: [0.009794866928600113]
---- EP [2/5] | BTCH [1307/3634] ||| train_loss = nan ----
LR: [0.009795666398291733]
---- EP [2/5] | BTCH [1308/3634] ||| train_loss = nan ----
LR: [0.009796464340926436]
---- EP [2/5] | BTCH [1309/3634] ||| train_loss = nan ----
LR: [0.00979726075623908]
---- EP [2/5] | BTCH [1310/3634] ||| train_loss = nan ----
LR: [0.009798055643965034]
---- EP [2/5] | BTCH [1311/3634] ||| train_loss = nan ----
LR: [0.009798849003840166]
---- EP [2/5] | BTCH [1312/3634] ||| train_loss = nan ----
LR: [0.009799640835600861]
---- EP [2/5] | BTCH [1313/3634] ||| train_loss = nan ----
LR: [0.009800431138984007]
---- EP [2/5] | BTCH [1314/3634] ||| train_loss = nan ----
LR: [0.009801219913726997]
---- EP [2/5] | BTCH [1315/3634] ||| train_loss = nan ----
LR: [0.009802007159567739]
---- EP [2/5] | BTCH [1316/3634] ||| train_loss = nan ----
LR: [0.009802792876244644]
---- EP [2/5] | BTCH [1317/3634] ||| train_loss = nan ----
LR: [0.009803577063496634]
---- EP [2/5] | BTCH [1318/3634] ||| train_loss = nan ----
LR: [0.009804359721063135]
---- EP [2/5] | BTCH [1319/3634] ||| train_loss = nan ----
LR: [0.009805140848684087]
---- EP [2/5] | BTCH [1320/3634] ||| train_loss = nan ----
LR: [0.009805920446099934]
---- EP [2/5] | BTCH [1321/3634] ||| train_loss = nan ----
LR: [0.009806698513051628]
---- EP [2/5] | BTCH [1322/3634] ||| train_loss = nan ----
LR: [0.009807475049280636]
---- EP [2/5] | BTCH [1323/3634] ||| train_loss = nan ----
LR: [0.009808250054528924]
---- EP [2/5] | BTCH [1324/3634] ||| train_loss = nan ----
LR: [0.009809023528538977]
---- EP [2/5] | BTCH [1325/3634] ||| train_loss = nan ----
LR: [0.009809795471053779]
---- EP [2/5] | BTCH [1326/3634] ||| train_loss = nan ----
LR: [0.009810565881816828]
---- EP [2/5] | BTCH [1327/3634] ||| train_loss = nan ----
LR: [0.009811334760572133]
---- EP [2/5] | BTCH [1328/3634] ||| train_loss = nan ----
LR: [0.009812102107064208]
---- EP [2/5] | BTCH [1329/3634] ||| train_loss = nan ----
LR: [0.009812867921038077]
---- EP [2/5] | BTCH [1330/3634] ||| train_loss = nan ----
LR: [0.009813632202239275]
---- EP [2/5] | BTCH [1331/3634] ||| train_loss = nan ----
LR: [0.009814394950413845]
---- EP [2/5] | BTCH [1332/3634] ||| train_loss = nan ----
LR: [0.009815156165308338]
---- EP [2/5] | BTCH [1333/3634] ||| train_loss = nan ----
LR: [0.00981591584666982]
---- EP [2/5] | BTCH [1334/3634] ||| train_loss = nan ----
LR: [0.009816673994245857]
---- EP [2/5] | BTCH [1335/3634] ||| train_loss = nan ----
LR: [0.009817430607784535]
---- EP [2/5] | BTCH [1336/3634] ||| train_loss = nan ----
LR: [0.009818185687034442]
---- EP [2/5] | BTCH [1337/3634] ||| train_loss = nan ----
LR: [0.009818939231744681]
---- EP [2/5] | BTCH [1338/3634] ||| train_loss = nan ----
LR: [0.009819691241664862]
---- EP [2/5] | BTCH [1339/3634] ||| train_loss = nan ----
LR: [0.009820441716545104]
---- EP [2/5] | BTCH [1340/3634] ||| train_loss = nan ----
LR: [0.009821190656136038]
---- EP [2/5] | BTCH [1341/3634] ||| train_loss = nan ----
LR: [0.00982193806018881]
---- EP [2/5] | BTCH [1342/3634] ||| train_loss = nan ----
LR: [0.009822683928455063]
---- EP [2/5] | BTCH [1343/3634] ||| train_loss = nan ----
LR: [0.009823428260686965]
---- EP [2/5] | BTCH [1344/3634] ||| train_loss = nan ----
LR: [0.009824171056637184]
---- EP [2/5] | BTCH [1345/3634] ||| train_loss = nan ----
LR: [0.009824912316058906]
---- EP [2/5] | BTCH [1346/3634] ||| train_loss = nan ----
LR: [0.00982565203870582]
---- EP [2/5] | BTCH [1347/3634] ||| train_loss = nan ----
LR: [0.00982639022433213]
---- EP [2/5] | BTCH [1348/3634] ||| train_loss = nan ----
LR: [0.009827126872692554]
---- EP [2/5] | BTCH [1349/3634] ||| train_loss = nan ----
LR: [0.009827861983542312]
---- EP [2/5] | BTCH [1350/3634] ||| train_loss = nan ----
LR: [0.009828595556637145]
---- EP [2/5] | BTCH [1351/3634] ||| train_loss = nan ----
LR: [0.009829327591733297]
---- EP [2/5] | BTCH [1352/3634] ||| train_loss = nan ----
LR: [0.009830058088587525]
---- EP [2/5] | BTCH [1353/3634] ||| train_loss = nan ----
LR: [0.0098307870469571]
---- EP [2/5] | BTCH [1354/3634] ||| train_loss = nan ----
LR: [0.009831514466599802]
---- EP [2/5] | BTCH [1355/3634] ||| train_loss = nan ----
LR: [0.009832240347273922]
---- EP [2/5] | BTCH [1356/3634] ||| train_loss = nan ----
LR: [0.009832964688738262]
---- EP [2/5] | BTCH [1357/3634] ||| train_loss = nan ----
LR: [0.00983368749075214]
---- EP [2/5] | BTCH [1358/3634] ||| train_loss = nan ----
LR: [0.009834408753075377]
---- EP [2/5] | BTCH [1359/3634] ||| train_loss = nan ----
LR: [0.009835128475468316]
---- EP [2/5] | BTCH [1360/3634] ||| train_loss = nan ----
LR: [0.009835846657691803]
---- EP [2/5] | BTCH [1361/3634] ||| train_loss = nan ----
LR: [0.009836563299507198]
---- EP [2/5] | BTCH [1362/3634] ||| train_loss = nan ----
LR: [0.009837278400676375]
---- EP [2/5] | BTCH [1363/3634] ||| train_loss = nan ----
LR: [0.00983799196096172]
---- EP [2/5] | BTCH [1364/3634] ||| train_loss = nan ----
LR: [0.00983870398012613]
---- EP [2/5] | BTCH [1365/3634] ||| train_loss = nan ----
LR: [0.009839414457933012]
---- EP [2/5] | BTCH [1366/3634] ||| train_loss = nan ----
LR: [0.009840123394146288]
---- EP [2/5] | BTCH [1367/3634] ||| train_loss = nan ----
LR: [0.009840830788530392]
---- EP [2/5] | BTCH [1368/3634] ||| train_loss = nan ----
LR: [0.009841536640850267]
---- EP [2/5] | BTCH [1369/3634] ||| train_loss = nan ----
LR: [0.009842240950871373]
---- EP [2/5] | BTCH [1370/3634] ||| train_loss = nan ----
LR: [0.009842943718359682]
---- EP [2/5] | BTCH [1371/3634] ||| train_loss = nan ----
LR: [0.009843644943081676]
---- EP [2/5] | BTCH [1372/3634] ||| train_loss = nan ----
LR: [0.009844344624804349]
---- EP [2/5] | BTCH [1373/3634] ||| train_loss = nan ----
LR: [0.00984504276329521]
---- EP [2/5] | BTCH [1374/3634] ||| train_loss = nan ----
LR: [0.00984573935832228]
---- EP [2/5] | BTCH [1375/3634] ||| train_loss = nan ----
LR: [0.009846434409654096]
---- EP [2/5] | BTCH [1376/3634] ||| train_loss = nan ----
LR: [0.009847127917059701]
---- EP [2/5] | BTCH [1377/3634] ||| train_loss = nan ----
LR: [0.009847819880308658]
---- EP [2/5] | BTCH [1378/3634] ||| train_loss = nan ----
LR: [0.009848510299171038]
---- EP [2/5] | BTCH [1379/3634] ||| train_loss = nan ----
LR: [0.00984919917341743]
---- EP [2/5] | BTCH [1380/3634] ||| train_loss = nan ----
LR: [0.00984988650281893]
---- EP [2/5] | BTCH [1381/3634] ||| train_loss = nan ----
LR: [0.009850572287147153]
---- EP [2/5] | BTCH [1382/3634] ||| train_loss = nan ----
LR: [0.009851256526174225]
---- EP [2/5] | BTCH [1383/3634] ||| train_loss = nan ----
LR: [0.009851939219672786]
---- EP [2/5] | BTCH [1384/3634] ||| train_loss = nan ----
LR: [0.009852620367415988]
---- EP [2/5] | BTCH [1385/3634] ||| train_loss = nan ----
LR: [0.009853299969177498]
---- EP [2/5] | BTCH [1386/3634] ||| train_loss = nan ----
LR: [0.0098539780247315]
---- EP [2/5] | BTCH [1387/3634] ||| train_loss = nan ----
LR: [0.009854654533852683]
---- EP [2/5] | BTCH [1388/3634] ||| train_loss = nan ----
LR: [0.00985532949631626]
---- EP [2/5] | BTCH [1389/3634] ||| train_loss = nan ----
LR: [0.00985600291189795]
---- EP [2/5] | BTCH [1390/3634] ||| train_loss = nan ----
LR: [0.009856674780373992]
---- EP [2/5] | BTCH [1391/3634] ||| train_loss = nan ----
LR: [0.009857345101521134]
---- EP [2/5] | BTCH [1392/3634] ||| train_loss = nan ----
LR: [0.00985801387511664]
---- EP [2/5] | BTCH [1393/3634] ||| train_loss = nan ----
LR: [0.00985868110093829]
---- EP [2/5] | BTCH [1394/3634] ||| train_loss = nan ----
LR: [0.009859346778764376]
---- EP [2/5] | BTCH [1395/3634] ||| train_loss = nan ----
LR: [0.009860010908373707]
---- EP [2/5] | BTCH [1396/3634] ||| train_loss = nan ----
LR: [0.009860673489545602]
---- EP [2/5] | BTCH [1397/3634] ||| train_loss = nan ----
LR: [0.0098613345220599]
---- EP [2/5] | BTCH [1398/3634] ||| train_loss = nan ----
LR: [0.00986199400569695]
---- EP [2/5] | BTCH [1399/3634] ||| train_loss = nan ----
LR: [0.009862651940237619]
---- EP [2/5] | BTCH [1400/3634] ||| train_loss = nan ----
LR: [0.009863308325463286]
---- EP [2/5] | BTCH [1401/3634] ||| train_loss = nan ----
LR: [0.009863963161155847]
---- EP [2/5] | BTCH [1402/3634] ||| train_loss = nan ----
LR: [0.009864616447097711]
---- EP [2/5] | BTCH [1403/3634] ||| train_loss = nan ----
LR: [0.009865268183071802]
---- EP [2/5] | BTCH [1404/3634] ||| train_loss = nan ----
LR: [0.009865918368861562]
---- EP [2/5] | BTCH [1405/3634] ||| train_loss = nan ----
LR: [0.009866567004250945]
---- EP [2/5] | BTCH [1406/3634] ||| train_loss = nan ----
LR: [0.009867214089024422]
---- EP [2/5] | BTCH [1407/3634] ||| train_loss = nan ----
LR: [0.009867859622966978]
---- EP [2/5] | BTCH [1408/3634] ||| train_loss = nan ----
LR: [0.009868503605864113]
---- EP [2/5] | BTCH [1409/3634] ||| train_loss = nan ----
LR: [0.009869146037501842]
---- EP [2/5] | BTCH [1410/3634] ||| train_loss = nan ----
LR: [0.0098697869176667]
---- EP [2/5] | BTCH [1411/3634] ||| train_loss = nan ----
LR: [0.009870426246145732]
---- EP [2/5] | BTCH [1412/3634] ||| train_loss = nan ----
LR: [0.009871064022726502]
---- EP [2/5] | BTCH [1413/3634] ||| train_loss = nan ----
LR: [0.009871700247197086]
---- EP [2/5] | BTCH [1414/3634] ||| train_loss = nan ----
LR: [0.009872334919346078]
---- EP [2/5] | BTCH [1415/3634] ||| train_loss = nan ----
LR: [0.009872968038962593]
---- EP [2/5] | BTCH [1416/3634] ||| train_loss = nan ----
LR: [0.00987359960583625]
---- EP [2/5] | BTCH [1417/3634] ||| train_loss = nan ----
LR: [0.009874229619757195]
---- EP [2/5] | BTCH [1418/3634] ||| train_loss = nan ----
LR: [0.009874858080516085]
---- EP [2/5] | BTCH [1419/3634] ||| train_loss = nan ----
LR: [0.009875484987904094]
---- EP [2/5] | BTCH [1420/3634] ||| train_loss = nan ----
LR: [0.00987611034171291]
---- EP [2/5] | BTCH [1421/3634] ||| train_loss = nan ----
LR: [0.009876734141734742]
---- EP [2/5] | BTCH [1422/3634] ||| train_loss = nan ----
LR: [0.009877356387762309]
---- EP [2/5] | BTCH [1423/3634] ||| train_loss = nan ----
LR: [0.009877977079588854]
---- EP [2/5] | BTCH [1424/3634] ||| train_loss = nan ----
LR: [0.00987859621700813]
---- EP [2/5] | BTCH [1425/3634] ||| train_loss = nan ----
LR: [0.00987921379981441]
---- EP [2/5] | BTCH [1426/3634] ||| train_loss = nan ----
LR: [0.00987982982780248]
---- EP [2/5] | BTCH [1427/3634] ||| train_loss = nan ----
LR: [0.009880444300767649]
---- EP [2/5] | BTCH [1428/3634] ||| train_loss = nan ----
LR: [0.009881057218505735]
---- EP [2/5] | BTCH [1429/3634] ||| train_loss = nan ----
LR: [0.009881668580813078]
---- EP [2/5] | BTCH [1430/3634] ||| train_loss = nan ----
LR: [0.009882278387486532]
---- EP [2/5] | BTCH [1431/3634] ||| train_loss = nan ----
LR: [0.009882886638323473]
---- EP [2/5] | BTCH [1432/3634] ||| train_loss = nan ----
LR: [0.009883493333121786]
---- EP [2/5] | BTCH [1433/3634] ||| train_loss = nan ----
LR: [0.00988409847167988]
---- EP [2/5] | BTCH [1434/3634] ||| train_loss = nan ----
LR: [0.009884702053796678]
---- EP [2/5] | BTCH [1435/3634] ||| train_loss = nan ----
LR: [0.009885304079271618]
---- EP [2/5] | BTCH [1436/3634] ||| train_loss = nan ----
LR: [0.009885904547904662]
---- EP [2/5] | BTCH [1437/3634] ||| train_loss = nan ----
LR: [0.009886503459496281]
---- EP [2/5] | BTCH [1438/3634] ||| train_loss = nan ----
LR: [0.00988710081384747]
---- EP [2/5] | BTCH [1439/3634] ||| train_loss = nan ----
LR: [0.00988769661075974]
---- EP [2/5] | BTCH [1440/3634] ||| train_loss = nan ----
LR: [0.009888290850035114]
---- EP [2/5] | BTCH [1441/3634] ||| train_loss = nan ----
LR: [0.009888883531476142]
---- EP [2/5] | BTCH [1442/3634] ||| train_loss = nan ----
LR: [0.009889474654885884]
---- EP [2/5] | BTCH [1443/3634] ||| train_loss = nan ----
LR: [0.009890064220067921]
---- EP [2/5] | BTCH [1444/3634] ||| train_loss = nan ----
LR: [0.009890652226826351]
---- EP [2/5] | BTCH [1445/3634] ||| train_loss = nan ----
LR: [0.009891238674965788]
---- EP [2/5] | BTCH [1446/3634] ||| train_loss = nan ----
LR: [0.00989182356429137]
---- EP [2/5] | BTCH [1447/3634] ||| train_loss = nan ----
LR: [0.009892406894608748]
---- EP [2/5] | BTCH [1448/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.009892988665724089]
---- EP [2/5] | BTCH [1449/3634] ||| train_loss = nan ----
LR: [0.009893568877444081]
---- EP [2/5] | BTCH [1450/3634] ||| train_loss = nan ----
LR: [0.009894147529575934]
---- EP [2/5] | BTCH [1451/3634] ||| train_loss = nan ----
LR: [0.00989472462192737]
---- EP [2/5] | BTCH [1452/3634] ||| train_loss = nan ----
LR: [0.009895300154306631]
---- EP [2/5] | BTCH [1453/3634] ||| train_loss = nan ----
LR: [0.009895874126522479]
---- EP [2/5] | BTCH [1454/3634] ||| train_loss = nan ----
LR: [0.009896446538384193]
---- EP [2/5] | BTCH [1455/3634] ||| train_loss = nan ----
LR: [0.009897017389701569]
---- EP [2/5] | BTCH [1456/3634] ||| train_loss = nan ----
LR: [0.009897586680284927]
---- EP [2/5] | BTCH [1457/3634] ||| train_loss = nan ----
LR: [0.009898154409945101]
---- EP [2/5] | BTCH [1458/3634] ||| train_loss = nan ----
LR: [0.009898720578493444]
---- EP [2/5] | BTCH [1459/3634] ||| train_loss = nan ----
LR: [0.009899285185741829]
---- EP [2/5] | BTCH [1460/3634] ||| train_loss = nan ----
LR: [0.009899848231502644]
---- EP [2/5] | BTCH [1461/3634] ||| train_loss = nan ----
LR: [0.009900409715588804]
---- EP [2/5] | BTCH [1462/3634] ||| train_loss = nan ----
LR: [0.009900969637813737]
---- EP [2/5] | BTCH [1463/3634] ||| train_loss = nan ----
LR: [0.009901527997991388]
---- EP [2/5] | BTCH [1464/3634] ||| train_loss = nan ----
LR: [0.009902084795936225]
---- EP [2/5] | BTCH [1465/3634] ||| train_loss = nan ----
LR: [0.009902640031463236]
---- EP [2/5] | BTCH [1466/3634] ||| train_loss = nan ----
LR: [0.009903193704387924]
---- EP [2/5] | BTCH [1467/3634] ||| train_loss = nan ----
LR: [0.009903745814526316]
---- EP [2/5] | BTCH [1468/3634] ||| train_loss = nan ----
LR: [0.009904296361694953]
---- EP [2/5] | BTCH [1469/3634] ||| train_loss = nan ----
LR: [0.009904845345710902]
---- EP [2/5] | BTCH [1470/3634] ||| train_loss = nan ----
LR: [0.00990539276639174]
---- EP [2/5] | BTCH [1471/3634] ||| train_loss = nan ----
LR: [0.009905938623555575]
---- EP [2/5] | BTCH [1472/3634] ||| train_loss = nan ----
LR: [0.009906482917021023]
---- EP [2/5] | BTCH [1473/3634] ||| train_loss = nan ----
LR: [0.00990702564660723]
---- EP [2/5] | BTCH [1474/3634] ||| train_loss = nan ----
LR: [0.009907566812133851]
---- EP [2/5] | BTCH [1475/3634] ||| train_loss = nan ----
LR: [0.009908106413421072]
---- EP [2/5] | BTCH [1476/3634] ||| train_loss = nan ----
LR: [0.009908644450289592]
---- EP [2/5] | BTCH [1477/3634] ||| train_loss = nan ----
LR: [0.009909180922560629]
---- EP [2/5] | BTCH [1478/3634] ||| train_loss = nan ----
LR: [0.009909715830055925]
---- EP [2/5] | BTCH [1479/3634] ||| train_loss = nan ----
LR: [0.009910249172597738]
---- EP [2/5] | BTCH [1480/3634] ||| train_loss = nan ----
LR: [0.00991078095000885]
---- EP [2/5] | BTCH [1481/3634] ||| train_loss = nan ----
LR: [0.009911311162112559]
---- EP [2/5] | BTCH [1482/3634] ||| train_loss = nan ----
LR: [0.009911839808732687]
---- EP [2/5] | BTCH [1483/3634] ||| train_loss = nan ----
LR: [0.009912366889693571]
---- EP [2/5] | BTCH [1484/3634] ||| train_loss = nan ----
LR: [0.009912892404820076]
---- EP [2/5] | BTCH [1485/3634] ||| train_loss = nan ----
LR: [0.009913416353937582]
---- EP [2/5] | BTCH [1486/3634] ||| train_loss = nan ----
LR: [0.009913938736871986]
---- EP [2/5] | BTCH [1487/3634] ||| train_loss = nan ----
LR: [0.009914459553449714]
---- EP [2/5] | BTCH [1488/3634] ||| train_loss = nan ----
LR: [0.009914978803497706]
---- EP [2/5] | BTCH [1489/3634] ||| train_loss = nan ----
LR: [0.009915496486843424]
---- EP [2/5] | BTCH [1490/3634] ||| train_loss = nan ----
LR: [0.009916012603314855]
---- EP [2/5] | BTCH [1491/3634] ||| train_loss = nan ----
LR: [0.009916527152740497]
---- EP [2/5] | BTCH [1492/3634] ||| train_loss = nan ----
LR: [0.00991704013494938]
---- EP [2/5] | BTCH [1493/3634] ||| train_loss = nan ----
LR: [0.009917551549771047]
---- EP [2/5] | BTCH [1494/3634] ||| train_loss = nan ----
LR: [0.009918061397035561]
---- EP [2/5] | BTCH [1495/3634] ||| train_loss = nan ----
LR: [0.009918569676573515]
---- EP [2/5] | BTCH [1496/3634] ||| train_loss = nan ----
LR: [0.009919076388216012]
---- EP [2/5] | BTCH [1497/3634] ||| train_loss = nan ----
LR: [0.009919581531794683]
---- EP [2/5] | BTCH [1498/3634] ||| train_loss = nan ----
LR: [0.009920085107141678]
---- EP [2/5] | BTCH [1499/3634] ||| train_loss = nan ----
LR: [0.009920587114089668]
---- EP [2/5] | BTCH [1500/3634] ||| train_loss = nan ----
LR: [0.009921087552471845]
---- EP [2/5] | BTCH [1501/3634] ||| train_loss = nan ----
LR: [0.009921586422121922]
---- EP [2/5] | BTCH [1502/3634] ||| train_loss = nan ----
LR: [0.009922083722874134]
---- EP [2/5] | BTCH [1503/3634] ||| train_loss = nan ----
LR: [0.009922579454563235]
---- EP [2/5] | BTCH [1504/3634] ||| train_loss = nan ----
LR: [0.009923073617024504]
---- EP [2/5] | BTCH [1505/3634] ||| train_loss = nan ----
LR: [0.009923566210093743]
---- EP [2/5] | BTCH [1506/3634] ||| train_loss = nan ----
LR: [0.009924057233607265]
---- EP [2/5] | BTCH [1507/3634] ||| train_loss = nan ----
LR: [0.009924546687401918]
---- EP [2/5] | BTCH [1508/3634] ||| train_loss = nan ----
LR: [0.009925034571315064]
---- EP [2/5] | BTCH [1509/3634] ||| train_loss = nan ----
LR: [0.009925520885184586]
---- EP [2/5] | BTCH [1510/3634] ||| train_loss = nan ----
LR: [0.009926005628848891]
---- EP [2/5] | BTCH [1511/3634] ||| train_loss = nan ----
LR: [0.009926488802146909]
---- EP [2/5] | BTCH [1512/3634] ||| train_loss = nan ----
LR: [0.009926970404918089]
---- EP [2/5] | BTCH [1513/3634] ||| train_loss = nan ----
LR: [0.009927450437002404]
---- EP [2/5] | BTCH [1514/3634] ||| train_loss = nan ----
LR: [0.009927928898240347]
---- EP [2/5] | BTCH [1515/3634] ||| train_loss = nan ----
LR: [0.009928405788472936]
---- EP [2/5] | BTCH [1516/3634] ||| train_loss = nan ----
LR: [0.009928881107541707]
---- EP [2/5] | BTCH [1517/3634] ||| train_loss = nan ----
LR: [0.00992935485528872]
---- EP [2/5] | BTCH [1518/3634] ||| train_loss = nan ----
LR: [0.009929827031556558]
---- EP [2/5] | BTCH [1519/3634] ||| train_loss = nan ----
LR: [0.009930297636188325]
---- EP [2/5] | BTCH [1520/3634] ||| train_loss = nan ----
LR: [0.009930766669027648]
---- EP [2/5] | BTCH [1521/3634] ||| train_loss = nan ----
LR: [0.009931234129918675]
---- EP [2/5] | BTCH [1522/3634] ||| train_loss = nan ----
LR: [0.00993170001870608]
---- EP [2/5] | BTCH [1523/3634] ||| train_loss = nan ----
LR: [0.009932164335235052]
---- EP [2/5] | BTCH [1524/3634] ||| train_loss = nan ----
LR: [0.00993262707935131]
---- EP [2/5] | BTCH [1525/3634] ||| train_loss = nan ----
LR: [0.009933088250901091]
---- EP [2/5] | BTCH [1526/3634] ||| train_loss = nan ----
LR: [0.009933547849731158]
---- EP [2/5] | BTCH [1527/3634] ||| train_loss = nan ----
LR: [0.009934005875688795]
---- EP [2/5] | BTCH [1528/3634] ||| train_loss = nan ----
LR: [0.009934462328621803]
---- EP [2/5] | BTCH [1529/3634] ||| train_loss = nan ----
LR: [0.009934917208378517]
---- EP [2/5] | BTCH [1530/3634] ||| train_loss = nan ----
LR: [0.009935370514807787]
---- EP [2/5] | BTCH [1531/3634] ||| train_loss = nan ----
LR: [0.009935822247758986]
---- EP [2/5] | BTCH [1532/3634] ||| train_loss = nan ----
LR: [0.009936272407082012]
---- EP [2/5] | BTCH [1533/3634] ||| train_loss = nan ----
LR: [0.009936720992627286]
---- EP [2/5] | BTCH [1534/3634] ||| train_loss = nan ----
LR: [0.00993716800424575]
---- EP [2/5] | BTCH [1535/3634] ||| train_loss = nan ----
LR: [0.009937613441788869]
---- EP [2/5] | BTCH [1536/3634] ||| train_loss = nan ----
LR: [0.009938057305108635]
---- EP [2/5] | BTCH [1537/3634] ||| train_loss = nan ----
LR: [0.009938499594057558]
---- EP [2/5] | BTCH [1538/3634] ||| train_loss = nan ----
LR: [0.009938940308488676]
---- EP [2/5] | BTCH [1539/3634] ||| train_loss = nan ----
LR: [0.009939379448255545]
---- EP [2/5] | BTCH [1540/3634] ||| train_loss = nan ----
LR: [0.009939817013212249]
---- EP [2/5] | BTCH [1541/3634] ||| train_loss = nan ----
LR: [0.009940253003213391]
---- EP [2/5] | BTCH [1542/3634] ||| train_loss = nan ----
LR: [0.009940687418114099]
---- EP [2/5] | BTCH [1543/3634] ||| train_loss = nan ----
LR: [0.009941120257770025]
---- EP [2/5] | BTCH [1544/3634] ||| train_loss = nan ----
LR: [0.009941551522037347]
---- EP [2/5] | BTCH [1545/3634] ||| train_loss = nan ----
LR: [0.009941981210772763]
---- EP [2/5] | BTCH [1546/3634] ||| train_loss = nan ----
LR: [0.009942409323833492]
---- EP [2/5] | BTCH [1547/3634] ||| train_loss = nan ----
LR: [0.009942835861077281]
---- EP [2/5] | BTCH [1548/3634] ||| train_loss = nan ----
LR: [0.009943260822362403]
---- EP [2/5] | BTCH [1549/3634] ||| train_loss = nan ----
LR: [0.009943684207547645]
---- EP [2/5] | BTCH [1550/3634] ||| train_loss = nan ----
LR: [0.00994410601649233]
---- EP [2/5] | BTCH [1551/3634] ||| train_loss = nan ----
LR: [0.009944526249056293]
---- EP [2/5] | BTCH [1552/3634] ||| train_loss = nan ----
LR: [0.009944944905099902]
---- EP [2/5] | BTCH [1553/3634] ||| train_loss = nan ----
LR: [0.009945361984484043]
---- EP [2/5] | BTCH [1554/3634] ||| train_loss = nan ----
LR: [0.00994577748707013]
---- EP [2/5] | BTCH [1555/3634] ||| train_loss = nan ----
LR: [0.009946191412720096]
---- EP [2/5] | BTCH [1556/3634] ||| train_loss = nan ----
LR: [0.009946603761296404]
---- EP [2/5] | BTCH [1557/3634] ||| train_loss = nan ----
LR: [0.009947014532662038]
---- EP [2/5] | BTCH [1558/3634] ||| train_loss = nan ----
LR: [0.009947423726680504]
---- EP [2/5] | BTCH [1559/3634] ||| train_loss = nan ----
LR: [0.009947831343215837]
---- EP [2/5] | BTCH [1560/3634] ||| train_loss = nan ----
LR: [0.00994823738213259]
---- EP [2/5] | BTCH [1561/3634] ||| train_loss = nan ----
LR: [0.009948641843295846]
---- EP [2/5] | BTCH [1562/3634] ||| train_loss = nan ----
LR: [0.009949044726571208]
---- EP [2/5] | BTCH [1563/3634] ||| train_loss = nan ----
LR: [0.009949446031824806]
---- EP [2/5] | BTCH [1564/3634] ||| train_loss = nan ----
LR: [0.009949845758923296]
---- EP [2/5] | BTCH [1565/3634] ||| train_loss = nan ----
LR: [0.009950243907733851]
---- EP [2/5] | BTCH [1566/3634] ||| train_loss = nan ----
LR: [0.009950640478124178]
---- EP [2/5] | BTCH [1567/3634] ||| train_loss = nan ----
LR: [0.009951035469962502]
---- EP [2/5] | BTCH [1568/3634] ||| train_loss = nan ----
LR: [0.009951428883117574]
---- EP [2/5] | BTCH [1569/3634] ||| train_loss = nan ----
LR: [0.009951820717458669]
---- EP [2/5] | BTCH [1570/3634] ||| train_loss = nan ----
LR: [0.00995221097285559]
---- EP [2/5] | BTCH [1571/3634] ||| train_loss = nan ----
LR: [0.00995259964917866]
---- EP [2/5] | BTCH [1572/3634] ||| train_loss = nan ----
LR: [0.00995298674629873]
---- EP [2/5] | BTCH [1573/3634] ||| train_loss = nan ----
LR: [0.009953372264087174]
---- EP [2/5] | BTCH [1574/3634] ||| train_loss = nan ----
LR: [0.009953756202415892]
---- EP [2/5] | BTCH [1575/3634] ||| train_loss = nan ----
LR: [0.009954138561157308]
---- EP [2/5] | BTCH [1576/3634] ||| train_loss = nan ----
LR: [0.009954519340184372]
---- EP [2/5] | BTCH [1577/3634] ||| train_loss = nan ----
LR: [0.009954898539370557]
---- EP [2/5] | BTCH [1578/3634] ||| train_loss = nan ----
LR: [0.00995527615858986]
---- EP [2/5] | BTCH [1579/3634] ||| train_loss = nan ----
LR: [0.009955652197716809]
---- EP [2/5] | BTCH [1580/3634] ||| train_loss = nan ----
LR: [0.009956026656626451]
---- EP [2/5] | BTCH [1581/3634] ||| train_loss = nan ----
LR: [0.009956399535194359]
---- EP [2/5] | BTCH [1582/3634] ||| train_loss = nan ----
LR: [0.009956770833296633]
---- EP [2/5] | BTCH [1583/3634] ||| train_loss = nan ----
LR: [0.0099571405508099]
---- EP [2/5] | BTCH [1584/3634] ||| train_loss = nan ----
LR: [0.009957508687611305]
---- EP [2/5] | BTCH [1585/3634] ||| train_loss = nan ----
LR: [0.009957875243578525]
---- EP [2/5] | BTCH [1586/3634] ||| train_loss = nan ----
LR: [0.009958240218589761]
---- EP [2/5] | BTCH [1587/3634] ||| train_loss = nan ----
LR: [0.009958603612523736]
---- EP [2/5] | BTCH [1588/3634] ||| train_loss = nan ----
LR: [0.009958965425259704]
---- EP [2/5] | BTCH [1589/3634] ||| train_loss = nan ----
LR: [0.009959325656677438]
---- EP [2/5] | BTCH [1590/3634] ||| train_loss = nan ----
LR: [0.009959684306657241]
---- EP [2/5] | BTCH [1591/3634] ||| train_loss = nan ----
LR: [0.009960041375079942]
---- EP [2/5] | BTCH [1592/3634] ||| train_loss = nan ----
LR: [0.00996039686182689]
---- EP [2/5] | BTCH [1593/3634] ||| train_loss = nan ----
LR: [0.009960750766779965]
---- EP [2/5] | BTCH [1594/3634] ||| train_loss = nan ----
LR: [0.009961103089821571]
---- EP [2/5] | BTCH [1595/3634] ||| train_loss = nan ----
LR: [0.009961453830834636]
---- EP [2/5] | BTCH [1596/3634] ||| train_loss = nan ----
LR: [0.009961802989702617]
---- EP [2/5] | BTCH [1597/3634] ||| train_loss = nan ----
LR: [0.009962150566309494]
---- EP [2/5] | BTCH [1598/3634] ||| train_loss = nan ----
LR: [0.009962496560539774]
---- EP [2/5] | BTCH [1599/3634] ||| train_loss = nan ----
LR: [0.009962840972278487]
---- EP [2/5] | BTCH [1600/3634] ||| train_loss = nan ----
LR: [0.009963183801411195]
---- EP [2/5] | BTCH [1601/3634] ||| train_loss = nan ----
LR: [0.009963525047823978]
---- EP [2/5] | BTCH [1602/3634] ||| train_loss = nan ----
LR: [0.009963864711403451]
---- EP [2/5] | BTCH [1603/3634] ||| train_loss = nan ----
LR: [0.009964202792036745]
---- EP [2/5] | BTCH [1604/3634] ||| train_loss = nan ----
LR: [0.009964539289611525]
---- EP [2/5] | BTCH [1605/3634] ||| train_loss = nan ----
LR: [0.009964874204015978]
---- EP [2/5] | BTCH [1606/3634] ||| train_loss = nan ----
LR: [0.009965207535138817]
---- EP [2/5] | BTCH [1607/3634] ||| train_loss = nan ----
LR: [0.009965539282869284]
---- EP [2/5] | BTCH [1608/3634] ||| train_loss = nan ----
LR: [0.009965869447097143]
---- EP [2/5] | BTCH [1609/3634] ||| train_loss = nan ----
LR: [0.009966198027712689]
---- EP [2/5] | BTCH [1610/3634] ||| train_loss = nan ----
LR: [0.009966525024606739]
---- EP [2/5] | BTCH [1611/3634] ||| train_loss = nan ----
LR: [0.009966850437670637]
---- EP [2/5] | BTCH [1612/3634] ||| train_loss = nan ----
LR: [0.009967174266796256]
---- EP [2/5] | BTCH [1613/3634] ||| train_loss = nan ----
LR: [0.009967496511875992]
---- EP [2/5] | BTCH [1614/3634] ||| train_loss = nan ----
LR: [0.00996781717280277]
---- EP [2/5] | BTCH [1615/3634] ||| train_loss = nan ----
LR: [0.00996813624947004]
---- EP [2/5] | BTCH [1616/3634] ||| train_loss = nan ----
LR: [0.009968453741771778]
---- EP [2/5] | BTCH [1617/3634] ||| train_loss = nan ----
LR: [0.009968769649602487]
---- EP [2/5] | BTCH [1618/3634] ||| train_loss = nan ----
LR: [0.009969083972857196]
---- EP [2/5] | BTCH [1619/3634] ||| train_loss = nan ----
LR: [0.009969396711431463]
---- EP [2/5] | BTCH [1620/3634] ||| train_loss = nan ----
LR: [0.009969707865221368]
---- EP [2/5] | BTCH [1621/3634] ||| train_loss = nan ----
LR: [0.009970017434123523]
---- EP [2/5] | BTCH [1622/3634] ||| train_loss = nan ----
LR: [0.009970325418035062]
---- EP [2/5] | BTCH [1623/3634] ||| train_loss = nan ----
LR: [0.009970631816853648]
---- EP [2/5] | BTCH [1624/3634] ||| train_loss = nan ----
LR: [0.00997093663047747]
---- EP [2/5] | BTCH [1625/3634] ||| train_loss = nan ----
LR: [0.009971239858805244]
---- EP [2/5] | BTCH [1626/3634] ||| train_loss = nan ----
LR: [0.009971541501736214]
---- EP [2/5] | BTCH [1627/3634] ||| train_loss = nan ----
LR: [0.009971841559170146]
---- EP [2/5] | BTCH [1628/3634] ||| train_loss = nan ----
LR: [0.00997214003100734]
---- EP [2/5] | BTCH [1629/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.009972436917148619]
---- EP [2/5] | BTCH [1630/3634] ||| train_loss = nan ----
LR: [0.00997273221749533]
---- EP [2/5] | BTCH [1631/3634] ||| train_loss = nan ----
LR: [0.009973025931949353]
---- EP [2/5] | BTCH [1632/3634] ||| train_loss = nan ----
LR: [0.009973318060413091]
---- EP [2/5] | BTCH [1633/3634] ||| train_loss = nan ----
LR: [0.009973608602789475]
---- EP [2/5] | BTCH [1634/3634] ||| train_loss = nan ----
LR: [0.009973897558981964]
---- EP [2/5] | BTCH [1635/3634] ||| train_loss = nan ----
LR: [0.00997418492889454]
---- EP [2/5] | BTCH [1636/3634] ||| train_loss = nan ----
LR: [0.009974470712431719]
---- EP [2/5] | BTCH [1637/3634] ||| train_loss = nan ----
LR: [0.009974754909498538]
---- EP [2/5] | BTCH [1638/3634] ||| train_loss = nan ----
LR: [0.009975037520000564]
---- EP [2/5] | BTCH [1639/3634] ||| train_loss = nan ----
LR: [0.00997531854384389]
---- EP [2/5] | BTCH [1640/3634] ||| train_loss = nan ----
LR: [0.009975597980935138]
---- EP [2/5] | BTCH [1641/3634] ||| train_loss = nan ----
LR: [0.009975875831181456]
---- EP [2/5] | BTCH [1642/3634] ||| train_loss = nan ----
LR: [0.009976152094490518]
---- EP [2/5] | BTCH [1643/3634] ||| train_loss = nan ----
LR: [0.009976426770770529]
---- EP [2/5] | BTCH [1644/3634] ||| train_loss = nan ----
LR: [0.009976699859930216]
---- EP [2/5] | BTCH [1645/3634] ||| train_loss = nan ----
LR: [0.009976971361878839]
---- EP [2/5] | BTCH [1646/3634] ||| train_loss = nan ----
LR: [0.009977241276526183]
---- EP [2/5] | BTCH [1647/3634] ||| train_loss = nan ----
LR: [0.009977509603782558]
---- EP [2/5] | BTCH [1648/3634] ||| train_loss = nan ----
LR: [0.009977776343558805]
---- EP [2/5] | BTCH [1649/3634] ||| train_loss = nan ----
LR: [0.00997804149576629]
---- EP [2/5] | BTCH [1650/3634] ||| train_loss = nan ----
LR: [0.009978305060316911]
---- EP [2/5] | BTCH [1651/3634] ||| train_loss = nan ----
LR: [0.009978567037123087]
---- EP [2/5] | BTCH [1652/3634] ||| train_loss = nan ----
LR: [0.009978827426097767]
---- EP [2/5] | BTCH [1653/3634] ||| train_loss = nan ----
LR: [0.009979086227154434]
---- EP [2/5] | BTCH [1654/3634] ||| train_loss = nan ----
LR: [0.009979343440207088]
---- EP [2/5] | BTCH [1655/3634] ||| train_loss = nan ----
LR: [0.009979599065170262]
---- EP [2/5] | BTCH [1656/3634] ||| train_loss = nan ----
LR: [0.009979853101959018]
---- EP [2/5] | BTCH [1657/3634] ||| train_loss = nan ----
LR: [0.009980105550488944]
---- EP [2/5] | BTCH [1658/3634] ||| train_loss = nan ----
LR: [0.009980356410676156]
---- EP [2/5] | BTCH [1659/3634] ||| train_loss = nan ----
LR: [0.009980605682437296]
---- EP [2/5] | BTCH [1660/3634] ||| train_loss = nan ----
LR: [0.009980853365689537]
---- EP [2/5] | BTCH [1661/3634] ||| train_loss = nan ----
LR: [0.00998109946035058]
---- EP [2/5] | BTCH [1662/3634] ||| train_loss = nan ----
LR: [0.009981343966338648]
---- EP [2/5] | BTCH [1663/3634] ||| train_loss = nan ----
LR: [0.0099815868835725]
---- EP [2/5] | BTCH [1664/3634] ||| train_loss = nan ----
LR: [0.009981828211971418]
---- EP [2/5] | BTCH [1665/3634] ||| train_loss = nan ----
LR: [0.009982067951455212]
---- EP [2/5] | BTCH [1666/3634] ||| train_loss = nan ----
LR: [0.00998230610194422]
---- EP [2/5] | BTCH [1667/3634] ||| train_loss = nan ----
LR: [0.009982542663359312]
---- EP [2/5] | BTCH [1668/3634] ||| train_loss = nan ----
LR: [0.00998277763562188]
---- EP [2/5] | BTCH [1669/3634] ||| train_loss = nan ----
LR: [0.00998301101865385]
---- EP [2/5] | BTCH [1670/3634] ||| train_loss = nan ----
LR: [0.009983242812377668]
---- EP [2/5] | BTCH [1671/3634] ||| train_loss = nan ----
LR: [0.009983473016716317]
---- EP [2/5] | BTCH [1672/3634] ||| train_loss = nan ----
LR: [0.009983701631593305]
---- EP [2/5] | BTCH [1673/3634] ||| train_loss = nan ----
LR: [0.009983928656932664]
---- EP [2/5] | BTCH [1674/3634] ||| train_loss = nan ----
LR: [0.00998415409265896]
---- EP [2/5] | BTCH [1675/3634] ||| train_loss = nan ----
LR: [0.009984377938697286]
---- EP [2/5] | BTCH [1676/3634] ||| train_loss = nan ----
LR: [0.009984600194973258]
---- EP [2/5] | BTCH [1677/3634] ||| train_loss = nan ----
LR: [0.009984820861413028]
---- EP [2/5] | BTCH [1678/3634] ||| train_loss = nan ----
LR: [0.009985039937943271]
---- EP [2/5] | BTCH [1679/3634] ||| train_loss = nan ----
LR: [0.009985257424491191]
---- EP [2/5] | BTCH [1680/3634] ||| train_loss = nan ----
LR: [0.009985473320984522]
---- EP [2/5] | BTCH [1681/3634] ||| train_loss = nan ----
LR: [0.009985687627351527]
---- EP [2/5] | BTCH [1682/3634] ||| train_loss = nan ----
LR: [0.009985900343520992]
---- EP [2/5] | BTCH [1683/3634] ||| train_loss = nan ----
LR: [0.00998611146942224]
---- EP [2/5] | BTCH [1684/3634] ||| train_loss = nan ----
LR: [0.009986321004985114]
---- EP [2/5] | BTCH [1685/3634] ||| train_loss = nan ----
LR: [0.00998652895013999]
---- EP [2/5] | BTCH [1686/3634] ||| train_loss = nan ----
LR: [0.009986735304817774]
---- EP [2/5] | BTCH [1687/3634] ||| train_loss = nan ----
LR: [0.009986940068949892]
---- EP [2/5] | BTCH [1688/3634] ||| train_loss = nan ----
LR: [0.009987143242468313]
---- EP [2/5] | BTCH [1689/3634] ||| train_loss = nan ----
LR: [0.00998734482530552]
---- EP [2/5] | BTCH [1690/3634] ||| train_loss = nan ----
LR: [0.009987544817394533]
---- EP [2/5] | BTCH [1691/3634] ||| train_loss = nan ----
LR: [0.009987743218668896]
---- EP [2/5] | BTCH [1692/3634] ||| train_loss = nan ----
LR: [0.009987940029062687]
---- EP [2/5] | BTCH [1693/3634] ||| train_loss = nan ----
LR: [0.009988135248510508]
---- EP [2/5] | BTCH [1694/3634] ||| train_loss = nan ----
LR: [0.009988328876947491]
---- EP [2/5] | BTCH [1695/3634] ||| train_loss = nan ----
LR: [0.009988520914309297]
---- EP [2/5] | BTCH [1696/3634] ||| train_loss = nan ----
LR: [0.009988711360532115]
---- EP [2/5] | BTCH [1697/3634] ||| train_loss = nan ----
LR: [0.009988900215552663]
---- EP [2/5] | BTCH [1698/3634] ||| train_loss = nan ----
LR: [0.00998908747930819]
---- EP [2/5] | BTCH [1699/3634] ||| train_loss = nan ----
LR: [0.009989273151736469]
---- EP [2/5] | BTCH [1700/3634] ||| train_loss = nan ----
LR: [0.009989457232775804]
---- EP [2/5] | BTCH [1701/3634] ||| train_loss = nan ----
LR: [0.00998963972236503]
---- EP [2/5] | BTCH [1702/3634] ||| train_loss = nan ----
LR: [0.00998982062044351]
---- EP [2/5] | BTCH [1703/3634] ||| train_loss = nan ----
LR: [0.009989999926951133]
---- EP [2/5] | BTCH [1704/3634] ||| train_loss = nan ----
LR: [0.009990177641828319]
---- EP [2/5] | BTCH [1705/3634] ||| train_loss = nan ----
LR: [0.009990353765016016]
---- EP [2/5] | BTCH [1706/3634] ||| train_loss = nan ----
LR: [0.009990528296455704]
---- EP [2/5] | BTCH [1707/3634] ||| train_loss = nan ----
LR: [0.009990701236089385]
---- EP [2/5] | BTCH [1708/3634] ||| train_loss = nan ----
LR: [0.0099908725838596]
---- EP [2/5] | BTCH [1709/3634] ||| train_loss = nan ----
LR: [0.009991042339709407]
---- EP [2/5] | BTCH [1710/3634] ||| train_loss = nan ----
LR: [0.009991210503582404]
---- EP [2/5] | BTCH [1711/3634] ||| train_loss = nan ----
LR: [0.00999137707542271]
---- EP [2/5] | BTCH [1712/3634] ||| train_loss = nan ----
LR: [0.009991542055174978]
---- EP [2/5] | BTCH [1713/3634] ||| train_loss = nan ----
LR: [0.009991705442784387]
---- EP [2/5] | BTCH [1714/3634] ||| train_loss = nan ----
LR: [0.00999186723819665]
---- EP [2/5] | BTCH [1715/3634] ||| train_loss = nan ----
LR: [0.009992027441358]
---- EP [2/5] | BTCH [1716/3634] ||| train_loss = nan ----
LR: [0.009992186052215206]
---- EP [2/5] | BTCH [1717/3634] ||| train_loss = nan ----
LR: [0.009992343070715568]
---- EP [2/5] | BTCH [1718/3634] ||| train_loss = nan ----
LR: [0.009992498496806907]
---- EP [2/5] | BTCH [1719/3634] ||| train_loss = nan ----
LR: [0.00999265233043758]
---- EP [2/5] | BTCH [1720/3634] ||| train_loss = nan ----
LR: [0.009992804571556468]
---- EP [2/5] | BTCH [1721/3634] ||| train_loss = nan ----
LR: [0.00999295522011299]
---- EP [2/5] | BTCH [1722/3634] ||| train_loss = nan ----
LR: [0.009993104276057083]
---- EP [2/5] | BTCH [1723/3634] ||| train_loss = nan ----
LR: [0.00999325173933922]
---- EP [2/5] | BTCH [1724/3634] ||| train_loss = nan ----
LR: [0.009993397609910401]
---- EP [2/5] | BTCH [1725/3634] ||| train_loss = nan ----
LR: [0.009993541887722156]
---- EP [2/5] | BTCH [1726/3634] ||| train_loss = nan ----
LR: [0.009993684572726546]
---- EP [2/5] | BTCH [1727/3634] ||| train_loss = nan ----
LR: [0.009993825664876157]
---- EP [2/5] | BTCH [1728/3634] ||| train_loss = nan ----
LR: [0.009993965164124109]
---- EP [2/5] | BTCH [1729/3634] ||| train_loss = nan ----
LR: [0.009994103070424048]
---- EP [2/5] | BTCH [1730/3634] ||| train_loss = nan ----
LR: [0.009994239383730147]
---- EP [2/5] | BTCH [1731/3634] ||| train_loss = nan ----
LR: [0.009994374103997115]
---- EP [2/5] | BTCH [1732/3634] ||| train_loss = nan ----
LR: [0.009994507231180188]
---- EP [2/5] | BTCH [1733/3634] ||| train_loss = nan ----
LR: [0.009994638765235125]
---- EP [2/5] | BTCH [1734/3634] ||| train_loss = nan ----
LR: [0.009994768706118226]
---- EP [2/5] | BTCH [1735/3634] ||| train_loss = nan ----
LR: [0.00999489705378631]
---- EP [2/5] | BTCH [1736/3634] ||| train_loss = nan ----
LR: [0.009995023808196729]
---- EP [2/5] | BTCH [1737/3634] ||| train_loss = nan ----
LR: [0.009995148969307368]
---- EP [2/5] | BTCH [1738/3634] ||| train_loss = nan ----
LR: [0.009995272537076636]
---- EP [2/5] | BTCH [1739/3634] ||| train_loss = nan ----
LR: [0.009995394511463473]
---- EP [2/5] | BTCH [1740/3634] ||| train_loss = nan ----
LR: [0.009995514892427351]
---- EP [2/5] | BTCH [1741/3634] ||| train_loss = nan ----
LR: [0.009995633679928268]
---- EP [2/5] | BTCH [1742/3634] ||| train_loss = nan ----
LR: [0.009995750873926755]
---- EP [2/5] | BTCH [1743/3634] ||| train_loss = nan ----
LR: [0.00999586647438387]
---- EP [2/5] | BTCH [1744/3634] ||| train_loss = nan ----
LR: [0.009995980481261199]
---- EP [2/5] | BTCH [1745/3634] ||| train_loss = nan ----
LR: [0.00999609289452086]
---- EP [2/5] | BTCH [1746/3634] ||| train_loss = nan ----
LR: [0.009996203714125502]
---- EP [2/5] | BTCH [1747/3634] ||| train_loss = nan ----
LR: [0.009996312940038301]
---- EP [2/5] | BTCH [1748/3634] ||| train_loss = nan ----
LR: [0.009996420572222964]
---- EP [2/5] | BTCH [1749/3634] ||| train_loss = nan ----
LR: [0.009996526610643725]
---- EP [2/5] | BTCH [1750/3634] ||| train_loss = nan ----
LR: [0.009996631055265348]
---- EP [2/5] | BTCH [1751/3634] ||| train_loss = nan ----
LR: [0.009996733906053133]
---- EP [2/5] | BTCH [1752/3634] ||| train_loss = nan ----
LR: [0.0099968351629729]
---- EP [2/5] | BTCH [1753/3634] ||| train_loss = nan ----
LR: [0.009996934825991005]
---- EP [2/5] | BTCH [1754/3634] ||| train_loss = nan ----
LR: [0.009997032895074332]
---- EP [2/5] | BTCH [1755/3634] ||| train_loss = nan ----
LR: [0.009997129370190292]
---- EP [2/5] | BTCH [1756/3634] ||| train_loss = nan ----
LR: [0.009997224251306832]
---- EP [2/5] | BTCH [1757/3634] ||| train_loss = nan ----
LR: [0.009997317538392421]
---- EP [2/5] | BTCH [1758/3634] ||| train_loss = nan ----
LR: [0.009997409231416064]
---- EP [2/5] | BTCH [1759/3634] ||| train_loss = nan ----
LR: [0.009997499330347293]
---- EP [2/5] | BTCH [1760/3634] ||| train_loss = nan ----
LR: [0.009997587835156167]
---- EP [2/5] | BTCH [1761/3634] ||| train_loss = nan ----
LR: [0.00999767474581328]
---- EP [2/5] | BTCH [1762/3634] ||| train_loss = nan ----
LR: [0.009997760062289753]
---- EP [2/5] | BTCH [1763/3634] ||| train_loss = nan ----
LR: [0.009997843784557236]
---- EP [2/5] | BTCH [1764/3634] ||| train_loss = nan ----
LR: [0.009997925912587911]
---- EP [2/5] | BTCH [1765/3634] ||| train_loss = nan ----
LR: [0.009998006446354487]
---- EP [2/5] | BTCH [1766/3634] ||| train_loss = nan ----
LR: [0.009998085385830203]
---- EP [2/5] | BTCH [1767/3634] ||| train_loss = nan ----
LR: [0.00999816273098883]
---- EP [2/5] | BTCH [1768/3634] ||| train_loss = nan ----
LR: [0.009998238481804669]
---- EP [2/5] | BTCH [1769/3634] ||| train_loss = nan ----
LR: [0.009998312638252549]
---- EP [2/5] | BTCH [1770/3634] ||| train_loss = nan ----
LR: [0.009998385200307826]
---- EP [2/5] | BTCH [1771/3634] ||| train_loss = nan ----
LR: [0.009998456167946392]
---- EP [2/5] | BTCH [1772/3634] ||| train_loss = nan ----
LR: [0.009998525541144667]
---- EP [2/5] | BTCH [1773/3634] ||| train_loss = nan ----
LR: [0.009998593319879595]
---- EP [2/5] | BTCH [1774/3634] ||| train_loss = nan ----
LR: [0.009998659504128659]
---- EP [2/5] | BTCH [1775/3634] ||| train_loss = nan ----
LR: [0.009998724093869864]
---- EP [2/5] | BTCH [1776/3634] ||| train_loss = nan ----
LR: [0.00999878708908175]
---- EP [2/5] | BTCH [1777/3634] ||| train_loss = nan ----
LR: [0.009998848489743382]
---- EP [2/5] | BTCH [1778/3634] ||| train_loss = nan ----
LR: [0.009998908295834361]
---- EP [2/5] | BTCH [1779/3634] ||| train_loss = nan ----
LR: [0.009998966507334813]
---- EP [2/5] | BTCH [1780/3634] ||| train_loss = nan ----
LR: [0.009999023124225395]
---- EP [2/5] | BTCH [1781/3634] ||| train_loss = nan ----
LR: [0.009999078146487294]
---- EP [2/5] | BTCH [1782/3634] ||| train_loss = nan ----
LR: [0.009999131574102229]
---- EP [2/5] | BTCH [1783/3634] ||| train_loss = nan ----
LR: [0.009999183407052446]
---- EP [2/5] | BTCH [1784/3634] ||| train_loss = nan ----
LR: [0.00999923364532072]
---- EP [2/5] | BTCH [1785/3634] ||| train_loss = nan ----
LR: [0.009999282288890361]
---- EP [2/5] | BTCH [1786/3634] ||| train_loss = nan ----
LR: [0.009999329337745203]
---- EP [2/5] | BTCH [1787/3634] ||| train_loss = nan ----
LR: [0.009999374791869613]
---- EP [2/5] | BTCH [1788/3634] ||| train_loss = nan ----
LR: [0.00999941865124849]
---- EP [2/5] | BTCH [1789/3634] ||| train_loss = nan ----
LR: [0.009999460915867257]
---- EP [2/5] | BTCH [1790/3634] ||| train_loss = nan ----
LR: [0.00999950158571187]
---- EP [2/5] | BTCH [1791/3634] ||| train_loss = nan ----
LR: [0.00999954066076882]
---- EP [2/5] | BTCH [1792/3634] ||| train_loss = nan ----
LR: [0.009999578141025117]
---- EP [2/5] | BTCH [1793/3634] ||| train_loss = nan ----
LR: [0.00999961402646831]
---- EP [2/5] | BTCH [1794/3634] ||| train_loss = nan ----
LR: [0.009999648317086475]
---- EP [2/5] | BTCH [1795/3634] ||| train_loss = nan ----
LR: [0.009999681012868217]
---- EP [2/5] | BTCH [1796/3634] ||| train_loss = nan ----
LR: [0.009999712113802673]
---- EP [2/5] | BTCH [1797/3634] ||| train_loss = nan ----
LR: [0.009999741619879507]
---- EP [2/5] | BTCH [1798/3634] ||| train_loss = nan ----
LR: [0.009999769531088916]
---- EP [2/5] | BTCH [1799/3634] ||| train_loss = nan ----
LR: [0.009999795847421625]
---- EP [2/5] | BTCH [1800/3634] ||| train_loss = nan ----
LR: [0.009999820568868889]
---- EP [2/5] | BTCH [1801/3634] ||| train_loss = nan ----
LR: [0.009999843695422495]
---- EP [2/5] | BTCH [1802/3634] ||| train_loss = nan ----
LR: [0.009999865227074758]
---- EP [2/5] | BTCH [1803/3634] ||| train_loss = nan ----
LR: [0.009999885163818523]
---- EP [2/5] | BTCH [1804/3634] ||| train_loss = nan ----
LR: [0.009999903505647166]
---- EP [2/5] | BTCH [1805/3634] ||| train_loss = nan ----
LR: [0.00999992025255459]
---- EP [2/5] | BTCH [1806/3634] ||| train_loss = nan ----
LR: [0.009999935404535233]
---- EP [2/5] | BTCH [1807/3634] ||| train_loss = nan ----
LR: [0.00999994896158406]
---- EP [2/5] | BTCH [1808/3634] ||| train_loss = nan ----
LR: [0.009999960923696566]
---- EP [2/5] | BTCH [1809/3634] ||| train_loss = nan ----
LR: [0.009999971290868775]
---- EP [2/5] | BTCH [1810/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.009999980063097243]
---- EP [2/5] | BTCH [1811/3634] ||| train_loss = nan ----
LR: [0.009999987240379055]
---- EP [2/5] | BTCH [1812/3634] ||| train_loss = nan ----
LR: [0.009999992822711828]
---- EP [2/5] | BTCH [1813/3634] ||| train_loss = nan ----
LR: [0.009999996810093705]
---- EP [2/5] | BTCH [1814/3634] ||| train_loss = nan ----
LR: [0.00999999920252336]
---- EP [2/5] | BTCH [1815/3634] ||| train_loss = nan ----
LR: [0.01]
---- EP [2/5] | BTCH [1816/3634] ||| train_loss = nan ----
LR: [0.009999999847478144]
---- EP [2/5] | BTCH [1817/3634] ||| train_loss = nan ----
LR: [0.009999999389912587]
---- EP [2/5] | BTCH [1818/3634] ||| train_loss = nan ----
LR: [0.009999998627303356]
---- EP [2/5] | BTCH [1819/3634] ||| train_loss = nan ----
LR: [0.009999997559650498]
---- EP [2/5] | BTCH [1820/3634] ||| train_loss = nan ----
LR: [0.009999996186954078]
---- EP [2/5] | BTCH [1821/3634] ||| train_loss = nan ----
LR: [0.00999999450921418]
---- EP [2/5] | BTCH [1822/3634] ||| train_loss = nan ----
LR: [0.009999992526430903]
---- EP [2/5] | BTCH [1823/3634] ||| train_loss = nan ----
LR: [0.009999990238604374]
---- EP [2/5] | BTCH [1824/3634] ||| train_loss = nan ----
LR: [0.00999998764573473]
---- EP [2/5] | BTCH [1825/3634] ||| train_loss = nan ----
LR: [0.009999984747822127]
---- EP [2/5] | BTCH [1826/3634] ||| train_loss = nan ----
LR: [0.009999981544866744]
---- EP [2/5] | BTCH [1827/3634] ||| train_loss = nan ----
LR: [0.009999978036868777]
---- EP [2/5] | BTCH [1828/3634] ||| train_loss = nan ----
LR: [0.009999974223828437]
---- EP [2/5] | BTCH [1829/3634] ||| train_loss = nan ----
LR: [0.00999997010574596]
---- EP [2/5] | BTCH [1830/3634] ||| train_loss = nan ----
LR: [0.009999965682621594]
---- EP [2/5] | BTCH [1831/3634] ||| train_loss = nan ----
LR: [0.009999960954455612]
---- EP [2/5] | BTCH [1832/3634] ||| train_loss = nan ----
LR: [0.009999955921248301]
---- EP [2/5] | BTCH [1833/3634] ||| train_loss = nan ----
LR: [0.00999995058299997]
---- EP [2/5] | BTCH [1834/3634] ||| train_loss = nan ----
LR: [0.00999994493971094]
---- EP [2/5] | BTCH [1835/3634] ||| train_loss = nan ----
LR: [0.00999993899138156]
---- EP [2/5] | BTCH [1836/3634] ||| train_loss = nan ----
LR: [0.00999993273801219]
---- EP [2/5] | BTCH [1837/3634] ||| train_loss = nan ----
LR: [0.009999926179603214]
---- EP [2/5] | BTCH [1838/3634] ||| train_loss = nan ----
LR: [0.00999991931615503]
---- EP [2/5] | BTCH [1839/3634] ||| train_loss = nan ----
LR: [0.009999912147668056]
---- EP [2/5] | BTCH [1840/3634] ||| train_loss = nan ----
LR: [0.009999904674142732]
---- EP [2/5] | BTCH [1841/3634] ||| train_loss = nan ----
LR: [0.009999896895579513]
---- EP [2/5] | BTCH [1842/3634] ||| train_loss = nan ----
LR: [0.009999888811978873]
---- EP [2/5] | BTCH [1843/3634] ||| train_loss = nan ----
LR: [0.009999880423341306]
---- EP [2/5] | BTCH [1844/3634] ||| train_loss = nan ----
LR: [0.009999871729667324]
---- EP [2/5] | BTCH [1845/3634] ||| train_loss = nan ----
LR: [0.009999862730957454]
---- EP [2/5] | BTCH [1846/3634] ||| train_loss = nan ----
LR: [0.00999985342721225]
---- EP [2/5] | BTCH [1847/3634] ||| train_loss = nan ----
LR: [0.009999843818432275]
---- EP [2/5] | BTCH [1848/3634] ||| train_loss = nan ----
LR: [0.009999833904618118]
---- EP [2/5] | BTCH [1849/3634] ||| train_loss = nan ----
LR: [0.009999823685770386]
---- EP [2/5] | BTCH [1850/3634] ||| train_loss = nan ----
LR: [0.009999813161889698]
---- EP [2/5] | BTCH [1851/3634] ||| train_loss = nan ----
LR: [0.009999802332976697]
---- EP [2/5] | BTCH [1852/3634] ||| train_loss = nan ----
LR: [0.009999791199032044]
---- EP [2/5] | BTCH [1853/3634] ||| train_loss = nan ----
LR: [0.009999779760056421]
---- EP [2/5] | BTCH [1854/3634] ||| train_loss = nan ----
LR: [0.009999768016050521]
---- EP [2/5] | BTCH [1855/3634] ||| train_loss = nan ----
LR: [0.009999755967015064]
---- EP [2/5] | BTCH [1856/3634] ||| train_loss = nan ----
LR: [0.009999743612950786]
---- EP [2/5] | BTCH [1857/3634] ||| train_loss = nan ----
LR: [0.009999730953858438]
---- EP [2/5] | BTCH [1858/3634] ||| train_loss = nan ----
LR: [0.009999717989738793]
---- EP [2/5] | BTCH [1859/3634] ||| train_loss = nan ----
LR: [0.009999704720592643]
---- EP [2/5] | BTCH [1860/3634] ||| train_loss = nan ----
LR: [0.009999691146420795]
---- EP [2/5] | BTCH [1861/3634] ||| train_loss = nan ----
LR: [0.009999677267224078]
---- EP [2/5] | BTCH [1862/3634] ||| train_loss = nan ----
LR: [0.009999663083003343]
---- EP [2/5] | BTCH [1863/3634] ||| train_loss = nan ----
LR: [0.00999964859375945]
---- EP [2/5] | BTCH [1864/3634] ||| train_loss = nan ----
LR: [0.009999633799493285]
---- EP [2/5] | BTCH [1865/3634] ||| train_loss = nan ----
LR: [0.009999618700205751]
---- EP [2/5] | BTCH [1866/3634] ||| train_loss = nan ----
LR: [0.009999603295897769]
---- EP [2/5] | BTCH [1867/3634] ||| train_loss = nan ----
LR: [0.009999587586570277]
---- EP [2/5] | BTCH [1868/3634] ||| train_loss = nan ----
LR: [0.009999571572224236]
---- EP [2/5] | BTCH [1869/3634] ||| train_loss = nan ----
LR: [0.009999555252860622]
---- EP [2/5] | BTCH [1870/3634] ||| train_loss = nan ----
LR: [0.00999953862848043]
---- EP [2/5] | BTCH [1871/3634] ||| train_loss = nan ----
LR: [0.009999521699084675]
---- EP [2/5] | BTCH [1872/3634] ||| train_loss = nan ----
LR: [0.00999950446467439]
---- EP [2/5] | BTCH [1873/3634] ||| train_loss = nan ----
LR: [0.009999486925250626]
---- EP [2/5] | BTCH [1874/3634] ||| train_loss = nan ----
LR: [0.009999469080814453]
---- EP [2/5] | BTCH [1875/3634] ||| train_loss = nan ----
LR: [0.009999450931366961]
---- EP [2/5] | BTCH [1876/3634] ||| train_loss = nan ----
LR: [0.009999432476909252]
---- EP [2/5] | BTCH [1877/3634] ||| train_loss = nan ----
LR: [0.00999941371744246]
---- EP [2/5] | BTCH [1878/3634] ||| train_loss = nan ----
LR: [0.009999394652967725]
---- EP [2/5] | BTCH [1879/3634] ||| train_loss = nan ----
LR: [0.009999375283486212]
---- EP [2/5] | BTCH [1880/3634] ||| train_loss = nan ----
LR: [0.009999355608999099]
---- EP [2/5] | BTCH [1881/3634] ||| train_loss = nan ----
LR: [0.00999933562950759]
---- EP [2/5] | BTCH [1882/3634] ||| train_loss = nan ----
LR: [0.0099993153450129]
---- EP [2/5] | BTCH [1883/3634] ||| train_loss = nan ----
LR: [0.009999294755516272]
---- EP [2/5] | BTCH [1884/3634] ||| train_loss = nan ----
LR: [0.009999273861018959]
---- EP [2/5] | BTCH [1885/3634] ||| train_loss = nan ----
LR: [0.009999252661522235]
---- EP [2/5] | BTCH [1886/3634] ||| train_loss = nan ----
LR: [0.009999231157027394]
---- EP [2/5] | BTCH [1887/3634] ||| train_loss = nan ----
LR: [0.009999209347535749]
---- EP [2/5] | BTCH [1888/3634] ||| train_loss = nan ----
LR: [0.009999187233048629]
---- EP [2/5] | BTCH [1889/3634] ||| train_loss = nan ----
LR: [0.009999164813567385]
---- EP [2/5] | BTCH [1890/3634] ||| train_loss = nan ----
LR: [0.009999142089093383]
---- EP [2/5] | BTCH [1891/3634] ||| train_loss = nan ----
LR: [0.009999119059628012]
---- EP [2/5] | BTCH [1892/3634] ||| train_loss = nan ----
LR: [0.009999095725172673]
---- EP [2/5] | BTCH [1893/3634] ||| train_loss = nan ----
LR: [0.009999072085728793]
---- EP [2/5] | BTCH [1894/3634] ||| train_loss = nan ----
LR: [0.009999048141297814]
---- EP [2/5] | BTCH [1895/3634] ||| train_loss = nan ----
LR: [0.009999023891881195]
---- EP [2/5] | BTCH [1896/3634] ||| train_loss = nan ----
LR: [0.009998999337480417]
---- EP [2/5] | BTCH [1897/3634] ||| train_loss = nan ----
LR: [0.009998974478096978]
---- EP [2/5] | BTCH [1898/3634] ||| train_loss = nan ----
LR: [0.009998949313732393]
---- EP [2/5] | BTCH [1899/3634] ||| train_loss = nan ----
LR: [0.009998923844388198]
---- EP [2/5] | BTCH [1900/3634] ||| train_loss = nan ----
LR: [0.009998898070065945]
---- EP [2/5] | BTCH [1901/3634] ||| train_loss = nan ----
LR: [0.009998871990767213]
---- EP [2/5] | BTCH [1902/3634] ||| train_loss = nan ----
LR: [0.009998845606493587]
---- EP [2/5] | BTCH [1903/3634] ||| train_loss = nan ----
LR: [0.009998818917246678]
---- EP [2/5] | BTCH [1904/3634] ||| train_loss = nan ----
LR: [0.009998791923028116]
---- EP [2/5] | BTCH [1905/3634] ||| train_loss = nan ----
LR: [0.009998764623839545]
---- EP [2/5] | BTCH [1906/3634] ||| train_loss = nan ----
LR: [0.009998737019682631]
---- EP [2/5] | BTCH [1907/3634] ||| train_loss = nan ----
LR: [0.009998709110559062]
---- EP [2/5] | BTCH [1908/3634] ||| train_loss = nan ----
LR: [0.009998680896470536]
---- EP [2/5] | BTCH [1909/3634] ||| train_loss = nan ----
LR: [0.009998652377418777]
---- EP [2/5] | BTCH [1910/3634] ||| train_loss = nan ----
LR: [0.009998623553405523]
---- EP [2/5] | BTCH [1911/3634] ||| train_loss = nan ----
LR: [0.009998594424432534]
---- EP [2/5] | BTCH [1912/3634] ||| train_loss = nan ----
LR: [0.009998564990501588]
---- EP [2/5] | BTCH [1913/3634] ||| train_loss = nan ----
LR: [0.009998535251614479]
---- EP [2/5] | BTCH [1914/3634] ||| train_loss = nan ----
LR: [0.00999850520777302]
---- EP [2/5] | BTCH [1915/3634] ||| train_loss = nan ----
LR: [0.009998474858979048]
---- EP [2/5] | BTCH [1916/3634] ||| train_loss = nan ----
LR: [0.009998444205234411]
---- EP [2/5] | BTCH [1917/3634] ||| train_loss = nan ----
LR: [0.009998413246540981]
---- EP [2/5] | BTCH [1918/3634] ||| train_loss = nan ----
LR: [0.009998381982900647]
---- EP [2/5] | BTCH [1919/3634] ||| train_loss = nan ----
LR: [0.009998350414315314]
---- EP [2/5] | BTCH [1920/3634] ||| train_loss = nan ----
LR: [0.00999831854078691]
---- EP [2/5] | BTCH [1921/3634] ||| train_loss = nan ----
LR: [0.009998286362317381]
---- EP [2/5] | BTCH [1922/3634] ||| train_loss = nan ----
LR: [0.009998253878908686]
---- EP [2/5] | BTCH [1923/3634] ||| train_loss = nan ----
LR: [0.009998221090562809]
---- EP [2/5] | BTCH [1924/3634] ||| train_loss = nan ----
LR: [0.00999818799728175]
---- EP [2/5] | BTCH [1925/3634] ||| train_loss = nan ----
LR: [0.009998154599067532]
---- EP [2/5] | BTCH [1926/3634] ||| train_loss = nan ----
LR: [0.009998120895922186]
---- EP [2/5] | BTCH [1927/3634] ||| train_loss = nan ----
LR: [0.009998086887847773]
---- EP [2/5] | BTCH [1928/3634] ||| train_loss = nan ----
LR: [0.009998052574846364]
---- EP [2/5] | BTCH [1929/3634] ||| train_loss = nan ----
LR: [0.009998017956920055]
---- EP [2/5] | BTCH [1930/3634] ||| train_loss = nan ----
LR: [0.00999798303407096]
---- EP [2/5] | BTCH [1931/3634] ||| train_loss = nan ----
LR: [0.009997947806301203]
---- EP [2/5] | BTCH [1932/3634] ||| train_loss = nan ----
LR: [0.00999791227361294]
---- EP [2/5] | BTCH [1933/3634] ||| train_loss = nan ----
LR: [0.009997876436008335]
---- EP [2/5] | BTCH [1934/3634] ||| train_loss = nan ----
LR: [0.009997840293489576]
---- EP [2/5] | BTCH [1935/3634] ||| train_loss = nan ----
LR: [0.009997803846058867]
---- EP [2/5] | BTCH [1936/3634] ||| train_loss = nan ----
LR: [0.009997767093718433]
---- EP [2/5] | BTCH [1937/3634] ||| train_loss = nan ----
LR: [0.009997730036470514]
---- EP [2/5] | BTCH [1938/3634] ||| train_loss = nan ----
LR: [0.009997692674317374]
---- EP [2/5] | BTCH [1939/3634] ||| train_loss = nan ----
LR: [0.009997655007261288]
---- EP [2/5] | BTCH [1940/3634] ||| train_loss = nan ----
LR: [0.00999761703530456]
---- EP [2/5] | BTCH [1941/3634] ||| train_loss = nan ----
LR: [0.009997578758449501]
---- EP [2/5] | BTCH [1942/3634] ||| train_loss = nan ----
LR: [0.009997540176698448]
---- EP [2/5] | BTCH [1943/3634] ||| train_loss = nan ----
LR: [0.009997501290053758]
---- EP [2/5] | BTCH [1944/3634] ||| train_loss = nan ----
LR: [0.009997462098517798]
---- EP [2/5] | BTCH [1945/3634] ||| train_loss = nan ----
LR: [0.009997422602092963]
---- EP [2/5] | BTCH [1946/3634] ||| train_loss = nan ----
LR: [0.00999738280078166]
---- EP [2/5] | BTCH [1947/3634] ||| train_loss = nan ----
LR: [0.009997342694586322]
---- EP [2/5] | BTCH [1948/3634] ||| train_loss = nan ----
LR: [0.00999730228350939]
---- EP [2/5] | BTCH [1949/3634] ||| train_loss = nan ----
LR: [0.009997261567553333]
---- EP [2/5] | BTCH [1950/3634] ||| train_loss = nan ----
LR: [0.009997220546720632]
---- EP [2/5] | BTCH [1951/3634] ||| train_loss = nan ----
LR: [0.009997179221013794]
---- EP [2/5] | BTCH [1952/3634] ||| train_loss = nan ----
LR: [0.009997137590435336]
---- EP [2/5] | BTCH [1953/3634] ||| train_loss = nan ----
LR: [0.009997095654987801]
---- EP [2/5] | BTCH [1954/3634] ||| train_loss = nan ----
LR: [0.009997053414673746]
---- EP [2/5] | BTCH [1955/3634] ||| train_loss = nan ----
LR: [0.009997010869495747]
---- EP [2/5] | BTCH [1956/3634] ||| train_loss = nan ----
LR: [0.009996968019456402]
---- EP [2/5] | BTCH [1957/3634] ||| train_loss = nan ----
LR: [0.009996924864558325]
---- EP [2/5] | BTCH [1958/3634] ||| train_loss = nan ----
LR: [0.009996881404804146]
---- EP [2/5] | BTCH [1959/3634] ||| train_loss = nan ----
LR: [0.009996837640196519]
---- EP [2/5] | BTCH [1960/3634] ||| train_loss = nan ----
LR: [0.009996793570738113]
---- EP [2/5] | BTCH [1961/3634] ||| train_loss = nan ----
LR: [0.009996749196431617]
---- EP [2/5] | BTCH [1962/3634] ||| train_loss = nan ----
LR: [0.009996704517279738]
---- EP [2/5] | BTCH [1963/3634] ||| train_loss = nan ----
LR: [0.009996659533285204]
---- EP [2/5] | BTCH [1964/3634] ||| train_loss = nan ----
LR: [0.009996614244450757]
---- EP [2/5] | BTCH [1965/3634] ||| train_loss = nan ----
LR: [0.009996568650779159]
---- EP [2/5] | BTCH [1966/3634] ||| train_loss = nan ----
LR: [0.009996522752273194]
---- EP [2/5] | BTCH [1967/3634] ||| train_loss = nan ----
LR: [0.009996476548935661]
---- EP [2/5] | BTCH [1968/3634] ||| train_loss = nan ----
LR: [0.00999643004076938]
---- EP [2/5] | BTCH [1969/3634] ||| train_loss = nan ----
LR: [0.009996383227777187]
---- EP [2/5] | BTCH [1970/3634] ||| train_loss = nan ----
LR: [0.009996336109961939]
---- EP [2/5] | BTCH [1971/3634] ||| train_loss = nan ----
LR: [0.009996288687326509]
---- EP [2/5] | BTCH [1972/3634] ||| train_loss = nan ----
LR: [0.009996240959873792]
---- EP [2/5] | BTCH [1973/3634] ||| train_loss = nan ----
LR: [0.0099961929276067]
---- EP [2/5] | BTCH [1974/3634] ||| train_loss = nan ----
LR: [0.009996144590528163]
---- EP [2/5] | BTCH [1975/3634] ||| train_loss = nan ----
LR: [0.009996095948641127]
---- EP [2/5] | BTCH [1976/3634] ||| train_loss = nan ----
LR: [0.009996047001948564]
---- EP [2/5] | BTCH [1977/3634] ||| train_loss = nan ----
LR: [0.00999599775045346]
---- EP [2/5] | BTCH [1978/3634] ||| train_loss = nan ----
LR: [0.009995948194158817]
---- EP [2/5] | BTCH [1979/3634] ||| train_loss = nan ----
LR: [0.009995898333067658]
---- EP [2/5] | BTCH [1980/3634] ||| train_loss = nan ----
LR: [0.009995848167183028]
---- EP [2/5] | BTCH [1981/3634] ||| train_loss = nan ----
LR: [0.009995797696507986]
---- EP [2/5] | BTCH [1982/3634] ||| train_loss = nan ----
LR: [0.009995746921045611]
---- EP [2/5] | BTCH [1983/3634] ||| train_loss = nan ----
LR: [0.009995695840799002]
---- EP [2/5] | BTCH [1984/3634] ||| train_loss = nan ----
LR: [0.009995644455771271]
---- EP [2/5] | BTCH [1985/3634] ||| train_loss = nan ----
LR: [0.00999559276596556]
---- EP [2/5] | BTCH [1986/3634] ||| train_loss = nan ----
LR: [0.009995540771385017]
---- EP [2/5] | BTCH [1987/3634] ||| train_loss = nan ----
LR: [0.009995488472032818]
---- EP [2/5] | BTCH [1988/3634] ||| train_loss = nan ----
LR: [0.00999543586791215]
---- EP [2/5] | BTCH [1989/3634] ||| train_loss = nan ----
LR: [0.009995382959026224]
---- EP [2/5] | BTCH [1990/3634] ||| train_loss = nan ----
LR: [0.009995329745378269]
---- EP [2/5] | BTCH [1991/3634] ||| train_loss = nan ----
VAL ||| loss = nan, psnr = nan, ssim = nan
LR: [0.009995276226971531]
---- EP [2/5] | BTCH [1992/3634] ||| train_loss = nan ----
LR: [0.009995222403809274]
---- EP [2/5] | BTCH [1993/3634] ||| train_loss = nan ----
LR: [0.009995168275894781]
---- EP [2/5] | BTCH [1994/3634] ||| train_loss = nan ----
LR: [0.009995113843231356]
---- EP [2/5] | BTCH [1995/3634] ||| train_loss = nan ----
LR: [0.00999505910582232]
---- EP [2/5] | BTCH [1996/3634] ||| train_loss = nan ----
LR: [0.009995004063671013]
---- EP [2/5] | BTCH [1997/3634] ||| train_loss = nan ----
LR: [0.009994948716780791]
---- EP [2/5] | BTCH [1998/3634] ||| train_loss = nan ----
LR: [0.009994893065155032]
---- EP [2/5] | BTCH [1999/3634] ||| train_loss = nan ----
LR: [0.00999483710879713]
---- EP [2/5] | BTCH [2000/3634] ||| train_loss = nan ----
LR: [0.009994780847710499]
---- EP [2/5] | BTCH [2001/3634] ||| train_loss = nan ----
LR: [0.009994724281898574]
---- EP [2/5] | BTCH [2002/3634] ||| train_loss = nan ----
LR: [0.009994667411364804]
---- EP [2/5] | BTCH [2003/3634] ||| train_loss = nan ----
LR: [0.009994610236112658]
---- EP [2/5] | BTCH [2004/3634] ||| train_loss = nan ----
LR: [0.009994552756145626]
---- EP [2/5] | BTCH [2005/3634] ||| train_loss = nan ----
LR: [0.009994494971467215]
---- EP [2/5] | BTCH [2006/3634] ||| train_loss = nan ----
LR: [0.009994436882080947]
---- EP [2/5] | BTCH [2007/3634] ||| train_loss = nan ----
LR: [0.009994378487990369]
---- EP [2/5] | BTCH [2008/3634] ||| train_loss = nan ----
LR: [0.009994319789199043]
---- EP [2/5] | BTCH [2009/3634] ||| train_loss = nan ----
LR: [0.009994260785710548]
---- EP [2/5] | BTCH [2010/3634] ||| train_loss = nan ----
LR: [0.009994201477528488]
---- EP [2/5] | BTCH [2011/3634] ||| train_loss = nan ----
LR: [0.009994141864656478]
---- EP [2/5] | BTCH [2012/3634] ||| train_loss = nan ----
LR: [0.009994081947098157]
---- EP [2/5] | BTCH [2013/3634] ||| train_loss = nan ----
LR: [0.009994021724857178]
---- EP [2/5] | BTCH [2014/3634] ||| train_loss = nan ----
LR: [0.009993961197937216]
---- EP [2/5] | BTCH [2015/3634] ||| train_loss = nan ----
LR: [0.009993900366341965]
---- EP [2/5] | BTCH [2016/3634] ||| train_loss = nan ----
LR: [0.009993839230075137]
---- EP [2/5] | BTCH [2017/3634] ||| train_loss = nan ----
LR: [0.009993777789140458]
---- EP [2/5] | BTCH [2018/3634] ||| train_loss = nan ----
LR: [0.00999371604354168]
---- EP [2/5] | BTCH [2019/3634] ||| train_loss = nan ----
LR: [0.009993653993282567]
---- EP [2/5] | BTCH [2020/3634] ||| train_loss = nan ----
LR: [0.00999359163836691]
---- EP [2/5] | BTCH [2021/3634] ||| train_loss = nan ----
LR: [0.009993528978798507]
---- EP [2/5] | BTCH [2022/3634] ||| train_loss = nan ----
LR: [0.009993466014581185]
---- EP [2/5] | BTCH [2023/3634] ||| train_loss = nan ----
LR: [0.009993402745718782]
---- EP [2/5] | BTCH [2024/3634] ||| train_loss = nan ----
LR: [0.009993339172215161]
---- EP [2/5] | BTCH [2025/3634] ||| train_loss = nan ----
LR: [0.0099932752940742]
---- EP [2/5] | BTCH [2026/3634] ||| train_loss = nan ----
LR: [0.009993211111299794]
---- EP [2/5] | BTCH [2027/3634] ||| train_loss = nan ----
LR: [0.00999314662389586]
---- EP [2/5] | BTCH [2028/3634] ||| train_loss = nan ----
LR: [0.009993081831866334]
---- EP [2/5] | BTCH [2029/3634] ||| train_loss = nan ----
LR: [0.009993016735215167]
---- EP [2/5] | BTCH [2030/3634] ||| train_loss = nan ----
LR: [0.00999295133394633]
---- EP [2/5] | BTCH [2031/3634] ||| train_loss = nan ----
LR: [0.009992885628063816]
---- EP [2/5] | BTCH [2032/3634] ||| train_loss = nan ----
LR: [0.00999281961757163]
---- EP [2/5] | BTCH [2033/3634] ||| train_loss = nan ----
LR: [0.0099927533024738]
---- EP [2/5] | BTCH [2034/3634] ||| train_loss = nan ----
LR: [0.009992686682774374]
---- EP [2/5] | BTCH [2035/3634] ||| train_loss = nan ----
LR: [0.009992619758477414]
---- EP [2/5] | BTCH [2036/3634] ||| train_loss = nan ----
LR: [0.009992552529587006]
---- EP [2/5] | BTCH [2037/3634] ||| train_loss = nan ----
LR: [0.009992484996107248]
---- EP [2/5] | BTCH [2038/3634] ||| train_loss = nan ----
LR: [0.009992417158042263]
---- EP [2/5] | BTCH [2039/3634] ||| train_loss = nan ----
LR: [0.009992349015396187]
---- EP [2/5] | BTCH [2040/3634] ||| train_loss = nan ----
LR: [0.00999228056817318]
---- EP [2/5] | BTCH [2041/3634] ||| train_loss = nan ----
LR: [0.009992211816377416]
---- EP [2/5] | BTCH [2042/3634] ||| train_loss = nan ----
LR: [0.009992142760013091]
---- EP [2/5] | BTCH [2043/3634] ||| train_loss = nan ----
LR: [0.009992073399084415]
---- EP [2/5] | BTCH [2044/3634] ||| train_loss = nan ----
LR: [0.009992003733595625]
---- EP [2/5] | BTCH [2045/3634] ||| train_loss = nan ----
LR: [0.009991933763550967]
---- EP [2/5] | BTCH [2046/3634] ||| train_loss = nan ----
LR: [0.00999186348895471]
---- EP [2/5] | BTCH [2047/3634] ||| train_loss = nan ----
LR: [0.009991792909811144]
---- EP [2/5] | BTCH [2048/3634] ||| train_loss = nan ----
LR: [0.009991722026124571]
---- EP [2/5] | BTCH [2049/3634] ||| train_loss = nan ----
LR: [0.00999165083789932]
---- EP [2/5] | BTCH [2050/3634] ||| train_loss = nan ----
LR: [0.00999157934513973]
---- EP [2/5] | BTCH [2051/3634] ||| train_loss = nan ----
LR: [0.009991507547850166]
---- EP [2/5] | BTCH [2052/3634] ||| train_loss = nan ----
LR: [0.009991435446035007]
---- EP [2/5] | BTCH [2053/3634] ||| train_loss = nan ----
LR: [0.00999136303969865]
---- EP [2/5] | BTCH [2054/3634] ||| train_loss = nan ----
LR: [0.009991290328845517]
---- EP [2/5] | BTCH [2055/3634] ||| train_loss = nan ----
LR: [0.009991217313480039]
---- EP [2/5] | BTCH [2056/3634] ||| train_loss = nan ----
LR: [0.009991143993606674]
---- EP [2/5] | BTCH [2057/3634] ||| train_loss = nan ----
LR: [0.009991070369229893]
---- EP [2/5] | BTCH [2058/3634] ||| train_loss = nan ----
LR: [0.009990996440354189]
---- EP [2/5] | BTCH [2059/3634] ||| train_loss = nan ----
LR: [0.009990922206984072]
---- EP [2/5] | BTCH [2060/3634] ||| train_loss = nan ----
LR: [0.009990847669124071]
---- EP [2/5] | BTCH [2061/3634] ||| train_loss = nan ----
LR: [0.009990772826778734]
---- EP [2/5] | BTCH [2062/3634] ||| train_loss = nan ----
LR: [0.009990697679952625]
---- EP [2/5] | BTCH [2063/3634] ||| train_loss = nan ----
LR: [0.00999062222865033]
---- EP [2/5] | BTCH [2064/3634] ||| train_loss = nan ----
LR: [0.009990546472876454]
---- EP [2/5] | BTCH [2065/3634] ||| train_loss = nan ----
LR: [0.009990470412635618]
---- EP [2/5] | BTCH [2066/3634] ||| train_loss = nan ----
Traceback (most recent call last):
  File "/home/jupyter/vsr/script.py", line 142, in <module>
    train(model, criterion, optimiser, 
  File "/home/jupyter/vsr/script.py", line 56, in train
    loss = criterion(y, upsampled_vids)
  File "/home/jupyter/vsr/losses.py", line 77, in criterion
    return w_c*charbonnier_criterion(upsampled_vids, hq_vids) + w_f*flow_criterion(upsampled_vids, hq_vids)
  File "/home/jupyter/vsr/losses.py", line 68, in criterion
    return floss(upsampled_vids, hq_vids)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jupyter/vsr/losses.py", line 41, in forward
    flow_upsampled = checkpoint.checkpoint(self.chkpoint, ten1, ten2)
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 249, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
  File "/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py", line 107, in forward
    outputs = run_function(*args)
  File "/home/jupyter/vsr/losses.py", line 33, in chkpoint
    return self.net(*self.t(ten1, ten2), num_flow_updates = 1)[-1]
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_presets.py", line 201, in forward
    img1 = F.normalize(img1, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
  File "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 363, in normalize
    return F_t.normalize(tensor, mean=mean, std=std, inplace=inplace)
  File "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_tensor.py", line 920, in normalize
    mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 1332808) is killed by signal: Terminated. 
